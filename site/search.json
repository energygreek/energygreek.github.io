{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"Welcome","text":"<p>A self-host blog, build with mkdocs, compatible to Obsidian and Foam.   - Status Page - Email to Me </p>","path":["Welcome"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/","level":1,"title":"计算函数x^2在区间0到1之间的积分","text":"<p>要计算函数f(x)=x²在区间[0,1]上的定积分，我们可以使用积分的基本公式：</p> <p>∫(从0到1) x² dx = [x³/3]从0到1 = (1³/3) - (0³/3) = ⅓</p> <p>因此，x²在0到1区间内的积分结果是⅓。这个结果表示函数曲线与x轴在该区间内围成的面积为⅓个平方单位。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#x2","level":1,"title":"函数x^2的导函数","text":"<p>函数f(x) = x²的导函数可以通过求导法则计算：</p> <p>使用幂函数求导法则：d/dx(xⁿ) = n·xⁿ⁻¹</p> <p>因此： f'(x) = d/dx(x²) = 2x</p> <p>所以，x²的导函数是2x。这个结果表示原函数在任意点x处的瞬时变化率。</p> <p>x²的导数2x表示什么？</p> <p>x²的二阶导数是什么？</p> <p>再给我几个类似x²的导数例子</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_1","level":1,"title":"导函数和积分函数的关系","text":"","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_2","level":2,"title":"第一部分：导数和不定积分的互逆关系","text":"<ol> <li> <p>‌不定积分是导数的“逆运算”：‌</p> </li> <li> <p>如果 <code>F(x)</code> 是函数 <code>f(x)</code> 的一个‌原函数（或称反导数）‌，即 <code>F'(x) = f(x)</code>，那么函数 <code>f(x)</code> 的‌不定积分‌定义为所有原函数的集合，表示为：</p> <p><pre><code>textCopy Code\n\n∫ f(x) dx = F(x) + C\n</code></pre>    * 这里的 <code>C</code> 是任意常数，称为积分常数。因为一个函数的导数相同，其原函数之间只相差一个常数。    * ‌核心：‌ 求不定积分的过程，本质上就是寻找一个函数 <code>F(x)</code>，使得它的导数 <code>F'(x)</code> 等于被积函数 <code>f(x)</code>。‌不定积分“撤销”了导数的效果。‌ 2. ‌导数是不定积分的导数：‌</p> </li> <li> <p>如果 <code>F(x)</code> 是 <code>f(x)</code> 的一个原函数（或者说 <code>∫ f(x) dx = F(x) + C</code>），那么对这个不定积分结果求导，就会得到原来的被积函数：</p> <p><pre><code>textCopy Code\n\nd/dx [ ∫ f(x) dx ] = d/dx [F(x) + C] = F'(x) + 0 = f(x)\n</code></pre>    * ‌核心：‌ 对一个函数先积分再求导，结果会回到原点函数（被积函数）。导数“撤销”了不定积分的效果（常数 <code>C</code> 在求导时会消失）。</p> </li> </ol>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_3","level":3,"title":"总结第一部分（不定积分层面）","text":"<p>‌导数和不定积分是互逆的运算（除了相差一个常数）。‌</p> <ul> <li><code>∫ F'(x) dx = F(x) + C</code></li> <li><code>d/dx [ ∫ f(x) dx ] = f(x)</code></li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#-","level":2,"title":"第二部分：导数与定积分的关系 - 微积分基本定理的核心","text":"<p>这是微积分基本定理最具威力、最实用的部分，它建立了导数和定积分（求面积）的直接联系。</p> <ol> <li>‌构造累积函数：‌ 给定一个在区间 <code>[a, b]</code> 上连续的函数 <code>f(t)</code>。定义一个新函数 <code>F(x)</code>，它在区间 <code>[a, x]</code> 上计算 <code>f(t)</code> 曲线下的面积（<code>x</code> 在 <code>[a, b]</code> 之间）：</li> </ol> <pre><code>textCopy Code\n\nF(x) = ∫ₐˣ f(t) dt\n</code></pre> <ul> <li>这个函数 <code>F(x)</code> 被称为 <code>f(x)</code> 的‌累积函数‌或‌面积函数‌。它表示从固定起点 <code>a</code> 到可变终点 <code>x</code> 之间，曲线 <code>f(t)</code> 下的面积。</li> <li>‌关键结论：‌ 微积分基本定理指出：</li> </ul> <pre><code>textCopy Code\n\nF'(x) = d/dx [ ∫ₐˣ f(t) dt ] = f(x)\n</code></pre> <ul> <li>‌解释：‌ 累积函数 <code>F(x)</code>（即从 <code>a</code> 到 <code>x</code> 的定积分）的‌导数‌，恰好等于积分号下的原函数 <code>f</code> 在点 <code>x</code> 处的值 <code>f(x)</code>。</li> <li>‌几何意义：‌ 函数 <code>F(x)</code> 在某一点 <code>x</code> 处的变化率（导数），恰好等于曲线 <code>f(t)</code> 在该点 <code>x</code> 处的高度 <code>f(x)</code>。这意味着累积面积的增长速率就等于曲线的高度。</li> <li> <p>‌计算定积分的强大工具：‌ 这个定理的另一个等价表述提供了计算定积分的革命性方法：</p> </li> <li> <p>如果 <code>F(x)</code> 是 <code>f(x)</code> 在区间 <code>[a, b]</code> 上的‌任意一个‌原函数（即 <code>F'(x) = f(x)</code>），那么：</p> <p><pre><code>textCopy Code\n\n∫ₐᵇ f(x) dx = F(b) - F(a)\n</code></pre>    * ‌意义：‌ 要计算函数 <code>f(x)</code> 从 <code>a</code> 到 <code>b</code> 的定积分（曲线下的面积），只需要找到它的任何一个原函数 <code>F(x)</code>，然后计算该原函数在上限 <code>b</code> 的值减去在下限 <code>a</code> 的值。‌这避免了用极限定义求定积分所需的复杂计算（黎曼和）。‌    * 通常记作： <code>[F(x)]ₐᵇ</code> 或 <code>F(x) |ₐᵇ</code> 或 <code>F(b) - F(a)</code>。</p> </li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_4","level":3,"title":"用你的例子验证","text":"<ul> <li>‌导函数：‌ 你计算了 <code>f(x) = x²</code> 的导函数是 <code>f'(x) = 2x</code>。</li> <li>‌不定积分：‌</li> <li>根据第一部分，<code>2x</code> 的不定积分应该是 <code>x² + C</code>（因为 <code>d/dx (x² + C) = 2x</code>）。</li> <li><code>x²</code> 的不定积分是 <code>∫ x² dx = x³/3 + C</code>（因为 <code>d/dx (x³/3 + C) = x²</code>）。这验证了互逆关系。</li> <li>‌定积分（与导数的关系 - 第二部分）：‌</li> <li>你之前计算了 <code>∫₀¹ x² dx</code>。</li> <li>根据微积分基本定理第二部分：<ol> <li>找到 <code>f(x) = x²</code> 的一个原函数 <code>F(x) = x³/3</code>。</li> <li>计算 <code>F(1) - F(0) = (1³/3) - (0³/3) = 1/3 - 0 = 1/3</code>。</li> </ol> </li> <li>这和你之前直接计算的结果完全一致，体现了定理的强大实用性。</li> <li>‌累积函数与导数：‌</li> <li>定义累积函数 <code>F(x) = ∫₀ˣ t² dt</code>。</li> <li>根据微积分基本定理第二部分，<code>F'(x) = d/dx [ ∫₀ˣ t² dt ] = x²</code>。</li> <li>我们也知道 <code>∫₀ˣ t² dt = [t³/3]₀ˣ = x³/3</code>。</li> <li>对这个结果求导验证： <code>d/dx (x³/3) = x²</code>。完美符合定理结论 <code>F'(x) = f(x)</code>。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_5","level":2,"title":"总结","text":"<p>微积分基本定理揭示了导函数和积分函数之间深刻的、互逆的统一关系：</p> <ol> <li>‌反导数关系：‌ 不定积分是求导的逆运算（相差一个常数）。</li> <li>‌导数描述累积变化率：‌ 定积分（累积函数 <code>∫ₐˣ f(t) dt</code>）的导数等于被积函数 <code>f(x)</code>。导数描述了累积量（如面积）随上限变化的瞬时速率。</li> <li>‌原函数计算定积分：‌ 定积分 <code>∫ₐᵇ f(x) dx</code> 的值等于被积函数 <code>f(x)</code> 的任何一个原函数 <code>F(x)</code> 在积分上限 <code>b</code> 的值减去在下限 <code>a</code> 的值（<code>F(b) - F(a)</code>）。这是计算定积分最有效的方法。</li> </ol> <p>简而言之，‌微分（求导）和积分（特别是作为累计算过程的定积分）是互为逆运算的统一体‌。这个关系是微积分成为强大数学工具的基础，使我们能够通过研究变化率（导数）来理解累积量（积分），反之亦然。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_6","level":1,"title":"导数和定积分的关系图","text":"<p>以下是导数和定积分关系的可视化总结，结合几何意义与微积分基本定理的核心要点：</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_7","level":3,"title":"一、几何关系图解","text":"<ol> <li>‌导数→函数变化率‌    导数为函数曲线在某点的切线斜率（瞬时变化率），反映函数增减趋势。例如，若导数为正，原函数在该区间递增‌12。</li> <li>‌定积分→累积面积‌    定积分表示函数曲线与x轴围成的有向面积（上方为正，下方为负），是导数的“逆向累积”过程‌34。</li> </ol>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_8","level":3,"title":"二、微积分基本定理的核心关联","text":"<ol> <li>‌第一定理（导数与积分互逆）‌</li> <li>若 <code>F(x) = ∫ₐˣ f(t) dt</code>，则 <code>F'(x) = f(x)</code>，即定积分的导数等于被积函数‌45。</li> <li>‌几何意义‌：面积函数 <code>F(x)</code> 的瞬时变化率等于曲线高度 <code>f(x)</code>‌15。</li> <li>‌第二定理（计算定积分）‌</li> <li>若 <code>F(x)</code> 是 <code>f(x)</code> 的原函数，则 <code>∫ₐᵇ f(x) dx = F(b) - F(a)</code>，通过原函数差值求面积‌46。</li> </ol>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_9","level":3,"title":"三、动态关系示例","text":"<ul> <li>‌导数→积分‌：已知速度 <code>v(t)</code>（位移的导数），通过积分 <code>∫v(t) dt</code> 可求位移‌46。</li> <li>‌积分→导数‌：已知面积函数 <code>F(x)</code>，求导可得曲线高度 <code>f(x)</code>‌57。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_10","level":3,"title":"四、关键对比总结","text":"‌概念‌ ‌数学表达‌ ‌几何意义‌ ‌物理应用‌ 导数 <code>f'(x) = dy/dx</code> 切线斜率 瞬时速度、加速度 定积分 <code>∫ₐᵇ f(x) dx</code> 曲线下净面积 总位移、功 互逆关系 <code>d/dx [∫ₐˣ f(t) dt] = f(x)</code> 面积变化率=曲线高度 速度与位移的相互转化‌46 <p>通过以上图表与关系对比，可清晰理解导数与定积分如何通过微积分基本定理实现动态统一。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_11","level":1,"title":"曲线高度指的是什么","text":"<p>在微积分的几何解释中，‌曲线高度‌指的是函数 y=f(x)y = f(x)y=f(x) 在某一特定点 xxx 处的函数值 f(x)f(x)f(x)，也就是该点在坐标系中相对于 xxx-轴的垂直距离。以下是具体说明：</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#1","level":3,"title":"‌1. 曲线高度的定义‌","text":"<ul> <li>‌数学表达‌：对于函数 y=f(x)y = f(x)y=f(x)，在 x=ax = ax=a 处的曲线高度就是 f(a)f(a)f(a)。</li> <li>‌几何意义‌：</li> <li>在函数图像上，点 (a,f(a))(a, f(a))(a,f(a)) 到 xxx-轴的垂直距离为 ∣f(a)∣|f(a)|∣f(a)∣（如图1）。</li> <li>若 f(a)&gt;0f(a) &gt; 0f(a)&gt;0，高度为正（曲线位于 xxx-轴上方）；</li> <li>若 f(a)&lt;0f(a) &lt; 0f(a)&lt;0，高度为负（曲线位于 xxx-轴下方）。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#2","level":3,"title":"‌2. 与导数和积分的关系‌","text":"","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#1_1","level":4,"title":"‌（1）导数视角‌","text":"<ul> <li>导数 f′(x)f'(x)f′(x) 表示曲线在某点的‌切线斜率‌，而 f(x)f(x)f(x) 是该点的‌纵坐标值‌（高度）。</li> <li>‌动态关联‌：</li> <li>若将 f(x)f(x)f(x) 视为位置函数，f′(x)f'(x)f′(x) 是其瞬时速度（高度的变化率）。</li> <li>例如：自由落体中，高度 h(t)h(t)h(t) 的导数 h′(t)h'(t)h′(t) 是速度 v(t)v(t)v(t)。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#2_1","level":4,"title":"‌（2）积分视角‌","text":"<ul> <li>‌定积分‌ ∫abf(x)dx\\int_a^b f(x) dx∫ab​f(x)dx 是曲线 y=f(x)y = f(x)y=f(x) 与 xxx-轴之间的‌有向面积‌，其大小取决于曲线在各点的高度 f(x)f(x)f(x)（如图2）。</li> <li>‌微积分基本定理‌：</li> <li>面积函数 F(x)=∫axf(t)dtF(x) = \\int_a^x f(t) dtF(x)=∫ax​f(t)dt 的导数 F′(x)=f(x)F'(x) = f(x)F′(x)=f(x)，即面积变化率等于曲线当前高度‌12。</li> <li>‌几何解释‌：当 xxx 向右移动时，F(x)F(x)F(x) 的增加速率由 f(x)f(x)f(x) 的高度直接决定（如图3）。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#3","level":3,"title":"‌3. 物理意义中的“高度”‌","text":"<ul> <li>‌位移与速度‌：若 f(t)f(t)f(t) 表示物体在时间 ttt 时的高度，则 f′(t)f'(t)f′(t) 是速度（高度的瞬时变化率），而 ∫abf′(t)dt=f(b)−f(a)\\int_a^b f'(t) dt = f(b) - f(a)∫ab​f′(t)dt=f(b)−f(a) 是高度变化量。</li> <li>‌其他应用‌：</li> <li>经济学中，总收益曲线的“高度”是收益值，导数是边际收益。</li> <li>概率中，概率密度函数 f(x)f(x)f(x) 的“高度”反映概率分布的密度。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#4","level":3,"title":"‌4. 常见误区澄清‌","text":"<ul> <li>‌高度 ≠ 斜率‌：</li> <li>高度是函数值 f(x)f(x)f(x)（纵坐标），而斜率是导数 f′(x)f'(x)f′(x)（切线的倾斜程度）。</li> <li>例如：抛物线 y=x2y = x^2y=x2 在 x=1x = 1x=1 处高度为 111，斜率为 222。</li> <li>‌负高度的意义‌：</li> <li>当 f(x)&lt;0f(x) &lt; 0f(x)&lt;0，曲线位于 xxx-轴下方，定积分计算时会抵消正面积（如图4）。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_12","level":3,"title":"‌总结图示‌","text":"‌概念‌ ‌数学表达‌ ‌曲线高度的角色‌ 函数值 y=f(x)y = f(x)y=f(x)","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_13","level":1,"title":"导数和不定积分的关系图","text":"<p>以下是导数和不定积分关系的可视化解析，结合几何意义与微积分基本定理的核心要点：</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_14","level":3,"title":"一、核心关系图解","text":"<ol> <li>‌导数→函数变化率‌    导数为函数曲线在某点的切线斜率（瞬时变化率），反映函数增减趋势。例如，若导数为正，原函数在该区间递增‌12。</li> <li>‌不定积分→原函数族‌    不定积分是导数的逆运算，表示所有原函数的集合（相差常数C）。几何上对应斜率相同的曲线族‌34。</li> </ol>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_15","level":3,"title":"二、微积分基本定理的动态关联","text":"<ol> <li> <p>‌互逆性‌</p> </li> <li> <p>导数到积分：若 <code>F(x) = ∫f(x)dx</code>，则 <code>F'(x) = f(x)</code>，即积分后求导恢复原函数‌35。</p> </li> <li>积分到导数：若 <code>F'(x) = f(x)</code>，则 <code>∫f(x)dx = F(x) + C</code>，即导数的积分得到原函数族‌78。</li> <li> <p>‌几何意义‌</p> </li> <li> <p>导数（切线斜率）决定原函数的增减速度；</p> </li> <li>不定积分（曲线族）的每一条曲线在相同x处的斜率相等‌19。</li> </ol>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_16","level":3,"title":"三、关键对比总结","text":"‌概念‌ ‌数学表达‌ ‌几何意义‌ ‌动态关系‌ 导数 <code>f'(x) = dy/dx</code> 切线斜率（变化率） 控制原函数的瞬时变化‌29 不定积分 <code>∫f(x)dx = F(x) + C</code> 平行曲线族（斜率相同） 逆向还原导数对应的函数‌34 互逆操作 <code>d/dx[∫f(x)dx] = f(x)</code> 斜率→曲线 / 曲线→斜率 构成微积分基本定理‌56 <p>通过以上图表与动态演示，可直观理解导数与不定积分如何通过斜率与面积的互逆性实现统一‌110。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_17","level":1,"title":"能不能认为导数是点，不定积分是线，定积分是面？","text":"<p>以下是关于导数、不定积分与定积分几何意义的层级关系分析，结合数学本质与几何直观的详细说明：</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_18","level":3,"title":"一、‌导数是“点”属性‌（瞬时性）","text":"<ol> <li>‌数学定义‌    导数 f′(x)f'(x)f′(x) 是函数在某一点 xxx 处的‌瞬时变化率‌，通过极限 lim⁡Δx→0f(x+Δx)−f(x)Δx\\lim_{\\Delta x \\to 0} \\frac{f(x+\\Delta x)-f(x)}{\\Delta x}limΔx→0​Δxf(x+Δx)−f(x)​ 定义，反映函数在该点的局部行为‌12。</li> <li>‌几何意义‌</li> <li>导数对应函数图像上某点的‌切线斜率‌，是曲线在该点的线性近似‌45。</li> <li>‌物理类比‌：如瞬时速度是位移-时间曲线某点的切线斜率‌26。</li> <li>‌局限性‌：仅描述单点特性，无法直接体现整体累积效应‌13。</li> </ol>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_19","level":3,"title":"二、‌不定积分是“线”属性‌（曲线族）","text":"<ol> <li>‌数学定义‌    不定积分 ∫f(x)dx=F(x)+C\\int f(x)dx = F(x) + C∫f(x)dx=F(x)+C 是导数的逆运算，表示所有原函数的集合（相差常数 CCC）‌78。</li> <li>‌几何意义‌</li> <li>不定积分对应‌一族平行曲线‌，这些曲线在相同横坐标处的切线斜率相同（即导数相同），仅通过纵向平移（CCC 的变化）区分‌810。</li> <li>‌物理类比‌：已知速度 v(t)v(t)v(t) 求位移 s(t)s(t)s(t)，需通过初始条件确定具体曲线（如初始位置）‌711。</li> </ol>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_20","level":3,"title":"三、‌定积分是“面”属性‌（累积性）","text":"<ol> <li>‌数学定义‌    定积分 ∫abf(x)dx\\int_a^b f(x)dx∫ab​f(x)dx 是函数在区间 [a,b][a,b][a,b] 上的黎曼和极限，表示有向面积‌1213。</li> <li>‌几何意义‌</li> <li>当 f(x)≥0f(x) \\geq 0f(x)≥0，定积分是曲线与 xxx-轴围成的面积；若 f(x)f(x)f(x) 有正有负，则为净面积（正负抵消）‌1314。</li> <li>‌物理类比‌：变速运动的位移是速度-时间曲线下的面积‌1216。</li> </ol>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_21","level":3,"title":"四、三者的层级关系总结","text":"‌概念‌ ‌数学对象‌ ‌几何对应‌ ‌关键特性‌ 导数 点属性（f′(x)f'(x)f′(x)） 切线斜率 瞬时性、局部描述‌13 不定积分 线属性（F(x)+CF(x)+CF(x)+C） 平行曲线族 全局性、需初始条件‌89 定积分 面属性（∫abf(x)dx\\int_a^b f(x)dx∫ab​f(x)dx） 有向面积 累积性、与区间相关‌1314","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_22","level":3,"title":"五、‌这种比喻的合理性与局限性‌","text":"<ol> <li>‌合理性‌</li> <li>直观体现了从‌局部（点）→整体（线/面）‌的数学层次：导数刻画点的变化，积分累积为线或面‌1819。</li> <li>符合微积分基本定理：定积分通过原函数（不定积分）计算，而原函数由导数逆向求得‌813。</li> <li>‌局限性‌</li> <li>‌导数并非孤立点‌：其定义依赖邻域极限，需函数在该点附近有定义‌12。</li> <li>‌积分不限于几何量‌：定积分可表示物理量（如功、概率），不定积分可解微分方程，超出几何范畴‌712。</li> </ol> <p>综上，用“点、线、面”比喻导数、不定积分和定积分的几何特性是直观且有效的，但需注意数学定义的完整性和应用场景的广泛性‌1819。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#x2_1","level":1,"title":"列举原函数x^2的不定积分","text":"","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#x2x2x2","level":3,"title":"‌原函数 x2x^2x2 的不定积分‌","text":"","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#1_2","level":4,"title":"‌1. 基本计算‌","text":"<p>不定积分是导数的逆运算，因此求 x2x^2x2 的不定积分，即寻找一个函数 F(x)F(x)F(x)，使得：</p> <p>F′(x)=x2F'(x) = x^2F′(x)=x2</p> <p>根据幂函数积分公式：</p> <p>∫xn dx=xn+1n+1+C(n≠−1)\\int x^n \\, dx = \\frac{x^{n+1}}{n+1} + C \\quad (n \\neq -1)∫xndx=n+1xn+1​+C(n=−1)</p> <p>对于 n=2n = 2n=2：</p> <p>∫x2 dx=x33+C\\int x^2 \\, dx = \\frac{x^{3}}{3} + C∫x2dx=3x3​+C</p> <p>其中，CCC 是‌积分常数‌（因为导数会消去常数项）。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#2_2","level":4,"title":"‌2. 验证‌","text":"<p>对 F(x)=x33+CF(x) = \\frac{x^3}{3} + CF(x)=3x3​+C 求导：</p> <p>F′(x)=ddx(x33+C)=x2+0=x2F'(x) = \\frac{d}{dx} \\left( \\frac{x^3}{3} + C \\right) = x^2 + 0 = x^2F′(x)=dxd​(3x3​+C)=x2+0=x2</p> <p>验证正确。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#3_1","level":4,"title":"‌3. 几何意义‌","text":"<ul> <li>‌不定积分‌ ∫x2 dx=x33+C\\int x^2 \\, dx = \\frac{x^3}{3} + C∫x2dx=3x3​+C 表示一族‌三次抛物线‌，它们在任意点 xxx 处的斜率均为 x2x^2x2（即导数相同）。</li> <li>‌积分常数 CCC‌ 决定了曲线的垂直平移（如 C=0C=0C=0、C=1C=1C=1、C=−2C=-2C=−2 等不同曲线）。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#4_1","level":4,"title":"‌4. 示例曲线族‌","text":"CCC 取值 原函数表达式 曲线特征 C=0C = 0C=0 F(x)=x33F(x) = \\frac{x^3}{3}F(x)=3x3​ 通过原点 (0,0)(0,0)(0,0) C=1C = 1C=1 F(x)=x33+1F(x) = \\frac{x^3}{3} + 1F(x)=3x3​+1 整体上移 1 单位 C=−2C = -2C=−2 F(x)=x33−2F(x) = \\frac{x^3}{3} - 2F(x)=3x3​−2 整体下移 2 单位","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#5","level":4,"title":"‌5. 与定积分的关系‌","text":"<p>若计算定积分 ∫abx2 dx\\int_a^b x^2 \\, dx∫ab​x2dx，可直接利用原函数：</p> <p>∫abx2 dx=x33∣ab=b33−a33\\int_a^b x^2 \\, dx = \\left. \\frac{x^3}{3} \\right|_a^b = \\frac{b^3}{3} - \\frac{a^3}{3}∫ab​x2dx=3x3​​ab​=3b3​−3a3​</p> <p>‌几何意义‌：这是抛物线 y=x2y = x^2y=x2 在区间 [a,b][a,b][a,b] 下与 xxx-轴围成的面积（若 a≤ba \\leq ba≤b 且 x2≥0x^2 \\geq 0x2≥0）。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_23","level":3,"title":"‌总结‌","text":"<ul> <li>‌不定积分‌：∫x2 dx=x33+C\\int x^2 \\, dx = \\frac{x^3}{3} + C∫x2dx=3x3​+C（一族曲线）。</li> <li>‌定积分‌：∫abx2 dx=b3−a33\\int_a^b x^2 \\, dx = \\frac{b^3 - a^3}{3}∫ab​x2dx=3b3−a3​（具体面积值）。</li> <li>‌关键点‌：积分常数 CCC 反映原函数的不唯一性，而导数运算会消除常数项。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#x33","level":1,"title":"列出导函数x^3/3的不定积分","text":"","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#x33fracx333x3","level":3,"title":"‌导函数 x33\\frac{x^3}{3}3x3​ 的不定积分‌","text":"","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#1_3","level":4,"title":"‌1. 基本计算‌","text":"<p>不定积分是导数的逆运算，因此求 x33\\frac{x^3}{3}3x3​ 的不定积分，即寻找一个函数 F(x)F(x)F(x)，使得：</p> <p>F′(x)=x33F'(x) = \\frac{x^3}{3}F′(x)=3x3​</p> <p>根据幂函数积分公式：</p> <p>∫xn dx=xn+1n+1+C(n≠−1)\\int x^n \\, dx = \\frac{x^{n+1}}{n+1} + C \\quad (n \\neq -1)∫xndx=n+1xn+1​+C(n=−1)</p> <p>对于 x33\\frac{x^3}{3}3x3​，可以写成：</p> <p>∫x33 dx=13∫x3 dx=13⋅x44+C=x412+C\\int \\frac{x^3}{3} \\, dx = \\frac{1}{3} \\int x^3 \\, dx = \\frac{1}{3} \\cdot \\frac{x^{4}}{4} + C = \\frac{x^4}{12} + C∫3x3​dx=31​∫x3dx=31​⋅4x4​+C=12x4​+C</p> <p>其中，CCC 是‌积分常数‌（因为导数会消去常数项）。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#2_3","level":4,"title":"‌2. 验证‌","text":"<p>对 F(x)=x412+CF(x) = \\frac{x^4}{12} + CF(x)=12x4​+C 求导：</p> <p>F′(x)=ddx(x412+C)=4x312+0=x33F'(x) = \\frac{d}{dx} \\left( \\frac{x^4}{12} + C \\right) = \\frac{4x^3}{12} + 0 = \\frac{x^3}{3}F′(x)=dxd​(12x4​+C)=124x3​+0=3x3​</p> <p>验证正确。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#3_2","level":4,"title":"‌3. 几何意义‌","text":"<ul> <li>‌不定积分‌ ∫x33 dx=x412+C\\int \\frac{x^3}{3} \\, dx = \\frac{x^4}{12} + C∫3x3​dx=12x4​+C 表示一族‌四次曲线‌，它们在任意点 xxx 处的斜率均为 x33\\frac{x^3}{3}3x3​（即导数相同）。</li> <li>‌积分常数 CCC‌ 决定了曲线的垂直平移（如 C=0C=0C=0、C=1C=1C=1、C=−2C=-2C=−2 等不同曲线）。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#4_2","level":4,"title":"‌4. 示例曲线族‌","text":"CCC 取值 原函数表达式 曲线特征 C=0C = 0C=0 F(x)=x412F(x) = \\frac{x^4}{12}F(x)=12x4​ 通过原点 (0,0)(0,0)(0,0) C=1C = 1C=1 F(x)=x412+1F(x) = \\frac{x^4}{12} + 1F(x)=12x4​+1 整体上移 1 单位 C=−2C = -2C=−2 F(x)=x412−2F(x) = \\frac{x^4}{12} - 2F(x)=12x4​−2 整体下移 2 单位","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#5_1","level":4,"title":"‌5. 与定积分的关系‌","text":"<p>若计算定积分 ∫abx33 dx\\int_a^b \\frac{x^3}{3} \\, dx∫ab​3x3​dx，可直接利用原函数：</p> <p>∫abx33 dx=x412∣ab=b412−a412\\int_a^b \\frac{x^3}{3} \\, dx = \\left. \\frac{x^4}{12} \\right|_a^b = \\frac{b^4}{12} - \\frac{a^4}{12}∫ab​3x3​dx=12x4​​ab​=12b4​−12a4​</p> <p>‌几何意义‌：这是曲线 y=x33y = \\frac{x^3}{3}y=3x3​ 在区间 [a,b][a,b][a,b] 下与 xxx-轴围成的面积（若 x33≥0\\frac{x^3}{3} \\geq 03x3​≥0）。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_24","level":3,"title":"‌总结‌","text":"<ul> <li>‌不定积分‌：( \\int \\frac{x^3}{3} , dx = \\frac{x^4}{12}</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_25","level":1,"title":"原函数是指中学里学习的函数吗？","text":"<p>原函数（Primitive Function）与中学阶段学习的函数概念既有联系又有本质区别，具体分析如下：</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#1_4","level":3,"title":"‌1. 定义对比‌","text":"<ul> <li>‌中学函数‌   初中阶段将函数定义为“变量间的对应关系”，强调因变量 yyy 随自变量 xxx 变化的唯一性16。高中进一步抽象为集合间的映射关系 y=f(x)y=f(x)y=f(x)，但未涉及导数和积分16。</li> <li>‌原函数‌   原函数是微积分中的概念，指对于给定函数 f(x)f(x)f(x)，若存在可导函数 F(x)F(x)F(x) 满足 F′(x)=f(x)F'(x)=f(x)F′(x)=f(x)，则 F(x)F(x)F(x) 称为 f(x)f(x)f(x) 的原函数23。其核心是‌导数的逆运算‌，与中学函数的定义无直接关联68。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#2_4","level":3,"title":"‌2. 学习阶段与知识基础‌","text":"<ul> <li>‌中学函数‌   属于初等数学范畴，研究函数的定义、图像、性质（如单调性、奇偶性）及具体类型（一次、二次、指数函数等）16。</li> <li>‌原函数‌   属于高等数学内容，需以‌导数‌为基础，是积分学的核心概念，通常在大学阶段系统学习79。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#3_3","level":3,"title":"‌3. 典型应用差异‌","text":"‌对比项‌ ‌中学函数‌ ‌原函数‌ ‌核心问题‌ 求解析式、画图像、解方程 求导数的逆运算（如计算面积、解微分方程）912 ‌工具依赖‌ 代数运算、图像分析 微积分（极限、导数、积分法则）78 ‌实例‌ y=2x+1y=2x+1y=2x+1 的图像与性质 ∫2x dx=x2+C\\int 2x \\, dx = x^2 + C∫2xdx=x2+C 的求解810","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#4_3","level":3,"title":"‌4. 联系与进阶‌","text":"<ul> <li>‌衔接点‌：原函数的计算常以中学函数（如多项式、三角函数）为被积对象710。</li> <li>‌本质区别‌：原函数的存在性依赖于函数的‌连续性‌和‌可导性‌，而中学函数仅关注对应关系本身36。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_26","level":3,"title":"‌总结‌","text":"<p>原函数并非中学函数的直接延伸，而是微积分中基于导数的新概念24。两者分属不同的数学层次，前者是后者的必要基础，但研究目标和工具截然不同616。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#fx","level":1,"title":"F′(x)表示什么","text":"","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#fx_1","level":3,"title":"‌f′(x) 的数学含义‌","text":"","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#1_5","level":4,"title":"‌1. 基本定义‌","text":"<p>f′(x) 表示函数 f(x) 的‌导函数‌（简称导数），用于描述原函数 f(x) 在每一点处的瞬时变化率或斜率12。其严格定义为极限：</p> <p>f′(x)=lim⁡Δx→0f(x+Δx)−f(x)Δxf'(x) = \\lim_{\\Delta x \\to 0} \\frac{f(x+\\Delta x) - f(x)}{\\Delta x}f′(x)=Δx→0lim​Δxf(x+Δx)−f(x)​</p> <p>这一极限值反映了函数在 x 点附近的局部线性逼近特性24。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#2_5","level":4,"title":"‌2. 几何意义‌","text":"<ul> <li>‌切线斜率‌：f′(x₀) 表示函数 f(x) 在点 x₀ 处切线的斜率35。</li> <li>‌曲线变化趋势‌：</li> <li>f′(x) &gt; 0：函数在该区间单调递增7；</li> <li>f′(x) &lt; 0：函数单调递减7；</li> <li>f′(x) = 0：可能对应极值点或驻点7。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#3_4","level":4,"title":"‌3. 与导数值的区别‌","text":"<ul> <li>‌导函数 f′(x)‌：是定义在 f(x) 全体可导点上的新函数14。</li> <li>‌导数值 f′(x₀)‌：是导函数在某具体点 x₀ 的函数值，为一个常数56。例如，f′(x₀) 的导数为 0（即 [f′(x₀)]′ = 0）6。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#4_4","level":4,"title":"‌4. 高阶导数‌","text":"<ul> <li>‌二阶导数 f″(x)‌：表示导函数 f′(x) 的导数，反映原函数的凹凸性或加速度特性79。</li> <li>f″(x) &gt; 0：函数图像上凸（凹向上）；</li> <li>f″(x) &lt; 0：函数图像下凸（凹向下）7。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_27","level":3,"title":"‌总结‌","text":"<ul> <li>‌符号本质‌：f′(x) 是微积分中表示函数变化率的标准化符号，继承自函数符号体系 f(x)48。</li> <li>‌核心作用‌：通过导数可分析函数的单调性、极值、切线等性质，是连接初等数学与高等数学的关键工具</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#fxfx-y","level":1,"title":"为什么这两个相等？ F′(x)=f(x) 。是否前者是斜率，后者是y轴高度","text":"<p>你提到的等式 ‌F′(x) = f(x)‌ 是微积分基本定理（Fundamental Theorem of Calculus）的核心内容之一，它揭示了‌导数（斜率）‌和‌原函数（高度）‌之间的深刻联系。下面详细解释为什么两者相等，以及它们的几何和物理意义。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#1_6","level":3,"title":"‌1. 数学定义‌","text":"<ul> <li>‌F(x)‌ 是 ‌f(x)‌ 的一个‌原函数（不定积分）‌，即：   F(x)=∫f(x) dx+CF(x) = \\int f(x) \\, dx + CF(x)=∫f(x)dx+C</li> <li>‌F′(x)‌ 是 ‌F(x)‌ 的导数，表示 ‌F(x)‌ 在每一点的‌瞬时变化率（斜率）‌。</li> </ul> <p>根据微积分基本定理：</p> <p>F′(x)=ddx(∫f(x) dx)=f(x)F'(x) = \\frac{d}{dx} \\left( \\int f(x) \\, dx \\right) = f(x)F′(x)=dxd​(∫f(x)dx)=f(x)</p> <p>‌这意味着：‌</p> <ul> <li>‌求导‌和‌积分‌是互逆运算。</li> <li>‌F(x)‌ 的斜率（F′(x)）正好等于被积函数 ‌f(x)‌ 在该点的值。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#2_6","level":3,"title":"‌2. 几何解释‌","text":"","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#1-fx","level":4,"title":"‌(1) F(x) 是 \"面积累积函数\"‌","text":"<p>假设 ‌f(x)‌ 是一个连续函数，‌F(x)‌ 可以理解为：</p> <p>F(x)=∫axf(t) dtF(x) = \\int_a^x f(t) \\, dtF(x)=∫ax​f(t)dt</p> <p>即从某个固定点 ‌a‌ 到 ‌x‌ 之间，‌f(x)‌ 曲线下的‌面积‌（带符号，即上方为正，下方为负）。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#2-fx-fx","level":4,"title":"‌(2) F′(x) = f(x) 的直观理解‌","text":"<ul> <li>‌F(x)‌ 表示从 ‌a‌ 到 ‌x‌ 的累积面积。</li> <li>‌F′(x)‌ 是 ‌F(x)‌ 的变化率，即 ‌x‌ 稍微增加 ‌Δx‌ 时，面积的增量 ‌ΔF ≈ f(x)Δx‌。</li> <li>因此，‌F′(x)‌ 就是 ‌f(x)‌，即 ‌f(x)‌ 给出了 ‌F(x)‌ 的增长速率。</li> </ul> <p>‌举例：‌</p> <ul> <li>如果 ‌f(x)‌ 是速度，‌F(x)‌ 就是位移（位置变化）。</li> <li>‌F′(x)‌（位移的导数）= ‌f(x)‌（速度），符合物理直觉。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#3_5","level":3,"title":"‌3. 物理意义‌","text":"<ul> <li>‌f(x)‌ 可以代表：</li> <li>‌速度‌（如果 ‌F(x)‌ 是位移）</li> <li>‌加速度‌（如果 ‌F(x)‌ 是速度）</li> <li>‌功率‌（如果 ‌F(x)‌ 是能量）</li> <li>‌F′(x) = f(x)‌ 表明：</li> <li>‌变化率（导数）‌ 和 ‌累积量（积分）‌ 是同一现象的两个视角。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#4-fx-fx","level":3,"title":"‌4. 为什么不是 \"F(x) 高度，F′(x) 斜率\"？‌","text":"<ul> <li>‌F(x)‌ 确实代表 ‌y 轴高度‌（原函数的值）。</li> <li>‌F′(x)‌ 是 ‌F(x)‌ 的斜率（变化率）。</li> <li>但 ‌f(x)‌ 不是直接代表高度，而是 ‌F(x) 的斜率‌，即：   斜率=F′(x)=f(x)\\text{斜率} = F'(x) = f(x)斜率=F′(x)=f(x)   所以 ‌f(x)‌ 描述的是 ‌F(x)‌ 如何变化，而不是 ‌F(x)‌ 本身的值。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#5_2","level":3,"title":"‌5. 举例验证‌","text":"<p>‌例子1：线性函数‌</p> <ul> <li>设 ‌f(x) = 2x‌，则它的一个原函数是：   F(x)=x2+CF(x) = x^2 + CF(x)=x2+C</li> <li>计算导数：   F′(x)=2x=f(x)F'(x) = 2x = f(x)F′(x)=2x=f(x)   符合 ‌F′(x) = f(x)‌。</li> </ul> <p>‌例子2：三角函数‌</p> <ul> <li>设 ‌f(x) = cos x‌，则它的一个原函数是：   F(x)=sin⁡x+CF(x) = \\sin x + CF(x)=sinx+C</li> <li>计算导数：   F′(x)=cos⁡x=f(x)F'(x) = \\cos x = f(x)F′(x)=cosx=f(x)   仍然成立。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#6","level":3,"title":"‌6. 总结‌","text":"<ul> <li>‌F′(x) = f(x)‌ 表明：</li> <li>‌积分（求原函数）‌ 和 ‌求导‌ 是互逆运算。</li> <li>‌F(x)‌ 的斜率（F′(x)）就是被积函数 ‌f(x)‌。</li> <li>‌几何上‌：</li> <li>‌F(x)‌ 是 ‌f(x)‌ 的累积面积函数。</li> <li>‌F′(x)‌ 是 ‌f(x)‌，即面积变化的瞬时速率。</li> <li>‌物理上‌：</li> <li>如果 ‌f(x)‌ 是速度，‌F(x)‌ 就是位移，‌F′(x)‌ 又回到速度。</li> </ul> <p>这个关系是微积分的核心，连接了 ‌斜率（导数）‌ 和 ‌高度（积分）‌，使得我们可以通过导数研究函数的增长，或者通过积分计算累积量。</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#fx_2","level":1,"title":"所以F(x)指的中学的函数吗？","text":"","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#fx_3","level":3,"title":"‌F(x) 与中学函数的区别与联系‌","text":"<p>你的问题涉及微积分和中学数学的衔接，下面用清晰的对比和例子说明：</p>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#1_7","level":4,"title":"‌1. 中学的 \"函数\" 是什么？‌","text":"<ul> <li>‌定义‌：中学阶段（初等数学）的函数 ‌y = f(x)‌ 描述两个变量之间的依赖关系，例如：</li> <li>线性函数：f(x)=2x+1f(x) = 2x + 1f(x)=2x+1</li> <li>二次函数：f(x)=x2f(x) = x^2f(x)=x2</li> <li>‌核心内容‌：研究函数的‌解析式、图像、单调性、对称性‌等，‌不涉及导数和积分‌。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#2-fx","level":4,"title":"‌2. 微积分中的 F(x) 是什么？‌","text":"<ul> <li>‌定义‌：若 ‌F'(x) = f(x)‌，则 ‌F(x)‌ 称为 ‌f(x)‌ 的‌原函数‌（或不定积分）。例如：</li> <li>若 f(x)=2xf(x) = 2xf(x)=2x，则 F(x)=x2+CF(x) = x^2 + CF(x)=x2+C（因为 ddx(x2)=2x\\frac{d}{dx}(x^2) = 2xdxd​(x2)=2x）。</li> <li>‌核心内容‌：研究函数之间的‌导数与积分关系‌，属于高等数学范畴。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#3_6","level":4,"title":"‌3. 关键区别‌","text":"‌对比项‌ ‌中学函数 f(x)‌ ‌微积分中的 F(x)‌ ‌数学层次‌ 初等数学（代数、图像分析） 高等数学（微积分） ‌核心操作‌ 代入求值、画图、解方程 求导、积分、解微分方程 ‌变量关系‌ 描述 y 如何随 x 变化 描述 F(x) 如何由 f(x) 的积分得到 ‌典型问题‌ 求 f(3)f(3)f(3) 的值或函数零点 求 ∫f(x)dx\\int f(x)dx∫f(x)dx 或验证 F′(x)=f(x)F'(x) = f(x)F′(x)=f(x)","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#4_5","level":4,"title":"‌4. 联系与进阶‌","text":"<ul> <li>‌共同点‌：两者都使用 ‌f(x)、F(x)‌ 等符号表示函数关系，形式上相似。</li> <li>‌本质差异‌：</li> <li>中学的 ‌f(x)‌ 是静态的变量关系；</li> <li>微积分的 ‌F(x)‌ 是动态的（与导数、积分、变化率相关）。</li> <li>‌过渡示例‌：</li> <li>中学：已知 f(x)=3x2f(x) = 3x^2f(x)=3x2，求 f(2)=12f(2) = 12f(2)=12；</li> <li>微积分：已知 F′(x)=3x2F'(x) = 3x^2F′(x)=3x2，求 F(x)=x3+CF(x) = x^3 + CF(x)=x3+C。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#5_3","level":4,"title":"‌5. 为什么容易混淆？‌","text":"<ul> <li>‌符号相同‌：均用 ‌f(x)、F(x)‌ 表示函数，但上下文不同。</li> <li>‌中学未接触导数‌：原函数的概念需要以导数为前提，中学阶段尚未学习。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_28","level":3,"title":"‌总结‌","text":"<ul> <li>‌F(x) 不是中学的函数‌，而是微积分中由导数定义的‌原函数‌，二者属于不同数学层次。</li> <li>‌中学函数‌是微积分中 ‌f(x)‌ 的基础，而 ‌F(x)‌ 是 ‌f(x)‌ 的高阶扩展（积分形式）。</li> <li>‌类比‌：   中学的 f(x)f(x)f(x) 像“静止的照片”，而微积分的 F(x)F(x)F(x) 像“照片背后的动态变化过程”。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_29","level":1,"title":"原函数指的不定积分函数吗？","text":"","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_30","level":3,"title":"‌原函数与不定积分的关系‌","text":"","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#1_8","level":4,"title":"‌1. 定义区分‌","text":"<ul> <li>原函数‌：若 ‌F'(x) = f(x)‌，则 ‌F(x)‌ 称为 ‌f(x)‌ 的一个原函数26。</li> <li>例如，对于 f(x)=2xf(x) = 2xf(x)=2x，其原函数为 F(x)=x2+CF(x) = x^2 + CF(x)=x2+C（C为任意常数）6。</li> <li>‌不定积分‌：是 ‌f(x)‌ 的全体原函数的集合，记作 ∫f(x)dx=F(x)+C\\int f(x)dx = F(x) + C∫f(x)dx=F(x)+C（C为任意常数）13。</li> <li>不定积分强调“所有可能的原函数”，而原函数是其中的一个具体实例14。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#2_7","level":4,"title":"‌2. 联系与区别‌","text":"<ul> <li>‌联系‌：</li> <li>不定积分的结果是原函数的集合，即 ∫f(x)dx\\int f(x)dx∫f(x)dx 包含所有满足 F′(x)=f(x)F'(x) = f(x)F′(x)=f(x) 的函数34。</li> <li>两者在计算上等价，例如求 ∫2xdx\\int 2x dx∫2xdx 和求 2x2x2x 的原函数均得到 x2+Cx^2 + Cx2+C67。</li> <li>‌区别‌：</li> <li>‌原函数‌是单个函数（如 x2+3x^2 + 3x2+3），‌不定积分‌是函数族（如 x2+Cx^2 + Cx2+C）14。</li> <li>不定积分的符号 ∫\\int∫ 表示“求全体原函数”的操作，而原函数是操作的结果之一36。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#3_7","level":4,"title":"‌3. 几何意义‌","text":"<ul> <li>‌原函数‌：代表一条具体的积分曲线（如 y=x2+1y = x^2 + 1y=x2+1）46。</li> <li>‌不定积分‌：代表一族平行曲线（如 y=x2+Cy = x^2 + Cy=x2+C），这些曲线在垂直方向上平移得到46。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#4_6","level":4,"title":"‌4. 数学表述‌","text":"<ul> <li>若 F(x)F(x)F(x) 是 f(x)f(x)f(x) 的一个原函数，则不定积分可表示为：   ∫f(x)dx=F(x)+C\\int f(x)dx = F(x) + C∫f(x)dx=F(x)+C   其中 ‌C‌ 为任意常数，体现原函数的无穷性23。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#5_4","level":4,"title":"‌5. 常见误解澄清‌","text":"<ul> <li>“原函数=不定积分”：严格来说，原函数是集合中的元素，不定积分是集合本身14。  </li> <li>常数C的作用‌：不定积分中的 ‌C‌ 确保涵盖所有可能的原函数，而单个原函数对应某个特定的 ‌C‌ 值。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"AI%E5%AF%BC%E6%95%B0%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86%E5%92%8C%E5%AE%9A%E7%A7%AF%E5%88%86/#_31","level":3,"title":"‌总结‌","text":"<ul> <li>‌原函数‌ 是 ‌不定积分‌ 的一个具体实例，而不定积分是原函数的全体集合13。</li> <li>两者在微积分中紧密关联，但概念上存在个体与整体的差异47。</li> </ul>","path":["计算函数x^2在区间0到1之间的积分"],"tags":[]},{"location":"EVS_dec%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/","level":1,"title":"EVS_dec使用方法","text":"<p>转码器抓包，解析udp的payload 成 SLTAMRPEM，在phonely中导出evs的rtp成 rtpdump 格式，再用命令转成raw, 再用ffmpeg转成wav</p> <pre><code>EVS_dec  -VOIP_hf_only=1 16   ~/Downloads/wxDownloads/3602.rtpdump   /tmp/evs-output.16k\nffmpeg -f s16le -ar 16k  -i /tmp/evs-output.16k   /tmp/evs-output-3602.wav\n</code></pre>","path":["EVS_dec使用方法"],"tags":[]},{"location":"Install-KVM-on-Debian-of-aarch64-architecture/","level":1,"title":"Install KVM on Debian of aarch64 architecture","text":"<p>公司有台arm64位的设备，安装的银河麒麟系统，经验证就是debian 9。 现在需要运行更多arm64虚拟机。</p>","path":["Install KVM on Debian of aarch64 architecture"],"tags":["aarch64"]},{"location":"Install-KVM-on-Debian-of-aarch64-architecture/#_1","level":1,"title":"安装步骤","text":"","path":["Install KVM on Debian of aarch64 architecture"],"tags":["aarch64"]},{"location":"Install-KVM-on-Debian-of-aarch64-architecture/#sudoer","level":2,"title":"配置免密sudoer","text":"<p>这里记一个坑， 第一次配置时拼写错误，导致sudo 命令执行失败。需要重置密码，所以很麻烦。  然后推荐使用 <code>sudo visudo</code> 命令来修改sudoer配置文件，这个命令在编辑结束后校验配置文件，避免出现编辑错误导致无法使用sudo的情况。  </p> <pre><code>kylin@Kylin:~$ cat /etc/sudoers.d/kylin \nkylin   ALL=(ALL:ALL) NOPASSWD:ALL\n</code></pre>","path":["Install KVM on Debian of aarch64 architecture"],"tags":["aarch64"]},{"location":"Install-KVM-on-Debian-of-aarch64-architecture/#_2","level":2,"title":"配置软件源","text":"<p>第一个是本地iso, 下面的是中科大的镜像源。 每个都设置了trust免校验gpg</p> <pre><code>deb [trusted=yes] file:///mnt/iso/ juniper main multiverse restricted universe\ndeb [trusted=yes] http://ftp.cn.debian.org/debian/ stretch main contrib non-free\ndeb [trusted=yes] http://ftp.cn.debian.org/debian/ stretch-updates main contrib non-free\ndeb [trusted=yes] http://mirrors.ustc.edu.cn/debian-security/ stretch/updates main contrib non-free\ndeb [trusted=yes] http://ftp.cn.debian.org/debian/ stretch-backports main contrib non-free \n</code></pre>","path":["Install KVM on Debian of aarch64 architecture"],"tags":["aarch64"]},{"location":"Install-KVM-on-Debian-of-aarch64-architecture/#_3","level":2,"title":"安装虚拟工具","text":"<p>安装 qemu, libvirt, virt-manager</p> <pre><code>sudo apt install  qemu  libvirt virt-manager\n</code></pre>","path":["Install KVM on Debian of aarch64 architecture"],"tags":["aarch64"]},{"location":"Install-KVM-on-Debian-of-aarch64-architecture/#libvirt","level":2,"title":"libvirt 没有网络","text":"<p>执行<code>virsh net-list -all</code> 发现default 网络处于未激活状态， 于是执行 <code>systemctl status libvirtd</code> 发现</p> <p><pre><code>10月 30 15:46:27 Kylin libvirtd[16741]: 2020-10-30 07:46:27.262+0000: 16764: error : virFileReadAll:1420 : 打开文件 '/sys/class/net/virbr0-nic/operstate' 失败: 没有那个文件或目录\n10月 30 15:46:27 Kylin libvirtd[16741]: 2020-10-30 07:46:27.262+0000: 16764: error : virNetDevGetLinkInfo:2530 : unable to read: /sys/class/net/virbr0-nic/operstate: 没有那个文件或目录\n10月 30 15:46:54 Kylin libvirtd[16741]: 2020-10-30 07:46:54.710+0000: 16745: error : virFirewallApply:916 : 内部错误：Failed to initialize a valid firewall backend\n</code></pre> 需要安装以下组件，然后重启libvirtd，这是因为libvirt的网络依赖这几个组件来创建nat 网络</p> <pre><code>sudo apt install ebtables iptables dnsmasq\nsystemctl restart libvirtd\n</code></pre>","path":["Install KVM on Debian of aarch64 architecture"],"tags":["aarch64"]},{"location":"Install-KVM-on-Debian-of-aarch64-architecture/#virt-manager-aarch64-uefi","level":2,"title":"virt-manager 提示aarch64 安装 uefi 错误","text":"<p>直接安装 qemu-efi <pre><code>apt install qemu-efi\n</code></pre></p>","path":["Install KVM on Debian of aarch64 architecture"],"tags":["aarch64"]},{"location":"Install-KVM-on-Debian-of-aarch64-architecture/#virt-manager-root","level":2,"title":"virt-manager 允许非root用户访问","text":"<p>因为当以普通用户运行 virt-manager 时，qemu的连接指向非qemu:///system， 这时看到的虚拟机和root看到的不一样，所以必须使用sudo运行。 通过修改配置来启用普通用户也访问<code>qemu:///system</code>， 将uri_defualt 的注释去掉。</p> <pre><code>vim /etc/libvirt/libvirt.conf \n\n#\n# These can be used in cases when no URI is supplied by the application\n# (@uri_default also prevents probing of the hypervisor driver).\n#\nuri_default = \"qemu:///system\"\n</code></pre>","path":["Install KVM on Debian of aarch64 architecture"],"tags":["aarch64"]},{"location":"Install-KVM-on-Debian-of-aarch64-architecture/#virt-managerx86","level":1,"title":"这样就可以使用virt-manager来创建虚拟机了，跟x86的使用一样。","text":"<p>顺便记一下vnc的配置， 因为机器在机房里， 通过tigervnc来使用桌面。 另外提示一下，virt-manager 配置好后，可以直接连接远程的virt-manager,非常方便。</p> <p>使用tigervnc 连接需要在远程主机安装 tigervnc-server 和 tigervnc-password。 使用普通用户执行 <code>tigervnc-password</code> 设置访问密码，然后直接执行<code>tigervnc-server</code>。</p> <p>这时候vnc只接受本地连接， 如果远程访问，要使用ssh 本地转发来实现。 这也是vnc推荐的方式。</p> <p>现在本地允许本地转发命令， 监听本地端口 9302, 转发到远程的 9300 <pre><code>ssh -L 9302:localhost:9300   -N -f  ssh-kylin\n</code></pre></p> <p>然后执行 <code>vncviewer  127.0.0.1:9302</code> ，输入密码就能打开远程桌面了。</p>","path":["Install KVM on Debian of aarch64 architecture"],"tags":["aarch64"]},{"location":"Learn%20English%20Conjunction%20words/","level":1,"title":"连词和复合句","text":"<p>英语中，句子(sentence)通常由好个子句子组成，这叫复合句(compound sentense), 由连词和子语句(Clause)、短语(Phase)、单词(Word)组成。</p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_2","level":2,"title":"子句和短语","text":"<p>子句包含完整的主谓， 但短语没有主和谓， 有好多个phase组成。比较长度 Clause &gt; Phase &gt; Word, word很好区别。 短语是不完整的， 而子语句包含了完整的主谓（宾）。 <pre><code>Phrase: Meows so loudly\nClause: That cat meows so loudly\n</code></pre></p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_3","level":3,"title":"子句当名词","text":"<ul> <li>She completely understood <code>everything he said</code>. 拆成主谓宾'She understood XXX',  'everything he said' 是宾语XXX， 是一个名词</li> <li>They remembered <code>what the keynote speaker covered</code>. 同上</li> </ul>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_4","level":3,"title":"子句当副词","text":"<ul> <li>She fixed the sink <code>without facing difficulty</code>. 拆成主谓宾'She fixed XXX'。'without facing difficulty'修饰动词'fix'， 是副词</li> <li>The pool was installed <code>after they built the deck</code>. 拆成主谓 'The poll was adj'。 'after they built the deck'是修饰形容词（或was）， 是副词</li> </ul>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_5","level":3,"title":"子句当形容词","text":"<ul> <li>My friend <code>who rides a motorcycle</code> said it’s a great weekend to ride. 拆成主谓宾'XXX said XXX'。 'who rides a motorcycle' 形容词，形容'My Friend'</li> <li>No matter what time of day we visit, we always run into the dog <code>that barks</code>. 同上, 形容'dog'</li> </ul> <p>子句当名词和形容词时，比较好看出子句的主谓（宾）， 而当副词</p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_6","level":3,"title":"短句是几个单词组成，可以当很多成分","text":"<ul> <li>She runs <code>every Sunday</code>. 当副词</li> <li>She was <code>taller than all of her classmates</code>. 当形容词</li> <li><code>My small dog</code> barks at ducks. 名词</li> </ul>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_7","level":2,"title":"连接词","text":"<p>连接词用来连接子句和短语</p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_8","level":3,"title":"一致关系","text":"<p>for, and, nor, but, or, yet, so</p> <p></p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_9","level":3,"title":"配对关系， 搭配用","text":"<p>both/and, either/or, neither/nor, not only/but, whether/or</p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_10","level":3,"title":"主从关系","text":"<p>after, although, as, as if, as long as, as much as, as soon as, as though, because, before, by the time, even if, even though, if, in order that, in case, in the event that, lest, now that, once, only, only if, provided that, since, so, supposing, that, than, though, till, unless, until, when, whenever, where, whereas, wherever, whether or not, while</p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_11","level":2,"title":"按功能分连接词","text":"","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_12","level":4,"title":"表示强调","text":"<p>indeed</p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_13","level":4,"title":"表示递进","text":"<p>what's more, furthermore</p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_14","level":4,"title":"表示转折","text":"<p>however, but</p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_15","level":4,"title":"表示原因结果","text":"<p>because, as a result</p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#yet","level":2,"title":"yet 相关","text":"<p>yet 一直让我脑子转不过弯， 不知道怎么翻译成中文。例如歌名'Are you bored yet?'， 没yet是‘你无聊吗？’。 当有yet时我以为翻译成’你还无聊吗？‘， 而结果翻译成‘你觉得无聊了吗？’ </p> <p>gptchat解释“yet表示提问者预期如此，也就是提问者预期被提问者无聊了。”， 所以正确理解应该是： “你应该无聊了吧？” 显然这里yet是副词，修饰bored。</p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_16","level":3,"title":"当副词, 修饰形容词和动词","text":"<p>any yet 但是 nor yet 也不 ; 又不 ; 也没有 but yet 但还是 not yet 还没 why is there yet another problem</p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_17","level":3,"title":"当连词， 连接子句和短语","text":"<p>Yet she 而她已经 Yet Moralistic 但注重道德</p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20English%20Conjunction%20words/#_18","level":2,"title":"参考","text":"<p>https://www.grammarly.com/blog/parts-of-speech/conjunctions/ https://www.grammarly.com/blog/sentences/phrases/ https://www.grammarly.com/blog/grammar/clauses/</p>","path":["连词和复合句"],"tags":["English"]},{"location":"Learn%20GPIO/","level":1,"title":"Learn GPIO","text":"<p>GPIO是通用目的的输入输出引脚，可以配置很多功能，因为每个GPIO引脚都有许多寄存器，例如4个控制寄存器，2个数据寄存器，1个复位寄存器，1个时钟寄存器，2个复用功能寄存器。 树莓派，ESP32, arduino（Atmel328p）都有GPIO引脚。</p>","path":["Learn GPIO"],"tags":["GPIO","esp32"]},{"location":"Learn%20GPIO/#gpio","level":2,"title":"GPIO 的几种模式","text":"<ul> <li>输出： 点亮灯泡。又分为推挽（PUSH_PULL） 这是默认的输出模式（高/低电平）； 开漏（OPEN_DRAIN）用得少，这是只能将引脚设置成低电平，要靠外部电路实现高电平，应用在例如i2c总线。</li> <li>输入： 按钮控制。又分为内部上拉 PULL_UP 引脚默认高电平； 内部下拉 PULL_DOWN 引脚默认低电平。</li> </ul>","path":["Learn GPIO"],"tags":["GPIO","esp32"]},{"location":"Learn%20GPIO/#gpio-pwm","level":2,"title":"GPIO 输出数字信号和PWM","text":"<p>无论是PUSH_PULL还是OPEN_DRAIN，GPIO引脚只有高电平和低电平两种状态，这也叫数字信号，例如下面的发送摩斯码。 PWM信号实际是高低电平的串行信号组（例如__------），ESP32的所有GPIO支持输出PWM信号，但推荐使用 GPIO 4, 5, 12–14, 18–19, 21–23, 25–27, 32–33。 PWD信号用来驱动步进电机。</p>","path":["Learn GPIO"],"tags":["GPIO","esp32"]},{"location":"Learn%20GPIO/#gpio_1","level":2,"title":"GPIO 输出模拟信号","text":"<p>模拟信号（analog）可以驱动喇叭播放声音，ESP32中只有GPIO 25-26 支持输出模拟信号。 <pre><code>from machine import DAC, Pin\n\ndac = DAC(Pin(25))     # Use GPIO25\ndac.write(128)         # Output ~1.65V (128/255 × 3.3V)\n</code></pre></p>","path":["Learn GPIO"],"tags":["GPIO","esp32"]},{"location":"Learn%20GPIO/#gpio_2","level":2,"title":"GPIO 按钮实现发送摩斯码","text":"<pre><code>from machine import Pin\nimport time\n\nbutton = Pin(15, Pin.IN, Pin.PULL_UP)\nmorse = \"\"\npress_start = 0\nlast_event_time = time.ticks_ms()\n\nMORSE_TABLE = {\n    \".-\":\"A\",\"-...\":\"B\",\"-.-.\":\"C\",\"-..\":\"D\",\".\":\"E\",\n    \"..-.\":\"F\",\"--.\":\"G\",\"....\":\"H\",\"..\":\"I\",\".---\":\"J\",\n    \"-.-\":\"K\",\".-..\":\"L\",\"--\":\"M\",\"-.\":\"N\",\"---\":\"O\",\n    \".--.\":\"P\",\"--.-\":\"Q\",\".-.\":\"R\",\"...\":\"S\",\"-\":\"T\",\n    \"..-\":\"U\",\"...-\":\"V\",\".--\":\"W\",\"-..-\":\"X\",\"-.--\":\"Y\",\n    \"--..\":\"Z\", \"\": \" \"\n}\n\ndef decode(morse_code):\n    return MORSE_TABLE.get(morse_code, \"?\")\n\nwhile True:\n    now = time.ticks_ms()\n\n    if button.value() == 0:  # Press detected\n        press_start = now\n        while button.value() == 0:\n            time.sleep(0.01)\n        press_duration = time.ticks_diff(time.ticks_ms(), press_start)\n        symbol = \".\" if press_duration &lt; 300 else \"-\"\n        morse += symbol\n        last_event_time = time.ticks_ms()\n        print(\"Symbol:\", symbol)\n\n    # Check for end of character\n    if morse and time.ticks_diff(now, last_event_time) &gt; 1000:\n        char = decode(morse)\n        print(\"Char:\", char)\n        morse = \"\"\n\n    time.sleep(0.01)\n</code></pre>","path":["Learn GPIO"],"tags":["GPIO","esp32"]},{"location":"Learn%20GPIO/#_1","level":2,"title":"引用","text":"<p>https://blog.51cto.com/u_4029519/13530340 https://blog.csdn.net/makeryzx/article/details/78915955</p>","path":["Learn GPIO"],"tags":["GPIO","esp32"]},{"location":"Learn%20Midi/","level":1,"title":"Learn Midi","text":"<p>LMMS in Linux</p>","path":["Learn Midi"],"tags":["midi"]},{"location":"Learn%20Midi/#setup-default-sound-file","level":2,"title":"Setup default sound file","text":"<p>First download 'GeneralUser_GS' from https://www.schristiancollins.com/generaluser.php, unzip it, then in LMMS Edit-&gt;Setup-&gt;default sound file, select the right path.</p>","path":["Learn Midi"],"tags":["midi"]},{"location":"Learn%20Midi/#daily-music-support-midi","level":2,"title":"daily music support midi","text":"<p>https://www.flutetunes.com/</p>","path":["Learn Midi"],"tags":["midi"]},{"location":"Learn%20Midi/#reference","level":2,"title":"reference","text":"<p>https://lmms.io/forum/viewtopic.php?t=28485</p>","path":["Learn Midi"],"tags":["midi"]},{"location":"Linux-Interrupts/","level":1,"title":"Linux 中断请求","text":"<p>中断请求的英文是IRQ（Interrupt Request）,是用来驱动CPU正常工作的重要机制。 中断根据源头分类成： 由外设发出的硬件中断，软件发出的软中断，以及异常组成。</p> <p>以前，每个外设都连接一根线到PIC(programmable Interrupt circuit)芯片，有PIC芯片来发生数据到CPU,并将CPU的INTR引脚置位。 现在，CPU集成了PIC成为APIC(Advanced PIC)。</p>","path":["Linux 中断请求"],"tags":["Linux","内核原理"]},{"location":"Linux-Interrupts/#_1","level":2,"title":"中断分类","text":"<p>中断分为3类型</p>","path":["Linux 中断请求"],"tags":["Linux","内核原理"]},{"location":"Linux-Interrupts/#_2","level":3,"title":"硬件中断","text":"<p>鼠标和键盘，还有IO设备都会发出硬件中断，例如网卡的数据到了，就会出发中断请求（IRQ）， 这个请求会触发CPU去执行ISR, 而这个ISR需要在系统启动的时候注册的。一个Vector表。</p>","path":["Linux 中断请求"],"tags":["Linux","内核原理"]},{"location":"Linux-Interrupts/#_3","level":2,"title":"软件中断","text":"<p>当播放电影的时候，声音和画面的同步非常重要，这是由系统的定时器jiffies来不停地调度声音播放器来准确播放对应的声音。 软中断在实时操作系统的作用也非常重要。</p>","path":["Linux 中断请求"],"tags":["Linux","内核原理"]},{"location":"Linux-Interrupts/#_4","level":3,"title":"异常中断","text":"<p>异常中断又分为3类： 缺页异常(Faults)，陷入异常(Traps)，异常退出(Aborts)</p> <p>例如当程序的内存被swap到硬盘了或者一段动态链接库还没有载入到内存里来，在程序走到这个位置之前， 程序就会提前发出缺页异常，当系统检查了权限和地址有效后（地址有效表示在逻辑地址范围内）， CPU开始为程序执行加载需要的数据，并清除这个异常。 所以这个异常是可以修正的，这个请求必须提前发出。</p> <p>当GDB调试的时，设置断点会插入一条特殊的指令到程序里，当执行到断点位置就会出发Traps请求，软件的主导权由CPU交给GDB。</p> <p>当程序触发一个异常例如0/0时，会出发退出异常，由cpu来清理堆栈。</p>","path":["Linux 中断请求"],"tags":["Linux","内核原理"]},{"location":"Linux-Interrupts/#_5","level":2,"title":"请求的可阻塞性","text":"<p>对于硬件中断请求，CPU的决策是立即执行，对于软中断和异常，CPU采用尽量延后的策略。</p>","path":["Linux 中断请求"],"tags":["Linux","内核原理"]},{"location":"Linux-Interrupts/#_6","level":2,"title":"查看系统的中断","text":"<p>在中断执行 <code>watch -n1 \"cat /proc/interrupts\"</code>可以定时更新中断的次数</p> <p>列的含义从左至右以此为： <pre><code> IRQ vector, interrupt count per CPU (0 .. n), the hardware source, the hardware source's channel information, and the name of the device that caused the IRQ.\n</code></pre></p>","path":["Linux 中断请求"],"tags":["Linux","内核原理"]},{"location":"Non-constant%20time%20of%20comparation/","level":1,"title":"Non-constant time comparison bug","text":"<p>Tailscale 给我发的邮件说到了这个BUG, 发现挺有趣的。</p> <p>Hello, We recently fixed an insecure non-constant time comparison bug in the Tailscale DERP server that could have caused DERP servers to leak their private mesh keys via a timing side channel. We have deployed this fix to all Tailscale-operated DERP servers and rotated their mesh keys. </p>","path":["Non-constant time comparison bug"],"tags":["safety"]},{"location":"Non-constant%20time%20of%20comparation/#bug","level":2,"title":"BUG原因","text":"<p>非固定时长的比较，就是比较次数约多，耗时越长，例如常见for循环，还有'memncmp'。利用这个时间差异，也许能够猜到密码。 <pre><code>for (i = 0; i &lt; len; i++) {\n    if (a[i] != b[i]) return false;\n}\n</code></pre></p>","path":["Non-constant time comparison bug"],"tags":["safety"]},{"location":"Non-constant%20time%20of%20comparation/#_1","level":2,"title":"解决办法","text":"<p>使用固定时间（constant time）的比较函数，例如改成</p> <pre><code>flag = true\nfor (i = 0; i &lt; len; i++) {\n    if (a[i] != b[i]) flag = false;\n}\nreturn flag;\n</code></pre>","path":["Non-constant time comparison bug"],"tags":["safety"]},{"location":"a-FakeIt-issue/","level":1,"title":"FakeIt","text":"<p>FakeIt是一个单元测试工具，类比gmock, 但是比gmock更modern和轻量，因为它支持c++11和header-only</p>","path":["记一个FakeIt使用问题"],"tags":["unittest"]},{"location":"a-FakeIt-issue/#_1","level":2,"title":"使用方法","text":"<p>FakeIt和gmock都提供Mock和调用计数功能，Mock通常用于接口类，用来定义并实例化接口类对象。gmock和FakeIt都能对调用参数进行校验，但FakeIt的Verify函数还提供在校验失败时打印参数值，这是gmock不具备的</p> <pre><code>struct IAppManager {\n  // inotify calls when new event\n  virtual void notify_add_event(EventType event_type,\n                                const std::string&amp; filepath) = 0;\n  virtual void notify_rename_event(EventType event_type,\n                                   const std::string&amp; filepath,\n                                   const std::string&amp; filepath_new) = 0;\n\n  virtual ~IAppManager() = default;\n};\n\nTEST_CASE(\"Test Inotify\") {\n  Mock&lt;IAppManager&gt; appmanager_mock;\n  Fake(Dtor(appmanager_mock));\n  Fake(Method(appmanager_mock, notify_add_event));\n  Fake(Method(appmanager_mock, notify_rename_event));\n\n  auto&amp; app_manager = appmanager_mock.get();\n  SECTION(\"test add\") {\n    std::thread t1([&amp;app_manager](){\n      app_manager.notify_add_event(EventType::File, \"filename\");\n      app_manager.notify_add_event(EventType::File, \"filename\");\n      app_manager.notify_add_event(EventType::File, \"filename\");\n    });\n    t1.join();\n    Verify(Method(appmanager_mock, notify_add_event)).Exactly(2);\n  }\n}\n</code></pre> <p>这里没有对调用参数校验，而仅对调用次数验证，可以预见，结果失败，因为调用了3次。</p>","path":["记一个FakeIt使用问题"],"tags":["unittest"]},{"location":"a-FakeIt-issue/#_2","level":2,"title":"问题","text":"<p>上面的测试用例会失败，因为次数不匹配。而这时FakeIt会打印所有调用的参数值，但参数由于是个引用，而且引用在线程退出时被释放，打印一个无效引用导致会抛异常 <pre><code>due to a fatal error condition:                                                                 \n  SIGSEGV - Segmentation violation signal \n</code></pre></p>","path":["记一个FakeIt使用问题"],"tags":["unittest"]},{"location":"a-FakeIt-issue/#_3","level":2,"title":"解决办法","text":"<p>对于本测试而言，解决办法就是将传参所引用的对象duration改大，如全局变量或者static，或者在线程外定义它</p> <p><pre><code>TEST_CASE(\"Test Inotify\") {\n  Mock&lt;IAppManager&gt; appmanager_mock;\n  Fake(Dtor(appmanager_mock));\n  Fake(Method(appmanager_mock, notify_add_event));\n  Fake(Method(appmanager_mock, notify_rename_event));\n\n  auto&amp; app_manager = appmanager_mock.get();\n  SECTION(\"test add\") {\n    std::string filename = \"asd\";\n    std::thread t1([&amp;app_manager, &amp;filename](){\n      app_manager.notify_add_event(EventType::File, filename);\n      app_manager.notify_add_event(EventType::File, filename);\n      app_manager.notify_add_event(EventType::File, filename);\n    });\n    t1.join();\n    Verify(Method(appmanager_mock, notify_add_event)).Exactly(2);\n  }\n}\n</code></pre> 修改之后，不会触发SIGSEGV异常, 而是能正确打印出调用参数</p> <pre><code>  Expected pattern: appmanager_mock.notify_add_event( Any arguments )\n  Expected matches: exactly 2\n  Actual matches  : 3\n  Actual sequence : total of 3 actual invocations:                             \n    appmanager_mock.notify_add_event(?, asd)\n    appmanager_mock.notify_add_event(?, asd)\n    appmanager_mock.notify_add_event(?, asd) \n</code></pre> <p>但对于间接调用的接口，且在单元测试里无法控制变量类型，则没有什么办法，只能保证Extractly准确而不用打印参数值</p>","path":["记一个FakeIt使用问题"],"tags":["unittest"]},{"location":"a-FakeIt-issue/#gmock","level":2,"title":"gmock的方式","text":"<p>gmock使用预先设定调用参数，在调用时再判断，所以不会出现无效引用的问题</p>","path":["记一个FakeIt使用问题"],"tags":["unittest"]},{"location":"acronyms/","level":1,"title":"database acronyms","text":"<p>常常被几个缩写搞晕，今天有空好好查了下。</p>","path":["database acronyms"],"tags":["wiki"]},{"location":"acronyms/#crud","level":2,"title":"CRUD 增删改查","text":"<p>web后端代名词，CREATE READ UPDATE DELETE</p>","path":["database acronyms"],"tags":["wiki"]},{"location":"acronyms/#acid","level":2,"title":"ACID 事物操作的四个特性","text":"<p>Atomic 原子性，一次事物包含多个操作，这些操作要么都成功，要么都失败。 Consistency 一致性 Isolation 隔离性，多个事物之间按优先级并发，互不影响 Durability 持久性，数据储持久化，存储在磁盘上而非内存中</p>","path":["database acronyms"],"tags":["wiki"]},{"location":"acronyms/#cap","level":2,"title":"CAP 分布式系统的不可能三角的定理","text":"<p>Consistency 一致性，保证所有节点的数据状态都一致 Availbility 可用性，保证能对外服务 Partition tolerance 分区容忍性，可以接受系统出现分区，俗称脑裂。</p> <p>CAP是被证明的定理，不可能三角表示同时最多只能保证两个，而不能保证三个。三种情况解释如下： 1. 多节点的系统不能保证没有故障，就需要系统能接受系统出现分区（脑裂）。当出现分区时，需要从C一致性和A可用性中二选一，当选择一致性时，就放弃可用性。因为网络有分区无法保证查询信息是一致的，所以请求将返回失败。 2. 当选择可用性时，系统将每次都尝试返回最新的结果，即使由于分区导致数据不一定是最新的。 3. 而当没有出现分区时，可以同时保证一致性和可用性。</p> <p>简而言之1保证了C+P，2保证了A+P，3保证了C+A</p>","path":["database acronyms"],"tags":["wiki"]},{"location":"adb%20remote%20forward/","level":1,"title":"adb remote forward","text":"<p>连接安卓设备后，通过adb连接实现远程桌面的方法</p> <ol> <li>首先跳板机连接安卓，这里是wifi方式，adb connect 192.168.0.32:5555</li> <li>启动隧道转发，ssh -vCN -L5038:localhost:5037 -L27183:localhost:27183 adb@SERVER -p PORT</li> <li>在另一台设备上使用scrcpy远程安卓  <pre><code>user@client:~$ export ADB_SERVER_SOCKET=tcp:localhost:5038\nuser@client:~$ scrcpy --force-adb-forward -b2M -m800 --max-fps=15\n</code></pre></li> </ol>","path":["adb remote forward"],"tags":["android"]},{"location":"adb%20remote%20forward/#adb","level":2,"title":"对于不能有线连接设备的情况，通过下面命令开启无线adb","text":"<p>在adb shell中操作</p> <pre><code># This line enables adbd to run as tcpip by default\nroot@device:~$ echo \"service.adb.tcp.port=5555\" &gt;&gt; /system/build.prop\n\n# This line enables adbd to accept input from keyboard &amp; mouse using scrcpy\nroot@device:~$ echo \"persist.security.adbinput=1\" &gt;&gt; /system/build.prop\n\n# This line enables adbd\nroot@device:~$ echo \"persist.service.adb.enable=1\" &gt;&gt; /system/build.prop\n\n# After that, just reboot the DEVICE\nroot@device:~$ reboot\n</code></pre>","path":["adb remote forward"],"tags":["android"]},{"location":"adb%20remote%20forward/#_1","level":2,"title":"参考","text":"<p>https://psabadac.medium.com/ssh-adb-9d92c676d8c0</p>","path":["adb remote forward"],"tags":["android"]},{"location":"add-printer-in-linux/","level":1,"title":"linux 添加打印机","text":"<p>记一次arch 上添加打印机的过程， 公司有一个Ricoh c5503 的打印机，ip <code>192.168.4.99</code> 通过nmap这个地址可以发现开了不少端口</p> <pre><code>PORT     STATE SERVICE\n21/tcp   open  ftp\n23/tcp   open  telnet\n80/tcp   open  http\n139/tcp  open  netbios-ssn\n514/tcp  open  shell\n515/tcp  open  printer\n631/tcp  open  ipp\n7443/tcp open  oracleas-https\n8080/tcp open  http-proxy\n9100/tcp open  jetdirect\n</code></pre>","path":["add printer in linux"],"tags":["tool"]},{"location":"add-printer-in-linux/#avahi-daemon","level":2,"title":"启动avahi-daemon 服务","text":"<p>这个服务提供mDNS功能， 可以发现局域网内的主机提供的服务，例如打印服务，ssh。 各个主机通过<code>224.0.0.251</code> 地址多播自己提供的服务 主机也可以配置自己想广告的服务，这是用户可选的。 具体看wiki </p> <p>通过执行一下命令可以看到打印服务 <pre><code> avahi-browse --all --ignore-local --resolve --terminate \n</code></pre></p> <p>找到有用的信息如下: <pre><code>+    br0 IPv4 RICOH MP C4503 [002673734B1D]                 Web Site             local\n=    br0 IPv4 RICOH MP C4503 [002673734B1D]                 Web Site             local\n   hostname = [RNP002673734B1D.local]\n   address = [192.168.4.99]\n   port = [80]\n   txt = [\"path=/\"]\n</code></pre></p>","path":["add printer in linux"],"tags":["tool"]},{"location":"add-printer-in-linux/#cupsd","level":2,"title":"安装cupsd","text":"<p>启动<code>cups-browsed.service</code>服务后， 可以通过网页也配置打印机， 包括分享自己的打印机和添加别人的打印机。  我这里需要添加打印机服务</p> <ol> <li>浏览器输入<code>http://localhost:631/</code> 可以打开网页  </li> <li>administrator -&gt; add printer 输入root和密码  </li> <li>有以下选项 <pre><code>Backend Error Handler\nInternet Printing Protocol (ipp)\nLPD/LPR Host or Printer\nInternet Printing Protocol (ipps)\nAppSocket/HP JetDirect\nInternet Printing Protocol (http)\nInternet Printing Protocol (https)\nWindows Printer via SAMBA \n</code></pre></li> <li>我这里选择的<code>AppSocket/HP JetDirect</code>， 因为nmap显示是支持<code>jetdirect</code>的。 </li> <li>输入地址<code>socket://192.168.4.99:9100</code></li> <li>输入自定义的打印机名称和路径<code>/</code></li> </ol> <p>至此，浏览器打印页面就可以看到添加的打印机了</p>","path":["add printer in linux"],"tags":["tool"]},{"location":"add-printer-in-linux/#_1","level":2,"title":"分享打印机","text":"<p>没有分享的时候，只有本机可以使用，当想要给手机使用时，可以勾选分享。此时CUPS会使用mdns广播打印机服务到主机所处的网段，所以手机也必须在这个网段里。 ![[cups_share.png]]</p>","path":["add printer in linux"],"tags":["tool"]},{"location":"add-printer-in-linux/#_2","level":2,"title":"更新","text":"<p>开始时我走的ipp协议，打印机地址为'ipp://192.168.4.99:631/ipp', 后来连不上打印机  </p> <p>通过查端口发现有维护人员修改了打印机端口信息, 631和80端口都被封了，可能是出于安全考虑 <pre><code>PORT      STATE    SERVICE\n21/tcp    open     ftp\n23/tcp    open     telnet\n80/tcp    filtered http\n139/tcp   open     netbios-ssn\n514/tcp   open     shell\n515/tcp   open     printer\n631/tcp   filtered ipp\n7443/tcp  open     oracleas-https\n8080/tcp  open     http-proxy\n9100/tcp  open     jetdirect\n65000/tcp open     unknown\n</code></pre> 631没有开放，参考windows的同事配置，发现他们用的9100端口(9100是走socket协议)，所以需要重新添加打印机 新的网络地址即为'socket://127.0.0.1:9100'</p>","path":["add printer in linux"],"tags":["tool"]},{"location":"add-printer-in-linux/#2","level":2,"title":"更新2","text":"<p>之前是自己搓的桌面环境，需要手动在CUPS的web界面添加打印机。而自从使用了完整桌面GNOME发现非常简单。GNOME自带有打印机配置工具，只需要填入打印机的IP（也许由于不在一个网段），就会自动检测支持的协议并配置好。</p> <p>![[Pasted image 20240410175417.png]]</p>","path":["add printer in linux"],"tags":["tool"]},{"location":"advanced-marco-in-c/","level":1,"title":"C的宏定义","text":"<p>宏定义是在c/c++里特有的方式， 像变量一样， 又像模板编程一样， 但最常见的用法还是做头文件的唯一性保证  </p> <p>在每一个头文件都套用这种格式，就可以避免多次引入头文件而导致的重复定义报错</p> <pre><code>#ifdef FILE_NAME\n#def FILE_NAME\n\n// 代码\n\n#endif FILE_NAME\n</code></pre>","path":["advanced marco in c"],"tags":["c/cpp"]},{"location":"advanced-marco-in-c/#_1","level":2,"title":"原理","text":"<p>宏定义与变量、模板的最大区别在与处理的时期， 宏定义在预编译时处理， 而变量和模板函数则是在编译期处理。 查看预编译后的代码可以使用命令<code>gcc -E</code> 或者 <code>cpp</code>， 实际上是前者是调用了后者</p> <pre><code>NAME\n       cpp - The C Preprocessor\n</code></pre>","path":["advanced marco in c"],"tags":["c/cpp"]},{"location":"advanced-marco-in-c/#_2","level":2,"title":"用法","text":"<p>除了<code>#ifdef</code> 的用法，宏定义可以分两种类型，变量型和函数型</p>","path":["advanced marco in c"],"tags":["c/cpp"]},{"location":"advanced-marco-in-c/#_3","level":3,"title":"变量型","text":"<p>这个最简单，就像使用变量一样，先define 然后再使用</p> <p><pre><code># marco.c\n#define BUFFER_SIZE 1024\n\nint main(){\n    foo = (char *) malloc (BUFFER_SIZE);\n}\n</code></pre> 执行 <code>gcc -E marco.c</code> 得到 <pre><code>foo = (char *) malloc (1024);\n</code></pre></p> <p>多行使用 '\\' 来连接 <pre><code>#include &lt;stdio.h&gt;\n#define GREETING_STR \\\n  \"hello \\\nworld\"\n</code></pre></p> <ul> <li>注意, 宏定义的定义不分前后， 也不像变量那样先定义再使用， 宏定义可以先使用后定义  </li> </ul> <p>以下两种方式的效果相同</p> <pre><code>#define GREETING_NAME \"wayou\"\n\n#define GREETING \"hello,\" GREETING_NAME\n\nint main() {\nprintf(GREETING);\nreturn 0;\n}\n</code></pre> <pre><code>+#define GREETING \"hello,\" GREETING_NAME\n\n#define GREETING_NAME \"wayou\"\n\n-#define GREETING \"hello,\" GREETING_NAME\n\nint main() {\nprintf(GREETING);\nreturn 0;\n}\n</code></pre>","path":["advanced marco in c"],"tags":["c/cpp"]},{"location":"advanced-marco-in-c/#_4","level":3,"title":"函数型","text":"<p>函数类型的宏，可以像正常函数一样指定入参，入参需为逗号分隔合法的 C 字面量。 宏的参数必须要用括号包起来，否则当参数为表达式时，会出错</p> <pre><code>#define min(X, Y)  ((X) &lt; (Y) ? (X) : (Y))\n  x = min(a, b);          →  x = ((a) &lt; (b) ? (a) : (b));\n  y = min(1, 2);          →  y = ((1) &lt; (2) ? (1) : (2));\n  z = min(a + 28, *p);    →  z = ((a + 28) &lt; (*p) ? (a + 28) : (*p));\n ```\n\n### 宏定义字符串化\n\n当宏定义的参数被引号包起来时， 不会进行替换，如下\n```c\n#define foo(x) x, \"x\"\nfoo(bar)        → bar, \"x\"\n</code></pre> <p>加入需要将参数替换到字符串里， 可以使用'#'  </p> <pre><code>#define WARN_IF(EXP) \\\ndo { if (EXP) \\\n        fprintf (stderr, \"Warning: \" #EXP \"\\n\"); } \\\nwhile (0)\nWARN_IF (x == 0);\n     → do { if (x == 0)\n           fprintf (stderr, \"Warning: \" \"x == 0\" \"\\n\"); } while (0);\n</code></pre> <p>而当 这里的x 也是宏定义时， 只有if里的x会替换， 字符串里的x则不会替换  </p> <p><pre><code>#define X ( 1 - 1 )\nWARN_IF ( X == 0);\n</code></pre> 会被替换为  </p> <pre><code>do { if (( 1 - 1 ) == 0) fprintf (\nstderr\n, \"Warning: \" \"X == 0\" \"\\n\"); } while (0);\n</code></pre>","path":["advanced marco in c"],"tags":["c/cpp"]},{"location":"advanced-marco-in-c/#_5","level":3,"title":"拼接","text":"<p>通过 ## 可将两个宏展开成一个，即将两者进行了拼接，宏拼接一般用在需要拼接的宏是来自宏参数的情况， 其他情况，大可直接将两个宏写在一起即可</p> <p>当有以下情况时非常有用 <pre><code>struct command\n{\n  char *name;\n  void (*function) (void);\n};\n\nstruct command commands[] =\n{\n{ \"quit\", quit_command },\n{ \"help\", help_command },\n…\n};\n</code></pre></p> <p>可以使用如下： <pre><code>#define COMMAND(NAME)  { #NAME, NAME ## _command }\n\nstruct command commands[] =\n{\nCOMMAND (quit),\nCOMMAND (help),\n…\n};\n</code></pre></p>","path":["advanced marco in c"],"tags":["c/cpp"]},{"location":"advanced-marco-in-c/#_6","level":3,"title":"不定参数和混合参数","text":"<p>宏定义也可以使用不定参数 <pre><code>#define eprintf(args…) fprintf (stderr, args)\n// or\n#define eprintf(…) fprintf (stderr, __VA_ARGS__)\n</code></pre></p> <p>也可以使用混合参数 <pre><code>#define eprintf(format, args...) fprintf (stderr, format, args)\n</code></pre> 这个可以常在格式化打印时用到， 例如 <code>spdlog</code> 库  </p> <pre><code>#define SPDLOG_LOGGER_CALL(logger, level, ...)                                                                                             \\\n    if (logger-&gt;should_log(level))                                                                                                         \\\n    logger-&gt;log(spdlog::source_loc{SPDLOG_FILE_BASENAME(__FILE__), __LINE__, SPDLOG_FUNCTION}, level, __VA_ARGS__)\n\n#if SPDLOG_ACTIVE_LEVEL &lt;= SPDLOG_LEVEL_TRACE\n#define SPDLOG_LOGGER_TRACE(logger, ...) SPDLOG_LOGGER_CALL(logger, spdlog::level::trace, __VA_ARGS__)\n#define SPDLOG_TRACE(...) SPDLOG_LOGGER_TRACE(spdlog::default_logger_raw(), __VA_ARGS__)\n#else\n#define SPDLOG_LOGGER_TRACE(logger, ...) (void)0\n#define SPDLOG_TRACE(...) (void)0\n#endif\n\n#if SPDLOG_ACTIVE_LEVEL &lt;= SPDLOG_LEVEL_DEBUG\n#define SPDLOG_LOGGER_DEBUG(logger, ...) SPDLOG_LOGGER_CALL(logger, spdlog::level::debug, __VA_ARGS__)\n#define SPDLOG_DEBUG(...) SPDLOG_LOGGER_DEBUG(spdlog::default_logger_raw(), __VA_ARGS__)\n#else\n#define SPDLOG_LOGGER_DEBUG(logger, ...) (void)0\n#define SPDLOG_DEBUG(...) (void)0\n#endif\n</code></pre>","path":["advanced marco in c"],"tags":["c/cpp"]},{"location":"advanced-marco-in-c/#_7","level":2,"title":"重复和覆盖","text":"<p>这些是相似的： <pre><code>#define FOUR (2 + 2)\n#define FOUR         (2    +    2)\n#define FOUR (2 /* two */ + 2)\n</code></pre></p> <p>以下都是不同的宏 <pre><code>#define FOUR (2 + 2)\n#define FOUR ( 2+2 ) // 空白位置不一样 \n#define FOUR (2 * 2) // 宏的内容不一样\n#define FOUR(score,and,seven,years,ago) (2 + 2) // 入参不一样\n</code></pre></p> <p>对于使用了 <code>#undef</code> 注销过的宏，再次定义同名的宏时，要求新定义的宏不与老的相似。</p> <p>而如果说一个已经存在的宏，并没有注销，重复定义时，如果相似，则新的定义会忽略，如果不相似，编译器会报警告同时使用新定义的宏。这允许在多个文件中定义同一个宏。</p>","path":["advanced marco in c"],"tags":["c/cpp"]},{"location":"advanced-marco-in-c/#_8","level":2,"title":"最后","text":"<p>可以查看更多内置宏定义</p>","path":["advanced marco in c"],"tags":["c/cpp"]},{"location":"airplay-receiver-in-Linux/","level":1,"title":"Linux模拟airplay接收器","text":"<p>一直苦恼现在的手机没有3.5mm耳机孔，最近突然想到用airplay将音乐投到有耳机孔的电脑上听，发现有很多基于Linux的实现</p>","path":["Linux模拟airplay接收器"],"tags":["iphone"]},{"location":"aliyun-dynamic-dns/","level":1,"title":"阿里云动态设置 dns","text":"<p>如果服务器的公网ip动态变化的情况下，如何访问，甚至如何通过域名访问？ </p> <p>例如公司自己搭建的服务器如何暴露在公网上， 如果请求固定ip听说很贵， 还可以通过<code>frp</code>实现, 这里介绍2种方案</p>","path":["阿里云动态设置 dns"],"tags":["ddns","nat"]},{"location":"aliyun-dynamic-dns/#dns_1","level":2,"title":"动态dns","text":"<p>前提是服务器有出口ip, 而不是在路由器下。    * 如果服务器在路由器下， 通过设置nat,将外网访问的请求的目的ip转换为局域网'192.168..'，也能实现公网请求局域网的服务器</p> <p>阿里云（相信大多数云厂商都支持） 可以支持动态改变dns的解析地址，即通过api调用就能改变dns的解析， 这样当出口ip变化时， 立即调用api来修改dns解析  </p> <p>实现原理:</p> <ol> <li>定时检测出口ip, 例如每5分钟执行一次。 可以通过crontab和以下命令实现 <pre><code>curl https://httpbin.org/ip\n</code></pre></li> <li>通过阿里云的api操作dns</li> <li>如果服务器在内网，添加nat规则，将目的ip转换为内网ip</li> </ol> <p>这里有个现成的项目</p>","path":["阿里云动态设置 dns"],"tags":["ddns","nat"]},{"location":"aliyun-dynamic-dns/#frp","level":2,"title":"frp","text":"<p>frp 就是内网穿透了， 没有出口ip的情况下，例如在路由器下且路由器不支持nat的时候， 或者是在运营商级NAT的模式下，就可以采取这中方式。 但是前提是需要有公网的服务器</p> <p>实现原理：</p> <ol> <li>通过在公网服务器运行frp 服务端， 在没有出口ip的局域网服务器上运行frp客户端</li> <li>客户端主动去连接服务端， 连接上之后， 服务端会为客户端创建一个端口， 所有的向这个端口的请求都被转发到局域网的服务器，实现公网访问局域网的服务器</li> </ol>","path":["阿里云动态设置 dns"],"tags":["ddns","nat"]},{"location":"aliyun-dynamic-dns/#wireguard","level":2,"title":"wireguard","text":"<p>wireguard的功能更加强大，配对后就相当于互连了，不需要frp那样配置端口服务。而且自带加密，更安全。</p>","path":["阿里云动态设置 dns"],"tags":["ddns","nat"]},{"location":"aliyun-dynamic-dns/#zero-trust","level":2,"title":"zero-trust","text":"<p>研究过一会，发现这个和wireguard非常类似的功能。而且zero-trust有cloudflare提供了公网接入点，所以公网服务器的钱也省了, 再加上zero-trust自带的加密，所以是连cloudflare也不能侵入。这就比国内的NAT服务安全多了。唯一缺点估计是zero-trust的公网接入点都在国外，所以延迟会高些。</p>","path":["阿里云动态设置 dns"],"tags":["ddns","nat"]},{"location":"aliyun-dynamic-dns/#_1","level":2,"title":"总结","text":"<p>如果有出口ip, 即使经常变化， 可以使用动态dns的技术实现暴露到公网， 成本低廉。 否则使用frp,需要额外购买服务器，或者使用花生壳类似的穿透技术， 但是有被掏裤裆的风险。 有公网服务器就用wireguard， 否则用zero-trust。</p>","path":["阿里云动态设置 dns"],"tags":["ddns","nat"]},{"location":"amrnb-and-amrwb/","level":1,"title":"目的","text":"<p>最近在公司开发一个amrnb/amrwb的转码工具，在网上看了很多资料，主要是这篇AMR在IP域中的编码(rfc3267,4867) 对我帮助很大。 这里补充一下缺少和我自己的理解。</p>","path":["amrnb和amrwb的编解码"],"tags":["media"]},{"location":"amrnb-and-amrwb/#amr","level":2,"title":"AMR编码介绍","text":"<p>AMR是3GPP组织的一个音频编码规范，目前的手机都使用AMR, 比如公司的测试机华为、小米只支持amrnb/amrwb。amrnb是对窄带信号进行编码（200–3400 Hz），amrwb是对更宽的频率范围进行编码（50–7000 Hz）。  根据香农理论，采样频率要是目标频率的两倍，所以向上取整的amrnb的采样频率是8000Hz, amrwb的采样频率是16000Hz。</p>","path":["amrnb和amrwb的编解码"],"tags":["media"]},{"location":"amrnb-and-amrwb/#bitrate","level":2,"title":"bitrate","text":"<p>amrnb和amrwb有多种编码速率（bitrate），并支持在通话过程中通过CMR（codec mode request）协商来变化编码速率，不同于一般的编码器固定一种比特率。除此之外，还有没有人声时的SID（舒适噪音）模式。这时只需要发送一个Mode而不是发送无声的包，从而来降低带宽占用。</p>","path":["amrnb和amrwb的编解码"],"tags":["media"]},{"location":"amrnb-and-amrwb/#amrnb","level":3,"title":"amrnb 不同比特率时的语音帧大小","text":"Index Mode Class A bits total speech bits 0 4.75 42 95 1 5.15 49 103 2 5.9 55 118 3 6.7 58 134 4 7.4 61 148 5 7.95 75 159 6 10.2 65 204 7 12.2 81 244","path":["amrnb和amrwb的编解码"],"tags":["media"]},{"location":"amrnb-and-amrwb/#amrwb","level":3,"title":"amrwb 不同比特率的语音帧大小","text":"Index AMR-WB codec mode Total number of bits Class A Class B Class C 0 6.60 132 54 78 0 1 8.85 177 64 113 0 2 12.65 253 72 181 0 3 14.25 285 72 213 0 4 15.85 317 72 245 0 5 18.25 365 72 293 0 6 19.85 397 72 325 0 7 23.05 461 72 389 0 8 23.85 477 72 405 0","path":["amrnb和amrwb的编解码"],"tags":["media"]},{"location":"amrnb-and-amrwb/#payload-type","level":2,"title":"payload type","text":"<p>amrnb和amrwb使用的动态payload type, 所以在用wireshark分析时，需要经常调整payload-type值</p>","path":["amrnb和amrwb的编解码"],"tags":["media"]},{"location":"amrnb-and-amrwb/#align-mode","level":2,"title":"align mode","text":"<p>amrnb和amrwb在SIP协商中有两种align mode，对齐模式和节省带快模式。总结有几个区别 *  对齐模式下CMR占8位，每个TOC占8位，然后每个语音帧补齐为整字节。 *  节省带宽模式下，CMR占4位，每个TOC占6位，然后CMR + TOC + 所有语音帧加起来，最后补齐为整字节。</p> <p>以单帧的12.2kbps为例 * 语音帧为244位，对齐之后为<code>(244 + 8 - 1)/8 = 31</code>字节。加上1字节的CMR和1字节的TOC, 一共33字节。 * 语音帧为244位，加上4位CMR和6位TOC，一共为254位，对齐后为<code>(254 + 8-1)/8</code>，一种32字节字节。</p> <p>以两帧的12.2kbps为例 * 两个语音帧分别占用31字节，加上1字节的CMR和2字节的TOC, 一共 65字节。 * 两个语音帧分别占用244位， 加上4位的CMR和6 * 2位的TOC, 对齐后为<code>( 488 + 4 + 12  + 8 - 1)/8</code>，一共63字节。</p> <p>总之，对齐模式是先对齐成字节再求和，节省带宽模式是先计算<code>位和</code>再对齐成字节。特别是多帧的时候，节省带宽模式算起来更复杂。好在实际情况都是1帧。</p>","path":["amrnb和amrwb的编解码"],"tags":["media"]},{"location":"amrnb-and-amrwb/#opencore-amr","level":2,"title":"基于opencore-amr的编解码","text":"<p>开始用FFmpeg的库来做转码和推流，后来发现不支持节省带宽模式，而且还有个BUG，所以后面自己基于opencore的库写的转码功能。</p>","path":["amrnb和amrwb的编解码"],"tags":["media"]},{"location":"aria2c%20usage/","level":1,"title":"aria2c usage","text":"<p>aria2c支持很多类型的协议下载，http, bt等，支持任务列表，支持前台运行和后台运行， 还支持并发下载（单连接限速）和断点续传（前提是服务器支持）。因为现代浏览器普遍也支持断点续传和并发下载，所以aria2更适合用来批量下载。</p>","path":["aria2c usage"],"tags":["aria2"]},{"location":"aria2c%20usage/#_1","level":2,"title":"前台运行","text":"<p>就类似wget fcurl * 单个文件下载 aria2c \"下载链接\" * 文件列表下载 aria2c -i list.txt </p>","path":["aria2c usage"],"tags":["aria2"]},{"location":"aria2c%20usage/#_2","level":2,"title":"后台运行","text":"<p>aria2c 本身不支持类似<code>-d/--daemon</code>参数，所以要么在终端执行下面的命令，要么用systed来运行。 * 后台运行 aria2c -c -i list.txt -j4 --load-cookies=rapidshare &gt; /tmp/aria2c.log 2&gt;&amp;1 &amp; * 查看日志 tail -f /var/log/aria2c.log</p>","path":["aria2c usage"],"tags":["aria2"]},{"location":"aria2c%20usage/#systemd-webrpc","level":3,"title":"systemd 和 web/rpc 控制","text":"<p>创建文件~/.config/systemd/user/aria2cd.service，内容如下。这时只能通过rpc协议和aria2c交互，可以用curl和web来发送rpc。 <pre><code>[Unit]\nDescription=Aria2 Daemon\n\n[Service]\nType=simple\nExecStart=/usr/bin/aria2c --conf-path=/etc/aria2/aria2.conf\n\n[Install]\nWantedBy=default.target\n</code></pre> 我认为最好的纯静态前端YAAW for Chrome</p>","path":["aria2c usage"],"tags":["aria2"]},{"location":"aria2c%20usage/#_3","level":2,"title":"配置代理","text":"<p>有时aria2c运行在没有网络的服务器上，需要代理运行，如下添加http代理 <pre><code>all-proxy=http://ip:port\nhttp-proxy=http://ip:port\nhttps-proxy=http://ip:port\n</code></pre></p>","path":["aria2c usage"],"tags":["aria2"]},{"location":"aria2c%20usage/#_4","level":2,"title":"参考","text":"<p>https://www.linuxquestions.org/questions/linux-software-2/putting-aria2c-in-background-769997/</p>","path":["aria2c usage"],"tags":["aria2"]},{"location":"bash-envioirment/","level":1,"title":"bash 环境变量","text":"","path":["bash 环境变量"],"tags":["bash","env"]},{"location":"bash-learning/","level":1,"title":"bash使用技巧收集","text":"<p>Linux的命令行是非常强大的生产工具，现实中的问题好多可以不写复杂的编程代码而通过命令来解决, 而且不过几行代码而已  </p>","path":["bash learning"],"tags":["bash"]},{"location":"bash-learning/#shell","level":2,"title":"shell 内建命令","text":"<p>当执行which的时候，比如<code>which echo</code> 会输出'shell built-in command'而不是返回路径，就说明这个命令是内建命令 shell在执行内建命令时是直接执行，而非内建命令则fork一个子进程来执行</p>","path":["bash learning"],"tags":["bash"]},{"location":"bash-learning/#buffpipedelimiter","level":2,"title":"命令行的问题很多与缓冲buff、重定向pipe、delimiter分割符有关","text":"","path":["bash learning"],"tags":["bash"]},{"location":"bash-learning/#_1","level":2,"title":"技巧, 用命令代替编程","text":"","path":["bash learning"],"tags":["bash"]},{"location":"bash-learning/#xargs","level":3,"title":"使用xargs创建多进程并发","text":"<p>xargs可以将输入多进程并发处理，配合<code>find</code> 非常厉害。 配合wget就是一个并发爬虫了</p> <pre><code>EXAMPLES\n       find /tmp -name core -type f -print | xargs /bin/rm -f\n\n       Find files named core in or below the directory /tmp and delete them.  Note that this will work incorrectly if there are any filenames containing newlines or spaces.\n\n       find /tmp -name core -type f -print0 | xargs -0 /bin/rm -f\n\n       Find files named core in or below the directory /tmp and delete them, processing filenames in such a way that file or directory names containing spaces or newlines  are  correctly\n       handled.\n\n       find /tmp -depth -name core -type f -delete\n\n       Find  files  named  core in or below the directory /tmp and delete them, but more efficiently than in the previous example (because we avoid the need to use fork(2) and exec(2) to\n       launch rm and we don't need the extra xargs process).\n\n       cut -d: -f1 &lt; /etc/passwd | sort | xargs echo\n\n       Generates a compact listing of all the users on the system.\n</code></pre>","path":["bash learning"],"tags":["bash"]},{"location":"bash-learning/#find-exec","level":2,"title":"find -exec 用法","text":"<p><pre><code>find . -exec grep chrome {} \\;\nfind . -exec grep chrome {} +\n</code></pre> 1. \\; 是转义; 2. {} 会替换成 find出的文件名。 2. ; 和 + 的区别是： 当;时，grep命令会在每个文件名上执行一次，grep执行多次， 但+时，所有的文件名会将所有的文件名一次进行grep，grep执行一次。</p>","path":["bash learning"],"tags":["bash"]},{"location":"bash-learning/#awk-ors","level":3,"title":"使用awk ORS 分割结果","text":"<p>ls 本来是行分隔的 awk将ls的换行符变为|分割 <pre><code>ls | awk '{ ORS=\"|\"; print; }'\n</code></pre> 而<code>echo $(ls)</code> 则把ls的换行符变为空格</p>","path":["bash learning"],"tags":["bash"]},{"location":"bash-learning/#declare","level":3,"title":"使用declare 声明变量的类型和属性","text":"<p>declare可以指定变量的类型'-i'为整形，'-r'制度(等同shell的readonly)，'-g'全局变量 shell默认是字符串，使用'-i'后，数学运算不需要<code>let</code></p> <pre><code>#retry=0\ndeclare -i retry=0\nwhile [ $retry -lt 30 ] ; do\nps aux --cols=1024 | grep xxx\nif [ $? -eq 0 ] ; then\n        exit 0\nfi\nsleep 1\n#let retry=$retry+1\nretry=$retry+1\ndone\n</code></pre>","path":["bash learning"],"tags":["bash"]},{"location":"bash-safe/","level":1,"title":"bash safety","text":"<p>不管是大厂还是小厂，总能听到一些误操作新闻 那避免误操作就办法就是写脚本， 然后也有很多脚本出事的新闻, 通常有以下</p>","path":["bash safety"],"tags":["bash"]},{"location":"bash-safe/#_1","level":2,"title":"引用了不存在的变量","text":"<pre><code>#!/bin/bash\n\nABC_PATH=abc\n\n/bin/rm ${ABC_PATH}/\n</code></pre> <p>如果ABC_PATH变量被unset了， 那么就是删除系统了 不过听说<code>/bin/rm /</code> 的操作会可能被系统禁止， 但是<code>/bin/rm /*</code>则肯定能执行成功</p>","path":["bash safety"],"tags":["bash"]},{"location":"bash-safe/#_2","level":2,"title":"脚本没有输出","text":"<p>有很多公司用堡垒机来审计操作记录， 但是如果脚本没有输出，那么就不知道执行了什么命令， 再如果脚本也被删除死无对证，那就无法分析了</p>","path":["bash safety"],"tags":["bash"]},{"location":"bash-safe/#_3","level":2,"title":"解决办法","text":"","path":["bash safety"],"tags":["bash"]},{"location":"bash-safe/#bash-set-xeu","level":3,"title":"在bash 脚本前面加上   <code>set -xeu</code>","text":"<p>-x 调试模式，bash会输出所有命令 -e 遇到错误就退出 -u 引用了不存在的变量就退出</p>","path":["bash safety"],"tags":["bash"]},{"location":"bash-safe/#_4","level":3,"title":"添加默认值","text":"<p>path=${ABC_PATH-/} # default /</p> <p>这样，当ABC_PATH不存在时，就使用默认值'/'</p>","path":["bash safety"],"tags":["bash"]},{"location":"bash-safe/#_5","level":2,"title":"最好的办法","text":"<p>使用ansible， 可以对脚本进行版本管理和review， 可以避免脚本难以维护的问题 使用ide + bash 插件， 可以有提示</p>","path":["bash safety"],"tags":["bash"]},{"location":"bash-safe/#_6","level":2,"title":"良好的脚本习惯","text":"<p>除了在脚本前面加上 <code>set -xeu</code>外， 有一些建议 </p> <ol> <li>多用<code>&amp;&amp;</code>,<code>||</code> ，少用 <code>;</code> ，如果前面的命令出错，后面就不会执行， 而<code>;</code> 不管  </li> <li>善用 date， 例如将日志文件加上日期 <code>bash test.sh &gt; log_</code>date +%m_%d_%H_%M_%S``  </li> <li>脚本放在指定目录，不要与工作目录放在一起， 避免脚本自己被删， 死无对证</li> <li>定期备份</li> </ol>","path":["bash safety"],"tags":["bash"]},{"location":"bash-safe/#bash","level":1,"title":"bash 的条件判断","text":"<p>有以下脚本,当TMP 不为空的时候，才进行判断值是否大于2</p> <pre><code>if [ -n \"$TMP\" -a ${TMP} -gt 2 ];then\n        echo \"aaaa\"\nelse\n        echo \"bbbbbbbb\"\nfi\n</code></pre> <p>而当TMP 为空的时候，就会出现 <code>too many arguement</code>。这就说明了bash的执行流程，是先进行整行替换再执行（起码是整行，也许还是全文替换）。 替换后<code>[-n \"\" -a -gt 2]</code>。导致了报错。 解决这样的问题可以用默认值 TMP=${TMP:=2}, 这样当TMP为空的时候就会自动赋值为2 <pre><code>if [ -n \"$TMP\" -a ${TMP:=2} -gt 2 ];then\n        echo \"aaaa\"\nelse\n        echo \"bbbbbbbb\"\nfi\n</code></pre></p>","path":["bash safety"],"tags":["bash"]},{"location":"binary-tree-traversal/","level":1,"title":"二叉树遍历","text":"","path":["binary tree traversal"],"tags":["算法"]},{"location":"binary-tree-traversal/#_2","level":2,"title":"二叉树定义","text":"<p>二叉树的父节点最多有2个子节点，如果二叉树的所有父节点没有节点或者有2个节点，那么叫完全二叉树</p>","path":["binary tree traversal"],"tags":["算法"]},{"location":"binary-tree-traversal/#_3","level":2,"title":"二叉树的遍历方式","text":"<p>二叉树有4中遍历方式： 前序遍历， 中序， 后序， 以及层序  </p> <p>前三种可以对比着看，区别在于父节点先被访问的顺序，这里的先后都是相对于同一个树而言。 这里的访问意思是访问其值， 例如打印节点的数据：   * 前序遍历， 先父节点，再左子节点，最后是右子节点    * 中序遍历， 先左子节点， 再父节点， 最后是右子节点   * 中序遍历， 先左子节点， 再右子节点 ，最后父节点</p> <p>可见，都是先左子节点后右子节点  </p> <p>而层序遍历是从上往下，广度优先</p>","path":["binary tree traversal"],"tags":["算法"]},{"location":"binary-tree-traversal/#_4","level":2,"title":"效果","text":"<p>若有以下二叉树，则遍历结果 <pre><code>graph BT\n    A[1] --&gt; B[0]\n    C[2] --&gt; B\n    D[3] --&gt; A\n    E[4] --&gt; A\n    F[5] --&gt; C\n    G[6] --&gt; C\n    H[7] --&gt; D\n    I[8] --&gt; D\n    J[9] --&gt; E</code></pre></p> <p>层序: 0 1 2 3 4 5 6 7 8 9</p> <p>先序: 0 1 3 7 8 4 9 2 5 6 中序: 7 3 8 1 9 4 0 5 2 6 后序: 7 8 3 9 4 1 5 6 2 0 </p> <p>注意下划线，即036组成的一个树， 可以证实上面的总结  </p>","path":["binary tree traversal"],"tags":["算法"]},{"location":"binary-tree-traversal/#_5","level":2,"title":"代码实现","text":"<p>实现前三种遍历都有2种方式， 递归和使用stack</p> <p>节点数据结构 <pre><code>    def Node:\n        self.item\n        self.lchild\n        self.rchild\n</code></pre></p>","path":["binary tree traversal"],"tags":["算法"]},{"location":"binary-tree-traversal/#_6","level":3,"title":"递归实现","text":"<p>前序遍历 <pre><code>def front_recursion(root: Node):\n    if root is None:\n        return None\n    print(root.item)\n    if root.lchild is not None:\n        front_recursion(root.lchild)\n    if root.rchild is not None:\n        front_recursion(root.rchild)\n</code></pre></p> <p>中序遍历 <pre><code>def Middle_recursion(root: Node):\n    if root is None:\n        return None\n    if root.lchild is not None:\n        front_recursion(root.lchild)\n    print(root.item)\n    if root.rchild is not None:\n        front_recursion(root.rchild)\n</code></pre></p> <p>后序遍历 <pre><code>def Middle_recursion(root: Node):\n    if root is None:\n        return None\n    if root.lchild is not None:\n        front_recursion(root.lchild)\n    if root.rchild is not None:\n        front_recursion(root.rchild)\n    print(root.item)\n</code></pre></p>","path":["binary tree traversal"],"tags":["算法"]},{"location":"binary-tree-traversal/#stack","level":3,"title":"stack实现","text":"<p>前序遍历 <pre><code>def Front_stack(root: Node):\n    if root is None:\n        return None\n\n    stack = []\n    Node = root\n    stack.append(Node)\n\n    while Node or stack:\n        while Node:\n            # 访问和入栈的顺序顺序是先父节点后左节点\n            print(Node.item)\n            # 父节点入栈\n            stack.append(Node.lchild)\n            # 深度优先，找最左节点，下个循环就是先访问父节点后左子节点\n            Node = Node.lchild\n        # 这里需要好好体会，父节点和左子节点已经访问过，只剩下右节点\n        # 所以就是先左后右\n        Node = stack.pop()\n        Node = Node.rchild\n</code></pre></p> <p>中序遍历 <pre><code>def Middle_stack(root: Node):\n    if root is None:\n        return None\n\n    stack = []\n    Node = root\n    stack.append(Node)\n\n    while Node or stack:\n        while Node:\n            # 父节点入栈\n            # 左子节点入栈\n            # 但都不访问，因为压栈顺序是先父后左子，到出栈的时候再访问\n            stack.append(Node.lchild)\n            Node = Node.lchild\n\n        Node = stack.pop()\n        # 找到最左子节点了，开始出栈，所以肯定是先出左节点， 然后再出栈之后就是父节点\n        print(Node.item)\n        # 最后就是右节点， 回到第一个while 继续找右子树的最左节点\n        Node = Node.rchild\n</code></pre></p> <p>后序的stack比较复杂</p> <p>还有一个比较简单的先序stack <pre><code>def Front_stack(root: Node):\n    if root is None:\n        return None\n\n    stack = []\n    stack.append(root)\n\n    while stack:\n        Node = stack.pop()\n        print(Node.item)\n\n        # stack 先进后出，所以先压右节点\n        if Node.rchild is not None:\n            stack.append(Node.rchild)\n\n        if Node.lchild is not None:\n            stack.append(Node.lchild)\n</code></pre></p> <p>层序遍历,是广度优先的一种方式，所以使用到queue <pre><code>def Layer_queue(root: Node):\n    if root is None:\n        return None\n\n    queue = []\n    queue.append(root)\n    while queue:\n        # 取前面的\n        Node = queue.pop(0)\n        print(Node.item)\n        if Node.lchild is not None:\n            queue.append(Node.lchild)\n\n        if Node.rchild is not None:\n            queue.append(Node.rchild)\n</code></pre></p>","path":["binary tree traversal"],"tags":["算法"]},{"location":"binary-tree-traversal/#_7","level":3,"title":"后序栈遍历","text":"<p>后序遍历的顺序是先左子后右子，最后才是父节点</p> <pre><code>'''\n1. 同样先找到最左边的节点，父节点和左子节点入栈\n2. 找到最后一个左子节点之后，判断栈顶的节点，出栈顺序是先左子后父节点，所以只需要判断右子节点的情况：\n   如果栈顶节点的右子节点为空，直接打印栈顶节点。 如果栈顶节点的右子节点是上一个出栈的节点，那么说明已经访问到了右子节点，可以继续打印父节点  \n   如果栈顶的右子节点不为空也不是上一个访问的节点，所以要先去访问右子树， 将右子节点入栈，退出循环，执行第一步\n'''\ndef back_stack(self, root):\n    if root is None:\n        return None\n    stack = []\n    Tag = None\n    stack.append(root)\n    while stack:\n        Node = stack[-1]\n        while Node.lchild:\n            stack.append(Node.lchild)\n            Node = Node.lchild\n\n        while stack:\n            Node = stack[-1]\n            if Tag == Node.rchild or Node.rchild is None:\n                Node = stack.pop()\n                print(Node.item)\n                Tag = Node\n            elif Node.rchild is not None:\n                stack.append(Node.rchild)\n                break\n</code></pre>","path":["binary tree traversal"],"tags":["算法"]},{"location":"buffer-cache-too-high/","level":1,"title":"Linux 调优","text":"<p>系统原厂商是不喜欢讨论系统调优的，一方面说起来没完没了，二来比较复杂，而且私以为调优即说明系统默认不够好？</p> <p>而且SUSE的原厂规定:</p> <p>原理机制的介绍及系统调优并不在我们的技术支持范畴</p> <p>这里是一点相关介绍</p>","path":["buffer-cache too high"],"tags":["memory","linux"]},{"location":"buffer-cache-too-high/#buffercache","level":2,"title":"buffer/cache 的作用和区别","text":"<p>buffer是用于存放将要输出到disk（块设备）的数据，而cache是存放从disk上读出的数据。二者都是为提高IO性能而设计的。                                                                                                                                                        - buffer：缓冲将数据缓冲下来，解决速度慢和快的交接问题；速度快的需要通过缓冲区将数据一点一点传给速度慢的区域。                                                                                例如：从内存中将数据往硬盘中写入，并不是直接写入，而是缓冲到一定大小之后刷入硬盘中。                                                                                                          A buffer is something that has yet to be \"written\" to disk.                                                                                                                                    </p> <ul> <li>cache：缓存实现数据的重复使用，速度慢的设备需要通过缓存将经常要用到的数据缓存起来，缓存下来的数据可以提供高速的传输速度给速度快的设备。                                                     例如：将硬盘中的数据读取出来放在内存的缓存区中，这样以后再次访问同一个资源，速度会快很多。                                                                                                    A cache is something that has been \"read\" from the disk and stored for later use.                                                           </li> </ul> <p>总之buff和cache都是内存和硬盘之间的过渡，前者是写入磁盘方向，而后者是写入内存方向</p>","path":["buffer-cache too high"],"tags":["memory","linux"]},{"location":"buffer-cache-too-high/#cache","level":3,"title":"回收cache","text":"<p><pre><code>drop_caches回收一下。\n#sync;sync;sync\n#echo 3 &gt; /proc/sys/vm/drop_caches    \n</code></pre> free增加300M</p>","path":["buffer-cache too high"],"tags":["memory","linux"]},{"location":"buffer-cache-too-high/#swap","level":2,"title":"swap 介绍","text":"<p>Swap意思是交换分区，是硬盘中的一个分区。内核将内存Page移出内存到swap分区(swap out)</p> <p>swap通过 vm.swappiness 这个内核参数控制，默认值是60。<code>cat /proc/sys/vm/swappiness</code> 可以查看当前值 这个参数控制内核使用swap的优先级。该参数从0到100。</p> <p>设置该参数为0，表示只要有可能就尽力避免交换进程移出物理内存；                                                             设置该参数为100，这告诉内核疯狂的将swapout物理内存移到swap分区。 注意：设置该参数为0，并不代表禁用swap分区，只是告诉内核，能少用到swap分区就尽量少用到，设置vm.swappiness=100的话，则表示尽量使用swap分区。                                                    </p> <p>这里面涉及到当然还涉swappiness及到复杂的算法。如果以为所有物理内在用完之后，再使用swap, 实事并不是这样。以前曾经遇到过，物理内存只剩下10M了，但是依然没有使用Swap交换空间，另外一台服务器，物理内存还剩下15G，居然用了一点点Swap交换空间。 其实少量使用Swap交换空间是不会影响性能，只有当内存资源出现瓶颈或者内存泄露，进程异常时导致频繁、大量使用交换分区才会导致严重性能问题。             </p>","path":["buffer-cache too high"],"tags":["memory","linux"]},{"location":"buffer-cache-too-high/#swap_1","level":3,"title":"问题：何时使用swap","text":"<p>这个问题如上面说的，比较难说，理论上是当物理内存不够用的时候，又需要读入内存时，会将一些长时间不用的程序的内存Page 交换出去。                      但是很多时候会发现，内核即使在内存充足的情况下也是使用到swap</p>","path":["buffer-cache too high"],"tags":["memory","linux"]},{"location":"buffer-cache-too-high/#swap_2","level":3,"title":"问题: 那些东西被swap了？","text":"<p>可以看下面的测试</p>","path":["buffer-cache too high"],"tags":["memory","linux"]},{"location":"buffer-cache-too-high/#swap_3","level":3,"title":"回收swap","text":"<p>swapoff 之后执行<code>sudo sysctl vm.swappiness=0</code> 临时让内核不用swapout</p> <p><pre><code>并把swap的数据加载内存，并重启swap \n#swapoff -a\n#swapon -a\n</code></pre> 即把swap分区清空,  自测效果如下，内核版本<code>5.10.0-8-amd64</code></p> <pre><code>               total        used        free      shared  buff/cache   available\nMem:        12162380     4911564     5605744      459364     1645072     6466572\nSwap:        1000444      763040      237404\n</code></pre> <p>重启swap后 <pre><code>               total        used        free      shared  buff/cache   available\nMem:        12162380     5605800     4843176      524984     1713404     5707112\nSwap:        1000444           0     1000444\n</code></pre></p> <p>可见，停用swap后，swap的used大部分到了mem的<code>used</code>，小部分到了Mem的shared</p>","path":["buffer-cache too high"],"tags":["memory","linux"]},{"location":"buffer-cache-too-high/#_1","level":2,"title":"调优的一些有效工具","text":"<p>perf + flame火焰图: 查看运行耗时，可以查看函数调用耗时，如果是自己的程序，可以知道哪些函数需要优化 vmstat 查看磁盘io情况，使用<code>vmstat -t 3</code>命令，如果b状态的数字一直很大，那么说明磁盘阻塞严重，可能是磁盘坏了，可能是程序设计不合理</p> <p>还有top，iperf等等</p>","path":["buffer-cache too high"],"tags":["memory","linux"]},{"location":"buffer-stdbuf/","level":1,"title":"起因","text":"<p>遇到过一个面试题, 以下程序打印几个'A' <pre><code>#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n\nint main() {\n  printf(\"A\");\n  fork();\n  printf(\"A\");\n}\n</code></pre> 答案是4个,而以下是3个 <pre><code>#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n\nint main() {\n  printf(\"A\\n\");\n  fork();\n  printf(\"A\");\n}\n</code></pre> 再把上面的编译后的可执行文件重定向到文件, 则有4个'A' <pre><code>#./a.out &gt; r.log\n#cat r.log\n</code></pre> 原因就是缓冲 </p>","path":["输出缓冲和stdbuf"],"tags":["stdbuf","buffer","linux"]},{"location":"buffer-stdbuf/#linux","level":2,"title":"Linux 缓冲介绍","text":"<p>分为无缓冲、行缓冲和全缓冲</p>","path":["输出缓冲和stdbuf"],"tags":["stdbuf","buffer","linux"]},{"location":"buffer-stdbuf/#_2","level":2,"title":"演示","text":"<p>发现有些程序可以输出到屏幕，重定向到文件后，执行<code>ctl+c</code>退出后却没有任何内容，例如以下</p> <p><pre><code>#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n\nint main(void) {\n  while (1) {\n    printf(\"Hello World\\n\");\n    sleep(1);\n  }\n}\n</code></pre> 这个程序是死循环所以需要手动结束，且一直打印helloword。但如果将输出重定向到文件，</p> <p><pre><code>#./a.out &gt; r.log\n</code></pre> 当手动退出时，文件依旧是空的</p>","path":["输出缓冲和stdbuf"],"tags":["stdbuf","buffer","linux"]},{"location":"build-a-spider/","level":1,"title":"爬虫","text":"<p>这个截图是百度的爬虫爬取网站的记录。 ![[baiduspider.jpeg]]</p> <p>如何做一个最简单的爬虫？ 一条bash命令爬深圳7天天气 <pre><code>#获取7天的天气\nwget -q http://www.weather.com.cn/weather/101280601.shtml -O - \\\n| grep 'class=\"wea\"\\|^&lt;h1&gt;'  | grep -o \"&gt;.*&lt;\" | sed 's/&gt;//;s/&lt;//' \\\n| awk 'ORS=NR%2==1?\" \":\"\\n\" {print}'  \n\n7日（今天） 晴\n8日（明天） 晴\n9日（后天） 晴\n10日（周五） 晴\n11日（周六） 晴\n12日（周日） 晴\n13日（周一） 晴转小雨\n</code></pre></p>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#_2","level":3,"title":"这条命令如何写出来的","text":"<ol> <li>定目标，想好要爬什么，如爬深圳天气</li> <li>先在浏览器访问天气网站，网址http://www.weather.com.cn/， 再找到深圳7天天气的网页链接为http://www.weather.com.cn/weather/101280601.shtml</li> <li>右键菜单里选择查看网页源码，搜索天气的内容所在位置</li> <li>找规律： 日期和天气的行有特定起始内容，日期这行以<code>&lt;h1&gt;</code>开头，天气这行包含<code>class=\"wea\"</code></li> <li>格式化： 清除不要的内容，使用sed和awk</li> </ol>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#_3","level":3,"title":"拓展","text":"<p>只有这样没有意义， 不如自己在浏览器上看？ 但如果一次性查找武汉、北京、广州的天气，但网页只能查当天的，只有保存到硬盘的数据才能永远回头翻 或者如果想每天<code>自动</code>执行一遍呢？ 又或者如何自动发邮件提醒你带伞呢？ --都是可以的， 这需要更多耐心和学习     </p> <p>但因为bash处理网页比较麻烦，而且也不是今天的主题语言。</p>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#_4","level":2,"title":"关键组件","text":"<ul> <li>python</li> <li>scapy</li> <li>Beautiful Soup</li> </ul>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#python","level":2,"title":"python","text":"<p>python简单灵活的语法又有丰富的生态， 适合作为入门爬虫的编程语言</p>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#beautiful-soup","level":2,"title":"Beautiful Soup","text":"<p>早期使用python自带的request库， 就能简单地实现一个爬虫软件</p>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#scrapy","level":2,"title":"主角scrapy","text":"<p>An open source and collaborative framework for extracting the data you need from websites. In a fast, simple, yet extensible way.</p> <p>scrapy 是一套完整框架， 实现了爬取网站的许多细节工作，让我们不需要了解代码，就能爬网站。其开发商还提供爬虫托管服务， 可以将你的爬虫做成在线服务， 而bs只是一个库</p> <p>简单介绍 * 目录结构 * 配置</p>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#scrapy_1","level":3,"title":"scrapy选择器","text":"<p>选择器用来指定网页的位置，scrapy支持的选择器有两种： * css * xpath</p> <p>自己先在源码上找规律，也可以简单地使用浏览器提供的复制选择器功能  </p> <p>先手动验证, 获取列表的所有详情页链接 <pre><code>scrapy shell \"https://www.douban.com/group/search?cat=1013&amp;q=深圳租房\"  \n# xpath方式\nresponse.xpath('//td[has-class(\"td-subject\")]//a/@href').getall()\n# css方式\nresponse.css('td.td-subject').css('a::attr(href)').getall()\n</code></pre></p> <p>先手动验证, 获得下一页 <pre><code>response.css('span.next').css('a::attr(href)').get()\n# 控制台-&gt;‘Copy CSS Selector’\n# .next &gt; a:nth-child(2)\nresponse.css('.next &gt; a::attr(href)').get()\n</code></pre></p> <p>详细</p>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#_5","level":3,"title":"数据处理","text":"<p>爬到的数据可能乱和重复， 可以加个<code>清洗</code>的步骤， 在爬到数据后对数据过滤，删除不要的数据 <pre><code># 删除重复条目\nclass DuplicatesPipeline(object):\n\n    def __init__(self):\n        self.ids_seen = set()\n\n    def process_item(self, item, spider):\n        if item['title_digist'] in self.ids_seen:\n            raise DropItem(\"Duplicate item found: %s\" % item)\n        else:\n            self.ids_seen.add(item['title_digist'])\n            return item\n</code></pre></p>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#_6","level":2,"title":"具体项目 爬豆瓣租房","text":"","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#_7","level":2,"title":"使用爬虫清理百度搜索结果","text":"<p>百度搜索的有效结果只占少部分，其他是广告，视频和推荐词  </p> <p>用爬虫来提取有效结果 <pre><code># 标题\nresponse.css('#content_left &gt; div.result').css('a:nth-child(1)::text').getall()\n# 结果\nresponse.css('#content_left &gt; div.result').css('a:nth-child(1)::attr(href)').get()\n</code></pre></p>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#_8","level":2,"title":"部署成在线服务","text":"<pre><code>pip install shub\n\nshub login\nInsert your Zyte Scrapy Cloud API Key: &lt;API_KEY&gt;\n\n# Deploy the spider to Zyte Scrapy Cloud\nshub deploy\n\n# Schedule the spider for execution\nshub schedule blogspider \nSpider blogspider scheduled, watch it running here:\nhttps://app.zyte.com/p/26731/job/1/8\n\n# Retrieve the scraped data\nshub items 26731/1/8\n</code></pre>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#_9","level":2,"title":"其他问题","text":"","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#_10","level":3,"title":"登录","text":"<p>不是所有页面都能像豆瓣这样简单直接访问，有的需要登陆，这时需要设置cookie 可将浏览器的访问的请求复制为curl请求，再将curl请求转换为scrapy请求, 有工具curl2scrapy</p> <p>爬携程机票，但这样只能看最新或者最便宜的机票，无法自动订票 <pre><code>curl 'https://flights.ctrip.com/international/search/api/lowprice/calendar/getCalendarDetailList?v=0.4625948281116462' -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:78.0) Gecko/20100101 Firefox/78.0' -H 'Accept: application/json' -H 'Accept-Language: zh-CN,en-US;q=0.5' --compressed -H 'Content-Type: application/json;charset=utf-8' -H 'transactionID: 0feb04e3db5648acb409a9efaf68eb99' -H 'scope: d' -H 'Cache-Control: no-cache' -H 'Origin: https://flights.ctrip.com' -H 'Connection: keep-alive' -H 'Referer: https://flights.ctrip.com/online/list/oneway-wuh0-szx?_=1&amp;depdate=2021-12-08&amp;cabin=y_s&amp;adult=1&amp;searchid=j1043107111-1628648957090-97788Tk-0&amp;containstax=1' -H 'Cookie: _bfa=1.1638949895953.3tfx42.1.1638949895953.1638949895953.1.2; _bfs=1.2; FlightIntl=Search=[%22WUH|%E6%AD%A6%E6%B1%89(%E5%A4%A9%E6%B2%B3%E5%9B%BD%E9%99%85%E6%9C%BA%E5%9C%BA)(WUH)|477|WUH|WUH|480%22%2C%22SZX|%E6%B7%B1%E5%9C%B3(SZX)|30|SZX|480%22%2C%222021-12-09%22]; _RF1=116.30.223.163; _RSG=mtaCn0GabiBpwk2uaRD22A; _RDG=28d46524d5c5f727d530fed50e21ed2094; _RGUID=bb259100-3132-4df0-a082-35b9380aeeb3; _bfaStatus=send; MKT_Pagesource=PC; _bfaStatusPVSend=1; _bfi=p1%3D10320673302%26p2%3D10320673302%26v1%3D2%26v2%3D1' -H 'Sec-GPC: 1' -H 'TE: Trailers' --data-raw '{\"cabin\":\"Y_S\",\"flightWay\":\"S\",\"flightSegmentList\":[{\"arrivalCityCode\":\"SZX\",\"departureCityCode\":\"WUH\",\"departureDate\":\"2021-12-08\"}]}'\n</code></pre></p>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#ip","level":3,"title":"代理ip","text":"<p>爬取的时候莫名其妙 IP 就被网站封掉了，毕竟各大网站也不想自己的数据被轻易地爬走。 对于爬虫来说，为了解决封禁 IP 的问题，一个有效的方式就是使用代理，使用代理之后可以让爬虫伪装自己的真实 IP，如果使用大量的随机的代理进行爬取，那么网站就不知道是我们的爬虫一直在爬取了，这样就有效地解决了反爬的问题。</p> <p>阿布云</p>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#useragent","level":3,"title":"模拟用户代理useragent","text":"<p>User Agent中文名为用户代理，简称 UA，它是一个特殊字符串头，使得服务器能够识别客户使用的操作系统及版本、CPU 类型、浏览器及版本、浏览器渲染引擎、浏览器语言、浏览器插件等。</p> <p>可以使用自己浏览器的UA，也可以用百度蜘蛛的UA列表  但目标网站是否允许就难说了， 需要多试一试</p>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#_11","level":3,"title":"模拟浏览器","text":"<p>Selenium 是一个用于Web应用程序测试的工具。Selenium测试直接运行在浏览器中，就像真正的用户在操作一样。</p> <pre><code>cd ～/github/SeleniumLogin\npython SeleniumLogin/core/taobao.py\n</code></pre> <pre><code>def login(self, username, password, chromedriverpath, **kwargs):\n    # 基本设置\n    browser = webdriver.Chrome(options=self.chrome_opts)\n    browser.get(self.login_url)\n    driver_wait = WebDriverWait(browser, 60)\n    # 点击'亲, 请登录', 进入登录界面\n    button = driver_wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'h')))\n    button.click()\n    # 输入用户名密码\n    username_sender = driver_wait.until(EC.presence_of_element_located((By.ID, 'fm-login-id')))\n    username_sender.send_keys(username)\n    password_sender = driver_wait.until(EC.presence_of_element_located((By.ID, 'fm-login-password')))\n    password_sender.send_keys(password)\n    time.sleep(2)\n    # 检查是否出现了滑动验证码\n    try:\n        slider = browser.find_element_by_xpath(\"//span[contains(@class, 'btn_slide')]\")\n        if slider.is_displayed():\n            ActionChains(browser).click_and_hold(on_element=slider).perform()\n            ActionChains(browser).move_by_offset(xoffset=258, yoffset=0).perform()\n            ActionChains(browser).pause(0.5).release().perform()\n    except:\n        pass\n    # 点击登录按钮\n    #button = driver_wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'password-login')))\n    #button.click()\n    # 返回必要的数据\n    infos_return = {'username': username}\n    return infos_return, browser\n</code></pre>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#headless","level":3,"title":"headless","text":"<p>Splash HTTP API</p>","path":["爬虫"],"tags":["webcrawler"]},{"location":"build-a-spider/#_12","level":2,"title":"引用","text":"<p>http://c.biancheng.net/view/2011.html https://github.com/CharlesPikachu/SeleniumLogin</p>","path":["爬虫"],"tags":["webcrawler"]},{"location":"c-signal-and-exception/","level":1,"title":"c++的信号和异常","text":"<p>信号和异常都是c++程序会遇到的，以前常把信号也当异常来看待，当其实两者是截然不同的东西</p>","path":["c++ 信号和异常"],"tags":["c","cpp","signal","exception"]},{"location":"c-signal-and-exception/#_1","level":2,"title":"信号","text":"<p>信号不仅是对c++程序，而是对所有linux程序，是内核<code>在进程由内核态转用户态</code>时，检查信号槽并调用信号处理函数（用户定义或者默认）。 有些信号可以由程序处理（常见退出信号SIGINT），而有些无法处理（常见退出信号SIGABT, 段错误信号SIGSEGV），而大多信号默认是退出进程。</p>","path":["c++ 信号和异常"],"tags":["c","cpp","signal","exception"]},{"location":"c-signal-and-exception/#_2","level":2,"title":"异常","text":"<p>c++的异常是c所没有的，异常一般在出现<code>逻辑错误</code>和<code>运行时错误</code>时要抛出异常，如果没有异常处理函数，则coredump。</p>","path":["c++ 信号和异常"],"tags":["c","cpp","signal","exception"]},{"location":"c-signal-and-exception/#_3","level":2,"title":"触发方式","text":"<p>触发信号用raise，而异常用trow  <pre><code>int raise(int sig);\n</code></pre></p>","path":["c++ 信号和异常"],"tags":["c","cpp","signal","exception"]},{"location":"calculus%20learning/","level":1,"title":"calculus learning","text":"","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#x201","level":1,"title":"计算函数x^2在区间0到1之间的积分","text":"<p>要计算函数f(x)=x²在区间[0,1]上的定积分，我们可以使用积分的基本公式：</p> <p>∫(从0到1) x² dx = [x³/3]从0到1 = (1³/3) - (0³/3) = ⅓</p> <p>因此，x²在0到1区间内的积分结果是⅓。这个结果表示函数曲线与x轴在该区间内围成的面积为⅓个平方单位。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#x2","level":1,"title":"函数x^2的导函数","text":"<p>函数f(x) = x²的导函数可以通过求导法则计算：</p> <p>使用幂函数求导法则：d/dx(xⁿ) = n·xⁿ⁻¹</p> <p>因此： f'(x) = d/dx(x²) = 2x</p> <p>所以，x²的导函数是2x。这个结果表示原函数在任意点x处的瞬时变化率。</p> <p>x²的导数2x表示什么？</p> <p>x²的二阶导数是什么？</p> <p>再给我几个类似x²的导数例子</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_1","level":1,"title":"导函数和积分函数的关系","text":"","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_2","level":2,"title":"第一部分：导数和不定积分的互逆关系","text":"<ol> <li> <p>‌不定积分是导数的“逆运算”：‌</p> </li> <li> <p>如果 <code>F(x)</code> 是函数 <code>f(x)</code> 的一个‌原函数（或称反导数）‌，即 <code>F'(x) = f(x)</code>，那么函数 <code>f(x)</code> 的‌不定积分‌定义为所有原函数的集合，表示为：</p> <p><pre><code>textCopy Code\n\n∫ f(x) dx = F(x) + C\n</code></pre>    * 这里的 <code>C</code> 是任意常数，称为积分常数。因为一个函数的导数相同，其原函数之间只相差一个常数。    * ‌核心：‌ 求不定积分的过程，本质上就是寻找一个函数 <code>F(x)</code>，使得它的导数 <code>F'(x)</code> 等于被积函数 <code>f(x)</code>。‌不定积分“撤销”了导数的效果。‌ 2. ‌导数是不定积分的导数：‌</p> </li> <li> <p>如果 <code>F(x)</code> 是 <code>f(x)</code> 的一个原函数（或者说 <code>∫ f(x) dx = F(x) + C</code>），那么对这个不定积分结果求导，就会得到原来的被积函数：</p> <p><pre><code>textCopy Code\n\nd/dx [ ∫ f(x) dx ] = d/dx [F(x) + C] = F'(x) + 0 = f(x)\n</code></pre>    * ‌核心：‌ 对一个函数先积分再求导，结果会回到原点函数（被积函数）。导数“撤销”了不定积分的效果（常数 <code>C</code> 在求导时会消失）。</p> </li> </ol>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_3","level":3,"title":"总结第一部分（不定积分层面）","text":"<p>‌导数和不定积分是互逆的运算（除了相差一个常数）。‌</p> <ul> <li><code>∫ F'(x) dx = F(x) + C</code></li> <li><code>d/dx [ ∫ f(x) dx ] = f(x)</code></li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#-","level":2,"title":"第二部分：导数与定积分的关系 - 微积分基本定理的核心","text":"<p>这是微积分基本定理最具威力、最实用的部分，它建立了导数和定积分（求面积）的直接联系。</p> <ol> <li>‌构造累积函数：‌ 给定一个在区间 <code>[a, b]</code> 上连续的函数 <code>f(t)</code>。定义一个新函数 <code>F(x)</code>，它在区间 <code>[a, x]</code> 上计算 <code>f(t)</code> 曲线下的面积（<code>x</code> 在 <code>[a, b]</code> 之间）：</li> </ol> <pre><code>textCopy Code\n\nF(x) = ∫ₐˣ f(t) dt\n</code></pre> <ul> <li>这个函数 <code>F(x)</code> 被称为 <code>f(x)</code> 的‌累积函数‌或‌面积函数‌。它表示从固定起点 <code>a</code> 到可变终点 <code>x</code> 之间，曲线 <code>f(t)</code> 下的面积。</li> <li>‌关键结论：‌ 微积分基本定理指出：</li> </ul> <pre><code>textCopy Code\n\nF'(x) = d/dx [ ∫ₐˣ f(t) dt ] = f(x)\n</code></pre> <ul> <li>‌解释：‌ 累积函数 <code>F(x)</code>（即从 <code>a</code> 到 <code>x</code> 的定积分）的‌导数‌，恰好等于积分号下的原函数 <code>f</code> 在点 <code>x</code> 处的值 <code>f(x)</code>。</li> <li>‌几何意义：‌ 函数 <code>F(x)</code> 在某一点 <code>x</code> 处的变化率（导数），恰好等于曲线 <code>f(t)</code> 在该点 <code>x</code> 处的高度 <code>f(x)</code>。这意味着累积面积的增长速率就等于曲线的高度。</li> <li> <p>‌计算定积分的强大工具：‌ 这个定理的另一个等价表述提供了计算定积分的革命性方法：</p> </li> <li> <p>如果 <code>F(x)</code> 是 <code>f(x)</code> 在区间 <code>[a, b]</code> 上的‌任意一个‌原函数（即 <code>F'(x) = f(x)</code>），那么：</p> <p><pre><code>textCopy Code\n\n∫ₐᵇ f(x) dx = F(b) - F(a)\n</code></pre>    * ‌意义：‌ 要计算函数 <code>f(x)</code> 从 <code>a</code> 到 <code>b</code> 的定积分（曲线下的面积），只需要找到它的任何一个原函数 <code>F(x)</code>，然后计算该原函数在上限 <code>b</code> 的值减去在下限 <code>a</code> 的值。‌这避免了用极限定义求定积分所需的复杂计算（黎曼和）。‌    * 通常记作： <code>[F(x)]ₐᵇ</code> 或 <code>F(x) |ₐᵇ</code> 或 <code>F(b) - F(a)</code>。</p> </li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_4","level":3,"title":"用你的例子验证","text":"<ul> <li>‌导函数：‌ 你计算了 <code>f(x) = x²</code> 的导函数是 <code>f'(x) = 2x</code>。</li> <li>‌不定积分：‌</li> <li>根据第一部分，<code>2x</code> 的不定积分应该是 <code>x² + C</code>（因为 <code>d/dx (x² + C) = 2x</code>）。</li> <li><code>x²</code> 的不定积分是 <code>∫ x² dx = x³/3 + C</code>（因为 <code>d/dx (x³/3 + C) = x²</code>）。这验证了互逆关系。</li> <li>‌定积分（与导数的关系 - 第二部分）：‌</li> <li>你之前计算了 <code>∫₀¹ x² dx</code>。</li> <li>根据微积分基本定理第二部分：<ol> <li>找到 <code>f(x) = x²</code> 的一个原函数 <code>F(x) = x³/3</code>。</li> <li>计算 <code>F(1) - F(0) = (1³/3) - (0³/3) = 1/3 - 0 = 1/3</code>。</li> </ol> </li> <li>这和你之前直接计算的结果完全一致，体现了定理的强大实用性。</li> <li>‌累积函数与导数：‌</li> <li>定义累积函数 <code>F(x) = ∫₀ˣ t² dt</code>。</li> <li>根据微积分基本定理第二部分，<code>F'(x) = d/dx [ ∫₀ˣ t² dt ] = x²</code>。</li> <li>我们也知道 <code>∫₀ˣ t² dt = [t³/3]₀ˣ = x³/3</code>。</li> <li>对这个结果求导验证： <code>d/dx (x³/3) = x²</code>。完美符合定理结论 <code>F'(x) = f(x)</code>。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_5","level":2,"title":"总结","text":"<p>微积分基本定理揭示了导函数和积分函数之间深刻的、互逆的统一关系：</p> <ol> <li>‌反导数关系：‌ 不定积分是求导的逆运算（相差一个常数）。</li> <li>‌导数描述累积变化率：‌ 定积分（累积函数 <code>∫ₐˣ f(t) dt</code>）的导数等于被积函数 <code>f(x)</code>。导数描述了累积量（如面积）随上限变化的瞬时速率。</li> <li>‌原函数计算定积分：‌ 定积分 <code>∫ₐᵇ f(x) dx</code> 的值等于被积函数 <code>f(x)</code> 的任何一个原函数 <code>F(x)</code> 在积分上限 <code>b</code> 的值减去在下限 <code>a</code> 的值（<code>F(b) - F(a)</code>）。这是计算定积分最有效的方法。</li> </ol> <p>简而言之，‌微分（求导）和积分（特别是作为累计算过程的定积分）是互为逆运算的统一体‌。这个关系是微积分成为强大数学工具的基础，使我们能够通过研究变化率（导数）来理解累积量（积分），反之亦然。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_6","level":1,"title":"导数和定积分的关系图","text":"<p>以下是导数和定积分关系的可视化总结，结合几何意义与微积分基本定理的核心要点：</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_7","level":3,"title":"一、几何关系图解","text":"<ol> <li>‌导数→函数变化率‌    导数为函数曲线在某点的切线斜率（瞬时变化率），反映函数增减趋势。例如，若导数为正，原函数在该区间递增‌12。</li> <li>‌定积分→累积面积‌    定积分表示函数曲线与x轴围成的有向面积（上方为正，下方为负），是导数的“逆向累积”过程‌34。</li> </ol>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_8","level":3,"title":"二、微积分基本定理的核心关联","text":"<ol> <li>‌第一定理（导数与积分互逆）‌</li> <li>若 <code>F(x) = ∫ₐˣ f(t) dt</code>，则 <code>F'(x) = f(x)</code>，即定积分的导数等于被积函数‌45。</li> <li>‌几何意义‌：面积函数 <code>F(x)</code> 的瞬时变化率等于曲线高度 <code>f(x)</code>‌15。</li> <li>‌第二定理（计算定积分）‌</li> <li>若 <code>F(x)</code> 是 <code>f(x)</code> 的原函数，则 <code>∫ₐᵇ f(x) dx = F(b) - F(a)</code>，通过原函数差值求面积‌46。</li> </ol>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_9","level":3,"title":"三、动态关系示例","text":"<ul> <li>‌导数→积分‌：已知速度 <code>v(t)</code>（位移的导数），通过积分 <code>∫v(t) dt</code> 可求位移‌46。</li> <li>‌积分→导数‌：已知面积函数 <code>F(x)</code>，求导可得曲线高度 <code>f(x)</code>‌57。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_10","level":3,"title":"四、关键对比总结","text":"‌概念‌ ‌数学表达‌ ‌几何意义‌ ‌物理应用‌ 导数 <code>f'(x) = dy/dx</code> 切线斜率 瞬时速度、加速度 定积分 <code>∫ₐᵇ f(x) dx</code> 曲线下净面积 总位移、功 互逆关系 <code>d/dx [∫ₐˣ f(t) dt] = f(x)</code> 面积变化率=曲线高度 速度与位移的相互转化‌46 <p>通过以上图表与关系对比，可清晰理解导数与定积分如何通过微积分基本定理实现动态统一。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_11","level":1,"title":"曲线高度指的是什么","text":"<p>在微积分的几何解释中，‌曲线高度‌指的是函数 y=f(x)y = f(x)y=f(x) 在某一特定点 xxx 处的函数值 f(x)f(x)f(x)，也就是该点在坐标系中相对于 xxx-轴的垂直距离。以下是具体说明：</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#1","level":3,"title":"‌1. 曲线高度的定义‌","text":"<ul> <li>‌数学表达‌：对于函数 y=f(x)y = f(x)y=f(x)，在 x=ax = ax=a 处的曲线高度就是 f(a)f(a)f(a)。</li> <li>‌几何意义‌：</li> <li>在函数图像上，点 (a,f(a))(a, f(a))(a,f(a)) 到 xxx-轴的垂直距离为 ∣f(a)∣|f(a)|∣f(a)∣（如图1）。</li> <li>若 f(a)&gt;0f(a) &gt; 0f(a)&gt;0，高度为正（曲线位于 xxx-轴上方）；</li> <li>若 f(a)&lt;0f(a) &lt; 0f(a)&lt;0，高度为负（曲线位于 xxx-轴下方）。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#2","level":3,"title":"‌2. 与导数和积分的关系‌","text":"","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#1_1","level":4,"title":"‌（1）导数视角‌","text":"<ul> <li>导数 f′(x)f'(x)f′(x) 表示曲线在某点的‌切线斜率‌，而 f(x)f(x)f(x) 是该点的‌纵坐标值‌（高度）。</li> <li>‌动态关联‌：</li> <li>若将 f(x)f(x)f(x) 视为位置函数，f′(x)f'(x)f′(x) 是其瞬时速度（高度的变化率）。</li> <li>例如：自由落体中，高度 h(t)h(t)h(t) 的导数 h′(t)h'(t)h′(t) 是速度 v(t)v(t)v(t)。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#2_1","level":4,"title":"‌（2）积分视角‌","text":"<ul> <li>‌定积分‌ ∫abf(x)dx\\int_a^b f(x) dx∫ab​f(x)dx 是曲线 y=f(x)y = f(x)y=f(x) 与 xxx-轴之间的‌有向面积‌，其大小取决于曲线在各点的高度 f(x)f(x)f(x)（如图2）。</li> <li>‌微积分基本定理‌：</li> <li>面积函数 F(x)=∫axf(t)dtF(x) = \\int_a^x f(t) dtF(x)=∫ax​f(t)dt 的导数 F′(x)=f(x)F'(x) = f(x)F′(x)=f(x)，即面积变化率等于曲线当前高度‌12。</li> <li>‌几何解释‌：当 xxx 向右移动时，F(x)F(x)F(x) 的增加速率由 f(x)f(x)f(x) 的高度直接决定（如图3）。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#3","level":3,"title":"‌3. 物理意义中的“高度”‌","text":"<ul> <li>‌位移与速度‌：若 f(t)f(t)f(t) 表示物体在时间 ttt 时的高度，则 f′(t)f'(t)f′(t) 是速度（高度的瞬时变化率），而 ∫abf′(t)dt=f(b)−f(a)\\int_a^b f'(t) dt = f(b) - f(a)∫ab​f′(t)dt=f(b)−f(a) 是高度变化量。</li> <li>‌其他应用‌：</li> <li>经济学中，总收益曲线的“高度”是收益值，导数是边际收益。</li> <li>概率中，概率密度函数 f(x)f(x)f(x) 的“高度”反映概率分布的密度。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#4","level":3,"title":"‌4. 常见误区澄清‌","text":"<ul> <li>‌高度 ≠ 斜率‌：</li> <li>高度是函数值 f(x)f(x)f(x)（纵坐标），而斜率是导数 f′(x)f'(x)f′(x)（切线的倾斜程度）。</li> <li>例如：抛物线 y=x2y = x^2y=x2 在 x=1x = 1x=1 处高度为 111，斜率为 222。</li> <li>‌负高度的意义‌：</li> <li>当 f(x)&lt;0f(x) &lt; 0f(x)&lt;0，曲线位于 xxx-轴下方，定积分计算时会抵消正面积（如图4）。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_12","level":3,"title":"‌总结图示‌","text":"‌概念‌ ‌数学表达‌ ‌曲线高度的角色‌ 函数值 y=f(x)y = f(x)y=f(x)","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_13","level":1,"title":"导数和不定积分的关系图","text":"<p>以下是导数和不定积分关系的可视化解析，结合几何意义与微积分基本定理的核心要点：</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_14","level":3,"title":"一、核心关系图解","text":"<ol> <li>‌导数→函数变化率‌    导数为函数曲线在某点的切线斜率（瞬时变化率），反映函数增减趋势。例如，若导数为正，原函数在该区间递增‌12。</li> <li>‌不定积分→原函数族‌    不定积分是导数的逆运算，表示所有原函数的集合（相差常数C）。几何上对应斜率相同的曲线族‌34。</li> </ol>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_15","level":3,"title":"二、微积分基本定理的动态关联","text":"<ol> <li> <p>‌互逆性‌</p> </li> <li> <p>导数到积分：若 <code>F(x) = ∫f(x)dx</code>，则 <code>F'(x) = f(x)</code>，即积分后求导恢复原函数‌35。</p> </li> <li>积分到导数：若 <code>F'(x) = f(x)</code>，则 <code>∫f(x)dx = F(x) + C</code>，即导数的积分得到原函数族‌78。</li> <li> <p>‌几何意义‌</p> </li> <li> <p>导数（切线斜率）决定原函数的增减速度；</p> </li> <li>不定积分（曲线族）的每一条曲线在相同x处的斜率相等‌19。</li> </ol>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_16","level":3,"title":"三、关键对比总结","text":"‌概念‌ ‌数学表达‌ ‌几何意义‌ ‌动态关系‌ 导数 <code>f'(x) = dy/dx</code> 切线斜率（变化率） 控制原函数的瞬时变化‌29 不定积分 <code>∫f(x)dx = F(x) + C</code> 平行曲线族（斜率相同） 逆向还原导数对应的函数‌34 互逆操作 <code>d/dx[∫f(x)dx] = f(x)</code> 斜率→曲线 / 曲线→斜率 构成微积分基本定理‌56 <p>通过以上图表与动态演示，可直观理解导数与不定积分如何通过斜率与面积的互逆性实现统一‌110。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_17","level":1,"title":"能不能认为导数是点，不定积分是线，定积分是面？","text":"<p>以下是关于导数、不定积分与定积分几何意义的层级关系分析，结合数学本质与几何直观的详细说明：</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_18","level":3,"title":"一、‌导数是“点”属性‌（瞬时性）","text":"<ol> <li>‌数学定义‌    导数 f′(x)f'(x)f′(x) 是函数在某一点 xxx 处的‌瞬时变化率‌，通过极限 lim⁡Δx→0f(x+Δx)−f(x)Δx\\lim_{\\Delta x \\to 0} \\frac{f(x+\\Delta x)-f(x)}{\\Delta x}limΔx→0​Δxf(x+Δx)−f(x)​ 定义，反映函数在该点的局部行为‌12。</li> <li>‌几何意义‌</li> <li>导数对应函数图像上某点的‌切线斜率‌，是曲线在该点的线性近似‌45。</li> <li>‌物理类比‌：如瞬时速度是位移-时间曲线某点的切线斜率‌26。</li> <li>‌局限性‌：仅描述单点特性，无法直接体现整体累积效应‌13。</li> </ol>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_19","level":3,"title":"二、‌不定积分是“线”属性‌（曲线族）","text":"<ol> <li>‌数学定义‌    不定积分 ∫f(x)dx=F(x)+C\\int f(x)dx = F(x) + C∫f(x)dx=F(x)+C 是导数的逆运算，表示所有原函数的集合（相差常数 CCC）‌78。</li> <li>‌几何意义‌</li> <li>不定积分对应‌一族平行曲线‌，这些曲线在相同横坐标处的切线斜率相同（即导数相同），仅通过纵向平移（CCC 的变化）区分‌810。</li> <li>‌物理类比‌：已知速度 v(t)v(t)v(t) 求位移 s(t)s(t)s(t)，需通过初始条件确定具体曲线（如初始位置）‌711。</li> </ol>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_20","level":3,"title":"三、‌定积分是“面”属性‌（累积性）","text":"<ol> <li>‌数学定义‌    定积分 ∫abf(x)dx\\int_a^b f(x)dx∫ab​f(x)dx 是函数在区间 [a,b][a,b][a,b] 上的黎曼和极限，表示有向面积‌1213。</li> <li>‌几何意义‌</li> <li>当 f(x)≥0f(x) \\geq 0f(x)≥0，定积分是曲线与 xxx-轴围成的面积；若 f(x)f(x)f(x) 有正有负，则为净面积（正负抵消）‌1314。</li> <li>‌物理类比‌：变速运动的位移是速度-时间曲线下的面积‌1216。</li> </ol>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_21","level":3,"title":"四、三者的层级关系总结","text":"‌概念‌ ‌数学对象‌ ‌几何对应‌ ‌关键特性‌ 导数 点属性（f′(x)f'(x)f′(x)） 切线斜率 瞬时性、局部描述‌13 不定积分 线属性（F(x)+CF(x)+CF(x)+C） 平行曲线族 全局性、需初始条件‌89 定积分 面属性（∫abf(x)dx\\int_a^b f(x)dx∫ab​f(x)dx） 有向面积 累积性、与区间相关‌1314","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_22","level":3,"title":"五、‌这种比喻的合理性与局限性‌","text":"<ol> <li>‌合理性‌</li> <li>直观体现了从‌局部（点）→整体（线/面）‌的数学层次：导数刻画点的变化，积分累积为线或面‌1819。</li> <li>符合微积分基本定理：定积分通过原函数（不定积分）计算，而原函数由导数逆向求得‌813。</li> <li>‌局限性‌</li> <li>‌导数并非孤立点‌：其定义依赖邻域极限，需函数在该点附近有定义‌12。</li> <li>‌积分不限于几何量‌：定积分可表示物理量（如功、概率），不定积分可解微分方程，超出几何范畴‌712。</li> </ol> <p>综上，用“点、线、面”比喻导数、不定积分和定积分的几何特性是直观且有效的，但需注意数学定义的完整性和应用场景的广泛性‌1819。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#x2_1","level":1,"title":"列举原函数x^2的不定积分","text":"","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#x2x2x2","level":3,"title":"‌原函数 x2x^2x2 的不定积分‌","text":"","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#1_2","level":4,"title":"‌1. 基本计算‌","text":"<p>不定积分是导数的逆运算，因此求 x2x^2x2 的不定积分，即寻找一个函数 F(x)F(x)F(x)，使得：</p> <p>F′(x)=x2F'(x) = x^2F′(x)=x2</p> <p>根据幂函数积分公式：</p> <p>∫xn dx=xn+1n+1+C(n≠−1)\\int x^n \\, dx = \\frac{x^{n+1}}{n+1} + C \\quad (n \\neq -1)∫xndx=n+1xn+1​+C(n=−1)</p> <p>对于 n=2n = 2n=2：</p> <p>∫x2 dx=x33+C\\int x^2 \\, dx = \\frac{x^{3}}{3} + C∫x2dx=3x3​+C</p> <p>其中，CCC 是‌积分常数‌（因为导数会消去常数项）。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#2_2","level":4,"title":"‌2. 验证‌","text":"<p>对 F(x)=x33+CF(x) = \\frac{x^3}{3} + CF(x)=3x3​+C 求导：</p> <p>F′(x)=ddx(x33+C)=x2+0=x2F'(x) = \\frac{d}{dx} \\left( \\frac{x^3}{3} + C \\right) = x^2 + 0 = x^2F′(x)=dxd​(3x3​+C)=x2+0=x2</p> <p>验证正确。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#3_1","level":4,"title":"‌3. 几何意义‌","text":"<ul> <li>‌不定积分‌ ∫x2 dx=x33+C\\int x^2 \\, dx = \\frac{x^3}{3} + C∫x2dx=3x3​+C 表示一族‌三次抛物线‌，它们在任意点 xxx 处的斜率均为 x2x^2x2（即导数相同）。</li> <li>‌积分常数 CCC‌ 决定了曲线的垂直平移（如 C=0C=0C=0、C=1C=1C=1、C=−2C=-2C=−2 等不同曲线）。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#4_1","level":4,"title":"‌4. 示例曲线族‌","text":"CCC 取值 原函数表达式 曲线特征 C=0C = 0C=0 F(x)=x33F(x) = \\frac{x^3}{3}F(x)=3x3​ 通过原点 (0,0)(0,0)(0,0) C=1C = 1C=1 F(x)=x33+1F(x) = \\frac{x^3}{3} + 1F(x)=3x3​+1 整体上移 1 单位 C=−2C = -2C=−2 F(x)=x33−2F(x) = \\frac{x^3}{3} - 2F(x)=3x3​−2 整体下移 2 单位","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#5","level":4,"title":"‌5. 与定积分的关系‌","text":"<p>若计算定积分 ∫abx2 dx\\int_a^b x^2 \\, dx∫ab​x2dx，可直接利用原函数：</p> <p>∫abx2 dx=x33∣ab=b33−a33\\int_a^b x^2 \\, dx = \\left. \\frac{x^3}{3} \\right|_a^b = \\frac{b^3}{3} - \\frac{a^3}{3}∫ab​x2dx=3x3​​ab​=3b3​−3a3​</p> <p>‌几何意义‌：这是抛物线 y=x2y = x^2y=x2 在区间 [a,b][a,b][a,b] 下与 xxx-轴围成的面积（若 a≤ba \\leq ba≤b 且 x2≥0x^2 \\geq 0x2≥0）。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_23","level":3,"title":"‌总结‌","text":"<ul> <li>‌不定积分‌：∫x2 dx=x33+C\\int x^2 \\, dx = \\frac{x^3}{3} + C∫x2dx=3x3​+C（一族曲线）。</li> <li>‌定积分‌：∫abx2 dx=b3−a33\\int_a^b x^2 \\, dx = \\frac{b^3 - a^3}{3}∫ab​x2dx=3b3−a3​（具体面积值）。</li> <li>‌关键点‌：积分常数 CCC 反映原函数的不唯一性，而导数运算会消除常数项。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#x33","level":1,"title":"列出导函数x^3/3的不定积分","text":"","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#x33fracx333x3","level":3,"title":"‌导函数 x33\\frac{x^3}{3}3x3​ 的不定积分‌","text":"","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#1_3","level":4,"title":"‌1. 基本计算‌","text":"<p>不定积分是导数的逆运算，因此求 x33\\frac{x^3}{3}3x3​ 的不定积分，即寻找一个函数 F(x)F(x)F(x)，使得：</p> <p>F′(x)=x33F'(x) = \\frac{x^3}{3}F′(x)=3x3​</p> <p>根据幂函数积分公式：</p> <p>∫xn dx=xn+1n+1+C(n≠−1)\\int x^n \\, dx = \\frac{x^{n+1}}{n+1} + C \\quad (n \\neq -1)∫xndx=n+1xn+1​+C(n=−1)</p> <p>对于 x33\\frac{x^3}{3}3x3​，可以写成：</p> <p>∫x33 dx=13∫x3 dx=13⋅x44+C=x412+C\\int \\frac{x^3}{3} \\, dx = \\frac{1}{3} \\int x^3 \\, dx = \\frac{1}{3} \\cdot \\frac{x^{4}}{4} + C = \\frac{x^4}{12} + C∫3x3​dx=31​∫x3dx=31​⋅4x4​+C=12x4​+C</p> <p>其中，CCC 是‌积分常数‌（因为导数会消去常数项）。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#2_3","level":4,"title":"‌2. 验证‌","text":"<p>对 F(x)=x412+CF(x) = \\frac{x^4}{12} + CF(x)=12x4​+C 求导：</p> <p>F′(x)=ddx(x412+C)=4x312+0=x33F'(x) = \\frac{d}{dx} \\left( \\frac{x^4}{12} + C \\right) = \\frac{4x^3}{12} + 0 = \\frac{x^3}{3}F′(x)=dxd​(12x4​+C)=124x3​+0=3x3​</p> <p>验证正确。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#3_2","level":4,"title":"‌3. 几何意义‌","text":"<ul> <li>‌不定积分‌ ∫x33 dx=x412+C\\int \\frac{x^3}{3} \\, dx = \\frac{x^4}{12} + C∫3x3​dx=12x4​+C 表示一族‌四次曲线‌，它们在任意点 xxx 处的斜率均为 x33\\frac{x^3}{3}3x3​（即导数相同）。</li> <li>‌积分常数 CCC‌ 决定了曲线的垂直平移（如 C=0C=0C=0、C=1C=1C=1、C=−2C=-2C=−2 等不同曲线）。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#4_2","level":4,"title":"‌4. 示例曲线族‌","text":"CCC 取值 原函数表达式 曲线特征 C=0C = 0C=0 F(x)=x412F(x) = \\frac{x^4}{12}F(x)=12x4​ 通过原点 (0,0)(0,0)(0,0) C=1C = 1C=1 F(x)=x412+1F(x) = \\frac{x^4}{12} + 1F(x)=12x4​+1 整体上移 1 单位 C=−2C = -2C=−2 F(x)=x412−2F(x) = \\frac{x^4}{12} - 2F(x)=12x4​−2 整体下移 2 单位","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#5_1","level":4,"title":"‌5. 与定积分的关系‌","text":"<p>若计算定积分 ∫abx33 dx\\int_a^b \\frac{x^3}{3} \\, dx∫ab​3x3​dx，可直接利用原函数：</p> <p>∫abx33 dx=x412∣ab=b412−a412\\int_a^b \\frac{x^3}{3} \\, dx = \\left. \\frac{x^4}{12} \\right|_a^b = \\frac{b^4}{12} - \\frac{a^4}{12}∫ab​3x3​dx=12x4​​ab​=12b4​−12a4​</p> <p>‌几何意义‌：这是曲线 y=x33y = \\frac{x^3}{3}y=3x3​ 在区间 [a,b][a,b][a,b] 下与 xxx-轴围成的面积（若 x33≥0\\frac{x^3}{3} \\geq 03x3​≥0）。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_24","level":3,"title":"‌总结‌","text":"<ul> <li>‌不定积分‌：( \\int \\frac{x^3}{3} , dx = \\frac{x^4}{12}</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_25","level":1,"title":"原函数是指中学里学习的函数吗？","text":"<p>原函数（Primitive Function）与中学阶段学习的函数概念既有联系又有本质区别，具体分析如下：</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#1_4","level":3,"title":"‌1. 定义对比‌","text":"<ul> <li>‌中学函数‌   初中阶段将函数定义为“变量间的对应关系”，强调因变量 yyy 随自变量 xxx 变化的唯一性16。高中进一步抽象为集合间的映射关系 y=f(x)y=f(x)y=f(x)，但未涉及导数和积分16。</li> <li>‌原函数‌   原函数是微积分中的概念，指对于给定函数 f(x)f(x)f(x)，若存在可导函数 F(x)F(x)F(x) 满足 F′(x)=f(x)F'(x)=f(x)F′(x)=f(x)，则 F(x)F(x)F(x) 称为 f(x)f(x)f(x) 的原函数23。其核心是‌导数的逆运算‌，与中学函数的定义无直接关联68。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#2_4","level":3,"title":"‌2. 学习阶段与知识基础‌","text":"<ul> <li>‌中学函数‌   属于初等数学范畴，研究函数的定义、图像、性质（如单调性、奇偶性）及具体类型（一次、二次、指数函数等）16。</li> <li>‌原函数‌   属于高等数学内容，需以‌导数‌为基础，是积分学的核心概念，通常在大学阶段系统学习79。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#3_3","level":3,"title":"‌3. 典型应用差异‌","text":"‌对比项‌ ‌中学函数‌ ‌原函数‌ ‌核心问题‌ 求解析式、画图像、解方程 求导数的逆运算（如计算面积、解微分方程）912 ‌工具依赖‌ 代数运算、图像分析 微积分（极限、导数、积分法则）78 ‌实例‌ y=2x+1y=2x+1y=2x+1 的图像与性质 ∫2x dx=x2+C\\int 2x \\, dx = x^2 + C∫2xdx=x2+C 的求解810","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#4_3","level":3,"title":"‌4. 联系与进阶‌","text":"<ul> <li>‌衔接点‌：原函数的计算常以中学函数（如多项式、三角函数）为被积对象710。</li> <li>‌本质区别‌：原函数的存在性依赖于函数的‌连续性‌和‌可导性‌，而中学函数仅关注对应关系本身36。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_26","level":3,"title":"‌总结‌","text":"<p>原函数并非中学函数的直接延伸，而是微积分中基于导数的新概念24。两者分属不同的数学层次，前者是后者的必要基础，但研究目标和工具截然不同616。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#fx","level":1,"title":"F′(x)表示什么","text":"","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#fx_1","level":3,"title":"‌f′(x) 的数学含义‌","text":"","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#1_5","level":4,"title":"‌1. 基本定义‌","text":"<p>f′(x) 表示函数 f(x) 的‌导函数‌（简称导数），用于描述原函数 f(x) 在每一点处的瞬时变化率或斜率12。其严格定义为极限：</p> <p>f′(x)=lim⁡Δx→0f(x+Δx)−f(x)Δxf'(x) = \\lim_{\\Delta x \\to 0} \\frac{f(x+\\Delta x) - f(x)}{\\Delta x}f′(x)=Δx→0lim​Δxf(x+Δx)−f(x)​</p> <p>这一极限值反映了函数在 x 点附近的局部线性逼近特性24。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#2_5","level":4,"title":"‌2. 几何意义‌","text":"<ul> <li>‌切线斜率‌：f′(x₀) 表示函数 f(x) 在点 x₀ 处切线的斜率35。</li> <li>‌曲线变化趋势‌：</li> <li>f′(x) &gt; 0：函数在该区间单调递增7；</li> <li>f′(x) &lt; 0：函数单调递减7；</li> <li>f′(x) = 0：可能对应极值点或驻点7。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#3_4","level":4,"title":"‌3. 与导数值的区别‌","text":"<ul> <li>‌导函数 f′(x)‌：是定义在 f(x) 全体可导点上的新函数14。</li> <li>‌导数值 f′(x₀)‌：是导函数在某具体点 x₀ 的函数值，为一个常数56。例如，f′(x₀) 的导数为 0（即 [f′(x₀)]′ = 0）6。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#4_4","level":4,"title":"‌4. 高阶导数‌","text":"<ul> <li>‌二阶导数 f″(x)‌：表示导函数 f′(x) 的导数，反映原函数的凹凸性或加速度特性79。</li> <li>f″(x) &gt; 0：函数图像上凸（凹向上）；</li> <li>f″(x) &lt; 0：函数图像下凸（凹向下）7。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_27","level":3,"title":"‌总结‌","text":"<ul> <li>‌符号本质‌：f′(x) 是微积分中表示函数变化率的标准化符号，继承自函数符号体系 f(x)48。</li> <li>‌核心作用‌：通过导数可分析函数的单调性、极值、切线等性质，是连接初等数学与高等数学的关键工具</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#fxfx-y","level":1,"title":"为什么这两个相等？ F′(x)=f(x) 。是否前者是斜率，后者是y轴高度","text":"<p>你提到的等式 ‌F′(x) = f(x)‌ 是微积分基本定理（Fundamental Theorem of Calculus）的核心内容之一，它揭示了‌导数（斜率）‌和‌原函数（高度）‌之间的深刻联系。下面详细解释为什么两者相等，以及它们的几何和物理意义。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#1_6","level":3,"title":"‌1. 数学定义‌","text":"<ul> <li>‌F(x)‌ 是 ‌f(x)‌ 的一个‌原函数（不定积分）‌，即：   F(x)=∫f(x) dx+CF(x) = \\int f(x) \\, dx + CF(x)=∫f(x)dx+C</li> <li>‌F′(x)‌ 是 ‌F(x)‌ 的导数，表示 ‌F(x)‌ 在每一点的‌瞬时变化率（斜率）‌。</li> </ul> <p>根据微积分基本定理：</p> <p>F′(x)=ddx(∫f(x) dx)=f(x)F'(x) = \\frac{d}{dx} \\left( \\int f(x) \\, dx \\right) = f(x)F′(x)=dxd​(∫f(x)dx)=f(x)</p> <p>‌这意味着：‌</p> <ul> <li>‌求导‌和‌积分‌是互逆运算。</li> <li>‌F(x)‌ 的斜率（F′(x)）正好等于被积函数 ‌f(x)‌ 在该点的值。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#2_6","level":3,"title":"‌2. 几何解释‌","text":"","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#1-fx","level":4,"title":"‌(1) F(x) 是 \"面积累积函数\"‌","text":"<p>假设 ‌f(x)‌ 是一个连续函数，‌F(x)‌ 可以理解为：</p> <p>F(x)=∫axf(t) dtF(x) = \\int_a^x f(t) \\, dtF(x)=∫ax​f(t)dt</p> <p>即从某个固定点 ‌a‌ 到 ‌x‌ 之间，‌f(x)‌ 曲线下的‌面积‌（带符号，即上方为正，下方为负）。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#2-fx-fx","level":4,"title":"‌(2) F′(x) = f(x) 的直观理解‌","text":"<ul> <li>‌F(x)‌ 表示从 ‌a‌ 到 ‌x‌ 的累积面积。</li> <li>‌F′(x)‌ 是 ‌F(x)‌ 的变化率，即 ‌x‌ 稍微增加 ‌Δx‌ 时，面积的增量 ‌ΔF ≈ f(x)Δx‌。</li> <li>因此，‌F′(x)‌ 就是 ‌f(x)‌，即 ‌f(x)‌ 给出了 ‌F(x)‌ 的增长速率。</li> </ul> <p>‌举例：‌</p> <ul> <li>如果 ‌f(x)‌ 是速度，‌F(x)‌ 就是位移（位置变化）。</li> <li>‌F′(x)‌（位移的导数）= ‌f(x)‌（速度），符合物理直觉。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#3_5","level":3,"title":"‌3. 物理意义‌","text":"<ul> <li>‌f(x)‌ 可以代表：</li> <li>‌速度‌（如果 ‌F(x)‌ 是位移）</li> <li>‌加速度‌（如果 ‌F(x)‌ 是速度）</li> <li>‌功率‌（如果 ‌F(x)‌ 是能量）</li> <li>‌F′(x) = f(x)‌ 表明：</li> <li>‌变化率（导数）‌ 和 ‌累积量（积分）‌ 是同一现象的两个视角。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#4-fx-fx","level":3,"title":"‌4. 为什么不是 \"F(x) 高度，F′(x) 斜率\"？‌","text":"<ul> <li>‌F(x)‌ 确实代表 ‌y 轴高度‌（原函数的值）。</li> <li>‌F′(x)‌ 是 ‌F(x)‌ 的斜率（变化率）。</li> <li>但 ‌f(x)‌ 不是直接代表高度，而是 ‌F(x) 的斜率‌，即：   斜率=F′(x)=f(x)\\text{斜率} = F'(x) = f(x)斜率=F′(x)=f(x)   所以 ‌f(x)‌ 描述的是 ‌F(x)‌ 如何变化，而不是 ‌F(x)‌ 本身的值。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#5_2","level":3,"title":"‌5. 举例验证‌","text":"<p>‌例子1：线性函数‌</p> <ul> <li>设 ‌f(x) = 2x‌，则它的一个原函数是：   F(x)=x2+CF(x) = x^2 + CF(x)=x2+C</li> <li>计算导数：   F′(x)=2x=f(x)F'(x) = 2x = f(x)F′(x)=2x=f(x)   符合 ‌F′(x) = f(x)‌。</li> </ul> <p>‌例子2：三角函数‌</p> <ul> <li>设 ‌f(x) = cos x‌，则它的一个原函数是：   F(x)=sin⁡x+CF(x) = \\sin x + CF(x)=sinx+C</li> <li>计算导数：   F′(x)=cos⁡x=f(x)F'(x) = \\cos x = f(x)F′(x)=cosx=f(x)   仍然成立。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#6","level":3,"title":"‌6. 总结‌","text":"<ul> <li>‌F′(x) = f(x)‌ 表明：</li> <li>‌积分（求原函数）‌ 和 ‌求导‌ 是互逆运算。</li> <li>‌F(x)‌ 的斜率（F′(x)）就是被积函数 ‌f(x)‌。</li> <li>‌几何上‌：</li> <li>‌F(x)‌ 是 ‌f(x)‌ 的累积面积函数。</li> <li>‌F′(x)‌ 是 ‌f(x)‌，即面积变化的瞬时速率。</li> <li>‌物理上‌：</li> <li>如果 ‌f(x)‌ 是速度，‌F(x)‌ 就是位移，‌F′(x)‌ 又回到速度。</li> </ul> <p>这个关系是微积分的核心，连接了 ‌斜率（导数）‌ 和 ‌高度（积分）‌，使得我们可以通过导数研究函数的增长，或者通过积分计算累积量。</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#fx_2","level":1,"title":"所以F(x)指的中学的函数吗？","text":"","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#fx_3","level":3,"title":"‌F(x) 与中学函数的区别与联系‌","text":"<p>你的问题涉及微积分和中学数学的衔接，下面用清晰的对比和例子说明：</p>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#1_7","level":4,"title":"‌1. 中学的 \"函数\" 是什么？‌","text":"<ul> <li>‌定义‌：中学阶段（初等数学）的函数 ‌y = f(x)‌ 描述两个变量之间的依赖关系，例如：</li> <li>线性函数：f(x)=2x+1f(x) = 2x + 1f(x)=2x+1</li> <li>二次函数：f(x)=x2f(x) = x^2f(x)=x2</li> <li>‌核心内容‌：研究函数的‌解析式、图像、单调性、对称性‌等，‌不涉及导数和积分‌。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#2-fx","level":4,"title":"‌2. 微积分中的 F(x) 是什么？‌","text":"<ul> <li>‌定义‌：若 ‌F'(x) = f(x)‌，则 ‌F(x)‌ 称为 ‌f(x)‌ 的‌原函数‌（或不定积分）。例如：</li> <li>若 f(x)=2xf(x) = 2xf(x)=2x，则 F(x)=x2+CF(x) = x^2 + CF(x)=x2+C（因为 ddx(x2)=2x\\frac{d}{dx}(x^2) = 2xdxd​(x2)=2x）。</li> <li>‌核心内容‌：研究函数之间的‌导数与积分关系‌，属于高等数学范畴。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#3_6","level":4,"title":"‌3. 关键区别‌","text":"‌对比项‌ ‌中学函数 f(x)‌ ‌微积分中的 F(x)‌ ‌数学层次‌ 初等数学（代数、图像分析） 高等数学（微积分） ‌核心操作‌ 代入求值、画图、解方程 求导、积分、解微分方程 ‌变量关系‌ 描述 y 如何随 x 变化 描述 F(x) 如何由 f(x) 的积分得到 ‌典型问题‌ 求 f(3)f(3)f(3) 的值或函数零点 求 ∫f(x)dx\\int f(x)dx∫f(x)dx 或验证 F′(x)=f(x)F'(x) = f(x)F′(x)=f(x)","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#4_5","level":4,"title":"‌4. 联系与进阶‌","text":"<ul> <li>‌共同点‌：两者都使用 ‌f(x)、F(x)‌ 等符号表示函数关系，形式上相似。</li> <li>‌本质差异‌：</li> <li>中学的 ‌f(x)‌ 是静态的变量关系；</li> <li>微积分的 ‌F(x)‌ 是动态的（与导数、积分、变化率相关）。</li> <li>‌过渡示例‌：</li> <li>中学：已知 f(x)=3x2f(x) = 3x^2f(x)=3x2，求 f(2)=12f(2) = 12f(2)=12；</li> <li>微积分：已知 F′(x)=3x2F'(x) = 3x^2F′(x)=3x2，求 F(x)=x3+CF(x) = x^3 + CF(x)=x3+C。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#5_3","level":4,"title":"‌5. 为什么容易混淆？‌","text":"<ul> <li>‌符号相同‌：均用 ‌f(x)、F(x)‌ 表示函数，但上下文不同。</li> <li>‌中学未接触导数‌：原函数的概念需要以导数为前提，中学阶段尚未学习。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_28","level":3,"title":"‌总结‌","text":"<ul> <li>‌F(x) 不是中学的函数‌，而是微积分中由导数定义的‌原函数‌，二者属于不同数学层次。</li> <li>‌中学函数‌是微积分中 ‌f(x)‌ 的基础，而 ‌F(x)‌ 是 ‌f(x)‌ 的高阶扩展（积分形式）。</li> <li>‌类比‌：   中学的 f(x)f(x)f(x) 像“静止的照片”，而微积分的 F(x)F(x)F(x) 像“照片背后的动态变化过程”。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_29","level":1,"title":"原函数指的不定积分函数吗？","text":"","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_30","level":3,"title":"‌原函数与不定积分的关系‌","text":"","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#1_8","level":4,"title":"‌1. 定义区分‌","text":"<ul> <li>原函数‌：若 ‌F'(x) = f(x)‌，则 ‌F(x)‌ 称为 ‌f(x)‌ 的一个原函数26。</li> <li>例如，对于 f(x)=2xf(x) = 2xf(x)=2x，其原函数为 F(x)=x2+CF(x) = x^2 + CF(x)=x2+C（C为任意常数）6。</li> <li>‌不定积分‌：是 ‌f(x)‌ 的全体原函数的集合，记作 ∫f(x)dx=F(x)+C\\int f(x)dx = F(x) + C∫f(x)dx=F(x)+C（C为任意常数）13。</li> <li>不定积分强调“所有可能的原函数”，而原函数是其中的一个具体实例14。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#2_7","level":4,"title":"‌2. 联系与区别‌","text":"<ul> <li>‌联系‌：</li> <li>不定积分的结果是原函数的集合，即 ∫f(x)dx\\int f(x)dx∫f(x)dx 包含所有满足 F′(x)=f(x)F'(x) = f(x)F′(x)=f(x) 的函数34。</li> <li>两者在计算上等价，例如求 ∫2xdx\\int 2x dx∫2xdx 和求 2x2x2x 的原函数均得到 x2+Cx^2 + Cx2+C67。</li> <li>‌区别‌：</li> <li>‌原函数‌是单个函数（如 x2+3x^2 + 3x2+3），‌不定积分‌是函数族（如 x2+Cx^2 + Cx2+C）14。</li> <li>不定积分的符号 ∫\\int∫ 表示“求全体原函数”的操作，而原函数是操作的结果之一36。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#3_7","level":4,"title":"‌3. 几何意义‌","text":"<ul> <li>‌原函数‌：代表一条具体的积分曲线（如 y=x2+1y = x^2 + 1y=x2+1）46。</li> <li>‌不定积分‌：代表一族平行曲线（如 y=x2+Cy = x^2 + Cy=x2+C），这些曲线在垂直方向上平移得到46。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#4_6","level":4,"title":"‌4. 数学表述‌","text":"<ul> <li>若 F(x)F(x)F(x) 是 f(x)f(x)f(x) 的一个原函数，则不定积分可表示为：   ∫f(x)dx=F(x)+C\\int f(x)dx = F(x) + C∫f(x)dx=F(x)+C   其中 ‌C‌ 为任意常数，体现原函数的无穷性23。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#5_4","level":4,"title":"‌5. 常见误解澄清‌","text":"<ul> <li>“原函数=不定积分”：严格来说，原函数是集合中的元素，不定积分是集合本身14。  </li> <li>常数C的作用‌：不定积分中的 ‌C‌ 确保涵盖所有可能的原函数，而单个原函数对应某个特定的 ‌C‌ 值。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"calculus%20learning/#_31","level":3,"title":"‌总结‌","text":"<ul> <li>‌原函数‌ 是 ‌不定积分‌ 的一个具体实例，而不定积分是原函数的全体集合13。</li> <li>两者在微积分中紧密关联，但概念上存在个体与整体的差异47。</li> </ul>","path":["calculus learning"],"tags":["calculus"]},{"location":"carry-bit-overflow-bit/","level":1,"title":"进位位和溢出位(carry bit/overflow bit)","text":"<p>这两个标志位是运算器(alu)的组成部分，因为运算器在执行加法时，要关注两个问题：是否进位超了；是否溢出了。这两个问题很相似，但有区别。</p>","path":["进位位和溢出位(carry bit/overflow bit)"],"tags":["c"]},{"location":"carry-bit-overflow-bit/#_1","level":2,"title":"加法和减法","text":"<p>对于减法而言，实际是将减数翻转，然后执行加法。即： <pre><code>1 - 1 = 1 + (-1)\n</code></pre></p> <p>运算器做减法时要比较两数的绝对值大小再进行减法，符号设置成大的数的符号，例如 <pre><code>2 - 1 =&gt; 2 - 1 = 1 =&gt; 符号位设置成2的符号位\n1 - 2 =&gt; 2 - 1 = 1 =&gt; 符号位设置成1的符号位\n</code></pre></p> <p>数字在内存中存放的是“补码”形式，补码很多好处，对于正数而言，源码、反码、补码的二进制形式相同。补码统一了+0和-0的形式，而且补码适合做减法运算。 <pre><code>+0/-0\n原码: 0000 0000/ 1000 0000\n反码: 0000 0000/ 1111 1111 正数不变，负数的符号位不变，其它位取反\n补码: 0000 0000/10000 0000 正数不变，负数先转反码再加1，进位位丢掉后相同\n</code></pre></p>","path":["进位位和溢出位(carry bit/overflow bit)"],"tags":["c"]},{"location":"carry-bit-overflow-bit/#_2","level":2,"title":"进位标志位","text":"<p>进位位用来标志两数相加产生的进位超过了位数，例如 1+1 = 10，要多一位，如果运算器是8位的，执行 11111111+1的运算，就要进位，且超过了位数，这时候进位位就会置1。</p> <p>判断方法 Carry = (Result &gt;&gt; n) &amp; 1</p>","path":["进位位和溢出位(carry bit/overflow bit)"],"tags":["c"]},{"location":"carry-bit-overflow-bit/#_3","level":2,"title":"溢出标志位","text":"<p>溢出位只针对有符号数的运算，有符号数的第一位表示正负，0代表正，1代表负，其它位表示值。当值的部分想加产生进位时，导致符号位覆盖。</p> <p>判断方法（就8位而言） Overflow = (Result [7bit] XOR Op1[7bit] XOR Op2[7bit])</p> <p>溢出位置1时，虽然符号为不正确，但其值是正确的（包含符号位）。</p>","path":["进位位和溢出位(carry bit/overflow bit)"],"tags":["c"]},{"location":"carry-bit-overflow-bit/#_4","level":2,"title":"参考","text":"<p>源码/反码/补码 进位位/溢出位</p>","path":["进位位和溢出位(carry bit/overflow bit)"],"tags":["c"]},{"location":"change%20hostname%20of%20pve%20and%20vm/","level":1,"title":"change hostname of pve and vm","text":"<p>以前总不明白，创建虚拟机时填写的域名 example.com 的作用，直到自己用pve创建了多个虚拟机，</p>","path":["change hostname of pve and vm"],"tags":["pve"]},{"location":"change%20hostname%20of%20pve%20and%20vm/#change-domain-of-pve","level":2,"title":"change domain of pve","text":"<p>一开始我直接在系统里用hostnamectl来修改，然后发现执行pct命令时，报错没有虚拟机的配置文件，原来pct用hostname来隔离配置 <pre><code>$ pct set 110 --hostname docker.pve                                                        \nConfiguration file 'nodes/NEW_HOSTNAME/lxc/110.conf' does not exist\n</code></pre> 看官方的文档, 正确的方法要改好几个文件，于是重新改回去了。</p>","path":["change hostname of pve and vm"],"tags":["pve"]},{"location":"change%20hostname%20of%20pve%20and%20vm/#change-domain-of-lxc","level":2,"title":"change domain of lxc","text":"<p>这个开始在虚拟机里改，后来知道正确方法是用pct工具 <pre><code>pct set ID --hostname NEW_HOSTNAME\n</code></pre></p>","path":["change hostname of pve and vm"],"tags":["pve"]},{"location":"change%20hostname%20of%20pve%20and%20vm/#_1","level":2,"title":"参考","text":"<p>https://virtualizeeverything.com/2021/11/12/how-to-change-the-hostname-of-a-lxc-using-command-line-proxmox-7/</p>","path":["change hostname of pve and vm"],"tags":["pve"]},{"location":"cmake-learning/","level":1,"title":"cmake 学习","text":"","path":["cmake learning"],"tags":["cmake"]},{"location":"cmake-learning/#add_custom_command","level":2,"title":"add_custom_command 用法","text":"<p>用来定义自定义的方法, 而且有2套签名或者说触发规则 </p>","path":["cmake learning"],"tags":["cmake"]},{"location":"cmake-learning/#add_custom_target","level":3,"title":"与 <code>add_custom_target</code> 配合使用, 用于生成文件","text":"<p>这种情况下，<code>add_custom_target</code> 续要在<code>add_custom_command</code>之后出现。 语法 <pre><code>add_custom_command(OUTPUT output1 [output2 ...]\n                   COMMAND command1 [ARGS] [args1...]\n                   [COMMAND command2 [ARGS] [args2...] ...]\n                   [MAIN_DEPENDENCY depend]\n                   [DEPENDS [depends...]]\n                   [BYPRODUCTS [files...]]\n                   [IMPLICIT_DEPENDS &lt;lang1&gt; depend1\n                                    [&lt;lang2&gt; depend2] ...]\n                   [WORKING_DIRECTORY dir]\n                   [COMMENT comment]\n                   [DEPFILE depfile]\n                   [JOB_POOL job_pool]\n                   [VERBATIM] [APPEND] [USES_TERMINAL]\n                   [COMMAND_EXPAND_LISTS])\n</code></pre></p> <p>类似make的语法规则 <pre><code>target:dependency\n  command\n</code></pre> 如果<code>dependency</code>不存在，就去找生成依赖本身的规则，没有也生成依赖的规则，那么make会停止。 </p> <p>如下的例子 <pre><code> cmake_minimum_required(VERSION 3.5)\n project(test)\n add_executable(${PROJECT_NAME} main.c)\n add_custom_command(OUTPUT printout \n                    COMMAND ${CMAKE_COMMAND} -E echo compile finish\n                    VERBATIM\n                   )\n add_custom_target(finish\n                   DEPENDS printout\n                   )\n</code></pre></p> <p>finish 依赖 printout, 而<code>add_custom_command</code>定义了printout的规则，printout即为下面的command执行的输出   </p> <p>所以当生成finish目标的时候会触发上面的<code>add_custom_command</code> </p> <p>其实这种情况下， 直接将<code>add_custome_command</code>的command写到<code>add_custome_target</code>中也是一样的效果</p>","path":["cmake learning"],"tags":["cmake"]},{"location":"cmake-learning/#command-line-tool","level":3,"title":"command-line-tool","text":"<p>以上<code>add_cunstom_command</code>的两种用法都使用了<code>COMMAND ${CMAKE_COMMAND} -E</code>，这是使用了cmake内置的[命令]{https://cmake.org/cmake/help/latest/manual/cmake.1.html#run-a-command-line-tool}    </p>","path":["cmake learning"],"tags":["cmake"]},{"location":"cmake-learning/#_1","level":4,"title":"运用","text":"<p>例如生成protobuf的文件, 需要自定义方法</p> <pre><code>    # output files:\n    FOREACH (src ${proto_srcs})\n        get_filename_component(base_name ${src} NAME_WE)\n        get_filename_component(path_name ${src} PATH)\n\n        set(src \"${base_name}.proto\")\n        set(cpp \"${base_name}.pb.cc\")\n        set(hpp \"${base_name}.pb.h\")\n        set(grpc_cpp \"${base_name}.grpc.pb.cc\")\n        set(grpc_hpp \"${base_name}.grpc.pb.h\")\n\n        # custom command.\n        add_custom_command(\n            OUTPUT ${proto_cpp_dist}/${cpp} ${proto_cpp_dist}/${hpp} ${proto_hpp_dist}/${hpp}\n              ${proto_cpp_dist}/${grpc_cpp} ${proto_cpp_dist}/${grpc_hpp}\n            COMMAND ${PROTOBUF_PROTOC_EXECUTABLE}\n            ARGS ${OUTPUT_PATH}\n              --grpc_out ${proto_cpp_dist}\n              --plugin=protoc-gen-grpc=${GRPC_CPP_PLUGIN}\n              ${src} \n            DEPENDS ${src}\n            COMMAND ${CMAKE_COMMAND}\n            ARGS -E copy_if_different ${proto_cpp_dist}/${hpp} ${proto_hpp_dist}/${hpp}\n            COMMAND ${CMAKE_COMMAND}\n            ARGS -E copy_if_different  ${proto_cpp_dist}/${grpc_hpp} ${proto_hpp_dist}/${grpc_hpp}\n            WORKING_DIRECTORY ${path_name}\n            COMMENT \"${PROTOBUF_PROTOC_EXECUTABLE} --cpp_out=${proto_cpp_dist} ${src}\"\n            )\n\n        LIST(APPEND output ${proto_cpp_dist}/${cpp})\n    ENDFOREACH()\n</code></pre>","path":["cmake learning"],"tags":["cmake"]},{"location":"cmake-learning/#_2","level":3,"title":"单独使用, 编译触发","text":"<p>这个是当项目中有<code>add_library</code>或者<code>add_excutable</code>目标时可以在编译目标文件前/链接前/编译后触发 <pre><code>add_custom_command(TARGET &lt;target&gt;\n                   PRE_BUILD | PRE_LINK | POST_BUILD\n                   COMMAND command1 [ARGS] [args1...]\n                   [COMMAND command2 [ARGS] [args2...] ...]\n                   [BYPRODUCTS [files...]]\n                   [WORKING_DIRECTORY dir]\n                   [COMMENT comment]\n                   [VERBATIM] [USES_TERMINAL]\n                   [COMMAND_EXPAND_LISTS])\n</code></pre></p>","path":["cmake learning"],"tags":["cmake"]},{"location":"cmake-learning/#cmake_1","level":2,"title":"cmake 逻辑表达式","text":"","path":["cmake learning"],"tags":["cmake"]},{"location":"cmake-precompile-header/","level":1,"title":"cmake预处理头文件","text":"<p>预处理头文件是cmake 3.16添加的新功能，可以将头文件先</p> <pre><code>Precompiling header files can speed up compilation by creating a partially processed version of some header files, and then using that version during compilations rather than repeatedly parsing the original headers.\n</code></pre>","path":["cmake precompile header"],"tags":["cmake"]},{"location":"configure%20dns%20for%20pve/","level":1,"title":"为pve配置dns","text":"<p>我用闲暇台式机安装了pve, 创了一些虚拟机和lxc容器来跑本地部署的应用，例如代码管理的gitea, web应用，nginx反向代理等。 反向代理容器要访问其他容器，也要从外部访问容器，例如我的笔记本。 正好最近工作遇到些dns的问题，于是想自己搭建一个dns服务器。用来实现从外面，从容器都能通过域名来访问。就如同docker compose 里能通过容器名称来访问其他容器一样。反代nginx可以用frp等技术实现公网访问。</p>","path":["为pve配置dns"],"tags":["pve","dns"]},{"location":"configure%20dns%20for%20pve/#_1","level":2,"title":"实现效果","text":"<p>在笔记本上能访问 gitea.pve， 在nginx反代容器里也能访问 gitea.pve，但是前者得到10地址，后者得到192地址。</p>","path":["为pve配置dns"],"tags":["pve","dns"]},{"location":"configure%20dns%20for%20pve/#_2","level":2,"title":"网络规划","text":"<p>pve在安装了自动创建了网桥，桥接物理网卡，网络10.8.10.0/24，外面可以直接访问。后我自己创建了虚拟网络 192.168.10.1/24。于是每个容器和虚拟机都有两个地址，我称之外部地址和内部地址。 pve 创建网络位置在 Datacenter-&gt; pve -&gt; system -&gt; network</p>","path":["为pve配置dns"],"tags":["pve","dns"]},{"location":"configure%20dns%20for%20pve/#bind9","level":2,"title":"宿主机器上安装bind9和配置","text":"<p>在AI的帮助下，了解了bind9的view专门用来完成这样的事情。先修改文件 /etc/bind/named.conf.default-zones, 将原来的部分套上 'external view'，然后加上自定义根域名'pve'</p> <pre><code>+view \"external\" {   \n// prime the server with knowledge of the root servers\nzone \".\" {\n        type hint;\n        file \"/usr/share/dns/root.hints\";\n};\n\n...\n\n+zone \"pve\" {\n+        type master;\n+        file \"/etc/bind/db.pve.external\";\n+};\n\n+};\n</code></pre> <p>修改文件 /etc/bind/named.conf.local，原本这文件是空的，现在添加 'internal view'</p> <pre><code>//\n// Do any local configuration here\n//\n\n// Consider adding the 1918 zones here, if they are not used in your\n// organization\n//include \"/etc/bind/zones.rfc1918\";\n\n+acl \"internal-nets\" {\n+    192.168.10.0/24;    // VM subnet\n+    127.0.0.1;          // localhost\n+};\n+\n+view \"internal\" {\n+    match-clients { internal-nets; };\n+\n+    zone \"pve\" {\n+        type master;\n+        file \"/etc/bind/db.pve.internal\";\n+    };\n};\n</code></pre> <p>然后在/etc/bind/db.pve.external 中添加域名记录，ip是外部地址， 在/etc/bind/db.pve.internal添加域名记录，ip是内部地址, 内容如下 <pre><code>$TTL 86400\n@   IN  SOA ns1.pve. admin.pve. (\n        2025082701 3600 1800 1209600 86400 )\n    IN  NS  ns1.pve.\n\nns1      IN A 192.168.10.1\npve      IN A 192.168.10.1\ndocker   IN A 192.168.10.101\nfrp      IN A 192.168.10.102\ngitea    IN A 192.168.10.103\n</code></pre></p> <p>然后检查配置和更新配置 <pre><code>rndc reconfig pve\nrndc reload\n</code></pre></p> <p>注意： AI说修改了域名记录，要增加SOA号，例如 2025082701 -&gt; 2025082702</p>","path":["为pve配置dns"],"tags":["pve","dns"]},{"location":"configure%20dns%20for%20pve/#dig","level":2,"title":"dig 验证","text":"<ul> <li>在笔记本中dig @pve的ip 查询容器ip</li> <li>在pve里dig @192.168.10.1 查询容器的ip</li> </ul>","path":["为pve配置dns"],"tags":["pve","dns"]},{"location":"configure%20dns%20for%20pve/#dns","level":2,"title":"外部配合修改dns服务器","text":"<p>上面dig命令指定了dns服务器的ip, 为了让系统自动选择pve上的dns服务器来解析 *.pve 域名，要修改笔记本配置，使用的NetworkManager <pre><code>nmcli connection modify WIFI_CONNECTION ipv4.dns-search \"~pve\" \nnmcli connection modify MI-MINI_5G_D300 ipv4.dns 10.8.10.77\nnmcli connection modify MI-MINI_5G_D300 ipv4.dns-priority -1 \n</code></pre></p> <p>而我用了有以太网和wifi两个网络，我只修改了wlp5s0。通过前后 resolvectl status 对比，区别如下</p> <pre><code>Link 3 (wlp5s0)\n-    Current Scopes: LLMNR/IPv4 LLMNR/IPv6 mDNS/IPv4 mDNS/IPv6\n+    Current Scopes: DNS LLMNR/IPv4 LLMNR/IPv6 mDNS/IPv4 mDNS/IPv6\n         Protocols: -DefaultRoute +LLMNR +mDNS -DNSOverTLS DNSSEC=no/unsupported\n+       DNS Servers: 10.8.10.77\n+        DNS Domain: ~pve\n     Default Route: no\n</code></pre> <p>这样是做了dns转发，把*.pve的域名转发给10.8.10.77来处理。 效果如下 <pre><code># ping gitea.pve                  \nPING gitea.pve (10.8.10.130) 56(84) bytes of data.\n64 bytes from gitea.local (10.8.10.130): icmp_seq=1 ttl=64 time=0.588 ms\n64 bytes from gitea.local (10.8.10.130): icmp_seq=2 ttl=64 time=0.767 ms\n64 bytes from gitea.local (10.8.10.130): icmp_seq=3 ttl=64 time=2.95 ms\n</code></pre></p> <p>但是我配置 systemd-resolved 的 search 功能不生效，只能全写域名， 不能像在pve容器里那样省略'.pve'。</p>","path":["为pve配置dns"],"tags":["pve","dns"]},{"location":"configure%20dns%20for%20pve/#dns_1","level":2,"title":"内部配合修改dns服务器","text":"<p>pve创建容器时，默认拷贝宿主机的dns配置即/etc/resolve.conf，先将其修改成如下，search 的作用是简化域名 gitea.pve 成 gitea  <pre><code>nameserver 192.168.10.1\nnameserver 1.0.0.1\nsearch pve local\n</code></pre></p> <p>这样新建的容器的dns自动用搭建好的。 在已创建的容器里找到dns选项，手动修改。效果 <pre><code># ping gitea\nPING gitea.pve (192.168.10.103) 56(84) bytes of data.\n64 bytes from 192.168.10.103 (192.168.10.103): icmp_seq=1 ttl=64 time=0.022 ms\n64 bytes from 192.168.10.103 (192.168.10.103): icmp_seq=2 ttl=64 time=0.046 ms\n</code></pre></p>","path":["为pve配置dns"],"tags":["pve","dns"]},{"location":"connect_raspberry_to_arduino_via_i2c/","level":1,"title":"connect raspberry and arduino via i2c","text":"","path":["connect raspberry and arduino via i2c"],"tags":["i2c","arduino"]},{"location":"connect_raspberry_to_arduino_via_i2c/#_1","level":2,"title":"准备","text":"<p>先接线，然后启动 arduino, 最后在树莓派中验证和读写。</p>","path":["connect raspberry and arduino via i2c"],"tags":["i2c","arduino"]},{"location":"connect_raspberry_to_arduino_via_i2c/#gnd-sda-scl","level":3,"title":"连接两个设备的GND SDA SCL","text":"<p>树莓派的SDA连arduino的SDA，SCL接SCL，这跟串口的接线不一样（RX接TX,TX接RX）。</p> <p></p> <p></p>","path":["connect raspberry and arduino via i2c"],"tags":["i2c","arduino"]},{"location":"connect_raspberry_to_arduino_via_i2c/#arduino","level":3,"title":"启动arduino","text":"<p>arduino 从端代码，注册了i2c的地址为0x08</p> <pre><code>#include &lt;Wire.h&gt;\n#define SLAVE_ADDRESS 0x08\nbyte data_to_echo = 0;\nvoid setup()\n{\n  Wire.begin(SLAVE_ADDRESS);\n  Wire.onReceive(receiveData);\n  Wire.onRequest(sendData);\n}\nvoid loop() { }\nvoid receiveData(int bytecount)\n{\n  for (int i = 0; i &lt; bytecount; i++) {\n    data_to_echo = Wire.read();\n  }\n}\nvoid sendData()\n{\n  Wire.write(data_to_echo);\n}\n</code></pre>","path":["connect raspberry and arduino via i2c"],"tags":["i2c","arduino"]},{"location":"connect_raspberry_to_arduino_via_i2c/#i2c","level":3,"title":"树莓派开启i2c","text":"<p>进入树莓派终端执行<code>raspi-config</code> 开启I2c功能，重启后执行命令<code>i2cdetect -y 1</code>，可以看到bus上的设备。</p>","path":["connect raspberry and arduino via i2c"],"tags":["i2c","arduino"]},{"location":"connect_raspberry_to_arduino_via_i2c/#master","level":3,"title":"树莓派的master端读写操作代码","text":"<pre><code>#include &lt;linux/i2c-dev.h&gt;\n#include &lt;i2c/smbus.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;sys/ioctl.h&gt;\n\n#define DEVICE_ID 0x08\nint main (int argc, char **argv) {\n    // Setup I2C communication\n    int fd = open(\"/dev/i2c-1\", O_RDWR);\n    if (fd == -1) {\n        printf(\"Failed to init I2C communication.\\n\");\n        return -1;\n    }\n    ioctl (fd, I2C_SLAVE, DEVICE_ID);\n    printf(\"I2C communication successfully setup.\\n\");\n    // Send data to arduino\n    uint8_t data_to_send = 17;\n    i2c_smbus_write_byte(fd, data_to_send);\n    // Read data from arduino\n    int received_data = i2c_smbus_read_byte(fd);\n    printf(\"Data received: %d\\n\", received_data);\n    if (received_data == data_to_send) {\n       printf(\"Success!\\n\");\n    }\n    close(fd);\n    return 0;\n}\n</code></pre>","path":["connect raspberry and arduino via i2c"],"tags":["i2c","arduino"]},{"location":"container-tech/","level":1,"title":"容器的命名空间","text":"<p>容器是利用'cgroup'和'namespace' 实现软件级的虚拟化，产品有lxc和docker。不同与全虚拟化和半虚拟化，这些是硬件辅助的半虚拟化Zen(Zen也有全虚拟化)和全虚拟化kvm  因为容器使用主机内核，不存在特权指令翻译，所以从性能上比较，容器是最高效的，其次是kvm, Zen</p>","path":["容器的命名空间"],"tags":["docker","namespace"]},{"location":"container-tech/#cgroupnamespace","level":2,"title":"cgroup和namespace","text":"<p>这两个是容器技术的根基，包括Docker, lxc。实际上docker开始用的lxc，后来用go重新写了libcontainer来实现控制这两个东西 简单来说，cgroup实现对进程组的资源的限制和监控，而namespace如同c++里面类似，实现了进程组之间的隔离</p> <p>但除此之外, 虚拟化系统时则还需要rootfs支持</p>","path":["容器的命名空间"],"tags":["docker","namespace"]},{"location":"container-tech/#lxcdocker","level":2,"title":"LXC和Docker","text":"<p>lxc代码合入了内核，其原理和Docker非常类似, 不过Docker有比较丰富的全套工具和方便的api   </p>","path":["容器的命名空间"],"tags":["docker","namespace"]},{"location":"container-tech/#nsenter","level":2,"title":"nsenter命令的使用","text":"<p>容器技术都使用到了namespace, 而nsenter可以操作namespace, 进入容器内部，以下都一docker容器为例  </p> <p>使用命令, 获取到容器的首进程pid <pre><code>docker inspect --format '{{.State.Pid}}' containername\n3015\n</code></pre></p> <p>然后可以使用nsenter来进入容器，如同<code>docker exec</code> 一样 <pre><code>$ pwd\n/home/user\n$ sudo nsenter -t 3015 -m  pwd\n/\n</code></pre></p> <p><code>-m</code>表示挂载命名空间，这样就能访问docker里的进程的文件系统，所以能正确打印出容器进程的当前目录 <code>-t</code>表示目标进程，nsenter可以获取以下命名空间。 跟通过执行<code>ls /proc/self/ns</code>所看到的差不多，这里self是命令本身pid <pre><code>/proc/pid/ns/mnt    the mount namespace\n/proc/pid/ns/uts    the UTS namespace\n/proc/pid/ns/ipc    the IPC namespace\n/proc/pid/ns/net    the network namespace\n/proc/pid/ns/pid    the PID namespace\n/proc/pid/ns/user   the user namespace\n/proc/pid/ns/cgroup the cgroup namespace\n/proc/pid/ns/time   the time namespace\n/proc/pid/root      the root directory\n/proc/pid/cwd       the working directory respectively\n</code></pre> 上面的每项都有对应的参数，而'-a'表示进入上面的所有命名空间</p>","path":["容器的命名空间"],"tags":["docker","namespace"]},{"location":"cpp-cas/","level":1,"title":"CPP原子操作","text":"","path":["CPP原子操作"],"tags":["c/cpp","atomic"]},{"location":"cpp-cas/#_1","level":2,"title":"无锁队列","text":"","path":["CPP原子操作"],"tags":["c/cpp","atomic"]},{"location":"cpp-cas/#atomic","level":2,"title":"atomic","text":"<pre><code>      void\n      store(__pointer_type __p,\n        memory_order __m = memory_order_seq_cst) noexcept\n      { return _M_b.store(__p, __m); }\n\n      void\n      store(__pointer_type __p,\n        memory_order __m = memory_order_seq_cst) volatile noexcept\n      { return _M_b.store(__p, __m); }\n\n      __pointer_type\n      load(memory_order __m = memory_order_seq_cst) const noexcept\n      { return _M_b.load(__m); }\n\n      __pointer_type\n      load(memory_order __m = memory_order_seq_cst) const volatile noexcept\n      { return _M_b.load(__m); }\n\n      __pointer_type\n      exchange(__pointer_type __p,\n           memory_order __m = memory_order_seq_cst) noexcept\n      { return _M_b.exchange(__p, __m); }\n</code></pre>","path":["CPP原子操作"],"tags":["c/cpp","atomic"]},{"location":"cpp-cas/#cpp_1","level":2,"title":"cpp实现","text":"<pre><code>atomic::compare_exchange_weak\n</code></pre>","path":["CPP原子操作"],"tags":["c/cpp","atomic"]},{"location":"cpp-cas/#memory_order","level":2,"title":"memory_order","text":"<ul> <li>memory_order_relaxed</li> <li>memory_order_seq_cst</li> </ul>","path":["CPP原子操作"],"tags":["c/cpp","atomic"]},{"location":"cpp-template-programing/","level":1,"title":"模板编程","text":"<p>模板编程是其它高级语言没有的技术, 也称为范型编程，元编程(meta programing), stl的基石。这种对类型的泛化相当于在编程之上编程</p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#_2","level":2,"title":"概述","text":"<p>模板可以作用于函数和类，即能泛化<code>类型</code>，也可以泛化<code>大小</code> <pre><code> template &lt;typename T, int N&gt; void foo() { T t[N]; }\n template &lt;typename T, int N&gt; struct Foo { T t[N]; };\n\n int main() {\n    // array of two int\n    foo&lt;int, 2&gt;();\n    // class has a array of two int \n    Foo&lt;int, 2&gt; F;\n  } \n</code></pre></p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#_3","level":2,"title":"模板的特化","text":"<p>跟泛化相反的方向，叫特化，编译器会优先使用特化的版本, 而特化有2个方向，<code>类型特化</code>和<code>范围特化</code> </p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#_4","level":3,"title":"类型特化","text":"<p>对于特化类型个数的不同，分为偏特化和全特化，全特化即为所有类型都指定，特化类型越多匹配优先级越高  注意：模板函数不能偏特化</p> <pre><code>template&lt;typename T1, typename T2&gt; struct Foo{};\ntemplate&lt;typename T2&gt; struct Foo&lt;int, T2&gt; {};\n// 全特化\ntemplate&lt;&gt; struct Foo&lt;int,int&gt;{};\n</code></pre> <p>例如`Foo foo'，编译器会使用第三个版本","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#_5","level":3,"title":"范围特化","text":"<p>比如常见的指针和引用，这和int, float, class 都是无关的，属于另个维度，也可以说是范围, 在stl为兼容指针做大量的工作  </p> <p><pre><code>template &lt;typename T, typename N&gt; struct Foo&lt;T *, N&gt; {};\n</code></pre> 这样'Foo foo'会使用这个版本 <p>还例如指定对大小的特例化 <pre><code>//模板\ntemplate&lt;int n&gt; foo(){}\n\n//值特例化\ntemplate&lt;&gt; foo&lt;10&gt; foo(){}\n</code></pre> 那么如果调用<code>foo&lt;10&gt;();</code>时，优先匹配特例化版本</p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#_6","level":3,"title":"函数匹配优先级","text":"<p>在函数调用时，普通函数的匹配优先级高于模板函数 <pre><code>template &lt;typename T&gt; void f(T) { std::cout &lt;&lt; \"temp\\n\"; }\nvoid f(int d) { std::cout &lt;&lt; \"temp1\\n\"; }\ntemplate &lt;&gt; void f(int d) { std::cout &lt;&lt; \"temp2\\n\"; }\n\nf(1); // temp1\n</code></pre></p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#_7","level":3,"title":"自定义类型的范围特化","text":"<p>上面讲的是指针类型和引用类型两种，但如果是自定义类型，那就无穷无尽了，所以模板编程也是'图灵完备'的</p> <p>例如以下，创建了一个自定义的类型来包装基本类型(int,float)，这样可以有自定义类型的特化版本 <pre><code>  template &lt;typename T&gt; struct Decor { using type = T; };\n  template &lt;typename T&gt; struct Strip { using type = T; };\n  template &lt;typename T&gt; struct Strip&lt;Decor&lt;T&gt;&gt; { using type = T; };\n  template &lt;typename T&gt; using StripDecor = typename Strip&lt;T&gt;::type;\n\n  template &lt;typename T&gt; class Row {};\n\n  int main() {\n    using nodecor = Row&lt;int&gt;;\n    using decor = Decor&lt;Row&lt;int&gt;&gt;;\n    // 虽底层同为int, 但nodecor 类型不同于decor类型\n    static_assert(std::is_same&lt;col&gt;, nocol&gt;::value);\n    // 通过Strip取出其底层类型\n    static_assert(std::is_same&lt;StripDecor&lt;col&gt;, nocol&gt;::value);\n    return 0;\n  }\n</code></pre></p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#_8","level":3,"title":"模板的声明定义分离","text":"<ol> <li>由于template用来生成函数和类，所以编译器需要同时知道template的类型和其细节，所以模板函数不支持将定义放到源文件中</li> <li>而且编译器通常是以cpp为编译单元，当编译模板cpp时不知道调用cpp, 编译调用cpp时，不知道模板cpp。所以模板函数不支持将定义放到源文件中</li> <li>对于模板类可以将成员函数的定义放到源文件，但要为每个成员函数都添加'template'限定, 而且要为实例添加特例化。</li> <li>显式特例化支持只声明不定义，而在源文件中为每种所需的类型都特例化，即与3相同。其实显示特例化是不需要特例化而强制特例化。 </li> </ol> <p>如下，模板类的定义放到cpp中，这样会报错，因为在编译call_foo.cpp时不知到模板定义, 因为没有生成过int版本的Foo。 为此，必须在foo.cpp里添加<code>template class Foo&lt;int&gt;</code>, 如同4，实在吃力不讨好。 <pre><code>// foo.h\n    template&lt;typename T&gt;\n    class Foo {\n    public:\n      Foo();\n      void someMethod(T x);\n    private:\n      T x;\n    };\n\n// foo.cpp\n    template&lt;typename T&gt;\n    Foo&lt;T&gt;::Foo()\n    {\n      // ...\n    }\n    template&lt;typename T&gt;\n    void Foo&lt;T&gt;::someMethod(T x)\n    {\n      // ...\n    }\n\n// call_foo.cpp\n    void blah_blah_blah()\n    {\n      // ...\n      Foo&lt;int&gt; f;\n      f.someMethod(5);\n      // ...\n    }\n</code></pre></p> <p>当然把模板的定义放到头文件中会增加可执行文件的体积。</p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#_9","level":4,"title":"实际运用","text":"<p>grpc 能以流和非流方式传输，而grpc参数protobuf消息类型是另一个范围。那么要封装grpc方法, 需要封装流+类型</p> <p>举例protobuf的消息类型有string, fixed32 - string - fixed32 - Stream - Stream <p>通过上面的偏特化可以即能区分流和非流又能区分类型</p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#_10","level":3,"title":"赘述一下模板的类型","text":"<p>上面的模板类型T都是实际编程时定义的类型，但作为图灵完备的模板编程，未决的template类型也可以作为template类型</p> <p>如下是一个模板用另一个模板来特例化 <pre><code>template &lt;typename T&gt; struct Upper {};\ntemplate &lt;template &lt;typename&gt; class T&gt; struct Lower {};\n\ntemplate&lt;typename T&gt;\nLower&lt;Upper&lt;T&gt;&gt; l;\n</code></pre></p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#variadic-templates","level":2,"title":"可变模版variadic templates","text":"<p>c中有可变参数<code>...</code>和gcc内置<code>__VA_ARGS__</code>宏定义, 实现不同个数的变量打印。这是由编译期实现的，会将format的格式符替换成参数 <pre><code>int printf ( const char * format, ... );\n</code></pre></p> <p>c++有模版，而且在c++11之后引入了动态参数模版，即模版函数或类可以使用动态参数</p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#1","level":3,"title":"实际运用1","text":"<p>在实际项目中手动跑单元测试用例的时候，不希望再去看日志文件，而是想日志直接输出到终端, 有以下办法</p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#c11","level":4,"title":"c++11及以上标准","text":"<p>可以使用动态参数模版替换原本的日志打印函数 <pre><code>#undef log_debug\n\ntemplate&lt;typename First, typename ...Rest&gt;\nvoid log_debug(First &amp;&amp; first, Rest &amp;&amp; ... rest){\n  std::cout &lt;&lt; fmt::format(first, rest ...) &lt;&lt; std::endl;\n}\n\n// 这时日志就直接输出到终端了, 这里使用了fmt库\nlog_debug(\"aasdas{}\", \"bbbb\");\n</code></pre></p> <p>也可简单写成 <pre><code>template&lt;typename ...Args&gt;\nvoid log_debug(Args&amp;&amp; ...args){\n    std::cout &lt;&lt; fmt::format(args...) &lt;&lt; std::endl;\n}\n</code></pre></p> <p>如果不使用fmt格式化，还可以用 <pre><code>#undef log_debug\n// 定义一个空函数\nvoid log_debug(){}\n\ntemplate&lt;typename First, typename Rest&gt;\nvoid log_debug(First&amp;&amp; first, Arg&amp;&amp; ...arg){\n    std::cout &lt;&lt; first;\n    log_debug(arg...);\n}\n</code></pre> 需要解释一下，函数<code>log_debug()</code>必须要先声明，因为模版实例化的的最终要调用这个无参的函数 模拟一下堆栈, 因为参数在每次递归时减少一个，所以最终是0个参数 <pre><code>log_debug(1, 0.2, \"aaa\");\nlog_debug(0.2, \"aaa\");\nlog_debug(\"aaa\");\nlog_debug();\n</code></pre></p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#c11_1","level":4,"title":"c++11以前的标准","text":"<p>可以使用宏定义来替换了, 然后需要重载<code>,</code>方法 <pre><code>#define log_debug(...) std::cout , __VA_ARGS__ , std::endl\n\ntemplate &lt;typename T&gt;\nstd::ostream&amp; operator,(std::ostream&amp; out, const T&amp; t) {\n  out &lt;&lt; t;\n  return out;\n}\n\n//overloaded version to handle all those special std::endl and others...\nstd::ostream&amp; operator,(std::ostream&amp; out, std::ostream&amp;(*f)(std::ostream&amp;)) {\n  out &lt;&lt; f;\n  return out;\n}\n</code></pre></p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#c","level":4,"title":"直接用c的方式","text":"<p>因为printf是支持varidic的 <pre><code>#undef log_debug\n\n#define log_debug(...) printf(__VA_ARGS__), printf(\"\\n\")\n\nint main() {\n  log_debug(\"example\",\"output\",\"filler\",\"text\");\n  return 0;\n}\n</code></pre></p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#c17-fold-expression","level":4,"title":"c++17 引入了<code>fold expression</code>","text":"<p>可以改写为 <pre><code>template&lt;typename ...Args&gt;\nvoid log_debug(Args &amp;&amp; ...args)\n{\n    (std::cout &lt;&lt; ... &lt;&lt; args);\n}\n</code></pre></p> <p>动态参数模版除了以上的用法，还有更多用处, 例如<code>std::tupe</code>的实现</p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#2","level":3,"title":"实际运用2","text":"","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#_11","level":4,"title":"使用模板生成并发代码","text":"<p>以下代码实现复制二维数组， <pre><code>for( size_t ch=0 ; ch&lt;channelNum ; ++ch ) {\n    for( size_t i=0; i&lt;length ; ++i ) {\n        out[ch][i]=in[ch][i];\n    }\n}\n</code></pre></p> <p>但以下理论更快，没有两层for，前提是知道channel大小 <pre><code>for(size_t i=0;i&lt;length;++i) {\n    out[0][i]=in[0][i];\n    out[1][i]=in[1][i];\n    out[2][i]=in[2][i];\n    out[3][i]=in[3][i];\n}\n</code></pre></p> <p>但如果用模板，就不需要知道channel大小，自动生成上面的代码</p> <pre><code>template &lt;int count&gt; class Copy {\npublic:\n  static inline void go(float **const out, float **const in, int i) {\n    Copy&lt;count - 1&gt;::go(out, in, i);\n    out[count - 1][i] = in[count - 1][i];\n  }\n};\n\ntemplate &lt;&gt; class Copy&lt;0&gt; {\npublic:\n  static inline void go(float **const, float **const, int) {}\n};\n\ntemplate &lt;int channelNum&gt;\nvoid parall_copy(float **out, float **in, size_t length) {\n  for (size_t i = 0; i &lt; length; ++i) {\n    Copy&lt;channelNum&gt;::go(out, in, i);\n  }\n}\n</code></pre> <p>需要提醒的，如同打印日志的，0的特例化不能省，否则编译出错</p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#3","level":3,"title":"实际运用3 工厂模式","text":"<p>在使用spdlog时发现有使用到template未决名, 用来实现两个维度的工厂模式。</p> <p>第一层提供两种sink的工厂，而其factory是未决名，所以要加上<code>Factory::template</code>消歧义，不然<code>&lt;</code>会当成小于号  </p> <pre><code>//\n// factory functions\n//\ntemplate&lt;typename Factory = default_factory&gt;\ninline std::shared_ptr&lt;logger&gt; basic_logger_mt(const std::string &amp;logger_name, const filename_t &amp;filename, bool truncate = false)\n{\n    return Factory::template create&lt;sinks::basic_file_sink_mt&gt;(logger_name, filename, truncate);\n}\n\ntemplate&lt;typename Factory = default_factory&gt;\ninline std::shared_ptr&lt;logger&gt; basic_logger_st(const std::string &amp;logger_name, const filename_t &amp;filename, bool truncate = false)\n{\n    return Factory::template create&lt;sinks::basic_file_sink_st&gt;(logger_name, filename, truncate);\n}\n</code></pre> <p>此时factory可以是<code>synchronous_factory</code>, 也可以是异步版本，但这需要用户自己实现。 <pre><code>// Default logger factory-  creates synchronous loggers\nstruct synchronous_factory\n{\n    template&lt;typename Sink, typename... SinkArgs&gt;\n    static std::shared_ptr&lt;spdlog::logger&gt; create(std::string logger_name, SinkArgs &amp;&amp;... args)\n    {\n        auto sink = std::make_shared&lt;Sink&gt;(std::forward&lt;SinkArgs&gt;(args)...);\n        auto new_logger = std::make_shared&lt;logger&gt;(std::move(logger_name), std::move(sink));\n        details::registry::instance().initialize_logger(new_logger);\n        return new_logger;\n    }\n};\n\nusing default_factory = synchronous_factory;\n</code></pre></p> <p>简化为下面的demo，固然可以直接使用call_dd的方式，但维度只有一个。而call_dd2则有2个维度了 但必须使用<code>T::template</code>消歧义, 因为此时的foo未决名, 不知道是那个类里面的foo。 <pre><code>  struct AA {\n    template &lt;typename cc&gt; static void foo() { std::cout &lt;&lt; \"dd::foo\\n\"; };\n  };\n\n  struct BB {\n    template &lt;typename cc&gt; static void foo() { std::cout &lt;&lt; \"dd::foo\\n\"; };\n  };\n\n  template &lt;typename T&gt; void call_dd() { AA::foo&lt;T&gt;(); }\n  template &lt;typename T, typename K&gt; void call_dd2() { T::template foo&lt;K&gt;(); }\n\n  int main() {\n    call_dd&lt;void&gt;();\n    call_dd2&lt;AA&gt;();\n    call_dd2&lt;AA, int&gt;();\n    call_dd2&lt;BB, long&gt;();\n  }\n</code></pre></p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#_12","level":2,"title":"模版与宏定义、虚函数的区别","text":"<ol> <li>宏定义在预处理期执行，模板在编译期执行，而虚函数也称动态绑定在运行时执行</li> <li>宏和模板都将运行时的工作提前了，用编译时间换取运行效率</li> <li>宏定义没有类型检查，这点模板比较好</li> <li>模板虽然会延长编译时间，但当编译期实例化类型后，查找模板函数和查找普通函数的速度几乎相同</li> </ol>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#dependent-name","level":2,"title":"待决名dependent name","text":"<ol> <li>待决名的意思是在定义的地方，类型还不能决断，需要延后到实例化确定时。而非待决名指类型在定义的地方已经确定。  </li> <li>延后将导致此时无法在定义点进行错误检查，以及消除<code>typename</code>和<code>template</code>歧义，这导致需要在调用点加上template</li> </ol> <p>待决名如: <pre><code>template&lt;typename T&gt;\nstruct X : B&lt;T&gt; // \"B&lt;T&gt;\" 取决于 T\n{\n    typename T::A* pa; // \"T::A\" 取决于 T\n                       // （此 \"typename\" 的使用的目的见下文）\n    void f(B&lt;T&gt;* pb)\n    {\n        static int i = B&lt;T&gt;::i; // \"B&lt;T&gt;::i\" 取决于 T\n        pb-&gt;j++; // \"pb-&gt;j\" 取决于 T\n    }\n};\n</code></pre></p> <p>让人吃惊的例子, 这就是非待决名的情况下，立即绑定 <pre><code>#include &lt;iostream&gt;\n\nvoid g(double) { std::cout &lt;&lt; \"g(double)\\n\"; }\n\ntemplate&lt;class T&gt;\nstruct S\n{\n    void f() const\n    {\n        g(1); // \"g\" 是非待决名，现在绑定\n    }\n};\n\nvoid g(int) { std::cout &lt;&lt; \"g(int)\\n\"; }\n\nint main()\n{\n    g(1);  // 调用 g(int)\n\n    S&lt;int&gt; s;\n    s.f(); // 调用 g(double)\n}\n</code></pre></p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#typename","level":3,"title":"typename消歧义","text":"<p>在模板（包括别名模版）的声明或定义中，不是当前实例化的成员且取决于某个模板形参的名字不会被认为是类型， 除非使用关键词 typename 或它已经被设立为类型名（例如用 typedef 声明或通过用作基类名）。 </p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint p = 1;\n\ntemplate&lt;typename T&gt;\nvoid foo(const std::vector&lt;T&gt; &amp;v)\n{\n    // std::vector&lt;T&gt;::const_iterator 是待决名，\n    typename std::vector&lt;T&gt;::const_iterator it = v.begin();\n\n    // 下列内容因为没有 'typename' 而会被解析成\n    // 类型待决的成员变量 'const_iterator' 和某变量 'p' 的乘法。\n    // 因为在此处有一个可见的全局 'p'，所以此模板定义能编译。\n    std::vector&lt;T&gt;::const_iterator* p; \n\n    typedef typename std::vector&lt;T&gt;::const_iterator iter_t;\n    iter_t * p2; // iter_t 是待决名，但已知它是类型名\n}\n\ntemplate&lt;typename T&gt;\nstruct S\n{\n    typedef int value_t; // 当前实例化的成员\n    void f()\n    {\n        S&lt;T&gt;::value_t n{}; // S&lt;T&gt; 待决，但不需要 'typename'\n        std::cout &lt;&lt; n &lt;&lt; '\\n';\n    }\n};\n\nint main()\n{\n    std::vector&lt;int&gt; v;\n    foo(v); // 模板实例化失败：类型 std::vector&lt;int&gt; 中没有\n            // 名字是 'const_iterator' 的成员变量\n    S&lt;int&gt;().f();\n}\n</code></pre>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#template","level":3,"title":"template消歧义","text":"<p>与此相似，模板定义中不是当前实例化的成员的待决名同样不被认为是模板名，除非使用消歧义关键词 template，或它已被设立为模板名： </p> <p><pre><code>template&lt;typename T&gt;\nstruct S\n{\n    template&lt;typename U&gt; void foo() {}\n};\n\ntemplate&lt;typename T&gt;\nvoid bar()\n{\n    S&lt;T&gt; s;\n    s.foo&lt;T&gt;();          // 错误：&lt; 被解析为小于运算符\n    s.template foo&lt;T&gt;(); // OK\n}\n</code></pre> template 消歧义可以使用 <pre><code>T::template\ns.template\nthis-&gt;template\n</code></pre></p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#stdforward","level":2,"title":"std::forward 转发在模版的使用","text":"<p>为什么完美转发的对象必须是右值引用？</p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#_13","level":3,"title":"说明一下右值引用","text":"<pre><code> 引用类型   可以引用的值类型    使用场景\n非常量左值   常量左值    非常量右值   常量右值\n非常量左值引用     Y   N   N   N   无\n常量左值引用  Y   Y   Y   Y   常用于类中构建拷贝构造函数\n非常量右值引用     N   N   Y   N   移动语义、完美转发\n常量右值引用  N   N   Y   Y   无实际用途\n</code></pre>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp-template-programing/#_14","level":2,"title":"参考","text":"<p>https://en.cppreference.com/w/cpp/language/parameter_pack https://en.cppreference.com/w/cpp/language/fold https://en.cppreference.com/w/cpp/language/overload_resolution#Best_viable_function</p>","path":["模板编程"],"tags":["c/cpp","template programing"]},{"location":"cpp/","level":1,"title":"C++ 小技巧","text":"","path":["C++ 小技巧"],"tags":["c/cpp"]},{"location":"cpp/#lambda-const","level":2,"title":"使用lambda 定义一个可变的const","text":"<p>因为const 不能改变的，只有在程序运行的时候初始化。 而通过lamda，可以通过获取命令行输入来改变值</p> <pre><code>const int x = []() -&gt; int {\n        int t;\n        std::cin &gt;&gt; t;\n        return t;\n}();\n</code></pre>","path":["C++ 小技巧"],"tags":["c/cpp"]},{"location":"crash-boot/","level":1,"title":"前言","text":"<p>元旦过完回公司发现archlinux 系统无法启动了， 提示没有找到内核之类的错误。 虽然也没有找到根本原因，只知道是内核镜像丢失了， 这里记一下解决办法</p>","path":["crash boot"],"tags":["grub","linux"]},{"location":"crash-boot/#_2","level":1,"title":"现象","text":"<p>启动之后， 提示缺少内核， 需要先指定内核。 回车后进入grub 界面。 在grub 界面可以执行ls (hd*,gpt*)/ 来查看分区的文件 hd0、 hd1 代表的硬盘编号， gpt1、 gpt2、 gpt3 代表分区， ls (hd0, gpt1)/ 表示查看第一个硬盘第一个分区的文件</p> <pre><code>ls (hd1, gpt2)\nEFI  grub  initramfs-linux-fallback.img\n</code></pre> <p>我的boot分区是第二个硬盘的第二个分区， 可见确实没有 vmlinuz-linux 文件，也很奇怪</p>","path":["crash boot"],"tags":["grub","linux"]},{"location":"crash-boot/#_3","level":2,"title":"解决办法","text":"<p>没有 'vmlinuz-linux' 文件的话需要通过archlinux的U盘启动盘启动， 挂载分区后，arch-chroot 进入到坏系统  </p> <p>执行重装linux  <pre><code>pacman -S linux\n</code></pre> 执行grub 相关命令， 重建引导配置。 我的EFI单独分区了</p> <pre><code>grub-install --target=x86_64-efi --efi-directory=/boot/EFI --bootloader-id=Arch\ngrub-config -o /boot/grub/grub.cfg\n</code></pre> <p><code>exit</code>退出坏系统，umount 再重启。 一定要umount 分区否则grub不会生效</p>","path":["crash boot"],"tags":["grub","linux"]},{"location":"crash-boot/#umount-grub","level":2,"title":"没有umount 导致的grub不生效","text":"<p>因为没有umount，<code>exit</code>后直接重启， 发现依旧无法进入系统，还是进入了grub界面，好在linux内核镜像已经存在了，可以通过grub来配置启动 所以这种情况也适用于系统ok，但引导损坏的情况。</p>","path":["crash boot"],"tags":["grub","linux"]},{"location":"crash-boot/#_4","level":3,"title":"解决办法","text":"<p>我的boot分区是(hd1,gpt2)</p> <p>执行一下 <pre><code>set prefix=(hd1,gpt2)/grub/  # 指定实际的grub目录\nset root=(hd1,gp2)\ninsmod normal\nnormal\n</code></pre></p> <p>此时grub会刷新， 继续执行 <pre><code>insmod linux\nlinux /vmlinuz-linux root=/dev/nvme0n1p2   # 设置内核\ninitrd /initd.img\nboot\n</code></pre></p> <p>由于不知道nvme的命名方式，导致也挺麻烦， grub下可以看到uuid,但不能看到分区名称， 后来发现可以通过uuid方式指定root <pre><code>insmod linux\nlinux /vmlinuz root=UUID=xxxxxxxxxxx\ninitrd /initd.img\nboot\n</code></pre></p>","path":["crash boot"],"tags":["grub","linux"]},{"location":"crash-boot/#_5","level":2,"title":"扩充","text":"<p>同样可以通过磁盘+分区的方式指定内核和initrd</p>","path":["crash boot"],"tags":["grub","linux"]},{"location":"create%20cli%20use%20typescript/","level":1,"title":"implement cli use typescript","text":"<p>i have heard that typescript has a lot of packages already, so i tried it with guide of chatgpt.</p>","path":["implement cli use typescript"],"tags":["cli","typescript"]},{"location":"create%20cli%20use%20typescript/#steps-of-a-todo-command-line-cli-tool","level":2,"title":"steps of a todo command line cli tool","text":"<p>mkdir todo-cli &amp;&amp; cd todo-cli  </p> <p>npm init -y                      npm install inquirer chalk    - inquirer: For interactive terminal prompts. - chalk: For colored terminal output.  </p> <p>npm install --save-dev typescript ts-node @types/node @types/inquirer - typescript: TypeScript compiler. - ts-node: Run .ts files directly. - @types/...: Type definitions for Node.js and Inquirer (required for TypeScript support).</p> <p>npx tsc --init      - Generates a default TypeScript config file (tsconfig.json), which controls how TS is compiled.</p> <p>vi todo.ts           <pre><code>import fs from 'fs';\nimport inquirer from 'inquirer';\nimport chalk from 'chalk';\n\nconst FILE = 'todos.json';\n\ntype Todo = {\n  text: string;\n  done: boolean;\n};\n\nfunction loadTodos(): Todo[] {\n  if (!fs.existsSync(FILE)) return [];\n  return JSON.parse(fs.readFileSync(FILE, 'utf-8'));\n}\n\nfunction saveTodos(todos: Todo[]) {\n  fs.writeFileSync(FILE, JSON.stringify(todos, null, 2));\n}\n\nasync function main() {\n  const todos = loadTodos();\n\n  const { action } = await inquirer.prompt({\n    type: 'list',\n    name: 'action',\n    message: 'Choose action:',\n    choices: ['List TODOs', 'Add TODO', 'Mark TODO as done', 'Exit'],\n  });\n\n  switch (action) {\n    case 'List TODOs':\n      if (todos.length === 0) {\n        console.log(chalk.gray('No TODOs found.'));\n      } else {\n        todos.forEach((todo, i) =&gt; {\n          console.log(`${todo.done ? chalk.green('[x]') : chalk.red('[ ]')} ${i + 1}. ${todo.text}`);\n        });\n      }\n      break;\n\n    case 'Add TODO':\n      const { text } = await inquirer.prompt({\n        type: 'input',\n        name: 'text',\n        message: 'Enter TODO text:',\n      });\n      todos.push({ text, done: false });\n      saveTodos(todos);\n      console.log(chalk.green('TODO added.'));\n      break;\n\n    case 'Mark TODO as done':\n      if (todos.length === 0) {\n        console.log(chalk.gray('No TODOs to mark.'));\n        break;\n      }\n      const { index } = await inquirer.prompt({\n        type: 'list',\n        name: 'index',\n        message: 'Select TODO to mark as done:',\n        choices: todos.map((t, i) =&gt; ({\n          name: `${t.done ? '[x]' : '[ ]'} ${t.text}`,\n          value: i,\n        })),\n      });\n      todos[index].done = true;\n      saveTodos(todos);\n      console.log(chalk.green('Marked as done.'));\n      break;\n  }\n\n  if (action !== 'Exit') main();\n}\n\nmain();\n</code></pre></p> <p>npx ts-node todo.ts      </p>","path":["implement cli use typescript"],"tags":["cli","typescript"]},{"location":"create-loop-block/","level":1,"title":"在文件系统之上再创一个文件系统","text":"<p>例如在ext3的文件系统上创建一个xfs的文件系统，可以通过回环设备loop， 我们经常通过 <code>mount -o loop</code> 来 mount一个iso文件 但mount 的选项总是ro的</p> <pre><code>mount: /mnt: WARNING: device write-protected, mounted read-only.\n</code></pre> <p>不仅如此， 先在当前文件系统dd出一个文件， 再绑定到loop设备上，然后mount 到某个目录后， 可以进行<code>读写</code>访问</p> <p><pre><code>[root@ha1 ~]# dd if=/dev/urandom of=file bs=1M count=2\n2+0 records in\n2+0 records out\n2097152 bytes (2.1 MB, 2.0 MiB) copied, 0.0164121 s, 128 MB/s\n\n[root@ha1 ~]# mkfs.ext3  file \nmke2fs 1.44.6 (5-Mar-2019)\nDiscarding device blocks: done                            \nCreating filesystem with 2048 1k blocks and 256 inodes\n\nAllocating group tables: done                            \nWriting inode tables: done                            \nCreating journal (1024 blocks): done\nWriting superblocks and filesystem accounting information: done\n\n[root@ha1 ~]# mount -o loop file  /mnt\n[root@ha1 ~]# ls /mnt/\nlost+found\n\n[root@ha1 mnt]# echo abc &gt; abc\n[root@ha1 mnt]# ls\nabc  lost+found\n</code></pre> 绑定loop设备和挂载是由mount 一个命令完成的。</p>","path":["在文件系统之上再创一个文件系统"],"tags":["filesystem","linux"]},{"location":"create-loop-block/#loop","level":2,"title":"手动绑定loop","text":"<p><pre><code>[root@ha1 ~]# losetup -f\n/dev/loop1\n\n[root@ha1 ~]# losetup -f file \n</code></pre> 这样只是将文件绑定了loop设备，需要再挂载到文件目录<code>mount /dev/loop0 /mnt</code></p> <pre><code>[root@ha1 ~]# ls /mnt/\nabc  lost+found\n[root@ha1 ~]# \n</code></pre> <p>losetup -f 可以返回第一个未被使用的loop设备名</p>","path":["在文件系统之上再创一个文件系统"],"tags":["filesystem","linux"]},{"location":"create-loop-block/#loop_1","level":2,"title":"创建loop设备","text":"<p>有的系统默认创建了 loop0 .. loop7 的块设备，有的则是在需要的时候创建，比如mount iso的时候发现没有loop设备，则会创建</p> <ol> <li>手动创建loop设备通过 <code>mknode</code> 创建</li> </ol> <pre><code>mknode  /dev/loop0 b 7 0\nmknode  /dev/loop1 b 7 0\n...\n\nmknode /dev/loop7 b 7 0\n</code></pre> <ol> <li>如果8个loop0 .. loop8 设备都占用了， 可以再创建loop8</li> </ol> <p><pre><code>$sudo mknod /dev/loop8 b 7 8 \n\n$ls -l /dev/loop8\nbrw-r--r-- 1 root root 7, 8 Jun 11 19:16 /dev/loop8\n</code></pre> ps： /dev/loop* 是块设备</p>","path":["在文件系统之上再创一个文件系统"],"tags":["filesystem","linux"]},{"location":"crontab-manual/","level":1,"title":"Linux定时器","text":"<p>https://www.computerhope.com/unix/ucrontab.htm#command-entries</p>","path":["Linux定时器"],"tags":["linux"]},{"location":"crontab-manual/#systemd-run","level":2,"title":"使用systemd-run 替换","text":"<pre><code># systemd-run --on-active=30 /bin/touch /tmp/foo\n# systemd-run --on-active=\"12h 30m\" --unit some-unit.service\n</code></pre>","path":["Linux定时器"],"tags":["linux"]},{"location":"ddns/","level":1,"title":"Ddns","text":"","path":["Ddns"],"tags":["ddns"]},{"location":"ddns/#code","level":2,"title":"code","text":"<pre><code>    \"\"\"\n    更新\n    \"\"\"\n    parser = ArgumentParser(description=__description__,\n                            epilog=__doc__, formatter_class=RawTextHelpFormatter)\n    parser.add_argument('-v', '--version',\n                        action='version', version=__version__)\n    parser.add_argument('-c', '--config',\n                        default=\"config.json\", help=\"run with config file [配置文件路径]\")\n    config_file = parser.parse_args().config\n    get_config(path=config_file)\n    # Dynamicly import the dns module as configuration\n    dns_provider = str(get_config('dns', 'dnspod').lower())\n    dns = getattr(__import__('dns', fromlist=[dns_provider]), dns_provider)\n    dns.Config.ID = get_config('id')\n    dns.Config.TOKEN = get_config('token')\n    dns.Config.TTL = get_config('ttl')\n    if get_config('debug'):\n        ip.DEBUG = get_config('debug')\n        basicConfig(\n            level=DEBUG,\n            format='%(asctime)s &lt;%(module)s.%(funcName)s&gt; %(lineno)d@%(pathname)s \\n[%(levelname)s] %(message)s')\n        print(\"DDNS[\", __version__, \"] run:\", os_name, sys.platform)\n        print(\"Configuration was loaded from &lt;==\", path.abspath(config_file))\n        print(\"=\" * 25, ctime(), \"=\" * 25, sep=' ')\n\n    proxy = get_config('proxy') or 'DIRECT'\n    proxy_list = proxy.strip('; ') .split(';')\n\n    cache = get_config('cache', True) and Cache(CACHE_FILE)\n    if cache is False:\n        info(\"Cache is disabled!\")\n    elif get_config.time &gt;= cache.time:\n        warning(\"Cache file is out of dated.\")\n        cache.clear()\n    elif not cache:\n        debug(\"Cache is empty.\")\n    update_ip('4', cache, dns, proxy_list)\n    update_ip('6', cache, dns, proxy_list)\n\n\nif __name__ == '__main__':\n    main()\n</code></pre> <pre><code>{\n  \"$schema\": \"https://ddns.newfuture.cc/schema/v2.8.json\",\n  \"id\": \"\",\n  \"token\": \"\",\n  \"dns\": \"alidns\",\n  \"ipv4\": [\"\", \"\"],\n  \"index4\": \"public\",\n  \"ttl\": 600,\n  \"proxy\": \"DIRECT\",\n  \"debug\": false\n}\n</code></pre>","path":["Ddns"],"tags":["ddns"]},{"location":"defualt%20route%20in%20linux/","level":1,"title":"defualt route in linux","text":"<p>默认路由非常重要，当对端地址在路由表中查不到从哪个网口出去时，就走默认路由对应的网卡。</p>","path":["defualt route in linux"],"tags":["network","route"]},{"location":"defualt%20route%20in%20linux/#_1","level":2,"title":"即使是只有一张网卡，也应该配默认路由","text":"<p>最近遇到问题，使用命令<code>ip addr add 10.9.3.211/24 dev enp1s0</code>给虚拟机加ip后，路由表如下: <pre><code>#ip route\n10.9.3.0/24 dev enp1s0 proto kernel scope link src 10.9.3.211 \n</code></pre> 能ping网关和其他同网段主机，但ping不同其他网段的主机，显示'network unreachable'， 反向也不行。使用命令<code>ip route add default via 10.9.3.1 dev enp1s0</code>配置默认路由，问题就解决了。而通过网卡配置和网卡启动脚本例如<code>ifup</code>，或者网络管理工具NetworkManager，是会自动添加默认路由的，所以不存在这个问题。</p>","path":["defualt route in linux"],"tags":["network","route"]},{"location":"defualt%20route%20in%20linux/#1metric","level":2,"title":"拓展1，路由Metric","text":"<p>所有匹配不到的包就走默认路由指定的网关，如果存在多个网卡，可以有多个默认路由如下，这时候靠metric来指定优先级，metric在配置里指定</p> <p><pre><code>default via 10.14.160.1 dev enp1s0 proto static metric 90 \ndefault via 10.14.162.1 dev enp10s0 proto static metric 100 \ndefault via 10.14.161.1 dev enp9s0 proto static metric 100 \n</code></pre> 这时10.14.160.0/24网段的包走enp1s0，10.14.162.0/24走enp10s0， 10.14.161.0/24走enp9s0，因为enp1s0的metric最小，优先级最高，其他网段的包走enp1s0。  </p>","path":["defualt route in linux"],"tags":["network","route"]},{"location":"defualt%20route%20in%20linux/#_2","level":3,"title":"手动再添加路由，优先级比默认路由高","text":"<p>例如指定1.1.1.1走非默认路由， <pre><code>ip route add 1.1.1.1 via 10.14.161.1 dev enp9s0 \n</code></pre> 这时ping 1.1.1.1就不走默认路由了。</p>","path":["defualt route in linux"],"tags":["network","route"]},{"location":"defualt%20route%20in%20linux/#lookup","level":3,"title":"lookup 设置表的优先级","text":"<p>上面的手动添加路由可以指定非3个网段的包走非默认路由，但是无法超越同网段的优先级，意思就是无法指定10.14.161.0/24的包走10.14.160.1这个网关。这时就需要创建新的路由表，通过表的优先级来实现</p> <pre><code>echo \"200 custom1\" | sudo tee -a /etc/iproute2/rt_tables\nsudo ip route add 10.14.162.100 via 10.14.160.1 dev enp1s0 table custom1\nsudo ip rule add to 10.14.162.100 lookup custom1\n</code></pre> <p>不过似乎大部分情况没意义，我遇到有意义的情况是使用了tailscale exit node时，所有包都走了隧道。如果希望本地某个主机不走隧道，就需要lookup 自定义路由表。</p>","path":["defualt route in linux"],"tags":["network","route"]},{"location":"docker-network/","level":1,"title":"docker network","text":"<p>记录一次docker的网络问题，以及学到的知识。</p>","path":["docker network"],"tags":["docker","network"]},{"location":"docker-network/#_1","level":2,"title":"背景","text":"<p>公司用docker容器替代虚拟机来隔离，用来ssh登录以及运行不同的服务。容器连接了双网络，一个用来访问同宿主机上的容器，另一个用来从其他主机访问。</p>","path":["docker network"],"tags":["docker","network"]},{"location":"docker-network/#_2","level":2,"title":"问题","text":"<p>宿主机重启之后，容器无法访问。需要手动改路由。</p>","path":["docker network"],"tags":["docker","network"]},{"location":"docker-network/#_3","level":2,"title":"解决办法","text":"<p>每次修改路由麻烦，后面发现两个网络都是macvlan时，存在无法没有网络。</p>","path":["docker network"],"tags":["docker","network"]},{"location":"docker-network/#_4","level":2,"title":"创建桥接物理网卡","text":"<p>这是需要指定parent为物理网卡，既然是桥接物理网卡，就能从其他宿主机访问了。 <pre><code>docker network create -d bridge   --subnet=10.9.3.0/24   --gateway=10.9.3.1   -o parent=ens39f0 public_net_bridge\n</code></pre></p> <p><pre><code>docker network create -d macvlan  --subnet=10.9.3.0/24   --gateway=10.9.3.1   -o parent=ens39f0 public_net_macvlan\n</code></pre> 这两个由于使用的同一个网段/网卡，所以不可能同时存在。也许可以通过指定不同的ip-range来实现吗？</p>","path":["docker network"],"tags":["docker","network"]},{"location":"docker-network/#_5","level":2,"title":"创建桥接虚拟网卡","text":"<p>这种网络就不能从非宿主机的其他主机访问，只能在同宿机下的容器之间访问。我称之为私有网络  <pre><code>docker network create -d bridge   private_net_bridge\n</code></pre></p> <p><pre><code>docker network create -d macvlan  private_net_macvlan\n</code></pre> 这里没有指定网络地址</p>","path":["docker network"],"tags":["docker","network"]},{"location":"docker-network/#iperf","level":2,"title":"iperf测速","text":"<p>发现无论桥接物理网卡还是虚拟网卡，macvlan都要比bridge快</p> <ul> <li> <p>私有网络 bridge 模式分别测得: 20.4 Gbits/sec 22.6 Gbits/sec 23.0 Gbits/sec macvlan 模式分别测得: 26.1 Gbits/sec 24.4 Gbits/sec 26.7 Gbits/sec</p> </li> <li> <p>桥接物理网卡 macvlan: 25.7 Gbits/sec 25.5 Gbits/sec 27.3 Gbits/sec bridge: 20.2 Gbits/sec 20.4 Gbits/sec 23.2 Gbits/sec</p> </li> </ul>","path":["docker network"],"tags":["docker","network"]},{"location":"docker-network/#_6","level":2,"title":"顺便说下容器连接多网络的方法","text":"<p>容器启动的时候，只能指定一个网络, 然后启动之后，可以通过命令来连接多网络，可以在启动时设置--restart=alway,这样重启主机后自动连接双网络 <pre><code>docker network connect private_net_bridge test_container\n</code></pre></p>","path":["docker network"],"tags":["docker","network"]},{"location":"docker-network/#_7","level":2,"title":"杂项","text":"<p>网络配置挺复杂，macvlan 下面还分 * Bridge mode, 就是常见的模式，走宿主机的网卡 * 802.1q trunk bridge mode, 先在物理网卡上创建子网卡</p>","path":["docker network"],"tags":["docker","network"]},{"location":"docker-network/#ipvlan","level":3,"title":"IPvlan","text":"<p>除了bridge macvlan之外，还有IPvlan, 这种模式下，所有的容器都使用相同的mac地址，所以如果容器使用dhcp来获取ip地址，则可能有问题。 访问其他容器时，可以配置来使用macvlan模式。</p>","path":["docker network"],"tags":["docker","network"]},{"location":"docker-network/#overlay","level":3,"title":"overlay","text":"<p>docker network driver 除了上面的三种模式之外，还有overlay, 用于连接不同主机的网络，可以跨宿主机访问容器。</p>","path":["docker network"],"tags":["docker","network"]},{"location":"docker-network/#_8","level":2,"title":"宿主机网络类型","text":"<p>我通常会创建bridge并将物理网卡设为从卡，然后创建虚拟网桥，用于访问虚拟机。而除了bridge, 还有bond,另外还有team。总而言之，bridge可以使不同的虚拟机（client）使用网卡的虚拟化功能，而bond可以将不同的网卡绑定，实现负载均衡。如果两个网卡分别有1M带宽，那么bond后的网卡则有2M带宽。下面的链接先bonding,然后在bonding网卡上创建bridge网卡。参考</p>","path":["docker network"],"tags":["docker","network"]},{"location":"docker-overlay-filesystem/","level":1,"title":"docker overlay filesystem","text":"<p>overlay 是docker使用的文件系统，具有分层的特点, docker使用的文件系统经过很多变化，而且各发行版可能不同。 执行<code>docker info</code> 查看当前使用的是overlay2</p> <pre><code>sudo docker info | grep -i storage                                                                                                                                              \n Storage Driver: overlay2\n</code></pre>","path":["docker overlay filesystem"],"tags":["docker","filesystem"]},{"location":"docker-overlay-filesystem/#_1","level":2,"title":"历史","text":"<p>除了 overlay，类似有rootfs， aufs （ubuntu）， devicemapper（centos），不够成熟的btrfs</p> <p>他们都有2个目的： 1. 提供不含内核的文件系统（rootfs）即容器, 在内核之上。这是docker 最有价值的地方，就是无论在那里运行docker， 容器里的环境都是一致的 2. 提供分层</p>","path":["docker overlay filesystem"],"tags":["docker","filesystem"]},{"location":"docker-overlay-filesystem/#overlay","level":2,"title":"overlay的优势","text":"<ol> <li>page caching， 可以在多个不同实例之间共享</li> <li>写时复制， 只有执行write操作时， 会将lower layer 的文件复制到container层</li> <li>不同层之间，相同文件使用硬连接， 节省inode 和 大小</li> </ol> <p>写时复制 copy-up 会导致第一次写时造成延迟，特别是大文件，拷贝起来费时。 但第二次就不会延时， 而且overlay2 有caching， 相比其它文件系统，更减少延时</p>","path":["docker overlay filesystem"],"tags":["docker","filesystem"]},{"location":"docker-overlay-filesystem/#overlay_1","level":2,"title":"overlay的问题","text":"<ol> <li>实现不够完全， 例如没有实现uname </li> <li>先只读打开一个文件 open（read）， 再读写打开相同文件open（write）， 两个fd 会对应2个不同文件， 第一个对应的lower的文件，第二个造成写时复制，对应容器里的文件。 </li> <li>规避方法是先执行touch 操作。 现实的例子是 yum 需要安装yum-plugin-ovl。 但这个只有7.2才支持， 之前的话就需要先<code>touch /var/lib/rpm/*</code></li> </ol>","path":["docker overlay filesystem"],"tags":["docker","filesystem"]},{"location":"docker-overlay-filesystem/#_2","level":2,"title":"最佳实践","text":"<ol> <li>使用ssd </li> <li>对于写操作比较多的目录， 使用映射文件。这样跳过了overlay的复杂操作，直接使用主机的文件系统。</li> </ol>","path":["docker overlay filesystem"],"tags":["docker","filesystem"]},{"location":"docker-overlay-filesystem/#_3","level":2,"title":"分层介绍","text":"<p>我理解就是将分离的多个目录挂载到一起的技术。 例如对docker 容器的文件进行增删改后，再commit， 会多一层layer。  再当docker 容器启动时，会自动挂载多层layer。  组织： overlay对运行的实例通过元数据组织文件， 是否是link文件 </p> <pre><code>ls 04ea1faa8074e5862f40eecdba968bd9b7f222cb30e5bf6a0b9a9c48be0940f2/\ndiff  link  lower  merged  work\n</code></pre>","path":["docker overlay filesystem"],"tags":["docker","filesystem"]},{"location":"docker-overlay-filesystem/#mount","level":3,"title":"手动mount的例子","text":"<ol> <li>原本目录，文件都分散在不同目录ABC <pre><code>.\n├── A\n│   ├── aa\n│   └── a.txt\n├── B\n│   ├── a.txt\n│   └── b.txt\n├── C\n│   └── c.txt\n└── worker\n    └── work [error opening dir]\n</code></pre></li> <li>overlay 挂载到/tmp/test目录 <code>sudo mount -t overlay overlay -o lowerdir=A:B,upperdir=C,workdir=worker /tmp/test/</code></li> <li>查看test目录  <pre><code>/tmp/test/\n├── aa\n├── a.txt\n├── b.txt\n└── c.txt\n</code></pre> <pre><code>mount  | grep 'overlay'\noverlay on /tmp/test type overlay (rw,relatime,lowerdir=A:B,upperdir=C,workdir=worker)\n</code></pre></li> </ol>","path":["docker overlay filesystem"],"tags":["docker","filesystem"]},{"location":"docker-overlay-filesystem/#overlay_2","level":3,"title":"overlay的增删改","text":"<p>当运行docker容器时查看挂载</p> <p><pre><code>overlay on /var/lib/docker/overlay2/04ea1faa8074e5862f40eecdba968bd9b7f222cb30e5bf6a0b9a9c48be0940f2/merged type overlay \n(rw,relatime,\n    lowerdir=/var/lib/docker/overlay2/l/B74PWZCBMRCWXFH5UL2ZXB5WEU:/var/lib/docker/overlay2/l/WNHICVPVSDNUGSCZW435TPSMOK,\n    upperdir=/var/lib/docker/overlay2/04ea1faa8074e5862f40eecdba968bd9b7f222cb30e5bf6a0b9a9c48be0940f2/diff,\n    workdir=/var/lib/docker/overlay2/04ea1faa8074e5862f40eecdba968bd9b7f222cb30e5bf6a0b9a9c48be0940f2/work\n)\n</code></pre> docker 将镜像的文件挂载为只读， 将容器层挂载为可读可写。 文件系统可以分为2部分 upper（容器层） + lower （镜像层）</p> <ul> <li>当在容器里执行写时， 如果文件不存在， 会依次遍历lower。如果都不存在就会在upper层创建文件</li> <li>读也相同</li> <li>删除时会创建一个without 来隐藏， 这是为什么即使删除容器里的文件， 镜像还是会增大。 </li> <li>删除目录情况也差不多</li> </ul> <p>似乎很奇怪，为什么多了一个workdir,  据说这个目录总是空的，为了实现原子操作添加和删除文件</p>","path":["docker overlay filesystem"],"tags":["docker","filesystem"]},{"location":"docker-overlay-filesystem/#_4","level":3,"title":"特殊情况","text":"<p>在修改容器后， 容器系统会多一层， 里面包含了修改的文件，以及删除后生成的without文件， 然后生成镜像</p> <p>但对于以下特殊目录文件不会提交， 因为这些文件是运行时docker 要根据用户配置进行修改的。  </p> <ol> <li>/etc/hostname </li> <li>/etc/hosts </li> <li>/etc/resov.conf</li> </ol> <p>例如docker 的link选项，会在容器的hosts 文件里定义对应的容器名-&gt;容器ip</p>","path":["docker overlay filesystem"],"tags":["docker","filesystem"]},{"location":"docker-storage/","level":1,"title":"docker storage","text":"<p>docker 有3种方式使用系统存储:</p> <ul> <li>bind:    宿主机目录映射方式，启动容器命令添加参数<code>-v dir1:dir2</code>。将宿主机的目录dir1挂载到容器的dir2目录，实际执行的<code>mount -o bind</code>类似命令</li> <li>volume:    由docker管理的存储，先创建后使用，且可以在多个容器中共享，是官方推荐的方式</li> <li>tmpfs:    使用宿主机的内存作为存储，这种使用内存文件系统来挂载到容器目录, 使用参数<code>--mount type=tmpfs,destination=/dir</code>, tmpfs是退出即释放的一种文件系统</li> </ul>","path":["docker storage"],"tags":["docker"]},{"location":"docker-storage/#docker","level":2,"title":"docker使用的文件系统","text":"<p>docker使用的文件系统经过很多变化，而且在各发行版下可能不同，但目前主流的是overlay2，执行<code>docker info</code> 查看当前使用的是overlay2 <pre><code>sudo docker info | grep  Storage                                                                                                                                              \n Storage Driver: overlay2\n</code></pre></p> <p>除了overlay2，还有aufs（ubuntu），devicemapper（centos），btrfs和zfs。他们的实现都不同，都能支持分层和支持写时复制（Cow/copy-on-write），而他们实现的方式有区别，所以效率也有区别</p> <ul> <li>分层： 镜像都是分层的，在Dockerfile构建时，每次执行COPY/RUN时，都会增加一层</li> <li>写时复制: 在容器或者DockerFile执行修改操作时，包括权限修改，会将lower layer 的文件复制到container层再修改</li> </ul> <p>而容器就是在镜像顶层<code>压栈</code>了一个<code>可写</code>层，而且是临时的，当容器销毁时，这层的文件也会删除</p>","path":["docker storage"],"tags":["docker"]},{"location":"docker-storage/#overlay","level":2,"title":"overlay的优势","text":"<ol> <li>page caching， 可以在多个不同实例之间共享</li> <li>不同层之间，相同文件使用硬连接， 节省inode 和 大小</li> </ol> <p>写时复制 copy-up 会导致第一次写时造成延迟，特别是大文件，拷贝起来费时。 但第二次就不会延时， 而且overlay2 有caching， 相比其它文件系统，更减少延时</p>","path":["docker storage"],"tags":["docker"]},{"location":"docker-storage/#overlay_1","level":2,"title":"overlay的问题","text":"<ol> <li>实现不够完全， 例如没有实现uname </li> <li>先只读打开一个文件 open（read）， 再读写打开相同文件open（write）， 两个fd 会对应2个不同文件， 第一个对应的lower的文件，第二个造成写时复制，对应容器里的文件。 </li> <li>规避方法是先执行touch 操作。 现实的例子是 yum 需要安装yum-plugin-ovl。 但这个只有7.2才支持， 之前的话就需要先<code>touch /var/lib/rpm/*</code></li> </ol>","path":["docker storage"],"tags":["docker"]},{"location":"docker-storage/#_1","level":2,"title":"最佳实践","text":"<ol> <li>使用ssd </li> <li>对于写操作比较多的场景，例如数据库，应使用映射文件(bind)或者volume。这样跳过了overlay的复杂操作，直接使用主机的文件系统</li> </ol>","path":["docker storage"],"tags":["docker"]},{"location":"docker-storage/#overlay_2","level":2,"title":"overlay的增删改","text":"<p>当运行docker容器时查看挂载</p> <p><pre><code>overlay on /var/lib/docker/overlay2/04ea1faa8074e5862f40eecdba968bd9b7f222cb30e5bf6a0b9a9c48be0940f2/merged type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/l/B74PWZCBMRCWXFH5UL2ZXB5WEU:/var/lib/docker/overlay2/l/WNHICVPVSDNUGSCZW435TPSMOK,upperdir=/var/lib/docker/overlay2/04ea1faa8074e5862f40eecdba968bd9b7f222cb30e5bf6a0b9a9c48be0940f2/diff,workdir=/var/lib/docker/overlay2/04ea1faa8074e5862f40eecdba968bd9b7f222cb30e5bf6a0b9a9c48be0940f2/work)\n</code></pre> docker 将镜像的文件挂载为只读， 将容器层挂载为可读可写。 文件系统可以分为2部分 upper（容器层） + lower （镜像层）</p> <ul> <li>当在容器里执行写时， 如果文件不存在， 会依次遍历lower。如果都不存在就会在upper层创建文件</li> <li>读也相同</li> <li>删除时会创建一个without 来隐藏， 这是为什么即使删除容器里的文件， 镜像还是会增大。 </li> <li>删除目录情况也差不多</li> </ul>","path":["docker storage"],"tags":["docker"]},{"location":"docker-storage/#_2","level":2,"title":"特殊情况","text":"<p>在保存容器后(docker commit)，会多一层，里面包含了修改的文件，以及删除后生成的without文件，然后生成镜像</p> <p>但对于以下特殊目录文件不会提交， 因为这些文件是运行时docker 要根据用户配置进行修改的。  </p> <ol> <li>/etc/hostname </li> <li>/etc/hosts </li> <li>/etc/resov.conf</li> </ol> <p>例如docker 的link选项，会在容器的hosts 文件里定义对应的容器名-&gt;容器ip</p>","path":["docker storage"],"tags":["docker"]},{"location":"docker-storage/#mount-overlayfs","level":2,"title":"手动mount overlayfs的例子","text":"<ol> <li>原本目录，文件都分散在不同目录ABC <pre><code>.\n├── A\n│   ├── aa\n│   └── a.txt\n├── B\n│   ├── a.txt\n│   └── b.txt\n├── C\n│   └── c.txt\n└── worker\n    └── work [error opening dir]\n</code></pre></li> <li>overlay 挂载到/tmp/test目录 <code>sudo mount -t overlay overlay -o lowerdir=A:B,upperdir=C,workdir=worker /tmp/test/</code></li> <li>查看test目录  <pre><code>/tmp/test/\n├── aa\n├── a.txt\n├── b.txt\n└── c.txt\n</code></pre> <pre><code>mount  | grep 'overlay'\noverlay on /tmp/test type overlay (rw,relatime,lowerdir=A:B,upperdir=C,workdir=worker)\n</code></pre></li> </ol>","path":["docker storage"],"tags":["docker"]},{"location":"docker-storage/#_3","level":2,"title":"参考","text":"<p>https://docs.docker.com/storage/storagedriver/</p>","path":["docker storage"],"tags":["docker"]},{"location":"download%20music%20to%20ipod%20shuffle%204/","level":1,"title":"download music to ipod shuffle 4","text":"","path":["download music to ipod shuffle 4"],"tags":[]},{"location":"download%20music%20to%20ipod%20shuffle%204/#install-ipod-shuffle-4gpy","level":2,"title":"install ipod-shuffle-4g.py","text":"<p>Python script for building the Track and Playlist database for the newer gen IPod Shuffle. Forked from the shuffle-db-ng project and improved my nims11 and NicoHood.</p>","path":["download music to ipod shuffle 4"],"tags":[]},{"location":"download%20music%20to%20ipod%20shuffle%204/#automatically-or-manually-mount-ipod","level":2,"title":"automatically or manually mount ipod","text":"<p>mount /dev/sdb /mnt</p>","path":["download music to ipod shuffle 4"],"tags":[]},{"location":"download%20music%20to%20ipod%20shuffle%204/#copy-mp3-or-m4a-file-into-ipod","level":2,"title":"copy mp3 or m4a file into ipod","text":"<p>/mnt/iPod_Control/Music/F00/</p>","path":["download music to ipod shuffle 4"],"tags":[]},{"location":"download%20music%20to%20ipod%20shuffle%204/#command-of-update-play-list","level":2,"title":"command of update play list","text":"<p>sudo ./ipod-shuffle-4g.py -d 1 /mnt/          </p>","path":["download music to ipod shuffle 4"],"tags":[]},{"location":"dp-programming/","level":1,"title":"DP 四板斧","text":"<p>以跳台阶的题目为例， 题目是以每次跳1层或2层的方式跳到n台阶， 问一共有多少种跳法 开始我觉得这是求路径个数，而通常dp算最大或最小值， 不适用。  但后来换个角度想，求最大最小必须得试过所有方法才得出来的， 而将所有的试过的方法计数，就是这题的解</p>","path":["DP 四板斧"],"tags":["算法","DP"]},{"location":"dp-programming/#_1","level":2,"title":"写出递归","text":"<p>dp第一步要先写出递归来， 写递归得写收敛条件 这里的收敛条件是当传参小于0,则说明解法失败（多跳了），返回0。 当恰好为0则解法有效返回1  </p> <p>递归体就是跳1层和跳2层</p> <pre><code>static int jump(int number) {\n  if (number &lt; 0) {\n    return 0;\n  } else if (number == 0) {\n    return 1;\n  }\n  return jump(number - 1) + jump(number - 2);\n}\n\nint jumpFloor(int number) { \n  return jump(number - 1) + jump(number - 2); \n}\n</code></pre>","path":["DP 四板斧"],"tags":["算法","DP"]},{"location":"dp-programming/#_2","level":2,"title":"用缓存来优化递归","text":"<p>递归显然会重复计算， 可以用缓存计算结果来避免， 当有缓存时使用缓存，否则才去计算， 最后将结果缓存  </p> <p>并且使用缓存时应该指定尾递归的值</p> <pre><code>int jump(int number, int *cache) {\n  if (number &lt; 3) {\n    return cache[number];\n  }\n  // 缓存没命中就计算\n  int ret1 =\n      cache[number - 1] != -1 ? cache[number - 1] : jump(number - 1, cache);\n  int ret2 =\n      cache[number - 2] != -1 ? cache[number - 2] : jump(number - 2, cache);\n  cache[number] = ret1 + ret2;\n  return cache[number];\n}\n\nint jumpFloor(int number) {\n  int cache[number + 1];\n  for (int i = 0; i &lt; number + 1; i++) {\n    cache[i] = -1;\n  }\n\n  cache[0] = 0;\n  cache[1] = 1;\n  cache[2] = 2;\n  return jump(number, cache);\n}\n</code></pre>","path":["DP 四板斧"],"tags":["算法","DP"]},{"location":"dp-programming/#for","level":2,"title":"递归改for循环","text":"<p>递归的调用流程是自上而下，先计算(n)-&gt;计算(n -1)-&gt;再计算(n-2) ... 0 现在要反过来， 先计算(0)-&gt;计算(1)-&gt;计算(2) ... n  即自下而上</p> <pre><code>int jumpFloor(int number) {\n  if (number &lt; 3) {\n    return number;\n  }\n\n  // 之前要初始化为了判断， 而现在显然下标大于2的值是要计算出来的，不需要读取  \n  // 所以不需要初始化\n  int cache[number + 1];\n  cache[1] = 1;\n  cache[2] = 2;\n\n  for (int i = 3; i &lt;= number; i++) {\n    cache[i] = cache[i - 1] + cache[i - 2];\n  }\n\n  return cache[number];\n}\n</code></pre>","path":["DP 四板斧"],"tags":["算法","DP"]},{"location":"dp-programming/#_3","level":2,"title":"缩小缓存大小","text":"<p>仔细看， 其实每次计算只涉及最大的三个数， 所以数组并不需要那么大，只用3个单元就足够，故直接写成3个变量</p> <pre><code>  int jumpFloorD(int number) {\n    if (number &lt; 3) {\n      return number;\n    }\n\n    int total = 0;\n    int minors2 = 1;\n    int minors1 = 2;\n\n    for (int i = 3; i &lt;= number; i++) {\n      total = minors1 + minors2;\n      minors2 = minors1;\n      minors1 = total;\n    }\n\n    return total;\n  }\n</code></pre> <p>这样DP解法就出来了， 这个套路是我从力扣上学到的， 非常有效简单</p>","path":["DP 四板斧"],"tags":["算法","DP"]},{"location":"dp-programming/#_4","level":2,"title":"总结","text":"<p>从上可见，你需要训练如何发现递归关系，剩下的工作就是缓存递归调用的结果，最后是将从上到下的解决思路变为从下到上。这样我们就可以用O(N)的时间复杂度去遍历  </p>","path":["DP 四板斧"],"tags":["算法","DP"]},{"location":"dp-programming/#_5","level":2,"title":"参考","text":"<p>https://leetcode.com/discuss/study-guide/1490172/dynamic-programming-is-simple</p>","path":["DP 四板斧"],"tags":["算法","DP"]},{"location":"dpdk%20test%20speed/","level":1,"title":"dpdk-testpmd to test NIC speed","text":"<p>启动，进入dpdk 交互模式</p> <pre><code>./dpdk-testpmd -l 0-3 -n 4 --vdev=net_tap0,iface=tap0 -a 0000:07:00.0 -- -i --port-topology=chained \n\n#确认\ntestmpd&gt; show port summary all \n\n#设置转发\ntestpmd&gt; set fwd io \n\n#启动转发\ntestpmd&gt; start \n</code></pre> <p>设置tap设备的ip <pre><code>ip add add 10.9.108.211/24 dev tap0\nip route add 10.9.3.13 via 10.9.108.211 dev tap0\n#启动\niperf -s\n</code></pre></p>","path":["dpdk-testpmd to test NIC speed"],"tags":["dpdk"]},{"location":"entrypointandcmdindockerfile/","level":1,"title":"Dockerfile 中ENTRYPOINT和CMD的区别","text":"<p>Dockerfile 中，ENTRYPOINT和CMD来都可以用来设置默认命令，而代替<code>docker run</code>时的命令，也可以一起使用  </p> <p>单独使用ENTRYPOINT或CMD时，其区别在于对<code>docker run</code>的参数处理: CMD的命令会被<code>docker run</code>的参数覆盖，而ENTRYPOINT是追加</p> <p>例如： <pre><code># image1\nFROM ubuntu\nENTRYPOINT [\"echo\", \"hello world\"]\n</code></pre> <pre><code># image2\nFROM ubuntu\nCMD [\"echo\", \"hello world\"]\n</code></pre></p> <p>执行结果 <pre><code># docker run image1\nhello world\n\n# docker run image1 hostname\n0c33ff9af81c\n</code></pre></p> <pre><code># docker run image2\nhello world\n\n# docker run image2 hostname\nhello world 0c33ff9af81c\n</code></pre>","path":["Dockerfile 中ENTRYPOINT和CMD的区别"],"tags":["docker"]},{"location":"entrypointandcmdindockerfile/#entrypointcmd","level":2,"title":"实际情况多是entrypoint与cmd组合使用","text":"<p>cmd 为entrypoint 提供默认参数， 即如果'docker run'给了参数时，覆盖CMD参数，否则使用CMD提供的参数</p> <pre><code>FROM ubuntu\nENTRYPOINT [\"top\", \"-b\"]\nCMD [\"-c\"]\n</code></pre>","path":["Dockerfile 中ENTRYPOINT和CMD的区别"],"tags":["docker"]},{"location":"entrypointandcmdindockerfile/#cmdentrypoint","level":2,"title":"首先说cmd和entrypoint 都有两种模式","text":"<ol> <li>shell模式， 即没有用数组来传递参数, 直接接命令如 CMD top -p 或者 entrypoint top -p </li> <li>exec 模式， 即使用数组表示如 CMD [\"top\", \"-p\"]， 注意必须用双引号，因为这个是用json来传递的</li> </ol> <p>两者区别: shell模式不会接受命令行参数，而且1号进程是sh，而非如上的top。 这样的话top不能接受到<code>docker stop container</code>时的信号。  而一般我们写的程序都是捕捉SIGTERM来进行peaceful exit，那么就一定不能使用shell模式</p> <p>exec模式时， 可以接受docker run image param， 这个param会传递给top作为参数。 而且top 是1号进程，能接收信号。</p> <p>细微区别： 由于shell模式是先启动sh， 符号解析由shell执行，例如<code>$HOME</code>的展开由shell进行， 而用exec模式时，由docker 进行</p> <p>总之，推荐使用exec 模式</p>","path":["Dockerfile 中ENTRYPOINT和CMD的区别"],"tags":["docker"]},{"location":"entrypointandcmdindockerfile/#_1","level":2,"title":"额外话, 减小镜像体积","text":"<p>使用'\\' 或者 '&amp;&amp;' 将命令连起来可以减小镜像层数，从而减小体积。另外build时，单独一行的命令会在新的layer 层执行。有些命令产生的cache，会持续影响到下一层 例如<code>RUN apt-get dist-upgrade -y</code>，如果不想保留cache，需要在build时加入参数<code>docker build --no-cache.</code> </p> <p>还有最有效减小镜像体积的方式，也常见的是最后用空白镜像，'FROM SCRATCH', 这样把其他的层都干掉了, 只保留一层镜像</p>","path":["Dockerfile 中ENTRYPOINT和CMD的区别"],"tags":["docker"]},{"location":"esp32/","level":1,"title":"玩转ESP32","text":"<p>ESP32的生态比较好，类似arduino, 但是集成了wifi和蓝牙，有的甚至集成了gps，功能很强大而且便宜。最近淘宝买了一个ESP32-USB-Geek， 带一个LCD屏幕和几个扩展接口，还有闪存口可以读写。</p> <p>![[esp32-usb-geek.png.png]]</p>","path":["玩转ESP32"],"tags":["esp","arduino"]},{"location":"esp32/#_1","level":2,"title":"编译烧录","text":"<p>ESP32 有3种方式： 官方的idf， mpy, arduino。</p>","path":["玩转ESP32"],"tags":["esp","arduino"]},{"location":"esp32/#_2","level":3,"title":"官方工具","text":"<p>官方的idf分vscode插件和python脚本， vscode中没有成功，不过idf.py可以编译和烧录。</p> <p>根据官方文档写的下载安装idf，解压后执行脚本。安装脚本依赖python-venv， 而我最常用vituralenv</p> <pre><code>bash v5.3.1/esp-idf/install.sh\n</code></pre> <p>进入淘宝店例子, 用cmake管理的。 在跟目录执行</p> <pre><code>idf.py set-target esp32-s3\n</code></pre> <p>这种方式支持非常复杂的配置</p> <pre><code>idf.py menuconfig\n</code></pre> <p>编译刷入</p> <pre><code>idf.py build\n\nidf.py -p /dev/ttyACM0 flash\n</code></pre> <p>官方的方式最能了解物理设备了。看日志发现他生成了bin文件，并从0位置刷入bin文件。</p>","path":["玩转ESP32"],"tags":["esp","arduino"]},{"location":"esp32/#mpy-thonny-ide","level":3,"title":"mpy thonny ide","text":"<p>最好用pip安装最新的。 将python上传到esp后，点运行就可以了，还能在REPL中仿真调试，非常方便。</p>","path":["玩转ESP32"],"tags":["esp","arduino"]},{"location":"esp32/#arduino","level":3,"title":"arduino","text":"<p>arduino ide gui版本编译失败，而且因为是Linux版是用java写的，操作非常慢。改用arduio-cli脚本成功， 官方文档也说了arduino-cli非常强大。这里说脚本使用方法。</p>","path":["玩转ESP32"],"tags":["esp","arduino"]},{"location":"esp32/#_3","level":4,"title":"初始化配置","text":"<ol> <li> <p>首先下载压缩包，解压到PATH目录下。</p> </li> <li> <p>初始化配置， <code>arduino-cli config init</code> 可以生成配置文件'~/.arduino15/arduino-cli.yaml'。</p> </li> <li> <p>修改配置文件， 根据淘宝老板说的，ESP32的板子要从另外第三方源中， 因为这个源是githubcontent需要梯子才能访问，修改成如下</p> </li> </ol> <pre><code>$ cat ~/.arduino15/arduino-cli.yaml\n\nboard_manager:\n\nadditional_urls: ['https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_index.json']\n\n\n\nnetwork:\n\nproxy: 'socks5://ip:port'\n</code></pre>","path":["玩转ESP32"],"tags":["esp","arduino"]},{"location":"esp32/#_4","level":4,"title":"安装板子库和依赖库","text":"<p>当没有下载板子时，查看连接的设备会显示Unknown</p> <pre><code>$ arduino-cli board list\n\nPort Protocol Type Board Name FQBN Core\n\n/dev/ttyACM0 serial Serial Port (USB) Unknown\n</code></pre> <p>显示搜索所有板子（包括在添加的第三方源里的）, 这里搜索ESP32核心板， 淘宝老板说，我的开发板叫 ESP32S3 Dev Module</p> <pre><code>$ arduino-cli board listall ESP32S3 Dev Module\n\nESP32S3 Dev Module esp32:esp32:esp32s3\n</code></pre> <p>安装板子module， 比较大要等待一会。 tips： 板子的包叫module, 软件依赖库叫library</p> <pre><code>$ arduino-cli core install esp32:esp32\n</code></pre> <p>搜索已安装的安装核心板</p> <pre><code>$ arduino-cli core search esp32\n\nID Version Name\n\narduino:esp32 2.0.18-arduino.5 Arduino ESP32 Boards\n\nesp32:esp32 3.0.7 esp32\n</code></pre>","path":["玩转ESP32"],"tags":["esp","arduino"]},{"location":"esp32/#_5","level":4,"title":"编译","text":"<p>编译淘宝店的例子LCD_Button，要在LCD_Button外面执行</p> <p>arduino-cli compile --fqbn esp32:esp32:esp32s3 LCD_Button</p>","path":["玩转ESP32"],"tags":["esp","arduino"]},{"location":"esp32/#_6","level":4,"title":"上传到板子","text":"<p>arduino-cli upload -p /dev/ttyACM0 --fqbn esp32:esp32:esp32s3 LCD_Button</p> <p>有时候失败了，要按住Boot键插入电脑再松开，就能正常上传。</p> <pre><code>esptool.py v4.6\n\nSerial port /dev/ttyACM0\n\nConnecting...\n\nTraceback (most recent call last):\n\n...\n\nOSError: [Errno 71] Protocol error\n\nFailed uploading: uploading error: exit status 1\n</code></pre> <p>看这个日志，原来arduino也是调用的官方的idf工具的esptool脚本。 重新插入USB， 再次查看已连接的开发板就不会显示Unknown了</p> <pre><code>$ arduino-cli board list\n\nPort Protocol Type Board Name FQBN Core\n\n/dev/ttyACM0 serial Serial Port (USB) ESP32 Family Device esp32:esp32:esp32_family esp32:esp32\n</code></pre>","path":["玩转ESP32"],"tags":["esp","arduino"]},{"location":"esp32/#uart","level":2,"title":"连接串口UART","text":"<p>烧录了淘宝店给的串口收发例子，代码非常简单， 然后用我的USB转ttl工具测试成功。</p> <pre><code>import machine\n\n\n\nuart = machine.UART(1, baudrate=115200, tx=machine.Pin(43), rx=machine.Pin(44))\n\n\n\ndef send_data(data):\n\nuart.write(data)\n\n\n\ndef receive_data():\n\nif uart.any():\n\ndata = uart.read()\n\nprint(\"Received data:\",data)\n\n\n\n\nwhile True:\n\nsend_data(\"Hello UART\")\n\nreceive_data()\n</code></pre> <p>然而这里是不对的， 串口转TTL和ESP的USB都要连接到电脑上。单连一个都是进了mpy的repl。</p> <p>![[usb-ttl-esp32-uart.png.png]]</p>","path":["玩转ESP32"],"tags":["esp","arduino"]},{"location":"ffmpeg-AVCodecContext/","level":1,"title":"libavcodec使用","text":"<p>记录ffmpeg的学习系列，这是关于AVCodecContext的部分。</p>","path":["libavcodec使用"],"tags":["ffmpeg","音视频"]},{"location":"ffmpeg-AVCodecContext/#sample_fmt","level":2,"title":"sample_fmt","text":"<p>解码器avctx中的sample_fmt,是解码后的原始音频（PCM）采样格式，几乎所有的音频格式（amr,mp3）解码后都是PCM。但是采样格式可能不同，这个是由解码器来设定的。 具体在打开解码器的时候<code>avcodec_open2</code>, 需要传入解码解码avctx, 这个函数会调用解码器的<code>init</code>函数，从而将解码器的设定同步到avctx中。 对于编码器而言，这个值由是用户自己设置。如注释所说：</p> <pre><code>    /**\n     * audio sample format\n     * - encoding: Set by user.\n     * - decoding: Set by libavcodec.\n     */\n    enum AVSampleFormat sample_fmt;  ///&lt; sample format\n</code></pre> <p>所有的采样格式。因为工作需要解码amr, 先是自己基于opencore开发的，解码后是S16（即AV_SAMPLE_FMT_S16）, 而用ffmpeg解码后是AV_SAMPLE_FMT_FLTP, 这样的话重采样一次，效率低。后来发现ffmpeg有两套amr解码实现，选择opencore版本就是S16了。 <pre><code>enum AVSampleFormat {\n    AV_SAMPLE_FMT_NONE = -1,\n    AV_SAMPLE_FMT_U8,          ///&lt; unsigned 8 bits\n    AV_SAMPLE_FMT_S16,         ///&lt; signed 16 bits\n    AV_SAMPLE_FMT_S32,         ///&lt; signed 32 bits\n    AV_SAMPLE_FMT_FLT,         ///&lt; float\n    AV_SAMPLE_FMT_DBL,         ///&lt; double\n\n    AV_SAMPLE_FMT_U8P,         ///&lt; unsigned 8 bits, planar\n    AV_SAMPLE_FMT_S16P,        ///&lt; signed 16 bits, planar\n    AV_SAMPLE_FMT_S32P,        ///&lt; signed 32 bits, planar\n    AV_SAMPLE_FMT_FLTP,        ///&lt; float, planar\n    AV_SAMPLE_FMT_DBLP,        ///&lt; double, planar\n    AV_SAMPLE_FMT_S64,         ///&lt; signed 64 bits\n    AV_SAMPLE_FMT_S64P,        ///&lt; signed 64 bits, planar\n\n    AV_SAMPLE_FMT_NB           ///&lt; Number of sample formats. DO NOT USE if linking dynamically\n};\n</code></pre></p>","path":["libavcodec使用"],"tags":["ffmpeg","音视频"]},{"location":"firefox-manual-add-search-engine/","level":1,"title":"firefox 启用手动添加搜索引擎","text":"<ol> <li>Open a new tab and type about:config in the address bar</li> <li>In the search box type: browser.urlbar.update2.engineAliasRefresh</li> <li>Click on the little + symbol on the right. This is what it should look like after you pressed it: boolean true value after pressing plus sign</li> <li>Go to firefox Settings → Search. Or enter this in the address bar: about:preferences#search</li> <li>In the \"Search Shortcuts\" section you should notice a new \"add\" button.</li> </ol>","path":["firefox 启用手动添加搜索引擎"],"tags":["firefox"]},{"location":"firefox-manual-add-search-engine/#_1","level":2,"title":"参考","text":"<p>https://superuser.com/questions/7327/how-to-add-a-custom-search-engine-to-firefox</p>","path":["firefox 启用手动添加搜索引擎"],"tags":["firefox"]},{"location":"format-in-c/","level":1,"title":"在c语言中打印支持不同类型变量","text":"<p>in this doc, i'll introduce how to print(stringify) variable of different types, <code>typeof</code> is a GCC extension, and <code>_Generic</code> is part of C11. typeof is disabled by option '-std=*' or '-ansi<code>, so use</code>typeof` instead. </p>","path":["在c语言中打印支持不同类型变量"],"tags":["c"]},{"location":"format-in-c/#c11-_generic","level":2,"title":"c11 _Generic","text":"<pre><code>#include &lt;stdio.h&gt;\n\n#define PRINT_VAR(var)        \\\n    _Generic((var),           \\\n        int: print_int,       \\\n        float: print_float,   \\\n        double: print_double, \\\n        char: print_char      \\\n    )(#var, (var))\n\n// Type-specific print functions\nvoid print_int(const char* name, int value) {\n    printf(\"%s = %d\\n\", name, value);\n}\n\nvoid print_float(const char* name, float value) {\n    printf(\"%s = %.2f\\n\", name, value);\n}\n\nvoid print_double(const char* name, double value) {\n    printf(\"%s = %.2f\\n\", name, value);\n}\n\nvoid print_char(const char* name, char value) {\n    printf(\"%s = %c\\n\", name, value);\n}\n\nint main() {\n    int x = 10;\n    float y = 3.14f;\n    double z = 3.14159;\n    char c = 'A';\n\n    PRINT_VAR(x);  // Prints: x = 10\n    PRINT_VAR(y);  // Prints: y = 3.14\n    PRINT_VAR(z);  // Prints: z = 3.14\n    PRINT_VAR(c);  // Prints: c = A\n\n    return 0;\n}\n</code></pre>","path":["在c语言中打印支持不同类型变量"],"tags":["c"]},{"location":"format-in-c/#simpler-way","level":2,"title":"simpler way","text":"<p>linter raise warnings if place <code>printf</code> directly in <code>_Generic</code>.</p> <pre><code>#define DECLARE_PRINT_FUNC(value)                                              \\\n  do {                                                                         \\\n    printf(\"%s = \", #value);                                                   \\\n    char *format = NULL;                                                       \\\n    _Generic((value),                                                          \\\n        int: format = \"%d\\n\",                                                  \\\n        long unsigned int: format = \"%lu\\n\",                                   \\\n        long: format = \"%ld\\n\",                                                \\\n        float: format = \"%.2f\\n\",                                              \\\n        double: format = \"%.2f\\n\",                                             \\\n        char: format = \"%c\\n\",                                                 \\\n        default: format = NULL);                                               \\\n    format != NULL ? printf(format, (value)):                                  \\\n    printf(\"Unknown type\\n\");                                                  \\\n  } while (0)\n</code></pre>","path":["在c语言中打印支持不同类型变量"],"tags":["c"]},{"location":"format-in-c/#using-gcc-build-in-typeof-instead-of-_generic","level":2,"title":"using GCC build-in <code>typeof</code> instead of <code>_Generic</code>","text":"<pre><code>#include &lt;stdio.h&gt;\n\n#define PRINT_VAR_TYPEOF(var)                                                  \\\n  do {                                                                         \\\n    printf(\"%s = \", #var);                                                     \\\n    char *format = NULL;                                                       \\\n    __typeof__(var) _v = (var);                                                \\\n    if (__builtin_types_compatible_p(__typeof__(_v), int))                     \\\n      format = \"%d\\n\";                                                         \\\n    else if (__builtin_types_compatible_p(__typeof__(_v), float))              \\\n      format = \"%.2f\\n\";                                                       \\\n    else if (__builtin_types_compatible_p(__typeof__(_v), double))             \\\n      format = \"%.2f\\n\";                                                       \\\n    else if (__builtin_types_compatible_p(__typeof__(_v), char))               \\\n      format = \"%c\\n\";                                                         \\\n    printf(format, (var));                                                     \\\n  } while (0)\n</code></pre>","path":["在c语言中打印支持不同类型变量"],"tags":["c"]},{"location":"gcc-optimize-memory-function/","level":1,"title":"gcc 会优化很多内存相关的调用","text":"<p>他们通常在'string.h'里，比如memcpy, 当编译器通过上下文能推断出传入参数类型，libc的mempcy就会替换为gcc的memcpy, 这可能导致问题</p>","path":["gcc 会优化很多内存相关的调用"],"tags":["c","cpp","gcc"]},{"location":"gcc-optimize-memory-function/#_1","level":2,"title":"举例","text":"<p>知乎评论的，release版本的memset被替换, 导致跟debug版本不同行为bug <pre><code>https://www.zhihu.com/question/435258463/answer/1969561682\n</code></pre></p>","path":["gcc 会优化很多内存相关的调用"],"tags":["c","cpp","gcc"]},{"location":"gcc-optimize-memory-function/#_2","level":2,"title":"内存地址对齐","text":"<p>如果内存地址对齐的，那么'取值地址被取值长度求模为0'，例如<code>int i</code>, 则要求<code>(void*)&amp;i % sizeof(int) == 0</code> </p>","path":["gcc 会优化很多内存相关的调用"],"tags":["c","cpp","gcc"]},{"location":"gcc-optimize-memory-function/#_3","level":2,"title":"原因","text":"<p>当同时定义多个变量时，不考虑编译器优化，则他们在内存的位置相邻。按照不同的对齐长度，有不同的占用大小 这里以结构体举例</p> <p><pre><code>struct bar{\n    int interger;\n        char charactor;\n        long long longlong;\n};\n</code></pre> 使用<code>#pragma pack(4)</code> 设置按4字节对齐，默认也是4字节，那么<code>sizeof(struct abc) == 16</code> 使用gdb打印内存地址，可见地址都对齐的: '0x7fffffffe430&amp;4==0' '0x7fffffffe438%8==0' <pre><code>(gdb) p sizeof(struct abc)\n$5 = 16\n(gdb) p &amp;a.interger \n$1 = (int *) 0x7fffffffe430\n(gdb) p &amp;a.charactor \n$2 = 0x7fffffffe434 \"\\232\\177\"\n(gdb) p &amp;a.longlong \n$3 = (long long *) 0x7fffffffe438\n(gdb) p &amp;a\n$4 = (abc *) 0x7fffffffe430\n</code></pre></p> <p>顺便提一下，指针指向的是内存段的低地址，所以有个面试题是判断系统是大端小端的方法如下 通过如下强转int为char, 如果<code>c==0x12</code>则为大端，否则为小端系统 <pre><code>int i=0x12345678;\nchar c=(char)i;\n</code></pre></p> <p>使用<code>#pragma pack(1)</code> 设置为按1字节对齐，则上面的结构体大小为'13'，显然更省内存了 但通过取地址会发现地址未对齐, 求模不为0。 但我自己使用gcc测试地址依旧对齐的，原因是编译器会进行自然 对齐</p>","path":["gcc 会优化很多内存相关的调用"],"tags":["c","cpp","gcc"]},{"location":"gcc-optimize-memory-function/#_4","level":2,"title":"自然对齐","text":"<p>上面的<code>#pragma pack(1)</code>虽然使得longlong的地址对于bar来说偏移了5字节，但编译器始终能调整bar的起始地址使得longlong的地址对齐 <pre><code>595fac88 \nc3c5a2d8\n105d3ab8\n</code></pre></p>","path":["gcc 会优化很多内存相关的调用"],"tags":["c","cpp","gcc"]},{"location":"gcc-optimize-memory-function/#_5","level":2,"title":"不对齐的坏处","text":"<p>虽然上面说了编译器能自然对齐，但还是会真的出现不对齐访问。由于对内存的访问涉及到具体硬件的实现，所以一般会有几种影响 1. 硬件平台支持非对齐访问，但性能有损耗 2. 抛出异常给cpu,由cpu来校准，性能有更大损耗 3. 平台不支持，但也不抛异常，获取的是错误的值，导致难定位的异常</p>","path":["gcc 会优化很多内存相关的调用"],"tags":["c","cpp","gcc"]},{"location":"gcc-optimize-memory-function/#_6","level":2,"title":"引用","text":"<p>https://www.kernel.org/doc/html/latest/core-api/unaligned-memory-access.html</p>","path":["gcc 会优化很多内存相关的调用"],"tags":["c","cpp","gcc"]},{"location":"gdb/","level":1,"title":"gdb调试容器内的进程","text":"<p>先来个gdb手册链接 这里记录一下自己常用的技巧</p>","path":["gdb调试容器内的进程"],"tags":["c","cpp","gdb"]},{"location":"gdb/#debug","level":2,"title":"恢复debug符号","text":"<p>通常上线的程序要strip符号表来减少**内存占用**和硬盘占用，会执行以下命令 <pre><code>## 1. 只保留debug表的内容（可选），为以后调试用，生产时不用\nobjcopy --only-keep-debug foo foo.dbg\n\n## 2. 将foo的debug表删除，不要任何调试信息，用于生产使用\nobjcopy --strip-debug  foo \n</code></pre></p> <p>如果生产出问题了，就需要恢复debug信息，add-gnu-debuglink参数可以是foo.dbg, 也可以就是strip之前的foo文件 所以第一步是可选的 </p> <pre><code>## 3. 恢复debug信息\nobjcopy --add-gnu-debuglink=foo.dbg foo\n</code></pre> <p>但其实第三步也是可选的，只要把foo.dbg放到foo相同位置时，gdb就可以读取到debug信息</p>","path":["gdb调试容器内的进程"],"tags":["c","cpp","gdb"]},{"location":"gdb/#gdbinit","level":2,"title":"使用.gdbinit","text":"<p>.gdbinit 文件是类似.bash_profile的文件，一般在home目录或者项目根目录, gdb 自动读取   也可以手动读取其他位置的, 在gdb执行<code>source /somedir/.gdbinit</code></p> <p>通常可以在这个文件里定义一些设置例如<code>set pagination off</code> 关闭输出分页, 就不用每次交互确定 还可以定义命令 如pvector可以打印vector内的所有成员, 非常比较方便</p>","path":["gdb调试容器内的进程"],"tags":["c","cpp","gdb"]},{"location":"gdb/#gdb_1","level":2,"title":"gdb 调试容器内的进程","text":"<p>因为容器内运行的程序都是strip了debug符号的，所以之前调试都是先将debug文件复制到容器对应位置，然后将源码也映射到容器内，而且还要安装gdb和重新开启priveledge模式， 非常繁琐。  所以尝试如下操作： 1. 能不能单独一个容器安装gdb和符号和代码文件， 跨容器去调试另一个容器的进程呢？  2. 能不能在宿主机上直接调试容器进程呢？   </p> <p>经过一番搜索，没有第一种方案的实践办法，但第二种方案亲测可行！</p>","path":["gdb调试容器内的进程"],"tags":["c","cpp","gdb"]},{"location":"gdb/#_1","level":2,"title":"步骤","text":"<ol> <li>先启动容器，一般业务主进程的pid为1  </li> <li>在容器外面执行<code>ps aux | grep xxx</code>，因为在很多情况是多个容器跑同一个程序，所以<code>ps aux</code> 通过参数名来确定进程的pid， 当然最好的方式是通过进程namespace了 </li> <li>使用sudo gdb -p pid， 提示缺少<code>Missing separate debuginfo for target</code></li> <li>将debug符号文件复制到容器对应容器的目录</li> <li>再次attach，提示缺少源文件<code>/builds/project/src/aaa.cpp</code>，这是cmake编译时的目录，需要替换</li> <li>在gdb里执行命令 set substitute-path /builds/ /home/my-home/  # from -&gt; to</li> <li>然后使用l可以查看对应的源代码了</li> </ol>","path":["gdb调试容器内的进程"],"tags":["c","cpp","gdb"]},{"location":"gdb/#_2","level":2,"title":"总结","text":"<p>可以直接在宿主机上运行gdb来调试容器进程，并替换代码路径为宿主机的目录。 </p> <p>ps: gdb 启动时默认会读取~/.gdbinit 文件, 但是gdb会提示, 这是由于调试docker需要sudo权限，而我的gdbinit在非root目录</p> <pre><code>warning: File \"/home/h/.gdbinit\" auto-loading has been declined by your `auto-load safe-path' set to \"$debugdir:$datadir/auto-load\".                                                        \nTo enable execution of this file add                                                                                                                                                          \n        add-auto-load-safe-path /home/h/.gdbinit                                                                                                                                            \nline to your configuration file \"/root/.gdbinit\".                                                                                                                                             \nTo completely disable this security protection add                                                                                                                                            \n        set auto-load safe-path /                                                                                                                                                             \nline to your configuration file \"/root/.gdbinit\".                                                                                                                                             \n</code></pre> <p>也就是需要手动执行<code>set auto-load safe-path /</code> 或者将 <code>add-auto-load-safe-path /home/h/.gdbinit</code>写入/root/.gdbinit </p>","path":["gdb调试容器内的进程"],"tags":["c","cpp","gdb"]},{"location":"generate%20compile_commands%20json/","level":1,"title":"ways of generating compile command json file","text":"<p>clangd is programming language server of clang, requires a compile_commands.json file located in source code directory for the best. I recommend intercept-build for generating the file, because it is included in clang-tools package when compiling via make and makefile.</p> <ul> <li>intercept-build make -B</li> <li>bear make -B</li> <li>compiledb make -B</li> <li>meson, cmake</li> <li>codechecker</li> </ul> <p>or use bash script <pre><code>make --always-make --dry-run \\\n | grep -wE 'gcc|g\\+\\+' \\\n | grep -w '\\-c' \\\n | jq -nR '[inputs|{directory:\".\", command:., file: match(\" [^ ]+$\").string[1:]}]' \\\n &gt; compile_commands.json\n</code></pre></p>","path":["ways of generating compile command json file"],"tags":["clang","dev-tool"]},{"location":"generate%20compile_commands%20json/#reference","level":2,"title":"reference","text":"<p>https://releases.llvm.org/11.0.1/tools/clang/docs/JSONCompilationDatabase.html https://gist.github.com/gtors/effe8eef7dbe7052b22a009f3c7fc434 https://stackoverflow.com/questions/21134120/how-to-turn-makefile-into-json-compilation-database</p>","path":["ways of generating compile command json file"],"tags":["clang","dev-tool"]},{"location":"generate%20random%20number/","level":1,"title":"generate random number","text":"<p>Recently, when analyzing a pcap of an RTP stream, I found that the SSRC of two streams was the same. After some research, I discovered that using time() as a seed for srand() can return the same result if called multiple times within a second. Using gettimeofday() provides higher resolution.</p> <p>More importantly, srand() should be called only once in the main function!</p>","path":["generate random number"],"tags":["random","c"]},{"location":"generate%20random%20number/#use-time-as-rand-seed","level":2,"title":"use time() as rand seed","text":"<pre><code>    srand(time(NULL));  // Set random seed using current time\n    int r = rand();     // Get a pseudo-random number\n    return 0;\n</code></pre>","path":["generate random number"],"tags":["random","c"]},{"location":"generate%20random%20number/#use-gettimeofday-as-rand-seed","level":2,"title":"use gettimeofday() as rand seed","text":"<pre><code>void seed_rand_with_time() {\n    struct timeval tv;\n    gettimeofday(&amp;tv, NULL);\n    // Combine seconds and microseconds for better entropy\n    unsigned int seed = (unsigned int)(tv.tv_sec ^ tv.tv_usec);\n    srand(seed);\n}\n</code></pre>","path":["generate random number"],"tags":["random","c"]},{"location":"get%20fd%20in%20the%20other%20process/","level":1,"title":"获取其他进程打开的文件描述符","text":"<p>fd是文件描述符，每个进程的fd是不共享的，只能在当前进程操作。可以通过命令<code>ls /proc/self/fd -l</code>看到打开的fd。例如一眼能猜到0,1,2就是输入输出和错误输出都关联到了终端。那如果要从其他进程写入打开的文件呢，那就要先获取到fd, 当然不能复制fd的值，因为这个值只对本进程有效。</p> <p></p> <pre><code># ls /proc/self/fd -l\ntotal 0\nlrwx------ 1 hst hst 64 Jul 24 14:59 0 -&gt; /dev/pts/13\nlrwx------ 1 hst hst 64 Jul 24 14:59 1 -&gt; /dev/pts/13\nlrwx------ 1 hst hst 64 Jul 24 14:59 2 -&gt; /dev/pts/13\nlr-x------ 1 hst hst 64 Jul 24 14:59 3 -&gt; /proc/2453780/fd\n</code></pre> <p>而sendmsg 和 CMSG可以将本进程打开的文件描述符发送给其他进程，其他进程也能读写该文件。当然是在同主机下。</p> <p>注意 fork, CMSG, pidfd_getfd 获得的文件node是共享的，包括写入读取的偏移量</p>","path":["获取其他进程打开的文件描述符"],"tags":["linux","CMSG","sctp","file"]},{"location":"get%20fd%20in%20the%20other%20process/#sendmsgrecvmsg","level":2,"title":"sendmsg/recvmsg 发送接收文件描述符","text":"","path":["获取其他进程打开的文件描述符"],"tags":["linux","CMSG","sctp","file"]},{"location":"get%20fd%20in%20the%20other%20process/#_2","level":3,"title":"发送","text":"<pre><code>void send_fd(int socket, int fd_to_send) {\n    struct msghdr msg = {0};\n    char buf[CMSG_SPACE(sizeof(int))];\n    memset(buf, 0, sizeof(buf));\n\n    struct cmsghdr *cmsg;\n    char iobuf[1] = {0};\n    struct iovec io = {\n        .iov_base = iobuf,\n        .iov_len = sizeof(iobuf)\n    };\n\n    msg.msg_iov = &amp;io;\n    msg.msg_iovlen = 1;\n    msg.msg_control = buf;\n    msg.msg_controllen = sizeof(buf);\n\n    cmsg = CMSG_FIRSTHDR(&amp;msg);\n    cmsg-&gt;cmsg_level = SOL_SOCKET;\n    cmsg-&gt;cmsg_type = SCM_RIGHTS;\n    cmsg-&gt;cmsg_len = CMSG_LEN(sizeof(int));\n\n    memcpy(CMSG_DATA(cmsg), &amp;fd_to_send, sizeof(int));\n\n    if (sendmsg(socket, &amp;msg, 0) == -1) {\n        perror(\"sendmsg\");\n        exit(-1);\n    }\n}\n</code></pre>","path":["获取其他进程打开的文件描述符"],"tags":["linux","CMSG","sctp","file"]},{"location":"get%20fd%20in%20the%20other%20process/#_3","level":3,"title":"接收","text":"<pre><code>int recv_fd(int socket) {\n    struct msghdr msg = {0};\n    char m_buffer[1] = {0};\n    struct iovec io = {\n        .iov_base = m_buffer,\n        .iov_len = sizeof(m_buffer)\n    };\n\n    char cmsgbuf[CMSG_SPACE(sizeof(int))];\n    msg.msg_iov = &amp;io;\n    msg.msg_iovlen = 1;\n    msg.msg_control = cmsgbuf;\n    msg.msg_controllen = sizeof(cmsgbuf);\n\n    if (recvmsg(socket, &amp;msg, 0) == -1) {\n        perror(\"recvmsg\");\n        exit(-1);\n    }\n\n    struct cmsghdr *cmsg = CMSG_FIRSTHDR(&amp;msg);\n    int fd;\n    memcpy(&amp;fd, CMSG_DATA(cmsg), sizeof(int));\n    return fd;\n}\n</code></pre>","path":["获取其他进程打开的文件描述符"],"tags":["linux","CMSG","sctp","file"]},{"location":"get%20fd%20in%20the%20other%20process/#pidfd_getfd","level":2,"title":"更简单的方法获取文件描述符 pidfd_getfd","text":"<p>Linux 5.6后，pidfd_getfd 可以用来获取其他进程打开的fd，因为glibc没有包装这个函数，所以用syscall，汇编代码里也看到syscall。 <pre><code>       int syscall(SYS_pidfd_getfd, int pidfd, int targetfd,\n                   unsigned int flags);\n\n       Note: glibc provides no wrapper for pidfd_getfd(), necessitating\n       the use of syscall(2).\n</code></pre></p>","path":["获取其他进程打开的文件描述符"],"tags":["linux","CMSG","sctp","file"]},{"location":"get%20fd%20in%20the%20other%20process/#fork","level":2,"title":"还有更简单的fork继承文件描述符","text":"<p>fork前先打开文件，这样两个进程都能读写文件了。 <pre><code>int fd = open(\"text.txt\", O_RDONLY);\nfork();\n</code></pre></p>","path":["获取其他进程打开的文件描述符"],"tags":["linux","CMSG","sctp","file"]},{"location":"get%20fd%20in%20the%20other%20process/#reference","level":2,"title":"reference","text":"<p>https://www.man7.org/linux/man-pages/man3/cmsg.3.html https://man7.org/linux/man-pages/man2/pidfd_getfd.2.html https://stackoverflow.com/questions/2358684/can-i-share-a-file-descriptor-to-another-process-on-linux-or-are-they-local-to-t</p>","path":["获取其他进程打开的文件描述符"],"tags":["linux","CMSG","sctp","file"]},{"location":"gitcommand/","level":1,"title":"Git的重要操作","text":"","path":["Git的重要操作"],"tags":["git","tool"]},{"location":"gitcommand/#git_1","level":1,"title":"Git登录信息","text":"<p>在临时环境下拉代码， 如果重新生成密钥再添加到托管平台比较麻烦，要么拷贝自己的私钥过来，更加不安全。 这时候临时用密码登录最适合了， 但是每个pull fetch操作都要登录，这很烦躁，所以下面有2个方法解决</p>","path":["Git的重要操作"],"tags":["git","tool"]},{"location":"gitcommand/#_1","level":2,"title":"设置密码暂存","text":"<p>指类似sudo命令一样， 校验成功之后一段时间，不需要输入密码 <pre><code>git config --global   credential.helper 'cache --timeout 900'\n</code></pre> 我们都知道Git 的配置分3种级别 local system global， 这里推荐global。 因为只设置local，在有submodule的情况下，同样会提示输入密码。</p>","path":["Git的重要操作"],"tags":["git","tool"]},{"location":"gitcommand/#_2","level":2,"title":"设置密码永存","text":"<p>不推荐  <pre><code>git config --global   credential.helper store\n</code></pre></p>","path":["Git的重要操作"],"tags":["git","tool"]},{"location":"gitcommand/#git_2","level":2,"title":"git为不同项目配置不同的用户名和邮箱","text":"<p>电脑中同时有个人项目和公司项目时，有时候会导致commit 消息里面的邮件搞串了。可以通过git配置不同目录下的项目使用不同的信息。参考</p>","path":["Git的重要操作"],"tags":["git","tool"]},{"location":"go-learning/","level":1,"title":"go 学习笔记","text":"","path":["go 学习笔记"],"tags":["golang"]},{"location":"go-learning/#go_1","level":2,"title":"go为什么要指针和什么时候必须用指针","text":"<ol> <li>传递waitgroup时</li> <li>获取命令行参数</li> </ol>","path":["go 学习笔记"],"tags":["golang"]},{"location":"go-learning/#_1","level":2,"title":"全局变量和多变量赋值问题","text":"<p>因为很多函数需要处理error, 当存在全局变量时，可能会覆盖全局变量</p> <p><pre><code>var global_var int = 1\nfunc foo(){\n  // 此时覆盖了全局变量\n  global_var, err := os.OpenFile(\"file\")\n}\n</code></pre> 应改为 <pre><code>var global_var int = 1\nfunc foo(){\n  var err error\n  global_var, error = os.OpenFile(\"file\")\n}\n</code></pre></p>","path":["go 学习笔记"],"tags":["golang"]},{"location":"go-learning/#slice","level":2,"title":"数组和slice的区别","text":"<p>数组和slice使用上如同c++里的std::array和std::vector, 数组的长度固定，slice长度可以2倍扩容 但有传参上有大区别: golang中数组是值传递，相当于将整个数组复制一遍，而slice是引用传递，所以slice用得多，map同理  </p> <p>定义数组和slice: <pre><code>// 数组\nvar a [3] int\narr := [5] int {1,2,3,4,5}\nvar array2 = [...]int {6,7,8}\nq := [...] int {1,2,3} // 省略长度\nq2 := [...] int {99, -1} // 前99项为0,第100个元素是-1\n\n// slice\ns1 := []int{1, 2, 3}\na := [10]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 0}  //a是数组\ns2 := a[2:8]         \ns3 := make([]int, 10, 20) \n</code></pre></p>","path":["go 学习笔记"],"tags":["golang"]},{"location":"go-learning/#var-make","level":2,"title":"var 和 := 区别, 以及哪些类型需要make","text":"<p>两者很多时候可以相互替换，但是在不同类型上，有区别</p> <p>对于基本类型string, int, boolean, 数组，var<code>声明</code>即初始化 <pre><code>var str string // 自动初始化为空字符串\nvar inter int // 自动初始化为0\nvar bo bool // 自动初始化为false\n\n// 可以直接使用\nfmt.Printf(\"%s %d %t\", str, inter, bo) \n</code></pre></p> <p>而对于slice, map, chann类型而言, 使用<code>var m map[int]string</code>只是声明，需要再用<code>make</code>来获得内存和初始化 <pre><code>var m map[int] string // 此时不能使用m\nm = make(map[int] string){1:\"a\",2:\"b\"}\nfmt.Println(m[1])\n</code></pre> 而上面的步骤可以简化成 <pre><code>m := make(map[int] string){1:\"a\", 2:\"b\"}\n</code></pre> 或直接 <pre><code>m := map[int] string{1:\"a\", 2:\"b\"}\n</code></pre></p>","path":["go 学习笔记"],"tags":["golang"]},{"location":"grammer-noun-of-noun/","level":1,"title":"语法规则-名词修饰名词","text":"<p>无论书写还是口语，无论英文还是中文，当用名词修饰名词时，就感觉容易找不到主体(subject)  ，但这种用法有很常见，特别是中文。比如电脑/人脑，说明书/漫画书，都是用名词修饰名词，也可以说是造了新（名）词，在英文中有很多名词+名词合成的派生词， 例如bookstore。大家接受这种词因为没有歧义，大家都知道前面的名词是用来修饰后面的词。例如说电脑，大家都知道指“带电的脑”，不会以为指“脑里面的电”。bookstore 则都认为指 store of books(有书的店)，不会认为是 book of stores(有店的书)。</p> <p>但如果句子比较复杂时，就容易有歧义了。</p>","path":["语法规则-名词修饰名词"],"tags":["grammar"]},{"location":"grammer-noun-of-noun/#_1","level":2,"title":"举例中文","text":"<p>当长一点的句子，有词修饰词的情况时，就会可能有歧义，特别是比较陌生时，不一定能靠语句分析出主体，而熟悉的东西可以靠经验储备来辅助</p> <p>”新的证据表格“: 1. 新修饰的表格，表格有新旧之分，新表格和表格都用于记录证据 2. 新修饰的证据，证据有新旧之分，表格专门用来记录新证据</p>","path":["语法规则-名词修饰名词"],"tags":["grammar"]},{"location":"grammer-noun-of-noun/#_2","level":2,"title":"举例英文","text":"<p>new evidence table 这里有歧义： 新表格还是新证据？</p> <p>正确的说法 * new table of evidence， 新表格 * new evidence in the table, 新证据</p>","path":["语法规则-名词修饰名词"],"tags":["grammar"]},{"location":"grammer-noun-of-noun/#_3","level":2,"title":"英文中的名词修饰名词","text":"<p>英文中的名词 </p> <p>Noun-adjunct-维基 知乎</p>","path":["语法规则-名词修饰名词"],"tags":["grammar"]},{"location":"grammer-noun-of-noun/#of","level":2,"title":"多个of 情况","text":"<p>是不推荐的</p>","path":["语法规则-名词修饰名词"],"tags":["grammar"]},{"location":"grammer-noun-of-noun/#_4","level":2,"title":"总结","text":"<p>对于英文而言，名词修饰名词的情况比较少见，除非是常用的或者派生词。用“名词 of 名词”是比较合理的。而当多个of时， 虽然语法上没错，但是容易产生歧义，这时需要调整语句结构来消除歧义。中文同理。</p>","path":["语法规则-名词修饰名词"],"tags":["grammar"]},{"location":"grpc-callback-api/","level":1,"title":"grpc callback api","text":"","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#c-callback-based-asynchronous-api","level":2,"title":"C++ callback-based asynchronous API","text":"<ul> <li>Author(s): vjpai, sheenaqotj, yang-g, zhouyihaiding</li> <li>Approver: markdroth</li> <li>Status: Proposed</li> <li>Implemented in: https://github.com/grpc/grpc/projects/12</li> <li>Last updated: March 22, 2021</li> <li>Discussion at https://groups.google.com/g/grpc-io/c/rXLdWWiosWg</li> </ul>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#abstract","level":2,"title":"Abstract","text":"<p>Provide an asynchronous gRPC API for C++ in which the completion of RPC actions in the library will result in callbacks to user code,</p>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#background","level":2,"title":"Background","text":"<p>Since its initial release, gRPC has provided two C++ APIs:</p> <ul> <li>Synchronous API</li> <li>All RPC actions (such as unary calls, streaming reads, streaming writes, etc.) block for completion</li> <li>Library provides a thread-pool so that each incoming server RPC executes its method handler in its own thread</li> <li>Completion-queue-based (aka CQ-based) asynchronous API</li> <li>Application associates each RPC action that it initiates with a tag</li> <li>The library performs each RPC action</li> <li>The library posts the tag of a completed action onto a completion queue</li> <li>The application must poll the completion queue to determine which asynchronously-initiated actions have completed</li> <li>The application must provide and manage its own threads</li> <li>Server RPCs don't have any library-invoked method handler; instead the application is responsible for executing the actions for an RPC once it is notified of an incoming RPC via the completion queue</li> </ul> <p>The goal of the synchronous version is to be easy to program. However, this comes at the cost of high thread-switching overhead and high thread storage for systems with many concurrent RPCs. On the other hand, the asynchronous API allows the application full control over its threading and thus can scale further. The biggest problem with the asynchronous API is that it is just difficult to use. Server RPCs must be explicitly requested, RPC polling must be explicitly controlled by the application, lifetime management is complicated, etc. These have proved sufficiently difficult that the full features of the asynchronous API are basically never used by applications. Even if one can use the async API correctly, it also presents challenges in deciding how many completion queues to use and how many threads to use for polling them, as one can either optimize for reducing thread hops, avoiding stranding, reducing CQ contention, or improving locality. These goals are often in conflict and require substantial tuning.</p>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#related-proposals","level":3,"title":"Related proposals","text":"<ul> <li>The C++ callback API has an implementation that is built on top of a new callback completion queue in core. There is also another implementation, discussed below.</li> <li>The API structure has substantial similarities to the gRPC-Node and gRPC-Java APIs.</li> </ul>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#proposal","level":2,"title":"Proposal","text":"<p>The callback API is designed to have the performance and thread scalability of an asynchronous API without the burdensome programming model of the completion-queue-based model. In particular, the following are fundamental guiding principles of the API:</p> <ul> <li>Library directly calls user-specified code at the completion of RPC actions. This user code is run from the library's own threads, so it is very important that it must not wait for completion of any blocking operations (e.g., condition variable waits, invoking synchronous RPCs, blocking file I/O).</li> <li>No explicit polling required for notification of completion of RPC actions.</li> <li>In practice, these requirements mean that there must be a library-controlled poller for monitoring such actions. This is discussed in more detail in the Implementation section below.</li> <li>As in the synchronous API, server RPCs have an application-defined method handler function as part of their service definition. The library invokes this method handler when a new server RPC starts.</li> <li>Like the synchronous API and unlike the completion-queue-based asynchronous API, there is no need for the application to \"request\" new server RPCs. Server RPC context structures will be allocated and have their resources allocated as and when RPCs arrive at the server.</li> </ul>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#reactor-model","level":3,"title":"Reactor model","text":"<p>The most general form of the callback API is built around a reactor model. Each type of RPC has a reactor base class provided by the library. These types are:</p> <ul> <li><code>ClientUnaryReactor</code> and <code>ServerUnaryReactor</code> for unary RPCs</li> <li><code>ClientBidiReactor</code> and <code>ServerBidiReactor</code> for bidi-streaming RPCs</li> <li><code>ClientReadReactor</code> and <code>ServerWriteReactor</code> for server-streaming RPCs</li> <li><code>ClientWriteReactor</code> and <code>ServerReadReactor</code> for client-streaming RPCs</li> </ul> <p>Client RPC invocations from a stub provide a reactor pointer as one of their arguments, and the method handler of a server RPC must return a reactor pointer.</p> <p>These base classes provide three types of methods:</p> <ol> <li>Operation-initiation methods: start an asynchronous activity in the RPC. These are methods provided by the class and are not virtual. These are invoked by the application logic. All of these have a <code>void</code> return type. The <code>ReadMessageType</code> below is the request type for a server RPC and the response type for a client RPC; the <code>WriteMessageType</code> is the response type for a server RPC or the request type for a client RPC.</li> <li><code>void StartCall()</code>: (Client only) Initiates the operations of a call from the client, including sending any client-side initial metadata associated with the RPC. Must be called exactly once. No reads or writes will actually be started until this is called (i.e., any previous calls to <code>StartRead</code>, <code>StartWrite</code>, or <code>StartWritesDone</code> will be queued until <code>StartCall</code> is invoked). This operation is not needed at the server side since streaming operations at the server are released from backlog automatically by the library as soon as the application returns a reactor from the method handler, and because there is a separate method just for sending initial metadata.</li> <li><code>void StartSendInitialMetadata()</code>: (Server only) Sends server-side initial metadata. To be used in cases where initial metadata should be sent without sending a message. Optional; if not called, initial metadata will be sent when <code>StartWrite</code> or <code>Finish</code> is called. May not be invoked more than once or after <code>StartWrite</code> or <code>Finish</code> has been called. This does not exist at the client because sending initial metadata is part of <code>StartCall</code>.</li> <li><code>void StartRead(ReadMessageType*)</code>: Starts a read of a message into the object pointed to by the argument. <code>OnReadDone</code> will be invoked when the read is complete. Only one read may be outstanding at any given time for an RPC (though a read and a write can be concurrent with each other). If this operation is invoked by a client before calling <code>StartCall</code> or by a server before returning from the method handler, it will be queued until one of those events happens and will not actually trigger any activity or reactions until it is thereby released from the queue.</li> <li><code>void StartWrite(const WriteMessageType*)</code>: Starts a write of the object pointed to by the argument. <code>OnWriteDone</code> will be invoked when the write is complete. Only one write may be outstanding at any given time for an RPC (though a read and a write can be concurrent with each other).  As with <code>StartRead</code>, if this operation is invoked by a client before calling <code>StartCall</code> or by a server before returning from the method handler, it will be queued until one of those events happens and will not actually trigger any activity or reactions until it is thereby released from the queue.</li> <li><code>void StartWritesDone()</code>: (Client only) For client RPCs to indicate that there are no more writes coming in this stream.  <code>OnWritesDoneDone</code> will be invoked when this operation is complete. This causes future read operations on the server RPC to indicate that there is no more data available. Highly recommended but technically optional; may not be called more than once per call.  As with <code>StartRead</code> and <code>StartWrite</code>, if this operation is invoked by a client before calling <code>StartCall</code> or by a server before returning from the method handler, it will be queued until one of those events happens and will not actually trigger any activity or reactions until it is thereby released from the queue.</li> <li><code>void Finish(Status)</code>: (Server only) Sends completion status to the client, asynchronously. Must be called exactly once for all server RPCs, even for those that have already been cancelled. No further operation-initiation methods may be invoked after <code>Finish</code>.</li> <li>Operation-completion reaction methods: notification of completion of asynchronous RPC activity. These are all virtual methods that default to an empty function (i.e., <code>{}</code>) but may be overridden by the application's reactor definition. These are invoked by the library. All of these have a <code>void</code> return type. Most take a <code>bool ok</code> argument to indicate whether the operation completed \"normally,\" as explained below.</li> <li><code>void OnReadInitialMetadataDone(bool ok)</code>: (Client only) Invoked by the library to notify that the server has sent an initial metadata response to a client RPC. If <code>ok</code> is true, then the RPC received initial metadata normally. If it is false, there is no initial metadata either because the call has failed or because the call received a trailers-only response (which means that there was no actual message and that any information normally sent in initial metadata has been dispatched instead to trailing metadata, which is allowed in the gRPC HTTP/2 transport protocol). This reaction is automatically invoked by the library for RPCs of all varieties; it is uncommonly used as an application-defined reaction however.</li> <li><code>void OnReadDone(bool ok)</code>: Invoked by the library in response to a <code>StartRead</code> operation. The <code>ok</code> argument indicates whether a message was read as expected. A false <code>ok</code> could mean a failed RPC (e.g., cancellation) or a case where no data is possible because the other side has already ended its writes (e.g., seen at the server-side after the client has called <code>StartWritesDone</code>).</li> <li><code>void OnWriteDone(bool ok)</code>: Invoked by the library in response to a <code>StartWrite</code> operation. The <code>ok</code> argument that indicates whether the write was successfully sent; a false value indicates an RPC failure.</li> <li><code>void OnWritesDoneDone(bool ok)</code>: (Client only) Invoked by the library in response to a <code>StartWritesDone</code> operation. The bool <code>ok</code> argument that indicates whether the writes-done operation was successfully completed; a false value indicates an RPC failure.</li> <li><code>void OnCancel()</code>: (Server only) Invoked by the library if an RPC is canceled before it has a chance to successfully send status to the client side. The reaction may be used for any cleanup associated with cancellation or to guide the behavior of other parts of the system (e.g., by setting a flag in the service logic associated with this RPC to stop further processing since the RPC won't be able to send outbound data anyway). Note that servers must call <code>Finish</code> even for RPCs that have already been canceled as this is required to cleanup all their library state and move them to a state that allows for calling <code>OnDone</code>.</li> <li><code>void OnDone(const Status&amp;)</code> at the client, <code>void OnDone()</code> at the server: Invoked by the library when all outstanding and required RPC operations are completed for a given RPC. For the client-side, it additionally provides the status of the RPC (either as sent by the server with its <code>Finish</code> call or as provided by the library to indicate a failure), in which case the signature is <code>void OnDone(const Status&amp;)</code>. The server version has no argument, and thus has a signature of <code>void OnDone()</code>. Should be used for any application-level RPC-specific cleanup.</li> <li>Thread safety: the above calls may take place concurrently, except that <code>OnDone</code> will always take place after all other reactions. No further RPC operations are permitted to be issued after <code>OnDone</code> is invoked.</li> <li>IMPORTANT USAGE NOTE : code in any reaction must not block for an arbitrary amount of time since reactions are executed on a finite-sized, library-controlled threadpool. If any long-term blocking operations (like sleeps, file I/O, synchronous RPCs, or waiting on a condition variable) must be invoked as part of the application logic, then it is important to push that outside the reaction so that the reaction can complete in a timely fashion. One way of doing this is to push that code to a separate application-controlled thread.</li> <li>RPC completion-prevention methods. These are methods provided by the class and are not virtual. They are only present at the client-side because the completion of a server RPC is clearly requested when the application invokes <code>Finish</code>. These methods are invoked by the application logic. All of these have a <code>void</code> return type.</li> <li><code>void AddHold()</code>: (Client only) This prevents the RPC from being considered complete (ready for <code>OnDone</code>) until each <code>AddHold</code> on an RPC's reactor is matched to a corresponding <code>RemoveHold</code>. An application uses this operation before it performs any  extra-reaction flows, which refers to streaming operations initiated from outside a reaction method. Note that an RPC cannot complete before <code>StartCall</code>, so holds are not needed for any extra-reaction flows that take place before <code>StartCall</code>. As long as there are any holds present on an RPC, though, it may not have <code>OnDone</code> called on it, even if it has already received server status and has no other operations outstanding. May be called 0 or more times on any client RPC.</li> <li><code>void AddMultipleHolds(int holds)</code>: (Client only) Shorthand for <code>holds</code> invocations of <code>AddHold</code> .</li> <li><code>void RemoveHold()</code>: (Client only) Removes a hold reference on this client RPC. Must be called exactly as many times as <code>AddHold</code> was called on the RPC, and may not be called more times than <code>AddHold</code> has been called so far for any RPC. Once all holds have been removed, the server has provided status, and all outstanding or required operations have completed for an RPC, the library will invoke <code>OnDone</code> for that RPC.</li> </ol> <p>Examples are provided in the PR to de-experimentalize the callback API.</p>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#unary-rpc-shortcuts","level":3,"title":"Unary RPC shortcuts","text":"<p>As a shortcut, client-side unary RPCs may bypass the reactor model by directly providing a <code>std::function</code> for the library to call at completion rather than a reactor object pointer. This is passed as the final argument to the stub call, just as the reactor would be in the more general case. This is semantically equivalent to a reactor in which the <code>OnDone</code> function simply invokes the specified function (but can be implemented in a slightly faster way since such an RPC will definitely not wait separately for initial metadata from the server) and all other reactions are left empty. In practice, this is the common and recommended model for client-side unary RPCs, unless they have a specific need to wait for initial metadata before getting their full response message. As in the reactor model, the function provided as a callback may not include operations that block for an arbitrary amount of time.</p> <p>Server-side unary RPCs have the option of returning a library-provided default reactor when their method handler is invoked. This is provided by calling <code>DefaultReactor</code> on the <code>CallbackServerContext</code>. This default reactor provides a <code>Finish</code> method, but does not provide a user callback for <code>OnCancel</code> and <code>OnDone</code>. In practice, this is the common and recommended model for most server-side unary RPCs unless they specifically need to react to an <code>OnCancel</code> callback or do cleanup work after the RPC fully completes.</p>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#servercontext-extensions","level":3,"title":"ServerContext extensions","text":"<p><code>ServerContext</code> is now made a derived class of <code>ServerContextBase</code>. There is a new derived class of <code>ServerContextBase</code> called <code>CallbackServerContext</code> which provides a few additional functions:</p> <ul> <li><code>ServerUnaryReactor* DefaultReactor()</code> may be used by a method handler to return a default reactor from a unary RPC.</li> <li><code>RpcAllocatorState* GetRpcAllocatorState</code>: see advanced topics section</li> </ul> <p>Additionally, the <code>AsyncNotifyWhenDone</code> function is not present in the <code>CallbackServerContext</code>.</p> <p>All method handler functions for the callback API take a <code>CallbackServerContext*</code> as their first argument. <code>ServerContext</code> (used for the sync and CQ-based async APIs) and <code>CallbackServerContext</code> (used for the callback API) actually use the same underlying structure and thus their object pointers are meaningfully convertible to each other via a <code>static_cast</code> to <code>ServerContextBase*</code>. We recommend that any helper functions that need to work across API variants should use a <code>ServerContextBase</code> pointer or reference as their argument rather than a <code>ServerContext</code> or <code>CallbackServerContext</code> pointer or reference. For example, <code>ClientContext::FromServerContext</code> now uses a <code>ServerContextBase*</code> as its argument; this is not a breaking API change since the argument is now a parent class of the previous argument's class.</p>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#advanced-topics","level":3,"title":"Advanced topics","text":"","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#application-managed-server-memory-allocation","level":4,"title":"Application-managed server memory allocation","text":"<p>Callback services must allocate an object for the <code>CallbackServerContext</code> and for the request and response objects of a unary call.  Applications can supply a per-method custom memory allocator for gRPC server to use to allocate and deallocate the request and response messages, as well as a per-server custom memory allocator for context objects. These can be used for purposes like early or delayed release, freelist-based allocation, or arena-based allocation. For each unary RPC method, there is a generated method in the server called <code>SetMessageAllocatorFor_*MethodName*</code> . For each server, there is a method called <code>SetContextAllocator</code>. Each of these has numerous classes involved, and the best examples for how to use these features lives in the gRPC tests directory.</p> <ul> <li>Message allocator usage example</li> <li>Context allocator usage example</li> </ul>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#generic-non-code-generated-services","level":4,"title":"Generic (non-code-generated) services","text":"<p><code>RegisterCallbackGenericService</code> is a new method of <code>ServerBuilder</code> to allow for processing of generic (unparsed) RPCs. This is similar to the pre-existing <code>RegisterAsyncGenericService</code> but uses the callback API and reactors rather than the CQ-based async API. It is expected to be used primarily for generic gRPC proxies where the exact serialization format or list of supported methods is unknown.</p>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#per-method-specification","level":4,"title":"Per-method specification","text":"<p>Just as with async services, callback services may also be specified on a method-by-method basis (using the syntax <code>WithCallbackMethod_*MethodName*</code>), with any unlisted methods being treated as sync RPCs. The shorthand <code>CallbackService</code> declares every method as being processed by the callback API. For example:</p> <ul> <li><code>Foo::Service</code> -- purely synchronous service</li> <li><code>Foo::CallbackService</code> -- purely callback service</li> <li><code>Foo::WithCallbackMethod_Bar&lt;Service&gt;</code> -- synchronous service except for callback method <code>Bar</code></li> <li><code>Foo::WithCallbackMethod_Bar&lt;WithCallbackMethod_Baz&lt;Service&gt;&gt;</code> -- synchronous service except for callback methods <code>Bar</code> and <code>Baz</code></li> </ul>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#rationale","level":2,"title":"Rationale","text":"<p>Besides the content described in the background section, the rationale also includes early and consistent user demand for this feature as well as the fact that many users were simply spinning up a callback model on top of gRPC's completion queue-based asynchronous model.</p>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#implementation","level":2,"title":"Implementation","text":"<p>There is more than one mechanism available for implementing the background polling required by the C++ callback API. One has been implemented on top of the C++ completion queue API. In this approach, the callback API uses a number of library-owned threads to call <code>Next</code> on an async CQ that is owned by the internal implementation. Currently, the thread count is automatically selected by the library with no user input and is set to half the system's core count, but no less than 2 and no more than 16. This selection is subject to change in the future based on our team's ongoing performance analysis and tuning efforts. Despite being built on the CQ-based async API, the developer using the callback API does not need to consider any of the CQ details (e.g., shutdown, polling, or even the existence of a CQ).</p> <p>It is the gRPC team's intention that that implementation is only a temporary solution. A new structure called an <code>EventEngine</code> is being developed to provide the background threads needed for polling, and this sytem is also intended to provide a direct API for application use. This event engine would also allow the direct use of the core callback API that is currently only used by the Python async implementation. If this solution is adopted, there will be a new gRFC for it. This new implementation will not change the callback API at all but rather will only affect its performance. The C++ code for the callback API already has <code>if</code> branches in place to support the use of a poller that directly supplies the background threads, so the callback API will naturally layer on top of the <code>EventEngine</code> without further development effort.</p>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-callback-api/#open-issues-if-applicable","level":2,"title":"Open issues (if applicable)","text":"<p>N/A. The gRPC C++ callback API has been used internally at Google for two years now, and the code and API have evolved substantially during that period.</p>","path":["grpc callback api"],"tags":["c","cpp","grpc"]},{"location":"grpc-learning/","level":1,"title":"rpc","text":"<p>rpc 意为<code>远程过程调用</code>, http, grpc 广义上讲都是rpc。 而且还有个项目叫grpc-gateway, 可以将grpc通过http的方式暴露。</p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#grpc","level":1,"title":"grpc","text":"<p>grpc 是rpc的一种实现，由google开源，其他还有thrift, sogorpc 等等。 并且grpc使用的http/2协议</p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#http11-http2","level":2,"title":"http/1.1 与 http/2 的区别","text":"<ul> <li>2使用二进制，而1.1使用文本，提高效率</li> <li>2将相同的tcp连接合并为一个请求，提高性能,而1.1则为每个请求创建tcp连接</li> <li>2的客户端使用流，这样可以多次请求</li> <li>2含有trailers，也就是尾部消息，可以用来发送body的checksume等, 当然也可以直接放到body里 ...</li> </ul> <p>而1.1中也已经实现服务端到客户端的流,使用'Transfer-Encoding=chunked'来替代'Content-Length'，详见rfc <pre><code> A sender MUST NOT send a Content-Length header field in any message\n   that contains a Transfer-Encoding header field.\n</code></pre></p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#proto","level":2,"title":"认识proto文件","text":"","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#proto-serviceservice","level":3,"title":"proto 文件中多个service和单个service 区别","text":"<p>在同一个service里的方法会codegen到同一个类，但这个类比较鸡肋。 由于RPC调用是RESTful的，所以多次调用或者多个rpc方法无法通过同一个service来共享数据，这需要使用者借助其他办法来解决。</p> <p>service 还可以用以隔离相同名称的rpc， 如  - service1/helloworld - service2/helloworld</p> <p>而方法和方法通过<code>RpcServiceMethod</code>来保存，而通过index来调用 <pre><code>::grpc::Service::RequestAsyncUnary(0, context, request, response, new_call_cq, notification_cq, tag);\n::grpc::Service::RequestAsyncUnary(1, context, request, response, new_call_cq, notification_cq, tag);\n</code></pre></p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#rpc-unarycallstreamingcall","level":3,"title":"rpc 声明UnaryCall&amp;StreamingCall","text":"<p>非流调用也称为<code>UnaryCall</code>，指发送或接受的消息大小是固定的。 流调用称为<code>StreamingCall</code>，可以多次发送或者接收，所以消息大小并不固定。</p> <p>StreamCall 可以多次调用，直到发送<code>WriteDone/Finish</code>，所以在接受的一端总是 <pre><code>while(read stream){}\n</code></pre></p> <p>grpc支持客户端流服务端非流、客户端非流、服务端流以及双向流，而普通的就是客户端和服务端都不流NORMAL_RPC(unary call) - grpc::internal::RpcMethod::NORMAL_RPC - grpc::internal::RpcMethod::RpcType::SERVER_STREAMING - grpc::internal::RpcMethod::RpcType::CLIENT_STREAMING - grpc::internal::RpcMethod::RpcType::BIDI_STREAMING</p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#pbhgrpcpbh","level":3,"title":"认识pb.h和grpc.pb.h文件","text":"<p>protoc 调用<code>grpc_cpp_plugin</code> 插件生成grpc.pb.{h,cc}文件，生成rpc方法的实现  </p> <p>pb.{h,cc}则是定义了protobuf消息的序列化和反序列化方法</p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#_1","level":4,"title":"反射、序列化和反序列化的实现","text":"<p>pb.h 实现grpc的请求参数和返回参数的特定语言的解析，还有pb的通用方法， 例如: <code>has_xx</code>(版本3里只有自定义类型才支持), <code>class XXX_CPP_API</code></p> <p>生成的class都继承自<code>google::protobuf::Message</code> <pre><code>class HelloRequest PROTOBUF_FINAL :\n      public ::PROTOBUF_NAMESPACE_ID::Message\n\n#define PROTOBUF_NAMESPACE \"google::protobuf\"\n#define PROTOBUF_NAMESPACE_ID google::protobuf \n</code></pre> 而在<code>message</code>中有注释说明, 关键函数是<code>SerializeToString</code>和<code>ParseFromString</code>，还有个array版本<code>SerializeToArray</code>, 还有一个反射函数<code>GetDescriptor()</code>用来动态获取指定槽位的数据 <pre><code>// Example usage:\n  //\n  // Say you have a message defined as:\n  //\n  //   message Foo {\n  //     optional string text = 1;\n  //     repeated int32 numbers = 2;\n  //   }\n  //\n  // Then, if you used the protocol compiler to generate a class from the above\n  // definition, you could use it like so:\n  //\n  //   std::string data;  // Will store a serialized version of the message.\n  //\n  //   {\n  //     // Create a message and serialize it.\n  //     Foo foo;\n  //     foo.set_text(\"Hello World!\");\n  //     foo.add_numbers(1);\n  //     foo.add_numbers(5);\n  //     foo.add_numbers(42);\n  //\n  //     foo.SerializeToString(&amp;data);\n  //   }\n  //\n  //   {\n  //     // Parse the serialized message and check that it contains the\n  //     // correct data.\n  //     Foo foo;\n  //     foo.ParseFromString(data);\n  //\n  //     assert(foo.text() == \"Hello World!\");\n  //     assert(foo.numbers_size() == 3);\n  //     assert(foo.numbers(0) == 1);\n  //     assert(foo.numbers(1) == 5);\n  //     assert(foo.numbers(2) == 42);\n  //   }\n</code></pre></p> <p>如下可以将Message转换为基本类型 <pre><code>int size = reqMsg.ByteSizeLong();\nchar* array = new char[size];\nreqMsg.SerializeToArray(array, size);\n</code></pre></p> <pre><code>std::string bytes = reqMsg.SerializeAsString();\nconst char* array = bytes.data();\nint size = bytes.size();\n</code></pre> <p>进一步看<code>protobuf::message</code>继承自<code>protobuf::message_lite</code>, 后者实现了<code>SerializeAsString</code>和<code>SerializeToArray</code> <pre><code>inline uint8* SerializeToArrayImpl(const MessageLite&amp; msg, uint8* target,\n                                     int size) {\n    constexpr bool debug = false;\n    if (debug) {\n      // Force serialization to a stream with a block size of 1, which forces\n      // all writes to the stream to cross buffers triggering all fallback paths\n      // in the unittests when serializing to string / array.\n      io::ArrayOutputStream stream(target, size, 1);\n      uint8* ptr;\n      io::EpsCopyOutputStream out(\n          &amp;stream, io::CodedOutputStream::IsDefaultSerializationDeterministic(),\n          &amp;ptr);\n      ptr = msg._InternalSerialize(ptr, &amp;out);\n      out.Trim(ptr);\n      GOOGLE_DCHECK(!out.HadError() &amp;&amp; stream.ByteCount() == size);\n      return target + size;\n    } else {\n      io::EpsCopyOutputStream out(\n          target, size,\n          io::CodedOutputStream::IsDefaultSerializationDeterministic());\n实际调用-&gt;    auto res = msg._InternalSerialize(target, &amp;out);\n      GOOGLE_DCHECK(target + size == res);\n      return res;\n    }\n  }\n</code></pre> 可见，其实序列化最终调用的是pb.h文件里定义的<code>_InternalSerialize</code>, 举例官方例子<code>HelloRequest</code> <pre><code> ::PROTOBUF_NAMESPACE_ID::uint8* HelloRequest::_InternalSerialize(\n      ::PROTOBUF_NAMESPACE_ID::uint8* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream*   stream) const {\n    // @@protoc_insertion_point(serialize_to_array_start:helloworld.HelloRequest)\n    ::PROTOBUF_NAMESPACE_ID::uint32 cached_has_bits = 0;\n    (void) cached_has_bits;\n\n    // string name = 1;\n    if (this-&gt;name().size() &gt; 0) {\n      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(\n        this-&gt;_internal_name().data(), static_cast&lt;int&gt;(this-&gt;_internal_name().length()),\n        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,\n        \"helloworld.HelloRequest.name\");\n      target = stream-&gt;WriteStringMaybeAliased(\n          1, this-&gt;_internal_name(), target);\n    }\n\n    if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {\n      target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToA  rray(\n         _internal_metadata_.unknown_fields&lt;::PROTOBUF_NAMESPACE_ID::UnknownFieldSet&gt;(::PROTOB  UF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);\n    }\n    // @@protoc_insertion_point(serialize_to_array_end:helloworld.HelloRequest)\n    return target;\n  }\n</code></pre></p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#grpcpbrpc","level":4,"title":"grpc.pb生成的代码实现rpc调用","text":"<p>生成的框架代码用来继承实现Service和获取stub来发起rpc call。实际上这些代码并不是必须的 在下面讲了如何使用几个工厂类来创建Stub，还有直接<code>new</code>出Service</p> <pre><code>class XXXServer {\n        // 客户端使用的桩\n    class Stub\n        // base \n    class Service\n    // 各种版本的rpc包装，但都继承自base\n        class WithAsyncMethod_XXX\n        typedef WithAsyncMethod_XXX&lt;Service &gt; AsyncService;\n    typedef ExperimentalWithCallbackMethod_XXX&lt;Service &gt; CallbackService;\n    class WithGenericMethod_XXX\n    class WithRawMethod_XXX\n    typedef WithStreamedUnaryMethod_XXX&lt;Service &gt; StreamedUnaryService;\n}\n</code></pre>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#_2","level":2,"title":"同步与异步","text":"<p>grpc 的异步即为使用cq事件驱动（cq-based），使用tag标记事件。另外还有callback方式</p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#_3","level":3,"title":"对于客户端","text":"<p>同步时，通过调用'::grpc::internal::BlockingUnaryCall' 异步时，创建'ClientAsyncResponseReader'(非流), 然后通过调用'ClientAsyncResponseReader'的write和finish，并等待tag 当存在流时分别是 - ::grpc::ClientAsyncReader - ::grpc::ClientAsyncWriter - ::grpc::ClientAsyncReaderWriter</p> <p>这些类型可用对应的工厂类来创建, 生成代码的stub也是这么用的 <pre><code>class ClientReaderFactory \nclass ClientWriterFactory \nclass ClientReaderWriterFactory \n</code></pre></p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#_4","level":3,"title":"对于服务端","text":"<p>同步时，通过'AddMethod'来注册，生成代码会在父类构造时执行。注册后由grpc调用 <pre><code>Greeter::Service::Service() {\n    AddMethod(new ::grpc::internal::RpcServiceMethod(\n        Greeter_method_names[0],\n        ::grpc::internal::RpcMethod::NORMAL_RPC,\n        new ::grpc::internal::RpcMethodHandler&lt; Greeter::Service, ::helloworld::HelloRequest, ::helloworld::HelloReply&gt;(\n            [](Greeter::Service* service,\n               ::grpc_impl::ServerContext* ctx,\n               const ::helloworld::HelloRequest* req,\n               ::helloworld::HelloReply* resp) {\n                 return service-&gt;SayHello(ctx, req, resp);\n               }, this)));\n  }\n</code></pre></p> <p>异步时，类似客户端 - grpc::ServerAsyncReaderWriter - grpc::ServerAsyncReader - grpc::ServerAsyncWriter</p> <p>可见服务端是直接new出来的，异步时这些io操作对象也是直接new出来的, 在调用以下时传入 <pre><code>RequestAsyncBidiStreaming\nRequestAsyncClientStreaming\nRequestAsyncServerStreaming\n</code></pre></p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#grpc-callback","level":2,"title":"grpc callback","text":"<p>只在客户端使用，callback方式的请求可以传入一个lambda, 在请求完成时调用 <pre><code>    stub_-&gt;async()-&gt;SayHello(&amp;context, &amp;request, &amp;reply,\n                             [&amp;mu, &amp;cv, &amp;done, &amp;status](Status s) {\n                               status = std::move(s);\n                               std::lock_guard&lt;std::mutex&gt; lock(mu);\n                               done = true;\n                               cv.notify_one();\n                             });\n</code></pre></p> <p>新版本的grpc已经将实验性的标记去除，说明此方式成熟了 <pre><code>    #ifdef GRPC_CALLBACK_API_NONEXPERIMENTAL\n      ::grpc::Service::\n    #else\n      ::grpc::Service::experimental().\n    #endif\n</code></pre></p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#grpc_1","level":2,"title":"grpc异步流","text":"<p>官方仓库的示例代码没有异步且流的, 在实际项目中用到异步流,使用大概方法 1. 手动创建writereader 2. 启动时，调用'grpc::Service::RequestAsyncBidiStreaming' 和 'grpc::Service::RequestAsyncClientStreaming' 以及'RequestAsyncServerStreaming', 向cq塞请求new_connection事件 3. 收到'new_connection'事件返回后，再调用read事件。</p> <p>一共有5个类型 <pre><code>new_connection, read, write, finish, done\n</code></pre> 我写了一个demo grpcstreamhelloworld</p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#grpc_2","level":2,"title":"grpc 消息大小","text":"<p>老版本的grpc中，发送端是支持无限大小的，但接受端只能是4M <pre><code>#define GRPC_DEFAULT_MAX_SEND_MESSAGE_LENGTH -1\n#define GRPC_DEFAULT_MAX_RECV_MESSAGE_LENGTH (4 * 1024 * 1024)\n</code></pre> 服务端代码 <pre><code>std::unique_ptr&lt;Server&gt; ServerBuilder::BuildAndStart() {\n    if (max_receive_message_size_ &gt;= 0) {\n      args.SetInt(GRPC_ARG_MAX_RECEIVE_MESSAGE_LENGTH, max_receive_message_size_);\n    }\n</code></pre></p> <p>但在新版grpc中变了</p> <pre><code>  std::unique_ptr&lt;grpc::Server&gt; ServerBuilder::BuildAndStart() {\n    grpc::ChannelArguments args;\n    if (max_receive_message_size_ &gt;= -1) {\n      args.SetInt(GRPC_ARG_MAX_RECEIVE_MESSAGE_LENGTH, max_receive_message_size_);\n    }\n    if (max_send_message_size_ &gt;= -1) {\n      args.SetInt(GRPC_ARG_MAX_SEND_MESSAGE_LENGTH, max_send_message_size_);\n    }\n</code></pre>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#grpc_3","level":2,"title":"grpc 编译安装的问题","text":"<p>https://github.com/grpc/grpc/issues/13841</p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#grpc_4","level":2,"title":"grpc异步存在问题","text":"<p>因为异步服务端通过completionqueue来通知rpc执行结果和执行下次调用，通常使用多queue和多线程的方式提高处理效率 1. 通常情况是多queue, 即每个service对应一个queue, 而每个service又有多个rpc，线程去轮询这个complete_queue。这样导致高线程切换开销，而且complete_queue也占用大量内存 2. 多线程，queue可以用多个线程去轮询，但0.13版本可能出现bug</p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#grpc_5","level":2,"title":"grpc异步流存在的问题","text":"<p>grpc区别与其他框架很大一个优势是支持异步流，即可以多次请求和多次回复。异步是基于cq的事件驱动，所以必须等待tag回调, 连续两次发送会异常。 而真正的请求一般在业务模块处理, 不知道tag的状态即不知道是否正在发送， 那么如何在cq回调外发送消息呢？ </p> <p>办法是维护一个发送队列，消息先存队列里，等待cq回调时取出发送。 另外由于流同步需要显式发送结束标记(服务端调Stream::Finish, 客户端调用WriteDown和Finish),  所以需要有一个特殊消息加以区分，通常用空指针，也可以设置结束标志。另外由于发送代码会同时被业务调用和cq回调，需要对发送代码加锁</p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#grpc_6","level":2,"title":"调试grpc","text":"<p>通过设置环境变量，让grpc向控制台打印详细信息 <pre><code>export GRPC_VERBOSITY=DEBUG\nbash-5.0# ./build/bin/hasync slave  stdin stdout @127.0.0.1:7615\nD1026 08:27:44.142802149   24658 ev_posix.cc:174]            Using polling engine: epollex\nD1026 08:27:44.143406685   24658 dns_resolver_ares.cc:490]   Using ares dns resolver\nI1026 08:27:44.158115785   24658 server_builder.cc:332]      Synchronous server. Num CQs: 1, Min pollers: 1, Max Pollers: 2, CQ timeout (msec): 10000\n</code></pre></p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#_5","level":2,"title":"项目实践","text":"<p>项目使用客户端异步/同步，服务端全异步， 可以兼容四种传输方式</p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"grpc-learning/#_6","level":2,"title":"引用","text":"<p>https://grpc.github.io/grpc/cpp/grpcpp_2impl_2codegen_2sync__stream_8h_source.html https://grpc.github.io/grpc/cpp/grpcpp_2impl_2codegen_2byte__buffer_8h_source.html https://grpc.github.io/grpc/cpp/call__op__set_8h_source.html</p>","path":["grpc 学习"],"tags":["grpc","c","cpp"]},{"location":"guitar/","level":1,"title":"吉他学习","text":"","path":["吉他学习"],"tags":["guitar"]},{"location":"guitar/#10","level":2,"title":"最常用的10个和弦","text":"<p> 食指放在5弦的第二品上，中指放在4弦的第二品上, 或用中指放在5弦的第二品上，无名指放在4弦的第二品上</p> <p> 食指放在3弦的第二品上，中指放在1弦的第二品上，无名指放在2弦的第三品上</p> <p> 食指放在2弦的第一品上，中指放在4弦的第二品上，无名指放在5弦的第三品上</p> <p> 食指放在5弦的第二品上，中指放在6弦的第三品上，无名指放在1弦的第三品上, 或中指放在5弦的第二品上，无名指放在6弦的第三品上，小指放在1弦的第三品上</p> <p> 食指放在2弦的第一品上，中指放在4弦的第二品上，无名指放在3弦的第二品上</p> <p> 食指大横按在一品上，中指放在3弦的第二品上，无名指放在5弦第三品上，小指放在4弦第三品上 </p> <p> 食指指放在3弦的第一品上，中指放在5弦第二品上，无名指放在4弦第二品上</p> <p> 食指放在1弦第一品上，中指放在3弦第二品上，无名指放在2弦第三品上</p> <p> 食指放在4弦第二品上，中指放在3弦第二品上，无名指放在2弦第二品上</p> <p> 食指大横按放在第二品上，中指放在2弦第三品上，无名指放在4弦第四品上，小指放在3弦第四品上 </p>","path":["吉他学习"],"tags":["guitar"]},{"location":"guitar/#_2","level":2,"title":"八个实用的吉他和弦转换技巧","text":"<p>1.压熟要转换的和絃，确保没有杂音 2.找出共通的手指  3.练习手指移动的速度，先从练习移动低音的手指开始  4.相同指型的手指可以一起移动</p>","path":["吉他学习"],"tags":["guitar"]},{"location":"guitar/#_3","level":2,"title":"引用","text":"<p>https://www.zhihu.com/tardis/bd/ans/1797295715</p>","path":["吉他学习"],"tags":["guitar"]},{"location":"hash/","level":1,"title":"hash","text":"<p>不同的哈希库区别在哈希函数设计， 以及</p>","path":["hash"],"tags":["hash"]},{"location":"hash/#c","level":2,"title":"c实现哈希","text":"<pre><code>#define HASH_TABLE_SIZE 100\n\n// 定义映射结构体\ntypedef struct Mapping {\n    char internal_ip[16];\n    int internal_port;\n    char external_ip[16];\n    int external_port;\n    struct Mapping *next;\n} Mapping;\n\n// 定义哈希表\nMapping *hash_table[HASH_TABLE_SIZE];\n\n// 哈希函数\nunsigned int hash(const char *ip, int port) {\n    unsigned int hashval = 0;\n    for (int i = 0; ip[i] != '\\0'; i++) {\n        hashval = ip[i] + (hashval &lt;&lt; 6) + (hashval &lt;&lt; 16) - hashval;\n    }\n    hashval += port;\n    return hashval % HASH_TABLE_SIZE;\n}\n\n// 添加映射\nvoid add_mapping(const char *internal_ip, int internal_port, const char *external_ip, int external_port) {\n    unsigned int index = hash(internal_ip, internal_port);\n    Mapping *new_mapping = (Mapping *)malloc(sizeof(Mapping));\n    strcpy(new_mapping-&gt;internal_ip, internal_ip);\n    new_mapping-&gt;internal_port = internal_port;\n    strcpy(new_mapping-&gt;external_ip, external_ip);\n    new_mapping-&gt;external_port = external_port;\n    new_mapping-&gt;next = hash_table[index];\n    hash_table[index] = new_mapping;\n}\n\n// 查找映射\nMapping *find_mapping(const char *internal_ip, int internal_port) {\n    unsigned int index = hash(internal_ip, internal_port);\n    Mapping *current = hash_table[index];\n    while (current != NULL) {\n        if (strcmp(current-&gt;internal_ip, internal_ip) == 0 &amp;&amp; current-&gt;internal_port == internal_port) {\n            return current;\n        }\n        current = current-&gt;next;\n    }\n    return NULL;\n}\n\n// 释放哈希表\nvoid free_hash_table() {\n    for (int i = 0; i &lt; HASH_TABLE_SIZE; i++) {\n        Mapping *current = hash_table[i];\n        while (current != NULL) {\n            Mapping *temp = current;\n            current = current-&gt;next;\n            free(temp);\n        }\n    }\n}\n\nint main() {\n    // 初始化哈希表\n    for (int i = 0; i &lt; HASH_TABLE_SIZE; i++) {\n        hash_table[i] = NULL;\n    }\n\n    // 添加映射\n    add_mapping(\"192.168.1.100\", 8080, \"203.0.113.1\", 50000);\n\n    // 查找映射\n    Mapping *mapping = find_mapping(\"192.168.1.100\", 8080);\n    if (mapping != NULL) {\n        printf(\"Internal: %s:%d -&gt; External: %s:%d\\n\", mapping-&gt;internal_ip, mapping-&gt;internal_port, mapping-&gt;external_ip, mapping-&gt;external_port);\n    } else {\n        printf(\"Mapping not found.\\n\");\n    }\n\n    // 释放哈希表\n    free_hash_table();\n\n    return 0;\n}\n</code></pre>","path":["hash"],"tags":["hash"]},{"location":"hash/#_1","level":2,"title":"支持哈希表在线扩容，不中断读写","text":"<ol> <li>维护两张表</li> <li>读操作，先新表，读新表失败再读旧表。</li> <li>写操作，两边一起写。</li> <li>渐进式，小批量，将扩容操作分散到多次读写中。 即读写时，执行迁移函数，将小批量的旧表数据迁移到新表，直到迁移完成后废弃旧表。 </li> </ol> <pre><code>def 读：\n  读新表\n  如果失败：\n    读旧表\n\ndef 写：\n  如果新表存在：\n    写新表\n  写旧表\n\n  如果要扩容\n   设置迁移标志\n\ndef 迁移：\n  如果设置了迁移标志\n    迁移10个\n\ndef 包装读写\n  读\n  写\n  迁移\n</code></pre>","path":["hash"],"tags":["hash"]},{"location":"hash/#key","level":2,"title":"使用预先哈希过的key","text":"<p>除了在写入键值对时，在内部进行哈希计算，也最好能支持外部计算哈希值。 但是键(key)和键的哈希值(hash(key))必须都保存，因为哈希值有冲突，依旧需要键来比对。 伪代码 <pre><code>def 查找(key)\n    hash_val = hash_func(key)\n    entry = bins[hash_val]\n    for element in entry:\n       if element.key == key:\n            return element\n</code></pre></p>","path":["hash"],"tags":["hash"]},{"location":"hash/#hash_1","level":2,"title":"传输面的 hash 对性能影响非常明显","text":"<p>当对数据流的ip地址做3次hash时，iperf的tcp带宽为72.3 Mbits/sec， 当做2次时 117 Mbits/sec，当做1次时带宽203 Mbits/sec</p> <p>所以要提高哈希函数的速度，比如硬件加速。而回头看其实哈希很大目的是为了节省空间，如果空间足够容纳所有可能的ip，可以直接hash=ipv4（32bit）</p>","path":["hash"],"tags":["hash"]},{"location":"hash/#_2","level":2,"title":"硬件加速","text":"<p>使用lscpu命令或者<code>cat /proc/cpuinfo</code>的输出看flags字段，里面有显示硬件加速功能。例如在armv8中，有crc32, 表示cpu有专门硬件加速计算哈希。例如在dpdk初始化时，检查是否支持硬件加速。然后哈希函数<code>rte_hash_crc</code>就会用硬件加速了。</p> <pre><code>/* Setting the best available algorithm */\nRTE_INIT(rte_hash_crc_init_alg)\n{\n#if defined(RTE_ARCH_X86)\n    rte_hash_crc_set_alg(CRC32_SSE42_x64);\n#elif defined(RTE_ARCH_ARM64) &amp;&amp; defined(__ARM_FEATURE_CRC32)\n    rte_hash_crc_set_alg(CRC32_ARM64);\n#else\n    rte_hash_crc_set_alg(CRC32_SW);\n#endif\n}\n</code></pre>","path":["hash"],"tags":["hash"]},{"location":"hash/#_3","level":3,"title":"硬件加速性能","text":"<p>测试连续3个哈希函数，执行5000次，每次节约最多200ms。</p>","path":["hash"],"tags":["hash"]},{"location":"hash/#acl","level":2,"title":"从acl转到哈希","text":"<p>因为acl动态添加规则时，需要重新建立树结构，很费时间，即使用active/standby两个acl表，依旧不能解决修改规则太慢的问题。后分析应用常见，其实并不需要acl的条件范围匹配，而是只需要精准匹配，所以非常适合哈希查找， 因为哈希查找速度快，而且修改规则也快。</p>","path":["hash"],"tags":["hash"]},{"location":"hash/#_4","level":2,"title":"哈希局限","text":"<p>dpdk的哈希库还支持批量查找，acl库也支持批量查找，网上说比起for循环查找，能提高4～5倍。不过比起acl匹配有个局限，在acl中可以设置0.0.0.0/0来模糊查找，例如匹配二元值（src ip, dst ip）作为查找条件时，acl 可以设置 src ip=1.1.1.1/32, dst ip=0.0.0.0/0 来通配一个字段。 但在哈希中就必须二元同时比较，不可通配。</p>","path":["hash"],"tags":["hash"]},{"location":"hash/#_5","level":2,"title":"参考","text":"<p>http://benhoyt.com/writings/hash-table-in-c?utm_source=pocket_shared</p>","path":["hash"],"tags":["hash"]},{"location":"heap-sort/","level":1,"title":"堆排序","text":"<p>堆排类似选择排序，只排序未排序的部分，但堆排比较方式不同，每次只比较log(n)次 最终的堆排时间复杂度为O(nlogn)</p>","path":["堆排序"],"tags":["算法"]},{"location":"heap-sort/#_2","level":2,"title":"关键下标","text":"<p>堆一般用数组来表示，但是关系为</p> <ul> <li>当以1为起点时，若父节点是n</li> <li>左子节点=n*2</li> <li> <p>右子节点=n*2 + 1</p> </li> <li> <p>若节点为n, 则其父节点为n/2</p> </li> <li> <p>若元素为m个，则最后一个根节点（非叶节点）为m/2</p> </li> <li> <p>当以0为起点时，若父节点是n</p> </li> <li>左子节点=(n+1)*2-1 = n*2 + 1</li> <li> <p>右子节点=(n+1)*2+1 -1 = n*2 + 2</p> </li> <li> <p>若节点下标为n, 其父节点为(n+1)/2 - 1 = (n-1)/2</p> </li> <li>若元素为m个，则最后一个根节点（非叶节点）为(m+1)/2-1 = (m-1)/2</li> </ul> <p>可见，若以1为起点，要简洁很多</p>","path":["堆排序"],"tags":["算法"]},{"location":"heap-sort/#_3","level":2,"title":"建立堆","text":"<ol> <li>从第一个非叶子节点开始，比较父子节点中找的最值，如果需要调整则交换父子节点再递归遍历下一层：</li> <li>建立最小堆时，每次比较出最大值，一遍之后，堆顶为最大</li> <li>建立最大堆时，每次比较出最小值，一遍之后，堆顶为最小</li> <li>比较到顶部节点时，完成第一次遍历，找到了顶部的最值</li> <li>将堆顶的最值与尾部交换，遍历范围-1，然后从堆顶开始比较</li> <li>重复3动作，直到范围为1</li> </ol> <p>3的动作类似<code>选择排序</code>，只遍历未排序的部分</p>","path":["堆排序"],"tags":["算法"]},{"location":"heap-sort/#_4","level":2,"title":"最大堆和最小堆","text":"<p>最小堆可以求得topK**大**的数，反过来最大堆可以求得topK**小**的数</p>","path":["堆排序"],"tags":["算法"]},{"location":"heap-sort/#topk","level":3,"title":"topK","text":"<p>堆排序通常用来实现topK，适用于限制内存的情况。方法是建立一个堆大小为K： 先用头部K个数据建立最小堆，后续的数字与堆顶（最小）比，如果跟小则跳过，否则替换然后执行thiftdown。其时间复杂读为O)KlogK + NlogK), 只需要一次建堆，后续都是比较。空间复杂度为K。</p> <p>也可以则使用分治法，将数据分为多组，每组求其top k。最后合并起来再排序，求最终的topK。 分治法可以配合线程一起使用加快速度。</p> <pre><code>// 使用最小堆来实现topK\nvoid thiftdown(int *heap, int root, int size) {\n  int m = root;\n  int l = root * 2 + 1;\n  int r = root * 2 + 2;\n\n  if (l &lt; size &amp;&amp; heap[l] &gt; heap[m]) {\n    m = l;\n  }\n  if (r &lt; size &amp;&amp; heap[r] &gt; heap[m]) {\n    m = r;\n  }\n\n  if (m != root) {\n    int tmp = heap[root];\n    heap[root] = heap[m];\n    heap[m] = tmp;\n\n    thiftdown(heap, m, size);\n  }\n}\n\nvoid adjust(int *heap, int root, int size) {\n  int m = root;\n  int l = root * 2 + 1;\n  int r = root * 2 + 2;\n\n  if (l &lt; size &amp;&amp; heap[l] &lt; heap[m]) {\n    m = l;\n  }\n  if (r &lt; size &amp;&amp; heap[r] &lt; heap[m]) {\n    m = r;\n  }\n\n  if (m != root) {\n    int tmp = heap[root];\n    heap[root] = heap[m];\n    heap[m] = tmp;\n\n    adjust(heap, m, size);\n  }\n}\n\nvoid heapify(int *heap, int size) {\n  for (int i = (size - 1) / 2; i &gt;= 0; i--) {\n    thiftdown(heap, i, size);\n  }\n\n  while (size &gt; 0) {\n    int tmp = heap[0];\n    heap[0] = heap[size - 1];\n    heap[size - 1] = tmp;\n    size--;\n    thiftdown(heap, 0, size);\n  }\n}\n\nvoid add(int *heap, int val, int size) {\n  if (heap[0] &gt;= val) {\n    return;\n  }\n  heap[0] = val;\n  adjust(heap, 0, size);\n}\n</code></pre> <p>使用方法 <pre><code>heapify(m, 5);\nfor (int i = 5; i &lt; 49; i++) {\n  add(m, n[i], 5);\n}\nreturn m[0];\n</code></pre></p>","path":["堆排序"],"tags":["算法"]},{"location":"heap-sort/#topk_1","level":3,"title":"海量数据求topK","text":"<p>常见问题类似： 1. 求许多重复整数中，重复第K多的正整数。 2. 求文本中重复出现的词语次数，重复第K多的”， 3. ip中访问最K多的”。</p> <p>这些问题需要多一步统计，统计出现次数，然后再使用堆来查找topK。</p> <ol> <li>使用数组统计，如果目标都是正整数，如问题1</li> <li>使用map统计，int表示出现次数，如果目标字符串，如问题2和问题3 <p>统计完成后，将目标和计数放入结构体，再使用堆来找topK <pre><code>{\n  目标\n  次数\n}\n</code></pre></p>","path":["堆排序"],"tags":["算法"]},{"location":"heap-sort/#_5","level":2,"title":"总结","text":"<p>topK 问题除了堆排序以外，还常用快排来找。</p>","path":["堆排序"],"tags":["算法"]},{"location":"huawei-change-rom/","level":1,"title":"huawei change rom","text":"","path":["huawei change rom"],"tags":["android"]},{"location":"huawei-change-rom/#reference","level":2,"title":"reference","text":"<p>https://forum.xda-developers.com/t/guide-rom-8-1-lineageos-15-1-huawei-mediapad-m3-8-4-btv-w09-btv-dl09.4085995/</p>","path":["huawei change rom"],"tags":["android"]},{"location":"huawei-unlock-bootloader/","level":1,"title":"huawei unlock bootloader","text":"<p>解锁华为平板M3的BL锁，以及获取root权限</p>","path":["huawei unlock bootloader"],"tags":["android","lineage"]},{"location":"huawei-unlock-bootloader/#_1","level":1,"title":"背景","text":"<p>我有一个华为平板M3，WIFI版, 型号BTV-W09，系统是emui5， 买来没什么用，最大的功能就是看视频。 偶尔发现一个app，LinuxDeploy, 可以在安卓上安装完整的Linux系统，而不是内置的阉割版， 前提是获得root权限。</p>","path":["huawei unlock bootloader"],"tags":["android","lineage"]},{"location":"huawei-unlock-bootloader/#_2","level":1,"title":"步骤","text":"<p>全部步骤分4个：  1. 解BL 2. 刷入recovery 也就是RTWP 3. 将root压缩包复制到平板，在RTWP下安装 4. 安装supersu 的apk 5. 可选刷入xposed框架，并安装xposed manager，步骤参考3,4</p>","path":["huawei unlock bootloader"],"tags":["android","lineage"]},{"location":"huawei-unlock-bootloader/#_3","level":2,"title":"解锁","text":"<p>因为华为官方停止申请解锁BL的服务， 所以需要上淘宝找人帮你搞定。 解锁BL之后， 在关机状态按住电源和音量减，进入fastboot模式时，有红字提示unlocked</p>","path":["huawei unlock bootloader"],"tags":["android","lineage"]},{"location":"huawei-unlock-bootloader/#rec","level":2,"title":"刷入rec","text":"<p>找到与设备型号对应的rec非常重要，因为型号不对会刷不进去，我尝试了很多个版本，最终在华为论坛找到了。  有了rec后， 让手机处于fastboot状态， 连接手机到电脑，使用 <code>fastboot flash recovery rec</code> 来刷入 ，提书刷入成功之后，可能自动重启，如果没有重启，长按电源键强制关机。  关机状态下， 按住电源键和音量+，进入recovery ， 能看到RTWP的界面说明输入成功，如果没有看到RTWP,而是进入华为官方的eRecovery 表示失败，又可能是被华为覆盖了。 一旦能进入RTWP, 那么RTWP会自动安装，以后就不用担心被覆盖的问题。</p>","path":["huawei unlock bootloader"],"tags":["android","lineage"]},{"location":"huawei-unlock-bootloader/#root","level":2,"title":"刷入root工具","text":"<p>将root.zip 拷贝到平板的储存卡目录，进入RTWP，点INSTALL,  然后选择root.zip 就会开始安装了， 安装后再安装supersu 的应用</p> <p>这样就root成功了， 所以步骤很简单，找到对应机型的rec 很关键。 </p>","path":["huawei unlock bootloader"],"tags":["android","lineage"]},{"location":"huawei-unlock-bootloader/#xposed","level":2,"title":"刷入xposed","text":"<p>xposed 很强大，但是xposed只是个框架，需要安装包来实现对app的hack。但是我安装完，没发现什么很强大包，感觉也没什么用。 </p>","path":["huawei unlock bootloader"],"tags":["android","lineage"]},{"location":"huawei-unlock-bootloader/#_4","level":2,"title":"更新","text":"<p>平板一直都在吃灰，最近发现访问网站都报证书错误，可能是系统旧了(后面发现是电池馈电太久，时间不同步)，所以决定升级系统。这次完整贴出命令，因为发现我之前写的难以参考。在XDA网站发现有新的lineage17适合btv-w09,于是按照帖子里面的方法做： 1. 下载TWRP 3.3.1-1，lineage 17 系统压缩包， boot 镜像，我的是wifi-only版本。 2. 在平板关闭状态下，按住电源+音量减，振动的时候释放电源键，然后就进入fastboot状态，显示<code>phone unlock</code> 3. 刷入twrp <code>fastboot flash recovery twrp-xxx.img</code> 4. 刷入boot <code>fastboot flash boot boot-xxx.img</code> 5. 进入twrp，这里有点迷惑，网上说（包括我之前说的）按住电源+音量加总是无法进入twrp而是进入了华为的eRecovery,使用<code>adb boot-recovery</code>则进入了正常系统。最后发现在开发者模式下开启<code>高级重启</code>功能，重启的时候选择重启到<code>recovery</code>则能正常进入Twrp界面。可能是平板接着USB线。 6. 帖子上说了，升级lineage需要Wipe，彻底初始化但保留系统，执行后连sdcard目录也会格式化，剩几个标准目录。 7. 用adb push 将系统安装压缩包发送到平板的存储空间，<code>adb push Lineage-xxx.zip /sdcard</code>，然后在TWRP中选择 Install，选择这个zip 进行安装。 不过发现这个zip文件校验失败，不管他了。</p> <p>然后就重启进入新版本的Lineage 17(android 10)，可惜的是没有相机功能。</p>","path":["huawei unlock bootloader"],"tags":["android","lineage"]},{"location":"huawei-unlock-bootloader/#2025lineageos20","level":2,"title":"2025年重新刷lineageos20","text":"<p>同样问题又出现了</p> <ol> <li>进入 fastboot 模式 <code>adb reboot bootloader</code>， 如今没有adb reboot fastboot命令了， fastboot模式和bootloader模式应该是一样的</li> <li>刷入新的recovery <code>fastboot flash recovery ~/Downloads/recovery.img</code></li> <li>进入recovery，格式化data分区</li> <li>在recovery中点击Apply Update， 再点击Apply from ADB， 执行线刷</li> <li>在电脑输入<code>adb sideload ~/Downloads/lineage-20.0-20250102-RELEASE-btvw09.zip</code></li> </ol> <p>但是第5步出现错误 <pre><code>adb sideload ~/Downloads/lineage-20.0-20250102-RELEASE-btvw09.zipmain  \nadb: sideload connection failed: insufficient permissions for device: missing udev rules? user is in the plugdev group\nSee [http://developer.android.com/tools/device.html] for more information\nadb: trying pre-KitKat sideload method...\nadb: pre-KitKat sideload connection failed: insufficient permissions for device: missing udev rules? user is in the plugdev group\nSee [http://developer.android.com/tools/device.html] for more information \n</code></pre></p> <p>查看设备情况提示 <pre><code>adb devices\nList of devices attached\nSLYDU17401001667        no permissions (missing udev rules? user is in the plugdev group); see [http://developer.android.com/tools/device.html]\n</code></pre></p> <p>网上查找解决办法，尝试了好几个，最终通过 <pre><code># 添加udev规则\ncat /etc/udev/rules.d/51-android.rules\nSUBSYSTEM==\"usb\", ATTR{idVendor}==\"id_you_copied\", MODE=\"0666\", GROUP=\"plugdev\"\n\nsudo chmod a+r /etc/udev/rules.d/51-android.rules\nsudo udevadm control --reload-rules\nsudo udevadm trigger\n</code></pre></p> <p>上面还是不行，最后拔掉usb线又重新插入就正常了</p>","path":["huawei unlock bootloader"],"tags":["android","lineage"]},{"location":"ibus-setup/","level":1,"title":"ibus-setup","text":"<p>这里记录下ibus的配置记录，重新安装了系统，默认安装的ibus。之前用的fcitx5还不错，不过都尝试下。遇到两个问题：</p>","path":["ibus-setup"],"tags":["ibus","linux"]},{"location":"ibus-setup/#firefox","level":2,"title":"firefox里面单击选中的文字触发删除","text":"<p>之前安装的ibus-pinyin, 重新安装ibus-libpinyin后解决。参考</p>","path":["ibus-setup"],"tags":["ibus","linux"]},{"location":"ibus-setup/#_1","level":2,"title":"配置默认输入法","text":"<p>作为一名程序员，默认英文输入是基本素质，在fcitx5中强制的英文输入法是默认输入法。但ibus中不是，但可以通过dbus来修改。打开dconf-editor，依次找到<code>dconf-editor</code> -&gt; <code>desktop</code> -&gt; <code>ibus</code> -&gt; <code>general</code>，直接修改<code>preload-engines</code>的用户定义顺序，<code>engines-order</code>会跟随变化。将<code>ibus:us:en</code>提到<code>ibus-pinyin</code>数组前面就可以了。参考</p>","path":["ibus-setup"],"tags":["ibus","linux"]},{"location":"ibus-setup/#ibus","level":2,"title":"ibus 体验","text":"<p>ibus中的好像输入表情要容易些。</p>","path":["ibus-setup"],"tags":["ibus","linux"]},{"location":"ibus-setup/#gnome-ibus","level":2,"title":"gnome 配置ibus","text":"<p>最近切换到gnome-wayland， 配置ibus花了挺多时间。问题跟网上说的什么locale无关，gnome中的locale文件是修改配置时自动更新的。最终无头无脑卸载了fcitx相关的东西，并且重装了ibus和ibus-libpinyin，然后可能是重启后成功。</p>","path":["ibus-setup"],"tags":["ibus","linux"]},{"location":"install-k8s-cluster/","level":1,"title":"搭建k8s集群","text":"<p>引用 https://blog.piaoruiqing.com/2019/09/17/kubernetes-1-installation/ 照着文章搭建k8s集群，写得挺好，记录一下自己的搭建方法和问题</p>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#_1","level":2,"title":"环境","text":"<ol> <li>2个kvm虚拟机, 安装的centos7系统</li> <li>两个虚拟机都配置了双网卡，eth0和eth1， eth0桥接宿主机的bridge， eth1 接入libvirt default NAT网络</li> <li>官方推荐配置： CPU &gt; 2，内存 &gt; 2G</li> <li>eth1 的ip 分别为 192.168.122.61, 192.168.122.161</li> </ol>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#masterworker","level":2,"title":"Master和Worker 共同步骤","text":"<p>需要在所有节点执行</p>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#hostname","level":3,"title":"修改hostname","text":"<p>编辑hostname <pre><code>vim /etc/hostname # 修改hostname\n</code></pre> 配置host文件， 将所有节点都指定host </p>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#_2","level":3,"title":"关闭防火墙","text":"<ol> <li>systemctl disable --now firewalld</li> <li>修改 /etc/seconfig， 将selinux 配置成disable </li> </ol>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#swap","level":3,"title":"关闭 swap 分区","text":"<ol> <li>swapoff -a </li> <li>修改 /etc/fstab， 注释掉swap 记录</li> </ol>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#docker","level":3,"title":"安装docker 配置镜像源","text":"<p>修改 /etc/docker/daemon.json 文件</p> <pre><code>{\n  \"registry-mirrors\": [\"https://xxxxxxxx.mirror.aliyuncs.com\"],\n  \"exec-opts\": [\"native.cgroupdriver=systemd\"],\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"100m\"\n  },\n  \"storage-driver\": \"overlay2\"\n}\n</code></pre> <p>### 添加k8s 软件源 </p> <p>如下添加的aliyun的镜像源</p> <p>```  cat &lt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg exclude=kube* EOF <pre><code>### 安装k8s\n\n安装组件 \n</code></pre> yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes systemctl enable kubelet &amp;&amp; systemctl start kubelet <pre><code>### 配置网络\n</code></pre> cat &lt;  /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system <pre><code>上面的步骤需要在主备上执行\n\n## Master 操作 \n\n下面的步骤只在Master节点运行\n\n### 生成k8s初始化配置文件 \n</code></pre> [root@k8s-master ~]$ kubeadm config print init-defaults &gt; kubeadm-init.yaml <pre><code>得到 kubeadm-init.yaml 文件\n\n修改kubeadm-init.yaml 文件\n1. 修改 `advertiseAddress: 1.2.3.4` 为本机地址 192.168.122.61\n2. 修改 `imageRepository: k8s.gcr.io ` 为 imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers \n\n修改镜像地址，这样就避免下载k8s 镜像超时\n\n修改后的kubeadm-init.yaml\n\n```yaml\napiVersion: kubeadm.k8s.io/v1beta2\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 10.33.30.92\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /var/run/dockershim.sock\n  name: k8s-master\n  taints:\n  - effect: NoSchedule\n    key: node-role.kubernetes.io/master\n---\napiServer:\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta2\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrollerManager: {}\ndns:\n  type: CoreDNS\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers\nkind: ClusterConfiguration\nkubernetesVersion: v1.15.0\nnetworking:\n  dnsDomain: cluster.local\n  serviceSubnet: 10.96.0.0/12\nscheduler: {}\n</code></pre>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#k8s_1","level":3,"title":"下载k8s的组件镜像","text":"<pre><code>kubeadm config images pull --config kubeadm-init.yaml\n</code></pre>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#k8s_2","level":3,"title":"初始化 k8s","text":"<p><pre><code>kubeadm init --config kubeadm-init.yaml\n</code></pre> 执行无误后，得到worker 节点加入集群的命令  <pre><code>...\nYour Kubernetes control-plane has initialized successfully!\n...\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 10.33.30.92:6443 --token abcdef.0123456789abcdef \\\n    --discovery-token-ca-cert-hash sha256:2883b1961db36593fb67ab5cd024f451b934fc0e72e2fa3858dda3ad3b225837 \n</code></pre></p> <p>记录这个命令， 丢失的话也可以重新执行 <code>kubeadmin create token</code> 找回</p>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#kubectl","level":3,"title":"配置普通用户执行kubectl 命令","text":"<p>用普通用户执行一下命令， 这样普通用户也能管理集群  <pre><code>mkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n</code></pre></p>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#master","level":3,"title":"查看Master 节点状态","text":"<p>可见，Master节点未就绪，这是因为还没安装网络组件 <pre><code>[root@k8s-master kubernetes]$ kubectl get node\nNAME         STATUS     ROLES    AGE     VERSION\nk8s-master   NotReady   master   3m25s   v1.15.3\n</code></pre></p>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#_3","level":3,"title":"配置网络","text":"<ol> <li> <p>下载calico 描述文件  wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml</p> </li> <li> <p>修改calico 描述文件里的serviceSubnet，修改为跟kubeadmin-init.yaml一致 <pre><code>cat kubeadm-init.yaml | grep serviceSubnet:\nserviceSubnet: 10.96.0.0/12\n</code></pre></p> </li> </ol> <p>注意  1. calico 的地址必须和 kubeadm-init.yaml 保持一致， kubeadm-init.yaml 默认为 <code>serviceSubnet: 10.96.0.0/12</code>， 而calico的默认地址为<code>192.168.0.0/16</code>, 所以要么修改kubeadmin-init.yaml, 要么修改calico.yaml。 2. 这里的<code>Subnet</code> 不能涵盖到主机的地址范围即不能包含 <code>192.168.122.0/24</code> </p>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#calico","level":3,"title":"安装calico","text":"<pre><code>kubectl apply -f calico.yaml \n</code></pre>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#master_1","level":3,"title":"查看Master节点","text":"<p>当calico 安装好了， 可以发现Master 节点变为就绪， 至此Master 节点就配置好了 <pre><code>[root@k8s-master ~]$ kubectl get node\nNAME         STATUS   ROLES    AGE   VERSION\nk8s-master   Ready    master   15m   v1.15.3\n</code></pre></p>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#dashboard","level":2,"title":"安装dashboard","text":"<p>之前的步骤安装好了Master节点， 可选择安装dashboard，通过网页来管理集群 </p> <p>步骤很简单， 先下载dashboard， 再安装  <pre><code>[root@k8s-master ~]$ wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta4/aio/deploy/recommended.yaml\n[root@k8s-master ~]$ kubectl apply -f recommended.yaml \n</code></pre></p>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#dashboard_1","level":3,"title":"创建dashboard 用户","text":"<p>必须创建用户，然后获取token，才能在集群外访问， 否则必须在Master 的localhost 访问dashboard。  以下是创建用户的描述文件， 注意namespace， 例如官方的例子是 dashboard， 这样生成的token 不一样</p> <p>执行安装用户 <code>kubectl apply -f dashboard-adminuser.yaml</code></p> <pre><code># dashboard-adminuser.yaml\n\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: admin-user\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: admin-user\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: admin-user\n  namespace: kube-system\n</code></pre> <p>创建证书， k8s 不允许远程使用http，所以需要用证书访问dashboard </p> <pre><code>[root@k8s-master ~]$ grep 'client-certificate-data' ~/.kube/config | head -n 1 | awk '{print $2}' | base64 -d &gt;&gt; kubecfg.crt\n[root@k8s-master ~]$ grep 'client-key-data' ~/.kube/config | head -n 1 | awk '{print $2}' | base64 -d &gt;&gt; kubecfg.key\n[root@k8s-master ~]$ openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name \"kubernetes-client\"\n</code></pre> <p>将生成的 <code>kubecfg.p12</code> 文件导入到集群外的主机，即kvm宿主机上</p> <pre><code>scp root@10.33.30.92:/root/.kube/kubecfg.p12 ./\n</code></pre> <p>在宿主机上使用chrome 的高级功能里可以导入证书  </p> <p>重启chrome 登录后登录 <pre><code>https://192.168.122.61:6443/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#/login\n</code></pre></p> <p>打开网页后选择输入token， token通过在Master 节点执行一下命令生成， 注意参数 -n kube-system， 需要跟创建用户时的namespace保持一致  <pre><code>kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')\n</code></pre></p> <p>复制token 到网页上，就能登录Dashboard </p>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#worker","level":2,"title":"Worker节点加入集群","text":"<p>直接在worker节点执行 </p> <pre><code>kubeadm join 10.33.30.92:6443 --token abcdef.0123456789abcdef \\\n    --discovery-token-ca-cert-hash sha256:2883b1961db36593fb67ab5cd024f451b934fc0e72e2fa3858dda3ad3b225837\n</code></pre> <p>然后到Master 节点执行以下命令， 这里Name 显示了k8s-worker是因为我们在Hosts文件里指定了ip，所以k8s自动识别到了，否则会显示节点ip</p> <pre><code>[root@k8s-master ~]$ kubectl get node\nNAME         STATUS   ROLES    AGE   VERSION\nk8s-master   Ready    master   10h   v1.15.3\nk8s-worker   Ready    &lt;none&gt;   96s   v1.15.3\n</code></pre> <p>至此集群搭建完毕</p>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-k8s-cluster/#_4","level":2,"title":"遇到问题","text":"<ol> <li>因为我的虚拟机配置的双网卡， 需要在calico.yaml 配网卡interface <pre><code># Cluster type to identify the deployment type\n            - name: CLUSTER_TYPE\n              value: \"k8s,bgp\"\n            - name: IP_AUTODETECTION_METHOD\n              value: \"interface=eth1\"\n</code></pre></li> </ol>","path":["搭建k8s集群"],"tags":["k8s","docker"]},{"location":"install-wordpress/","level":1,"title":"安装wordpress记录","text":"<p>本文记录在debian上安装配置wordpress的补助，并配置了ftp功能，支持自更新wordpress。</p>","path":["安装wordpress记录"],"tags":["wordpress"]},{"location":"install-wordpress/#wordpress_1","level":2,"title":"安装wordpress","text":"<p>下载最新的包，解压到<code>/var/www/html</code></p>","path":["安装wordpress记录"],"tags":["wordpress"]},{"location":"install-wordpress/#_1","level":2,"title":"安装配置数据库","text":"<p>安装mariadb, 创建数据库和用户 <pre><code>mysql -u root\nCREATE DATABASE wordpressdb; \nCREATE USER wordpressuser@localhost IDENTIFIED BY 'password';\nGRANT ALL PRIVILEGES ON wordpressdb.* TO wordpressuser@localhost;\n</code></pre></p>","path":["安装wordpress记录"],"tags":["wordpress"]},{"location":"install-wordpress/#nginx-php","level":2,"title":"安装配置nginx php","text":"<p>安装nginx和php-7.4，还有php一些组件 nginx 配置 <pre><code>server { \n  listen 80 default_server; \n  listen [::]:80 default_server;\n  server_name your_domain.com;\n\n  root /var/www/html;\n  index index.php index.html index.htm;\n\n  location / {\n    # try_files $uri $uri/ =404;\n    try_files $uri $uri/ /index.php?q=$uri&amp;$args;\n  }\n\n  location ~ \\.php$ {\n      include snippets/fastcgi-php.conf;\n      fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n      fastcgi_pass unix:/run/php/php-fpm.sock;\n  }\n}\n</code></pre></p>","path":["安装wordpress记录"],"tags":["wordpress"]},{"location":"install-wordpress/#vsftpd","level":2,"title":"安装配置vsftpd","text":"<p>安装后，修改配置文件<code>/etc/vsftpd.conf</code></p> <pre><code>local_enable=YES\nwrite_enable=YES\nchroot_local_user=YES\nchroot_list_enable=YES\nchroot_list_file=/etc/vsftpd.chroot_list\nallow_writeable_chroot=YES\npm_service_name=ftp\n</code></pre>","path":["安装wordpress记录"],"tags":["wordpress"]},{"location":"install-wordpress/#_2","level":3,"title":"添加用户，并限制权限","text":"<p><pre><code>useradd [user_name]\npasswd [user_name]\nusermod -d /var/www/html/wordpress user_name -s /sbin/nologin\n\nsetfacl -m u:ftpsecure:r-x /var/www/html/\n\nsetfacl -R -m u:ftpsecure:rwx /var/www/html/wordpress\nsetfacl -R -d -m u:ftpsecure:rwx /var/www/html/wordpress\n</code></pre> 如果提示没有setfacl命令，则执行安装acl命令 <code>apt install acl</code></p>","path":["安装wordpress记录"],"tags":["wordpress"]},{"location":"install-wordpress/#ftp","level":3,"title":"ftp遇到问题和解决办法","text":"<ul> <li> <p>登陆提示\"500 OOPS: could not read chroot() list file:/etc/vsftpd.chroot_list\"，需要创建文件<code>/etc/vsftpd.chroot_list</code></p> </li> <li> <p>登陆ftp报530验证失败的问题，修改配置如下 <pre><code>pm_service_name=ftp\n</code></pre></p> </li> <li>登陆提示\"500 OOPS: vsftpd: refusing to run with writable root inside chroot()</li> </ul> <pre><code>allow_writeable_chroot=YES\n</code></pre> <ul> <li>登陆提示 500 OOPS: vsftpd: refusing to run with writable root ，意思是登陆者具备对目录的写权限，这是由于目录设定权限为777，所以要是重新设定为755 <pre><code>chmod 755 /srv/ftp\n</code></pre></li> </ul>","path":["安装wordpress记录"],"tags":["wordpress"]},{"location":"install-wordpress/#wordpress_2","level":2,"title":"配置wordpress","text":"<p>修改<code>wordpress/wp-config.php</code> 文件, 添加如下内容</p> <p><pre><code>define('FTP_HOST', 'localhost');\ndefine('FTP_USER', 'ftp');\ndefine('FTP_PASS', '');\n</code></pre> 通过wordpress的api可以生成随机token，将输出替换到<code>wordpress/wp-config.php</code> </p> <pre><code>$curl -s https://api.wordpress.org/secret-key/1.1/salt/\n\ndefine('AUTH_KEY',         'uOeyPW$K[P}23x^0l##N+qP#xzUlIBV[ZQlATs!7J?+5^!w0*bgEw|V6)k:YU0en');\ndefine('SECURE_AUTH_KEY',  'Ad*-`eK|U4Z*7g}7CdX&lt;q0^EuGqT1Tt}CaDRgF%NX-|fmk(:BACtws+^_0Pb8ZRA');\ndefine('LOGGED_IN_KEY',    ':Z$}=h~z-[]8W}wZ(|/;]ZY;U{&gt;u3K&gt;P|u6/d:6}&amp;h*);0ewhrcGm8$/tPii#{,%');\ndefine('NONCE_KEY',        'd}Ue8.+KPDGdH^%2t~fTljDj8e{q{raR!Q0piqM(gcQP&amp;7-$L3u0u|!Bn(-gh/?B');\ndefine('AUTH_SALT',        'UQh.k&gt;4UBTK6IecZe~lL6|J/w^KFROIeCdZw^g=(x?(L+j(-|%C FCt =V*XVz+k');\ndefine('SECURE_AUTH_SALT', 'hHr&amp;dDCApb14yz@ks+;}mk,s&lt;-[]KUj*UAhl0+&lt;pqT*!j;wxc+[mU[czh =&gt;&lt;#em');\ndefine('LOGGED_IN_SALT',   'WO,U^A||&amp;:E@2A2_|MS W1l`fguj-7E{Fz6QkC+OM96Ho49&lt;agM?O=G2FloxuF?6');\ndefine('NONCE_SALT',       'uDN.1::MJ&gt;~9Yp+e39y%o?r &gt;:+OcUSqg5_g&lt;Jt:Sr!um?U:U|MJ2q2qKiLDfmr@');\n</code></pre> <p>更新数据库配置到wp-config.php</p>","path":["安装wordpress记录"],"tags":["wordpress"]},{"location":"install-wordpress/#url","level":2,"title":"更新url","text":"<p>开始使用http访问，后面切换到https后一直提示错误说跳转太多次。后来发现原因是套了cloudflare，cloudflare设置的是前端https后端http, 后端以http访问真实服务器后又跳转到https。所以请求一直在cf&lt;-&gt;wordpress之间无限跳转。所以首先要设置cloudflare的代理模式为严格安全，strict full safe，也就是前端和后端都用证书。然后修改wordpress的url方法有很多，之前通过直接修改数据库，这次发现wordpress有个wp的命令行工具，一键修改。</p>","path":["安装wordpress记录"],"tags":["wordpress"]},{"location":"install-wordpress/#vsftpd_1","level":2,"title":"vsftpd 配置默认目录","text":"<p>为local user配置默认目录，例如所有用户登录后进入/home目录, 添加配置<code>local_root=/home</code>，为匿名用户配置默认目录为tmp目录，则添加配置<code>anon_root=/tmp</code></p>","path":["安装wordpress记录"],"tags":["wordpress"]},{"location":"install-wordpress/#_3","level":2,"title":"参考","text":"<p>https://serverfault.com/questions/544850/create-new-vsftpd-user-and-lock-to-specify-home-login-directory https://shiftedbits.org/2012/01/29/enable-wordpress-automatic-updates-on-a-debian-server/</p>","path":["安装wordpress记录"],"tags":["wordpress"]},{"location":"ipsec/","level":1,"title":"ipsec 和 vowifi","text":"<p>记录了ipsec和vowifi的心得。</p>","path":["ipsec 和 vowifi"],"tags":["ipsec","vowifi"]},{"location":"ipsec/#ip","level":2,"title":"ip 分片","text":"<p>当ip包长度大过MTU（以太网通常是1500）时，网卡（内核）会分成多个ip包发送。</p>","path":["ipsec 和 vowifi"],"tags":["ipsec","vowifi"]},{"location":"ipsec/#ipsecmtu","level":2,"title":"ipsec隧道的MTU","text":"<p>以太网的MTU都是1500, 但是因为ipsec带来的overhead, MTU会设置小一点避免路由二次分包。</p>","path":["ipsec 和 vowifi"],"tags":["ipsec","vowifi"]},{"location":"ipsec/#nat-vowifi","level":3,"title":"NAT模式，手机连接路由器, 真实vowifi场景","text":"<p>进入adb可以看到ipsec隧道ipsec272@lo 此时没有注册。 </p> <p>手机注册vowifi成功后，获得了虚拟ip, 修改了ipsec隧道网卡的MTU。    </p>","path":["ipsec 和 vowifi"],"tags":["ipsec","vowifi"]},{"location":"ipsec/#nattunnel","level":3,"title":"非NAT，tunnel模式","text":"<p>先了解ESP带来的消耗  </p> <p> * 外层ip头总长度1496 * ESP SPI 字段长度4 * ESP Sequence 字段长度4 * ESP IV 长度16  AES-CBC * ESP ICV 长度12 SHA1-96  * ESP Pad 长度1 无padding * ESP Next Header 长度1</p> <p>ESP总共是38 byte。外层ip总长度(1496) - 内层ip总长度(1438) - 外层ip头(20)= 38 byte。 外层ip头+ESP一共是58。 所以：  1. 避免路由下一跳二次分包，需要预留空间给ipsec头。ipsec隧道网卡的MTU应该设置为1500 - 58 = 1442 2. 为了避免本地网卡分包，ip包的大小也应该小于MTU 1442。则:    * TCP MSS = 1442 - ip头（20） - tcp头20 = 1402    * UDP payload = 1442 - ip头（20） - udp头8 = 1414</p>","path":["ipsec 和 vowifi"],"tags":["ipsec","vowifi"]},{"location":"ipsec/#dpdk","level":2,"title":"dpdk","text":"<p>dpdk 支持 ipsec 的加解密，可以管理硬件加解密设备（智能网卡）和软件加解密设备（通用cpu上计算）。这里都是软件加解密，x86和arm上用不同的软件加解密库。</p>","path":["ipsec 和 vowifi"],"tags":["ipsec","vowifi"]},{"location":"ipsec/#advantages-of-rte_security_action_type_cpu_crypto-over-rte_security_action_type_none","level":3,"title":"advantages of RTE_SECURITY_ACTION_TYPE_CPU_CRYPTO over RTE_SECURITY_ACTION_TYPE_NONE","text":"<p>None模式的没走SECURITY的api , 要自己往队列里送op（operation）, 所以有 ipsec_process 和 drain 操作。 而cpu模式是串连到一起的。 没有送和收，直接调用加解密设备（软件/硬件）。</p>","path":["ipsec 和 vowifi"],"tags":["ipsec","vowifi"]},{"location":"ipsec/#tcp-over-esp","level":2,"title":"tcp over ESP 分析小记","text":"<p>在排查网络问题时，不得不分析tcp报文，积累了一些知识：</p> <ol> <li>wireshark中用方括号[]包起来的是wireshark分析提供的，而不是报文的字段。例如[TCP Retransmission]</li> <li>wireshark中用用 tcp.seq = SEQ 和tcp.ack = SEQ+LEN 来定位发送和回复报文</li> <li>TCP重发间隔，TCP的防庸塞，重传的间隔是变化的，第一次重传可能200ms, 第二次可能400ms, 第三次可能1600了，感觉是指数递增。</li> <li>TCP重传间隔还跟ACK等待有关，ACK会晚一点回复，看是否有更多包过来，然后合并ACK。</li> <li>TCP发送时，关键字段有SEQ和LEN, 分别表示数据偏移起点和数据长度。而ACK消息的ACK表示收到了多少字节数据，而且ACK总是累计值，就是全部收到，而不是部分收到。例如发送端发了两个报文SEQ=100/LEN=50, SEQ=150/LEN=50, 然后对端回复ACK=200，意思是两个报文都收到了。</li> </ol>","path":["ipsec 和 vowifi"],"tags":["ipsec","vowifi"]},{"location":"ipsec/#sackselective-ack","level":3,"title":"SACK(Selective ACK)","text":"<p>前面说了TCP的ACK总是累积的(cumulative)， 而当启用了SACK， 我遇到是默认启用了。如果第一个包没有收到，就收到第二个包和后面的包，会回复SACK包，SACK的关键信息如下 <pre><code>[TCP Dup ACK #NB1] SLE=NB2 SRE=NB3 \n</code></pre> 这表示接收端缺少了<code>SEQ=NB1, LEN</code>这个包，并收到了从NB2-&gt;NB3的包。接收端请求重发NB1包，并且不会丢弃NB2-&gt;NB3之间的包。</p>","path":["ipsec 和 vowifi"],"tags":["ipsec","vowifi"]},{"location":"ipsec/#_1","level":2,"title":"参考","text":"<p>SLE/SRE </p>","path":["ipsec 和 vowifi"],"tags":["ipsec","vowifi"]},{"location":"iptables-forward/","level":1,"title":"Linux创建热点","text":"<p>iptables 用来配置转发数据包规则的工具，Linux的防火墙配置就是利用的iptables。普通的路由器也是使用的iptables来实现NAT地址转换。</p>","path":["Linux创建热点"],"tags":["linux","iptables"]},{"location":"iptables-forward/#iptables","level":2,"title":"使用iptables转发流量","text":"<p>路由器使用的局域网ip，例如可使用的局域网有3类 * A类地址：10.0.0.0 - 10.255.255.255  ==&gt; 10.0.0.0/8 * B类地址：172.16.0.0 - 172.31.255.255 ==&gt;  * C类地址：192.168.0.0 -192.168.255.255 ==&gt; 192.168.0.0/16</p>","path":["Linux创建热点"],"tags":["linux","iptables"]},{"location":"iptables-forward/#lan","level":3,"title":"公网访问路由LAN，常见防火墙后的服务器","text":"<p>假设公网客户（8.8.8.8）访问路由器下的服务（192.168.0.2）。请求先到达路由的公网地址假设1.1.1.1, 此时的ip层源地址和目的地址分别为（8.8.8.8/1.1.1.1)， 然后路由器需要将目的地址改写为192.168.0.2，此时ip包的地址为（8.8.8.8/192.168.0.2)，这需要的iptable规则为</p> <p><pre><code>iptables -t nat -A PREROUTING -d 1.1.1.1 -j DNAT --to-destination 192.168.0.2\n</code></pre> ip包就能正常到达192.168.0.2，处理完成之后，ip包变成(192.168.0.2/8.8.8.8)，这是可能有几种情况： * 没有路由规则能匹配8.8.8.8，则会被丢弃。 * 一般会发送到默认网关，然后由网关发送正确发送到8.8.8.8，但8.8.8.8客户不认识源地址192.168.0.2，所以包会被丢弃 * 直接在第一个路由上被丢弃，因为192.168.0.2是一个私有地址，不能被转发。</p> <p>所以需要另外一条iptables规则，将192.168.0.2发出的ip包改成（1.1.1.⅛.8.8.8）</p> <pre><code>iptables -t nat -A POSTROUTING -s 192.168.0.2 -j SNAT --to-source 1.1.1.1\n</code></pre>","path":["Linux创建热点"],"tags":["linux","iptables"]},{"location":"iptables-forward/#reference","level":2,"title":"Reference","text":"<p>https://serverfault.com/questions/627608/redirect-all-incoming-traffic-from-a-secondary-public-ip-to-an-internal-ip-addre</p>","path":["Linux创建热点"],"tags":["linux","iptables"]},{"location":"iwd-ap/","level":1,"title":"使用iwd创建ap热点","text":"<p>windows中有很多软件能创建热点，现在Linux也可以创建热点了，下面记录方法</p>","path":["使用iwd创建ap热点"],"tags":["linux","iptables"]},{"location":"iwd-ap/#ap","level":2,"title":"确认网卡支持AP","text":"<p>使用<code>iw list</code>查看wifi网卡信息，如果在Supported interface modes能找到AP，说明网卡支持创建热点。</p>","path":["使用iwd创建ap热点"],"tags":["linux","iptables"]},{"location":"iwd-ap/#iwd","level":2,"title":"使用iwd","text":"<p>之前研究的wifi棒子，都是用wpa_supplicant来创建热点。而在我自己的电脑里一直使用的intel的iwd。 1. 先修改iwd的配置文件/etc/iwd/main.conf <pre><code>[General]\nEnableNetworkConfiguration=true\n</code></pre> 2. 在iwd保存密码的目录创建ap子目录 <pre><code>mkdir -p /var/lib/iwd/ap/\n</code></pre> 3. 在ap目录创建配置文件名字如main.ap，内容如下 <pre><code>[Security]\nPassphrase=password123\n\n[IPv4]\nAddress=192.168.250.1\nGateway=192.168.250.1\nNetmask=255.255.255.0\nDNSList=8.8.8.8\n</code></pre> 4. 执行iwctl命令进入到iwd交互模式 <pre><code>[iwd]# device wlan0 set-property Mode ap\n[iwd]# ap wlan0 start-profile main\n[iwd]# \n</code></pre> 5. 启动内核转发 <pre><code># sudo sysctl -w net.ipv4.ip_forward=1\nnet.ipv4.ip_forward = 1\n# sudo iptables -t nat -A POSTROUTING -s 192.168.250.0/24 -j MASQUERADE\n</code></pre></p> <p>我做完上面的步骤后，发现wifi连接不上，也有报错。然后重启了iwd服务，发现没有了main这个热点，所以这个热点不会自动启动。在执行4步骤后，就能正常连接wifi了。</p>","path":["使用iwd创建ap热点"],"tags":["linux","iptables"]},{"location":"iwd-ap/#ad-hoc-ap","level":2,"title":"ad-hoc 和 ap 的区别","text":"<p>ad-hoc是去中心化的组网方式，各连接节点可以直接通讯，而有些终端可能不支持。AP模式又叫做infrustructure Mode，就是类似传统的路由器模式，所以兼容性更好。</p>","path":["使用iwd创建ap热点"],"tags":["linux","iptables"]},{"location":"iwd-ap/#_1","level":2,"title":"使用总结","text":"<p>这个ap不稳定，长时间使用后没有网络， 需要重建ap， 不推荐。最终还是装了个便宜路由器MI-mini。老旧路由器的性能差，当路由（NAT）的丢包率太高， 但当桥接入口（交换机）正常。</p>","path":["使用iwd创建ap热点"],"tags":["linux","iptables"]},{"location":"iwd-ap/#_2","level":2,"title":"参考","text":"<p>https://iwd.wiki.kernel.org/ap_mode</p>","path":["使用iwd创建ap热点"],"tags":["linux","iptables"]},{"location":"kmp-substring-searching-algorithm/","level":1,"title":"前言","text":"<p>leetcode的题目, 实现strstr,即查找子字符串</p>","path":["kmp 子串查找算法"],"tags":["algorithm","查找"]},{"location":"kmp-substring-searching-algorithm/#_2","level":2,"title":"最简单的算法","text":"<pre><code>int strStr(char * haystack, char * needle){\n    char *tmp = haystack;\n    while(*tmp != 0){\n        if(strncmp(tmp, needle,strlen(needle))==0){\n            return tmp - haystack;\n        }\n        tmp ++;\n    }\n    return -1;\n}\n</code></pre>","path":["kmp 子串查找算法"],"tags":["algorithm","查找"]},{"location":"kmp-substring-searching-algorithm/#kmp","level":2,"title":"kmp 算法","text":"<pre><code>// C++ program for implementation of KMP pattern searching \n// algorithm \n#include &lt;bits/stdc++.h&gt; \n\nvoid computeLPSArray(char* pat, int M, int* lps); \n\n// Prints occurrences of txt[] in pat[] \nvoid KMPSearch(char* pat, char* txt) \n{ \n    int M = strlen(pat); \n    int N = strlen(txt); \n\n    // create lps[] that will hold the longest prefix suffix \n    // values for pattern \n    int lps[M]; \n\n    // Preprocess the pattern (calculate lps[] array) \n    computeLPSArray(pat, M, lps); \n\n    int i = 0; // index for txt[] \n    int j = 0; // index for pat[] \n    while (i &lt; N) { \n        if (pat[j] == txt[i]) { \n            j++; \n            i++; \n        } \n\n        if (j == M) { \n            printf(\"Found pattern at index %d \", i - j); \n            j = lps[j - 1]; \n        } \n\n        // mismatch after j matches \n        else if (i &lt; N &amp;&amp; pat[j] != txt[i]) { \n            // Do not match lps[0..lps[j-1]] characters, \n            // they will match anyway \n            if (j != 0) \n                j = lps[j - 1]; \n            else\n                i = i + 1; \n        } \n    } \n} \n\n// Fills lps[] for given patttern pat[0..M-1] \nvoid computeLPSArray(char* pat, int M, int* lps) \n{ \n    // length of the previous longest prefix suffix \n    int len = 0; \n\n    lps[0] = 0; // lps[0] is always 0 \n\n    // the loop calculates lps[i] for i = 1 to M-1 \n    int i = 1; \n    while (i &lt; M) { \n        if (pat[i] == pat[len]) { \n            len++; \n            lps[i] = len; \n            i++; \n        } \n        else // (pat[i] != pat[len]) \n        { \n            // This is tricky. Consider the example. \n            // AAACAAAA and i = 7. The idea is similar \n            // to search step. \n            if (len != 0) { \n                len = lps[len - 1]; \n\n                // Also, note that we do not increment \n                // i here \n            } \n            else // if (len == 0) \n            { \n                lps[i] = 0; \n                i++; \n            } \n        } \n    } \n} \n\n// Driver program to test above function \nint main() \n{ \n    char txt[] = \"ABABDABACDABABCABAB\"; \n    char pat[] = \"ABABCABAB\"; \n    KMPSearch(pat, txt); \n    return 0; \n} \n</code></pre>","path":["kmp 子串查找算法"],"tags":["algorithm","查找"]},{"location":"learn%20fastapi/","level":1,"title":"learn fastapi","text":"<p>在[[setup-vue2]]中创建了vue前端页面，这里再使用fastapi来托管，这样只需要一个端口就能管理前后端，非常像golang的那一套</p>","path":["learn fastapi"],"tags":["python","backend"]},{"location":"learn%20fastapi/#_1","level":2,"title":"learn fastapi","text":"","path":["learn fastapi"],"tags":["python","backend"]},{"location":"learn%20geo%20ip/","level":1,"title":"learn geo ip","text":"<p>APNIC 数据库中查找COUNTRY里的CN</p>","path":["learn geo ip"],"tags":[]},{"location":"learn%20ip%20header/","level":1,"title":"learn ip header","text":"<p>ipv4的头最小长度是20, 因为ip4的头尾部可以包含一个或多个option和padding, 其长度可变。 而ipv6的头虽然固定长度，但是ipv6支持拓展 extension，其长度也可以变。</p>","path":["learn ip header"],"tags":["ip","network"]},{"location":"learn%20ip%20header/#ipv6-extension","level":2,"title":"ipv6 extension","text":"<p>ipv6的头里 'Next Header' 字段表示是否有下一个头。</p>","path":["learn ip header"],"tags":["ip","network"]},{"location":"learn%20ip%20header/#ipv4-options","level":2,"title":"ipv4 options","text":"<ul> <li>记录路由路径</li> <li>指定路由，曾经看到博客有人用路由打印出简历</li> </ul>","path":["learn ip header"],"tags":["ip","network"]},{"location":"learn%20ip%20header/#_1","level":2,"title":"参考","text":"<p>https://pall.as/ipv6-headers-and-extension-headers/ https://www.geeksforgeeks.org/computer-networks/options-field-in-ipv4-header/</p>","path":["learn ip header"],"tags":["ip","network"]},{"location":"learning%20lisp/","level":1,"title":"arc 是lisp一种方言，通用编程语言。","text":"<p>和常见的编程语言不同的是，他的操作符在前面例如加法运算（+ 1 1）。 自带了很多基础库，可以支持web和gui应用，跨平台。</p>","path":["arc 是lisp一种方言，通用编程语言。"],"tags":["arc","lisp"]},{"location":"learning%20lisp/#ide-rocket","level":2,"title":"开源免费的ide rocket","text":"","path":["arc 是lisp一种方言，通用编程语言。"],"tags":["arc","lisp"]},{"location":"learning%20lisp/#_1","level":2,"title":"参考","text":"<p>https://docs.racket-lang.org/quick/index.html http://arclanguage.org/forum</p>","path":["arc 是lisp一种方言，通用编程语言。"],"tags":["arc","lisp"]},{"location":"linux-perm/","level":1,"title":"linux 权限位","text":"<p>linux的权限位用来定义文件和目录的权限</p>","path":["linux 权限位"],"tags":["linux"]},{"location":"linux-perm/#selinux","level":2,"title":"selinux","text":"<p>权限位粒度太大，由selinux提供的权限控制比较好。</p>","path":["linux 权限位"],"tags":["linux"]},{"location":"linux-reset-password/","level":1,"title":"rhel系列修改密码","text":"<p>考rhce8 栽在改密码了， 现在彻底弄明白</p>","path":["rhel系列修改密码"],"tags":["linux","rhce"]},{"location":"linux-reset-password/#selinux","level":2,"title":"关于selinux","text":"<p>这是rhel和其他发行版的最大区别，也是我忽略的点。启用selinux 时，改密码后，额外要执行<code>touch /.autorelabel</code>， 新密码才能生效，而平时我使用centos一直是禁用selinux的。</p>","path":["rhel系列修改密码"],"tags":["linux","rhce"]},{"location":"linux-reset-password/#selinux_1","level":2,"title":"启用selinux","text":"<p>selinux 默认状态是enforcing, 禁用时为disable, 通过<code>sestate</code> 查看状态。</p>","path":["rhel系列修改密码"],"tags":["linux","rhce"]},{"location":"linux-reset-password/#etcselinuxconfig","level":3,"title":"编译'/etc/selinux/config'","text":"<p>修改selinux配置，从disable 到enforcing</p>","path":["rhel系列修改密码"],"tags":["linux","rhce"]},{"location":"linux-reset-password/#_1","level":3,"title":"执行两次下面动作","text":"<p>创建这个文件的意义是重新label selinux, 不仅是当修改selinux配置需要做，在重置root密码时也是需要 <pre><code>touch /.autorelabel\nreboot\n</code></pre></p>","path":["rhel系列修改密码"],"tags":["linux","rhce"]},{"location":"linux-reset-password/#_2","level":2,"title":"叙说改密","text":"<p>rhel5~8有两种方式重置密码，老版本为给linux启动参数加上'init=/bin/sh', 新版本为加<code>rd.break</code> 老版本适用于centos8（已测）, 而新版本应该不支持rhel5，6（未测），下面是完整步骤</p>","path":["rhel系列修改密码"],"tags":["linux","rhce"]},{"location":"linux-reset-password/#_3","level":3,"title":"老版本","text":"<ol> <li>进入grub界面，按e进入编辑启动参数，到linux 行，按ctrl+e或者end键到末尾，追加'init=/bin/sh'</li> <li>按ctrl+x继续，系统自动进入内存文件系统的根目录</li> <li>执行<code>/sbin/load_policy -i</code>来初始化selinux</li> <li>此时系统处于ro模式，执行<code>mount -oremount,rw /</code> 重新挂载根分区，使系统可写</li> <li><code>passwd</code> 设置root密码</li> <li>如果启用了selinux, 额外要执行<code>touch /.autorelabel</code></li> <li>最后执行<code>exit</code>或者 <code>exec /sbin/reboot</code> 或者<code>exec /sbin/init</code></li> </ol>","path":["rhel系列修改密码"],"tags":["linux","rhce"]},{"location":"linux-reset-password/#_4","level":3,"title":"新版本","text":"<ol> <li>进入grub界面，按e进入编辑启动参数，到linux 行，按ctrl+e或者end键到末尾，追加'rd.break'</li> <li>按ctrl+x继续，系统自动进入root系统，此时真正的文件系统以ro挂载在/sysroot</li> <li>执行<code>mount -oremount,rw /sysrot</code> 重新挂载</li> <li>执行<code>chroot /sysroot</code> 进入系统</li> <li>执行<code>passwd</code>设置root密码</li> <li>如果启用了selinux, 需要额外创建文件<code>touch /.autorelabel</code></li> <li>执行<code>exit</code> 退出，然后执行 <code>umount /sysroot</code> 来确保写入</li> <li>reboot 来重新进入</li> </ol>","path":["rhel系列修改密码"],"tags":["linux","rhce"]},{"location":"linux-reset-password/#rescue","level":2,"title":"通过rescue模式改密码","text":"<p>任何发行版都可以通过光盘引导来改密。如果熟悉archlinux安装的方式，就知道进入live os之后可以挂载原系统的磁盘 然后chroot成为root用户，就能直接执行<code>passwd</code>来修改密码</p>","path":["rhel系列修改密码"],"tags":["linux","rhce"]},{"location":"linux-reset-password/#_5","level":2,"title":"通过修改镜像改密码","text":"<p>最暴力的方式就是用guestfish工具, 一条命令改密。当然得先获取镜像文件 先切换到root用户，使用guestmount命令挂载分区，-i表示自动挂载 <pre><code>guestmount --add base.raw  -i /tmp/hm\n</code></pre> 然后chroot到挂载点 <pre><code>chroot /tmp/hm\n</code></pre> 然后改密 <pre><code>passwd\n</code></pre></p> <p>virt提供了简化版本，一条命令就能改密码 <pre><code>virt-customize -a centos8.qcow2 --root-password password:123456\n</code></pre></p> <p>可见镜像文件有多么不安全</p>","path":["rhel系列修改密码"],"tags":["linux","rhce"]},{"location":"linux-reset-password/#vmwarekvm","level":2,"title":"最后记录一下vmware虚拟机镜像转换kvm镜像","text":"<p>由于收到的vmware镜像，又没有装vmware workstation，所以找到转换镜像的方法，也很方便 <pre><code>qemu-img convert  CentOS\\ 5.vmdk  base-000001.raw       \n</code></pre> 但问题是不支持转换快照文件</p>","path":["rhel系列修改密码"],"tags":["linux","rhce"]},{"location":"linux-reset-password/#_6","level":2,"title":"引用","text":"<p>https://docs.openstack.org/image-guide/convert-images.html</p>","path":["rhel系列修改密码"],"tags":["linux","rhce"]},{"location":"lvm/","level":1,"title":"LVM 功能介绍","text":"<p>LVM 是在硬件和系统之间多加了一层，可以很方便地修改分区和扩容。 从效率上看肯定有所损失的，但是对于企业而言，灵活性也很重要 LVM具有在线扩容和快照的重要功能</p>","path":["LVM 功能介绍"],"tags":["linux","lvm"]},{"location":"lvm/#_1","level":2,"title":"在线扩容","text":"<p>当磁盘容量不够或者需要替换磁盘时，就需要扩容, 如果是替换磁盘就再需要换出旧硬盘</p>","path":["LVM 功能介绍"],"tags":["linux","lvm"]},{"location":"lvm/#_2","level":3,"title":"扩容步骤","text":"<p>使用lvm中的pvmove 命令假如原来是使用pv 为/dev/sda1, 新的硬盘为/dev/sdb1 1. 新建pv: # pvcreate /dev/sdb1  2. 扩容vg：# vgextend vg1 /dev/sdb1  3. 如果要调整分区大小，使用lvresize -r -S 新大小。 不带-r的话需要重新mount才能生效， -S 是表示最终大小，-s ± 是调整大小</p>","path":["LVM 功能介绍"],"tags":["linux","lvm"]},{"location":"lvm/#_3","level":3,"title":"换出步骤","text":"<p>vgreduce 是将pv踢出vg, pvremove是删除pv标记</p> <ol> <li>把sda1 上数据迁移到sdb1上： # pvmove  /dev/sda1  /dev/sdb1 </li> <li>vgreduce 从vg1踢出sda1盘 # vgreduce vg1 /dev/sda1  </li> <li>pvremove 删除磁盘分区的pv 标记 # pvremove /dev/sda1 </li> </ol>","path":["LVM 功能介绍"],"tags":["linux","lvm"]},{"location":"lvm/#_4","level":3,"title":"磁盘换出是否需要停业务","text":"<p>LVM的在线扩容是不需要停止业务的，但是应该在业务闲的时候做。LVM在做pvmove的时候，会冻结旧分区，新的操作就需要做备份。  pvmove有时候很慢，但是不能中断，否则出现很多遗留的分区。 </p> <p>与pvmove类似的功能的还有磁盘镜像， 磁盘镜像的好处很明显，即使复制失败了，原数据依然存在。</p> <p>但两个技术都要求能够“原子化”，所以不得不对业务有所影响，而且影响的是磁盘IO， 无法通过降低业务的NICE值来减弱这种影响</p>","path":["LVM 功能介绍"],"tags":["linux","lvm"]},{"location":"lvm/#lvm_1","level":2,"title":"LVM 快照功能","text":"<p>当系统是安装在LVM文件系统之上，那么当需要进行高危操作的时候，可以先对分区进行快照备份，避免操作失败又无法恢复。 公司有一台centos7的自用系统， 需要升级到Centos8 以支持 Docker buildx。 虽然因操作到无法运行yum,dnf 时宣布失败，但好在有snapshot备份， 恢复后完好如初，太好用。</p>","path":["LVM 功能介绍"],"tags":["linux","lvm"]},{"location":"lvm/#_5","level":3,"title":"步骤","text":"<ol> <li>挂载如下</li> </ol> <pre><code>$ lsblk \nNAME                  MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINT\nsda                     8:0    0   477G  0 disk  \n├─sda1                  8:1    0   200M  0 part  /boot/efi\n├─sda2                  8:2    0     1G  0 part  /boot\n└─sda3                  8:3    0 475.8G  0 part  \n  ├─centos-root       253:2    0    50G  0 lvm   /\n  ├─centos-swap       253:4    0  15.7G  0 lvm   [SWAP]\n  ├─centos-docker     253:18   0   150G  0 lvm   /var/lib/docker\n</code></pre> <p>根分区为50G, 而卷组还剩余160G,完全足够生成一个镜像，50G并未完全使用。 <pre><code>$ sudo vgs\n  VG     #PV #LV #SN Attr   VSize   VFree   \n  centos   1   4   0 wz--n- 475.74g  160.05g\n  data     1  13   0 wz--n-  &lt;7.28t &lt;721.91g\n</code></pre></p> <ol> <li> <p>先对根分区进行快照，注意是<code>根分区</code> <pre><code># lvcreate -s -n &lt;snapshot_name&gt; -L &lt;size&gt; &lt;logical_volume&gt;\n\n$ lvcreate -s -n backup -L 50G  /dev/centos/root\n</code></pre> 这里指定了快照的大小为50G, 理论上是要比源分区大， 这里也可以直接设置100G, 系统会自动调整大小到合适。</p> </li> <li> <p>进行一顿操作后， 进行恢复, 提示根分区正在使用， 重启后生效。</p> </li> </ol> <pre><code>$ lvconvert --mergesnapshot /dev/centos/backup \n  Delaying merge since origin is open.\n  Merging of snapshot centos/backup will occur on next activation of centos/root.\n</code></pre>","path":["LVM 功能介绍"],"tags":["linux","lvm"]},{"location":"lvm/#_6","level":3,"title":"保存","text":"<p>如果需要对快照进行备份到其他位置， 可以直接将快照分区挂载，然后通过tarball 来压缩。</p> <pre><code>tar -cvzf backup.tar.gz /mnt/lv_snapshot\n</code></pre> <p>还可以直接通过rsync 将挂载的snapshort 传输到其他服务器上</p> <pre><code>rsync -aPh /mnt/lv_snapshot  &lt;remote_user&gt;@&lt;destination_server&gt;:&lt;remote_destination&gt;\n</code></pre>","path":["LVM 功能介绍"],"tags":["linux","lvm"]},{"location":"lvm/#_7","level":3,"title":"快照回滚","text":"<p>lvm的snapshort 也是写时复制的（copy on write），所以创建快照操作非常快，  当分区进行删除和修改操作的时候， lvm文件系统会拷贝文件到其他地方保存。</p>","path":["LVM 功能介绍"],"tags":["linux","lvm"]},{"location":"lvm/#_8","level":3,"title":"问题","text":"<p>lvm快照不等于备份， 仅有快照是不能恢复的</p>","path":["LVM 功能介绍"],"tags":["linux","lvm"]},{"location":"lxc%20enable%20tun%20device/","level":1,"title":"lxc enable tun device","text":"<p>在lxc中运行tailscale时，默认使用tun模式，就是创建一个虚拟网卡，然后用路由规则将出去的流量都路由到tun的虚拟网卡中。但是lxc中默认没有'/dev/net/tun'，这时tailscaled 启动时会尝试执行'modprobe tun'，结果lxc的内核版本和宿主的不一致，所以导致下面的报错。解决办法有2个，一是使用tailscale的userspace networking（也就是sock5代理），二是将宿主机的tun设备绑定到lxc容器中。</p> <pre><code>Aug 21 15:20:22 debian-dockers tailscaled[22673]：Linux kernel version: 6.1.10-1-pve\nAug 21 15:20:22 debian-dockers tailscaled[22673]: is CONFIG_TUN enabled in your kernel? `modprobe tun` failed with: modprobe: FATAL: Module tun not found in directory /lib/modules/6.1.10-1-pve\nAug 21 15:20:22 debian-dockers tailscaled[22673]: kernel/drivers/net/tun.ko found on disk, but not for current kernel; are you in middle of a system update and haven't rebooted? found: linux-image-5.10.0-32-rt-am&gt;\nAug 21 15:20:22 debian-dockers tailscaled[22673]: wgengine.NewUserspaceEngine(tun \"tailscale0\") error: tstun.New(\"tailscale0\"): CreateTUN(\"tailscale0\") failed; /dev/net/tun does not exist\n</code></pre>","path":["lxc enable tun device"],"tags":["pve"]},{"location":"lxc%20enable%20tun%20device/#userspace-networking","level":2,"title":"使用userspace networking","text":"<p>修改/etc/default/tailscaled文件，修改FLAG为'FLAGS=\"--tun=userspace-networking\"'，这样tailscaled就不会去创建tun设备，而只是暴露一个端口，供应用来使用。  </p> <p>使用tailscale的方法 <pre><code>ALL_PROXY=socks5://localhost:1055/ HTTP_PROXY=http://localhost:1055/ http_proxy=http://localhost:1055/ ./my-app\n</code></pre></p> <p>另外也可以手动启动tailscaled <pre><code>tailscaled --tun=userspace-networking --socks5-server=localhost:1055 --outbound-http-proxy-listen=localhost:1055 &amp;\ntailscale up --auth-key=&lt;your-auth-key&gt;\n</code></pre></p>","path":["lxc enable tun device"],"tags":["pve"]},{"location":"lxc%20enable%20tun%20device/#lxctun","level":2,"title":"给lxc容器添加tun设备","text":"<p>将下面两行添加到容器配置文件，例如容器id为100, 则配置文件的路径是/etc/pve/nodes/lxc/100.conf <pre><code>lxc.cgroup2.devices.allow: c 10:200 rwm\nlxc.mount.entry: /dev/net dev/net none bind,create=dir\n</code></pre></p>","path":["lxc enable tun device"],"tags":["pve"]},{"location":"lxc%20enable%20tun%20device/#lxc-enable-fuse","level":2,"title":"lxc enable fuse","text":"<p>当lxc挂载webdav文件系统时，依赖fuse 驱动，可以在pve的lxc选项里添加feature。 参考 </p>","path":["lxc enable tun device"],"tags":["pve"]},{"location":"lxc%20enable%20tun%20device/#_1","level":2,"title":"参考","text":"<p>https://tailscale.com/kb/1112/userspace-networking https://github.com/tailscale/tailscale/issues/6941</p>","path":["lxc enable tun device"],"tags":["pve"]},{"location":"mail-setup/","level":1,"title":"Linux下的邮件配置","text":"<p>这里记录Linux（debian）下如何使用Mutt查看邮件，用fetchmail接收邮件，用msmtp发送邮件以及使用maildrop来筛选邮件。与其他邮件客户端相比，如thunderbird，他们使用的在线登陆方式，没有下载邮件来离线访问。而mutt支持离线访问本地的邮件，也可以配置为访问邮件服务器，查看服务器上的邮件。 在线方式除了离线不可用的缺点之外，每次打开mutt需要登陆，非常慢。 我这里的配置是比较简陋，适合公司少量邮件的场景。又因为目前使用的Byobu-terminal终端，其邮件提醒是基于/var/mail/spool/$USER文件。邮件比较多或者附件比较大的话，相较于用文件夹来存储邮件，这种方式会比较慢。</p>","path":["mail setup"],"tags":["email_client","mutt"]},{"location":"mail-setup/#_1","level":2,"title":"软件安装","text":"<p>需要安装 fetchmail, maildrop, mutt</p>","path":["mail setup"],"tags":["email_client","mutt"]},{"location":"mail-setup/#_2","level":2,"title":"接收配置","text":"<p>在家目录下创建文件.fetchmailrc <pre><code>poll imap.exmail.qq.com\n  protocol IMAP\n  user \"example@example.com\"\n  password \"password\"\n  keep\n  #fetchall\n  ssl\n\nmimedecode\nmda \"/usr/bin/maildrop\"\n</code></pre> keep 方式不会删除服务器上的邮件。然后启动定时任务，自动检查新邮件 <pre><code>systemctl --user enable --now fetchmail.service\n</code></pre></p>","path":["mail setup"],"tags":["email_client","mutt"]},{"location":"mail-setup/#_3","level":2,"title":"发送配置","text":"<p>在家目录创建文件.msmtproc，填入发送的验证信息 <pre><code>defaults\nauth           on\ntls            on\ntls_starttls off\ntls_trust_file /etc/ssl/certs/ca-certificates.crt\nlogfile        ~/.msmtp.log\n\n# exmail\naccount        office\nhost           smtp.exmail.qq.com\nport           465\nfrom           example@example.com\nuser           example@example.com\npassword       password\n</code></pre></p>","path":["mail setup"],"tags":["email_client","mutt"]},{"location":"mail-setup/#mutt","level":2,"title":"mutt配置","text":"<p>由于我不想删除/var/mail/里面的邮件，这样才能在byobu-terminal中提醒，所以没有配置maildrop。最后需要配置mutt读取/var/mail/$USER。在家目录或者xdg配置目录（~/.config/mutt）创建文件.muttrc/muttrc <pre><code>set spoolfile=/var/spool/mail/jimery\nset header_cache=~/.cache/mutt\nset send_charset=\"utf-8\"\n</code></pre></p> <p>这样就能查看邮件了。 在mutt里面手动管理邮件，存档或者删除。</p>","path":["mail setup"],"tags":["email_client","mutt"]},{"location":"mail-setup/#mutt_1","level":2,"title":"mutt使用","text":"<p>其实不用mutt, 直接用mail也可以，这个默认访问/var/mail/$USER,是Linux默认的邮件工具。 mutt能很方便调用msmtproc来发送邮件。</p>","path":["mail setup"],"tags":["email_client","mutt"]},{"location":"manage-temporary-file-with-systemd-tmpfiles/","level":1,"title":"使用systemd-tmpfiles来管理临时文件","text":"<p>vscode使用clangd作为c++的lsp非常好用，可以支持跳转、补全、clang-tidy、提示，但同时也对配置有要求，我的12Gi内存经常不够用而非常卡 于是摸索了一下，发现有两个问题： 1. clangd会占用很多内存  2. clangd在处理代码文件时会产生pch文件默认放到/tmp目录占用内存</p> <p>这里会说怎么解决这2个问题，也顺便用到systemd-tmpfiles工具</p>","path":["使用systemd-tmpfiles来管理临时文件"],"tags":["linux","tmpfile"]},{"location":"manage-temporary-file-with-systemd-tmpfiles/#_1","level":2,"title":"问题","text":"","path":["使用systemd-tmpfiles来管理临时文件"],"tags":["linux","tmpfile"]},{"location":"manage-temporary-file-with-systemd-tmpfiles/#_2","level":3,"title":"搜索过程","text":"<p>由于代码比较复杂，随便跳转几个文件就开始感到卡顿，一会就不能动了。切换X界面到终端, 执行<code>free</code>命令，可以看到shared和buff/cache两个部分占用很大内存 <pre><code>~ &gt; free -h\n               total        used        free      shared  buff/cache   available\nMem:            11Gi       7.1Gi       721Mi       1.0Gi       3.7Gi       3.1Gi\nSwap:             0B          0B          0B\n</code></pre></p> <p>通过man可以知道这几项的意思, 可见share在我的系统指'/tmp', 因为tmpfs挂载在/tmp目录 <pre><code>shared \nMemory used (mostly) by tmpfs (Shmem in /proc/meminfo)\n\nbuffers\nMemory used by kernel buffers (Buffers in /proc/meminfo)\n\ncache  \nMemory used by the page cache and slabs (Cached and SReclaimable in /proc/meminfo)\n\nbuff/cache\nSum of buffers and cache\n</code></pre> 而buff/cache指的缓存(cache)和内核(buff)占用, 通过<code>cat /proc/meminfo</code> 查看到buff占用不大，不是内核问题(因为我用的最新内核,所以抱有怀疑态度)</p> <pre><code>~ &gt; cat /proc/meminfo  | grep \"Buffers\\|Cached\"\nBuffers:          308440 kB\nCached:          3297168 kB\n</code></pre> <p>所以主要是/tmp目录占用内存过大，以及clangd占用内存过大</p>","path":["使用systemd-tmpfiles来管理临时文件"],"tags":["linux","tmpfile"]},{"location":"manage-temporary-file-with-systemd-tmpfiles/#_3","level":3,"title":"解决办法","text":"<ol> <li>对于clangd占用内存过大， 只有添加<code>-background-index=0</code>时，才能避免内存占用过大</li> <li>clangd在分析代码文件的时候，产生大量pch文件, 这些都会占用内存</li> </ol> <pre><code>~ &gt; ls /tmp/*.pch -lh\n-rw-r--r-- 1  100M May 13 11:18 /tmp/preamble-133598.pch\n-rw-r--r-- 1  104M May 13 11:17 /tmp/preamble-457bd6.pch\n-rw-r--r-- 1  104M May 13 11:17 /tmp/preamble-465a46.pch\n-rw-r--r-- 1  104M May 13 11:18 /tmp/preamble-99f5e5.pch\n-rw-r--r-- 1  99M May 13 11:17 /tmp/preamble-b56fad.pch\n</code></pre>","path":["使用systemd-tmpfiles来管理临时文件"],"tags":["linux","tmpfile"]},{"location":"manage-temporary-file-with-systemd-tmpfiles/#systemd-tmpfiles-clean-tmppch","level":2,"title":"使用systemd-tmpfiles-clean 来清除/tmp目录下的pch文件","text":"","path":["使用systemd-tmpfiles来管理临时文件"],"tags":["linux","tmpfile"]},{"location":"manage-temporary-file-with-systemd-tmpfiles/#systemd-tmpfiles_1","level":3,"title":"systemd-tmpfiles 介绍","text":"<p>systemd-tmpfiles 通过<code>systemd-tmpfiles-clean.timer</code>定时调用<code>systemd-tmpfiles-clean.service</code>, 来清理零时文件，且是默认启动的。 虽然/tmp目录使用的内存挂载<code>tmpfs</code>（也有写发行版使用物理磁盘来挂载），在重启时会清空，但对于服务器这种常年不会重启的系统，就需要这样的机制清理内存/磁盘。  </p> <p>timer默认的配置文件，<code>OnBootSec=15min</code>表示在系统启动15分钟后开始执行，而<code>OnUnitActiveSec=1d</code>表示在执行一次后，1天后再执行 <pre><code>~ &gt; cat /usr/lib/systemd/system/systemd-tmpfiles-clean.timer\n#  SPDX-License-Identifier: LGPL-2.1-or-later\n#\n#  This file is part of systemd.\n#\n#  systemd is free software; you can redistribute it and/or modify it\n#  under the terms of the GNU Lesser General Public License as published by\n#  the Free Software Foundation; either version 2.1 of the License, or\n#  (at your option) any later version.\n\n[Unit]\nDescription=Daily Cleanup of Temporary Directories\nDocumentation=man:tmpfiles.d(5) man:systemd-tmpfiles(8)\n\n[Timer]\nOnBootSec=15min\nOnUnitActiveSec=1d\n</code></pre></p> <p>上面的timer会定时调用<code>systemd-tmpfiles-clean.service</code>这个服务</p> <pre><code>~ &gt; sudo systemctl status systemd-tmpfiles-clean.service\n○ systemd-tmpfiles-clean.service - Cleanup of Temporary Directories\n     Loaded: loaded (/usr/lib/systemd/system/systemd-tmpfiles-clean.service; static)\n     Active: inactive (dead) since Wed 2021-05-12 16:37:27 HKT; 22h ago\nTriggeredBy: ● systemd-tmpfiles-clean.timer\n       Docs: man:tmpfiles.d(5)\n             man:systemd-tmpfiles(8)\n    Process: 36637 ExecStart=systemd-tmpfiles --clean (code=exited, status=0/SUCCESS)\n</code></pre>","path":["使用systemd-tmpfiles来管理临时文件"],"tags":["linux","tmpfile"]},{"location":"manage-temporary-file-with-systemd-tmpfiles/#systemd-tmpfiles_2","level":2,"title":"systemd-tmpfiles 配置","text":"<p>上面是timer的设置，这个timer适合服务器，但并不建议修改它们。而是添加规则，再手动调用<code>systemd-tmpfiles --clean</code> 配置规则的方法可以查看<code>man tmpfiles.d 5</code>，但只建议在/etc 和 ～/ 目录添加规则, 前者对所有用户生效，后者只对自己生效</p> <pre><code>TMPFILES.D(5)                                                                           tmpfiles.d                                                                           TMPFILES.D(5)\n\nNAME\n       tmpfiles.d - Configuration for creation, deletion and cleaning of volatile and temporary files\n\nSYNOPSIS\n       /etc/tmpfiles.d/*.conf\n       /run/tmpfiles.d/*.conf\n       /usr/lib/tmpfiles.d/*.conf\n\n       ~/.config/user-tmpfiles.d/*.conf\n       $XDG_RUNTIME_DIR/user-tmpfiles.d/*.conf\n       ~/.local/share/user-tmpfiles.d/*.conf\n</code></pre> <p>直接从/usr/lib/tmpfs.d/ 找合适的配置，拷贝到自己的目录再改</p> <p>删除/tmp/*.pch文件的效果 <pre><code>~ &gt; free\n               total        used        free      shared  buff/cache   available\nMem:        12158548     7808240      854296     1010820     3496012     3019688\nSwap:              0           0           0\n~ &gt; rm /tmp/*.pch\n~ &gt; free\n               total        used        free      shared  buff/cache   available\nMem:        12158548     7804356     1169052      699936     3185140     3334460\nSwap:              0           0           0\n</code></pre></p> <p>shared项少了许多, 再设置<code>background-index=0</code>后，内存占用大大减小</p>","path":["使用systemd-tmpfiles来管理临时文件"],"tags":["linux","tmpfile"]},{"location":"manage-temporary-file-with-systemd-tmpfiles/#_4","level":2,"title":"总结","text":"<p>使用systemd-tmpfs 来清除文件的方式不太适合这种场景, 但其本身是非常功能强大的管理工具</p>","path":["使用systemd-tmpfiles来管理临时文件"],"tags":["linux","tmpfile"]},{"location":"markdown/","level":1,"title":"Markdown in 5min","text":"","path":["Markdown in 5min"],"tags":[]},{"location":"markdown/#headers","level":2,"title":"Headers","text":"<pre><code># H1 Header\n## H2 Header\n### H3 Header\n#### H4 Header\n##### H5 Header\n###### H6 Header\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"markdown/#text-formatting","level":2,"title":"Text formatting","text":"<pre><code>**bold text**\n*italic text*\n***bold and italic***\n~~strikethrough~~\n`inline code`\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"markdown/#links-and-images","level":2,"title":"Links and images","text":"<pre><code>[Link text](https://example.com)\n[Link with title](https://example.com \"Hover title\")\n![Alt text](image.jpg)\n![Image with title](image.jpg \"Image title\")\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"markdown/#lists","level":2,"title":"Lists","text":"<pre><code>Unordered:\n- Item 1\n- Item 2\n  - Nested item\n\nOrdered:\n1. First item\n2. Second item\n3. Third item\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"markdown/#blockquotes","level":2,"title":"Blockquotes","text":"<pre><code>&gt; This is a blockquote\n&gt; Multiple lines\n&gt;&gt; Nested quote\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"markdown/#code-blocks","level":2,"title":"Code blocks","text":"<pre><code>```javascript\nfunction hello() {\n  console.log(\"Hello, world!\");\n}\n```\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"markdown/#tables","level":2,"title":"Tables","text":"<pre><code>| Header 1 | Header 2 | Header 3 |\n|----------|----------|----------|\n| Row 1    | Data     | Data     |\n| Row 2    | Data     | Data     |\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"markdown/#horizontal-rule","level":2,"title":"Horizontal rule","text":"<pre><code>---\nor\n***\nor\n___\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"markdown/#task-lists","level":2,"title":"Task lists","text":"<pre><code>- [x] Completed task\n- [ ] Incomplete task\n- [ ] Another task\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"markdown/#escaping-characters","level":2,"title":"Escaping characters","text":"<pre><code>Use backslash to escape: \\* \\_ \\# \\`\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"markdown/#line-breaks","level":2,"title":"Line breaks","text":"<pre><code>End a line with two spaces  \nto create a line break.\n\nOr use a blank line for a new paragraph.\n</code></pre>","path":["Markdown in 5min"],"tags":[]},{"location":"memory-management/","level":1,"title":"浅谈内存管理","text":"<p>这里记录一下看书所得，应用程序的内存管理，即glibc的malloc和相关函数</p>","path":["浅谈内存管理"],"tags":["memory","malloc"]},{"location":"memory-management/#_2","level":2,"title":"内存管理的重要性","text":"<p>过去Linux通过默认的dlmalloc来申请内存，但不支持多线程，这导致的竞争和性能降低，而ptmalloc2支持多线程，也成为了Linux新的默认方式 ptmalloc2通过为每个线程单独维护一个帧，这样每个线程的申请和释放可以并行执行，但当线程过多时，线程也将共享帧。这种帧叫做<code>per thread arena</code></p>","path":["浅谈内存管理"],"tags":["memory","malloc"]},{"location":"memory-management/#_3","level":2,"title":"主线程和线程的内存申请方式","text":"<p>主线程中使用brk来申请大块内存，其实<code>brk</code>不过是修改了寄存器的值。而且返回的大小通常要比malloc申请的多，如同测试中的在主线程中申请100个字节大小的内存，返回了132 KB。 <pre><code>55f7b402c000-55f7b404d000 rw-p 00000000 00:00 0                          [heap]\n</code></pre> 而在线程中，malloc使用mmap来申请内存，返回大小也比申请大小多，测试中的在线程中申请100字节，返回了64M的地址空间， 但只有8MB是可用的堆内存。 <pre><code>7fb738000000-7fb738021000 rw-p 00000000 00:00 0      \n7fb738021000-7fb73c000000 ---p 00000000 00:00 0      \n</code></pre></p> <p>主线程中申请的地址大于Data Section的地址，说明使用的<code>brk</code>，而后者申请时用了mmap，对比附录文档可以看出32位和64位区别比较大</p>","path":["浅谈内存管理"],"tags":["memory","malloc"]},{"location":"memory-management/#arena","level":2,"title":"arena","text":"<p>主线程和线程使用不同的arena，这样主线程和线程同时申请内存时不存在竞争。但不是所有的线程都独享一份arena, arena的个数限制如下</p> <pre><code>For 32 bit systems:\n     Number of arena = 2 * number of cores.\nFor 64 bit systems:\n     Number of arena = 8 * number of cores.\n</code></pre> <p>当线程个数太多时，会公用主线程的arena</p>","path":["浅谈内存管理"],"tags":["memory","malloc"]},{"location":"memory-management/#main-arena-per-thread-arena","level":3,"title":"main arena 和 per thread arena","text":"<p>main arena 指在主线程（main）中使用的，而后者是子线程中使用，两者有很大区别 主线程只有一块heap，所以没有heapinfo结构，而子线程有。主线程的<code>Arena header</code>是全局变量，所以存在于libc.so的Data Segment中  </p> <p>线程的arena含有多个heap, 每个heap都有heapinfo结构，多个heapinfo组成链表。线程的多个heap共享一个<code>malloc_state</code> 也称为<code>Arena header</code> </p> <p><code>Arena header</code>包含了bin、top chunk等信息  </p> <p>每个heap有多个chunk，每个chunk有个<code>malloc_chunk</code>结构，其管理chunk的状态和其在heap中的偏移大小，有以下几种状态</p> <ul> <li>Allocated chunk </li> <li>Free chunk</li> <li>Top chunk</li> <li>Last Remainder chunk</li> </ul> <p>Top chunk 处于arena的顶部，在freelist没有合适大小的chunk时使用，如果Top chunk比申请的大，则又分为两部分（新Top chunk和用户申请的chunk）  </p> <p>Last Remainder chunk, 是当用户请求small chunk时，会先遍历small bin和Unsorted bin， 如果都无法满足，则遍历其他bin。 如果找到的chunk还有剩余，则这个chunk变为<code>Last Remainder chunk</code>，且将被加入到<code>Unsorted bin</code> 这样的好处是多次申请small chunk时，会先向<code>Unsorted bin</code>的<code>Last Remainder chunk</code>申请， 所以小内存块会集中分布在<code>Last Remainder chunk</code>，提高小块内存的局部性  </p>","path":["浅谈内存管理"],"tags":["memory","malloc"]},{"location":"memory-management/#bin","level":2,"title":"bin","text":"<p>当malloc的内存被free后（仅仅是例子中的100字节chunk），并不会释放给内核，而是进入到glibc的bin中，也叫做<code>freelist</code>。 当下次申请内存时，会从bin中查找合适的chunk，而只有当没有合适的大小时，才向内核申请。</p> <p>所以bin用来保存free过的chunk, 基于chunk的大小分为 - Fast bin - Unsorted bin - Small bin - Large bin</p> <p>但不同的bin都使用链表来管理这些chunk</p>","path":["浅谈内存管理"],"tags":["memory","malloc"]},{"location":"memory-management/#_4","level":2,"title":"测试方法","text":"<p>获取程序运行时的pid, 假设为949293, 那么通过以下命令可以获取程序的内存结构 <pre><code>cat /proc/949632/maps\n# address                 perms offset  dev    inode             pathname\n55f7b378a000-55f7b378b000 r--p 00000000 103:02 4727634                   /tmp/a.out (deleted)\n55f7b378b000-55f7b378c000 r-xp 00001000 103:02 4727634                   /tmp/a.out (deleted)\n55f7b378c000-55f7b378d000 r--p 00002000 103:02 4727634                   /tmp/a.out (deleted)\n55f7b378d000-55f7b378e000 r--p 00002000 103:02 4727634                   /tmp/a.out (deleted)\n55f7b378e000-55f7b378f000 rw-p 00003000 103:02 4727634                   /tmp/a.out (deleted)\n55f7b402c000-55f7b404d000 rw-p 00000000 00:00 0                          [heap]\n7f4808000000-7f4808021000 rw-p 00000000 00:00 0 \n7f4808021000-7f480c000000 ---p 00000000 00:00 0 \n7f480ea3d000-7f480ea3e000 ---p 00000000 00:00 0 \n7f480ea3e000-7f480f241000 rw-p 00000000 00:00 0 \n...\n</code></pre> * address 是起始地址-结束地址，差值为空间大小 * perm 是指权限，分为rwx[p,s], [p,s]指最后一位可以是private或者shared, 这些能通过<code>mprotect</code>命令修改(c中的const实现) * offset 仅对mmap的区域有效，指映射偏移量 * pathname 如果此区域是映射的文件，则显示文件名。如果映射的是匿名映射则显示空白, 匿名映射包括线程通过mmap申请的堆内存，而[heap]是main函数的堆 </p> <p>所以通过计算address可以知道glibc申请的内存情况</p>","path":["浅谈内存管理"],"tags":["memory","malloc"]},{"location":"memory-management/#malloc","level":2,"title":"<code>malloc</code>的返回值有意义吗","text":"<p>在我本机（gcc (Debian 10.2.1-6) 10.2.1 20210110 12GB）上测试了一段程序 1. 如果一次性申请13GB，malloc返回失败 2. 如果每次只申请2GB但不释放，第10次申请（20GB）malloc返回成功 3. 如果每次只申请2GB但不释放且<code>访问</code>，第三次申请（6GB）malloc返回成功，但访问时OOM</p> <p>所以说，malloc的返回值是没有太大意义的</p> <pre><code>void foo(size_t large) {\n  char *buffer = (char *)malloc(large);\n  if (buffer == NULL) {\n    printf(\"error!\\n\");\n    exit(EXIT_FAILURE);\n  }\n  printf(\"Memory allocated\\n\");\n  //  for (size_t i = 0; i &lt; large; i += 4096) {\n  //    buffer[i] = 0;\n  //  }\n  printf(\"Travalse done\\n\");\n}\nint main() {\n  // size_t large = 1099511627776;\n  size_t large = 13958643712;\n  for (int i = 0; i &lt; 100; i++) {\n    foo(2147483648);\n  }\n\n  return EXIT_SUCCESS;\n}\n</code></pre>","path":["浅谈内存管理"],"tags":["memory","malloc"]},{"location":"memory-management/#_5","level":2,"title":"其他","text":"<p>内存管理不仅存在应用程序（或者说glibc）中，Linux内核也有内存管理。也不只有glibc的内存malloc一种实现，还有</p> <ul> <li>dlmalloc – General purpose allocator</li> <li>ptmalloc2 – glibc</li> <li>jemalloc – FreeBSD 的libc实现, 相比其他第三方，这个比较流行</li> <li>tcmalloc – Google 为多线程场景开发</li> <li>libumem – Solaris</li> </ul> <p>malloc是glibc对ptmalloc2的包装，而<code>ptmalloc2</code>是<code>dlmalloc</code>的重构，区别很大  </p> <p>最后总结，glibc的malloc通过两个系统调用函数brk和mmap来向内核申请内存，但内存释放后不会归还内核，而是放到freelist等待再次被利用</p>","path":["浅谈内存管理"],"tags":["memory","malloc"]},{"location":"memory-management/#_6","level":2,"title":"引用","text":"<p>https://man7.org/linux/man-pages/man5/proc.5.html https://sploitfun.wordpress.com/2015/02/10/understanding-glibc-malloc/comment-page-1/ https://lemire.me/blog/2021/10/27/in-c-how-do-you-know-if-the-dynamic-allocation-succeeded/</p>","path":["浅谈内存管理"],"tags":["memory","malloc"]},{"location":"miniserve/","level":1,"title":"网络文件浏览器","text":"<p>相比基于ftp, nfs，samba等传输共享方式，基于http的网络共享最简单了。因为终端方面，浏览器普及高，终端里面也能用curl等工具很方便使用。 服务端选择有： nginx（autoindex） 和 miniserve</p>","path":["网络文件浏览器"],"tags":["tool"]},{"location":"miniserve/#miniserve","level":2,"title":"miniserve","text":"<p>支持 url_prefix</p>","path":["网络文件浏览器"],"tags":["tool"]},{"location":"miniserve/#nginx","level":2,"title":"nginx","text":"<p>启用autoindex <pre><code>location /myfolder {  # new url path\n   alias /home/username/myfolder/; # directory to list\n   autoindex on;\n}\n</code></pre></p>","path":["网络文件浏览器"],"tags":["tool"]},{"location":"miniserve/#_2","level":2,"title":"文件列表","text":"<ol> <li>浏览器使用</li> <li>cli使用，例如显示文件列表 <pre><code>curl -s 'http://user:password@ip:port/miniserve/?raw=true'  | w3m -dump -T text/html\n</code></pre></li> </ol>","path":["网络文件浏览器"],"tags":["tool"]},{"location":"miniserve/#_3","level":2,"title":"网络文件浏览器","text":"","path":["网络文件浏览器"],"tags":["tool"]},{"location":"mutex-error/","level":1,"title":"mutex error","text":"<p>记一次单元测试用例时失败，且出现奇怪的报错 <pre><code>tpp.c:63: __pthread_tpp_change_priority: Assertion `new_prio == -1 ||(new_prio &gt;= __sched_fifo_min_prio &amp;&amp; new_prio &lt;=__sched_fifo_max_prio)' failed\n</code></pre></p>","path":["mutex error"],"tags":["mutex","c","cpp"]},{"location":"mutex-error/#_1","level":2,"title":"原因","text":"<p>函数定义如下，原因是下面的第一个assert条件不成立，new_prio != -1。这个函数的注释说明了需要使用者确保调用前已初始化。</p> <pre><code>/* We only want to initialize __sched_fifo_min_prio and __sched_fifo_max_prio\n   once.  The standard solution would be similar to pthread_once, but then\n   readers would need to use an acquire fence.  In this specific case,\n   initialization is comprised of just idempotent writes to two variables\n   that have an initial value of -1.  Therefore, we can treat each variable as\n   a separate, at-least-once initialized value.  This enables using just\n   relaxed MO loads and stores, but requires that consumers check for\n   initialization of each value that is to be used; see\n   __pthread_tpp_change_priority for an example.\n */\n</code></pre> <pre><code>int\n__pthread_tpp_change_priority (int previous_prio, int new_prio)\n{\n  struct pthread *self = THREAD_SELF;\n  struct priority_protection_data *tpp = THREAD_GETMEM (self, tpp);\n  int fifo_min_prio = atomic_load_relaxed (&amp;__sched_fifo_min_prio);\n  int fifo_max_prio = atomic_load_relaxed (&amp;__sched_fifo_max_prio);\n  if (tpp == NULL)\n    {\n      /* See __init_sched_fifo_prio.  We need both the min and max prio,\n         so need to check both, and run initialization if either one is\n         not initialized.  The memory model's write-read coherence rule\n         makes this work.  */\n      if (fifo_min_prio == -1 || fifo_max_prio == -1)\n        {\n          __init_sched_fifo_prio ();\n          fifo_min_prio = atomic_load_relaxed (&amp;__sched_fifo_min_prio);\n          fifo_max_prio = atomic_load_relaxed (&amp;__sched_fifo_max_prio);\n        }\n      size_t size = sizeof *tpp;\n      size += (fifo_max_prio - fifo_min_prio + 1)\n              * sizeof (tpp-&gt;priomap[0]);\n      tpp = calloc (size, 1);\n      if (tpp == NULL)\n        return ENOMEM;\n      tpp-&gt;priomax = fifo_min_prio - 1;\n      THREAD_SETMEM (self, tpp, tpp);\n    }\n  assert (new_prio == -1\n          || (new_prio &gt;= fifo_min_prio\n              &amp;&amp; new_prio &lt;= fifo_max_prio));\n  assert (previous_prio == -1\n          || (previous_prio &gt;= fifo_min_prio\n              &amp;&amp; previous_prio &lt;= fifo_max_prio));\n</code></pre> <p>网上帖子的原因是给初始化mutex并设置RECURSIVE类型时，忘了对mutexattr进行初始化，导致使用了脏内存 即<code>pthread_mutexattr_init(&amp;mutexattr)</code></p> <pre><code>pthread_mutexattr_t mutexattr;\n\n// Set the mutex as a recursive mutex\npthread_mutexattr_settype(&amp;mutexattr, PTHREAD_MUTEX_RECURSIVE_NP);\n\n// create the mutex with the attributes set\npthread_mutex_init(&amp;CritSec, &amp;mutexattr);\n\n// After initializing the mutex, the thread attribute can be destroyed\npthread_mutexattr_destroy(&amp;mutexattr);\n</code></pre> <p>总之，要在线程启动前初始化好mutex</p>","path":["mutex error"],"tags":["mutex","c","cpp"]},{"location":"mutex-error/#_2","level":2,"title":"其他问题","text":"<p>这个问题其实是c++代码抛出来的，多线程执行了下面的代码，导致了上面的问题。</p> <p>AppCache中有个小粒度的锁，但这个锁还未初始化就被其他线程去lock了，导致出现问题。所以要mutex最好要在线程启动前初始化</p> <pre><code>AppCache{\nstd::mutex\n}；\n</code></pre> <pre><code>  auto app = m_app_cache.find(app_path);\n  if (app == m_app_cache.end()) {\n    // create a new monitor element\n    m_app_cache.insert_or_assign(app_path, std::make_shared&lt;AppCache&gt;());\n  }\n  std::lock_guard&lt;std::mutex&gt; lk(app-&gt;second-&gt;cache_mutex);\n</code></pre>","path":["mutex error"],"tags":["mutex","c","cpp"]},{"location":"mutex-error/#_3","level":2,"title":"引用","text":"<p>https://sourceware.org/legacy-ml/libc-help/2008-05/msg00072.html?utm_source=pocket_mylist</p>","path":["mutex error"],"tags":["mutex","c","cpp"]},{"location":"my-urxvt/","level":1,"title":"urxvt配置","text":"<p>自使用arch以来，一直在用urxvt, 它简洁，轻量，但不可否认的有问题，比如中文输入模式长时间时会无法输入中文，配置麻烦, 需要在启动脚本配置.xresource 这里要记一下自己的urxvt的配置以做备份  </p>","path":["urxvt配置"],"tags":["linux","urxvt","terminal"]},{"location":"my-urxvt/#urxvt_1","level":2,"title":"使用urxvt的主要功能","text":"<p>urxvt 非常简洁的tab功能,支持多路复用以及右键菜单格式化字符串，而且支持假透明，非常轻量。</p> <p>urxvt不够现代化，不是开箱即用的，需要如下修改：  * tab功能需要修改perl的包，因为默认情况下不支持切换tab * 不支持icon, 需要在配置文件手动指定icon的位置 * tab功能需要额外启动参数，所以顺便编一个desktop启动文件</p>","path":["urxvt配置"],"tags":["linux","urxvt","terminal"]},{"location":"my-urxvt/#perl","level":2,"title":"perl修改","text":"<p>复制/usr/lib/perl/ext/tabbed到用户目录~/.urxvt/ext/, 修改<code>tab_key_press</code>函数如下</p> <pre><code># if ($keysym == 0xff51 || $keysym == 0xff53)  表示使用ctrl+shift 和方向键来移动tab\nsub tab_key_press {\n   my ($self, $tab, $event, $keysym, $str) = @_;\n\n   if ($event-&gt;{state} &amp; urxvt::ShiftMask &amp;&amp; !($event-&gt;{state} &amp; urxvt::ControlMask) ) {\n      if ($keysym == 0xff51 || $keysym == 0xff53) {\n         my ($idx) = grep $self-&gt;{tabs}[$_] == $tab, 0 .. $#{ $self-&gt;{tabs} };\n\n         --$idx if $keysym == 0xff51;\n         ++$idx if $keysym == 0xff53;\n\n         $self-&gt;make_current ($self-&gt;{tabs}[$idx % @{ $self-&gt;{tabs}}]);\n\n         return 1;\n      } elsif ($keysym == 0xff54) {\n         $self-&gt;new_tab;\n\n         return 1;\n      }\n   }elsif ($event-&gt;{state} &amp; urxvt::ControlMask &amp;&amp; $event-&gt;{state} &amp; urxvt::ShiftMask) {\n      if ($keysym == 0xff51 || $keysym == 0xff53) {\n         my ($idx1) = grep $self-&gt;{tabs}[$_] == $tab, 0 .. $#{ $self-&gt;{tabs} };\n         my  $idx2  = ($idx1 + ($keysym == 0xff51 ? -1 : +1)) % @{ $self-&gt;{tabs} };\n\n         ($self-&gt;{tabs}[$idx1], $self-&gt;{tabs}[$idx2]) =\n            ($self-&gt;{tabs}[$idx2], $self-&gt;{tabs}[$idx1]);\n\n         $self-&gt;make_current ($self-&gt;{tabs}[$idx2]);\n\n         return 1;\n      }\n   }\n\n   ()\n}\n</code></pre>","path":["urxvt配置"],"tags":["linux","urxvt","terminal"]},{"location":"my-urxvt/#urxvt_2","level":2,"title":"urxvt 启动文件","text":"<p>创建启动文件，使其默认为tab模式 '.local/share/applications/urxvtq.desktop' <pre><code>[Desktop Entry]\nVersion=1.0\nName=urxvtq\nComment=An unicode capable rxvt clone\nExec=urxvt -pe tabbed\nIcon=utilities-terminal\nTerminal=false\nType=Application\nCategories=System;TerminalEmulator;\n</code></pre></p>","path":["urxvt配置"],"tags":["linux","urxvt","terminal"]},{"location":"my-urxvt/#urxvt_3","level":2,"title":"urxvt 配置","text":"<p>创建如下的文件，并要在合适的启动脚本里添加一行<code>[ -f \"$HOME/.Xresources\" ] &amp;&amp;  xrdb -merge \"$HOME/.Xresources\"</code> <pre><code>!!$HOME/.Xresources\n\n!! dbi\nXft.dpi:98\n\n/* Couleurs Tango */\n\n!! 下划线色\nURxvt.colorUL:  #87afd7\nURxvt.colorBD:  white\nURxvt.colorIT:  green\n\n!! tab 配色\nURxvt.tabbed.tabbar-fg: 2\nURxvt.tabbed.tabbar-bg: 0\nURxvt.tabbed.tab-fg:    3\nURxvt.tabbed.tab-bg:    2\nURxvt.tabbed.tabren-bg: 3\nURxvt.tabbed.tabdiv-fg: 8\nURxvt.tabbed.tabsel-fg: 1\nURxvt.tabbed.tabsel-bg: 8\n\n!! fake transparent\nURxvt.transparent: true\nURxvt.shading:     10\nURxvt.fading:      40\n!! font\nURxvt.font:        xft:Monospace,xft:Awesome:pixelsize=14\nURxvt.boldfont:    xft:Monospace,xft:Awesome:style=Bold:pixelsize=16\n\n!! scroll behavior\nURxvt.scrollBar:         false\nURxvt.scrollTtyOutput:   false\nURxvt.scrollWithBuffer:  true\nURxvt.scrollTtyKeypress: true\n\n!! addtional\nURxvt.internalBorder:     0\nURxvt.cursorBlink: true\nURxvt.saveLines:          2000\nURxvt.mouseWheelScrollPage:             false\n\n! Restore Ctrl+Shift+(c|v)\nURxvt.keysym.Shift-Control-V: eval:paste_clipboard\nURxvt.keysym.Shift-Control-C: eval:selection_to_clipboard\nURxvt.iso14755: false\nURxvt.iso14755_52: false\n\n! alt+s 搜索\nURxvt.perl-ext:   default,matcher,searchable-scrollback\nURxvt.keysym.M-s: searchable-scrollback:start\n\n! url match 问题是tab模式下不支持跳转浏览器\nURxvt.url-launcher:       /usr/bin/firefox\nURxvt.matcher.button:     1\n\n\nURxvt.termName:         xterm-256color\nURxvt.iconFile:     /usr/share/icons/gnome/32x32/apps/gnome-terminal-icon.png\n! fast key\nURxvt.keysym.Control-Up:     \\033[1;5A\nURxvt.keysym.Control-Down:   \\033[1;5B\nURxvt.keysym.Control-Left:   \\033[1;5D\nURxvt.keysym.Control-Right:  \\033[1;5C\n</code></pre></p>","path":["urxvt配置"],"tags":["linux","urxvt","terminal"]},{"location":"my-urxvt/#_1","level":2,"title":"最后","text":"<p>用了kitty就不会有输入法的问题，字体也很丰富, 推荐现代化模拟终端kitty</p>","path":["urxvt配置"],"tags":["linux","urxvt","terminal"]},{"location":"mysql-statements-execution-order/","level":1,"title":"mysql sql语句优先级","text":"<pre><code>The actual execution of MySQL statements is a bit tricky. However, the standard does specify the order of interpretation of elements in the query. This is basically in the order that you specify, although I think HAVING and GROUP BY could come after SELECT:\n\n    FROM clause\n    WHERE clause\n    SELECT clause\n    GROUP BY clause\n    HAVING clause\n    ORDER BY clause\n\nThis is important for understanding how queries are parsed. You cannot use a column alias defined in a SELECT in the WHERE clause, for instance, because the WHERE is parsed before the SELECT. On the other hand, such an alias can be in the ORDER BY clause.\n\nAs for actual execution, that is really left up to the optimizer. For instance:\n\n. . .\nGROUP BY a, b, c\nORDER BY NULL\n\nand\n\n. . .\nGROUP BY a, b, c\nORDER BY a, b, c\n\nboth have the effect of the ORDER BY not being executed at all -- and so not executed after the GROUP BY (in the first case, the effect is to remove sorting from the GROUP BY and in the second the effect is to do nothing more than the GROUP BY already does).\n</code></pre>","path":["mysql sql语句优先级"],"tags":["mysql"]},{"location":"mysql-statements-execution-order/#_1","level":2,"title":"引用","text":"<p>https://stackoverflow.com/questions/24127932/mysql-query-clause-execution-order</p>","path":["mysql sql语句优先级"],"tags":["mysql"]},{"location":"nginx-fails-to-connect-to-unix-socket/","level":1,"title":"记录在部署一个nginx fastcgi 项目时失败， fastcgi 通过unix socket 通讯","text":"<p>这是一个flask 项目， 使用flup创建的fastcgi</p> <pre><code>#!/usr/bin/env python\nfrom flup.server.fcgi import WSGIServer\nfrom main import app\n\nif __name__ == '__main__':\n    # for apache\n    # WSGIServer(app).run()\n    # for nginx, need to set conmunication sock between nginx and the cgiserver\n    WSGIServer(app, bindAddress='/tmp/myflask-fcgi.sock').run()\n</code></pre> <p>这里直接说明结果， socket 文件不能创建在/tmp/ 或者 /vat/tmp 目录。</p> <p>nginx 错误配置 <pre><code>    location / { try_files $uri @myflask; }\n    location @myflask {\n        include fastcgi_params;\n        fastcgi_param PATH_INFO $fastcgi_script_name;\n        fastcgi_param SCRIPT_NAME \"\";\n        fastcgi_pass unix:/tmp/fcgi.sock;\n    }\n</code></pre></p> <p>nginx 错误提示 <pre><code> connect() to unix:/tmp/fcgi.sock failed (2: No such file or directory) while connecting to upstream\n</code></pre></p>","path":["记录在部署一个nginx fastcgi 项目时失败， fastcgi 通过unix socket 通讯"],"tags":["flask","webserver"]},{"location":"nginx-fails-to-connect-to-unix-socket/#_1","level":2,"title":"原因","text":"<p>如果socket创建在/tmp 或者 /var/tmp 目录， 只能被socket的进程发现。 意思是只有cgi程序能发现，所以nginx 无法连接了</p> <p>正确配置是创建到/var/sockets 目录，并注意权限问题 <pre><code>    location / { try_files $uri @myflask; }\n    location @myflask {\n        include fastcgi_params;\n        fastcgi_param PATH_INFO $fastcgi_script_name;\n        fastcgi_param SCRIPT_NAME \"\";\n        fastcgi_pass unix:/var/sockets/myflask-fcgi.sock;\n    }\n</code></pre></p>","path":["记录在部署一个nginx fastcgi 项目时失败， fastcgi 通过unix socket 通讯"],"tags":["flask","webserver"]},{"location":"nginx-fails-to-connect-to-unix-socket/#unix-socket","level":2,"title":"关于unix socket","text":"<p>以上是一种解决办法，当然使用ip来连接nginx和cgi也是可以的，但是unix socket 有不少好处。 </p>","path":["记录在部署一个nginx fastcgi 项目时失败， fastcgi 通过unix socket 通讯"],"tags":["flask","webserver"]},{"location":"nginx-fails-to-connect-to-unix-socket/#cgi","level":2,"title":"关于cgi","text":"<p>上面无论使用unix socket 还是 ip 来访问cgi， 这两种方式都是通过cgi来提供web服务。 而nginx 不支持cgi， 所以需要自己来通过python的 flup 来实现fastcgi。 nginx 只不过是一个代理的作用。而apache和tomcat 都能支持cgi</p> <pre><code>cgi 的定义是 common gateway interface， 是一个协议。 fastcgi，uwcgi都是升级版或者变种。  \nflup实现了cgi的服务程序，也就是可以用来解析脚本（python php 等等），提供web服务。\n</code></pre> <p>另外除了以上方式， nginx也可以使用pypass proxy 来转发请求，由应用自己来实现网络处理。 </p> <pre><code>location / {\n        proxy_pass https://localhost:8080\n        proxy_set_header Host            $host;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Real-IP       $remote_addr;\n        proxy_set_header X-Scheme        $scheme;\n        access_log /var/log/nginx/access.log my_tracking;\n    }\n</code></pre> <p>如过是python 就需要监听某个端口，这种是不稳定的。 不适合生产模式下使用。 </p>","path":["记录在部署一个nginx fastcgi 项目时失败， fastcgi 通过unix socket 通讯"],"tags":["flask","webserver"]},{"location":"notes/","level":1,"title":"Notes","text":"","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_1","level":2,"title":"笔记本的笔记整理和誊抄","text":"<p>主要是关于ffmpeg的知识总结</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#ffmpeg","level":2,"title":"FFmpeg","text":"<p>读法\"F-F-M-派格\", 由三个可执行文件组成\"ffmpeg/ffplay/ffprobe\"。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#ffmpeg_1","level":3,"title":"ffmpeg","text":"<ul> <li>支持的容器 <code>ffmpeg -muxers</code> 分为Demuxing和Muxing（D/E）封装和解封装，支持Muxing肯定支持Demuxing。</li> <li>支持的编码 <code>ffmpeg -codecs</code> 分为解码和编码(decoder/encoder)，支持编码一般能支持解码。</li> <li>容器帮助信息 <code>ffmpeg -h muxer=mp4</code> <code>ffmpeg -h demuxer=mp4</code> 加上<code>-h full</code>查看更多信息</li> <li>编码帮助信息 <code>ffmpeg -h encoder=h264</code> <code>ffmpeg -h decoder=h264</code> 加上<code>-h full</code>查看更多信息</li> <li>支持的滤镜 <code>ffmpeg -filters</code> 这里的滤镜不是PS等图片编辑软件里面的滤镜，而应该称做特效，支持视频和音频还有字幕。</li> </ul> <p>当转码或转容器格式时，-map参数用来手动选择流，参数格式 -map nx 其中n表示选择第n个输入，m代表第n个输入中的第m个流，而x表示第n个输入中的第m个流的第x个通道。当没有-map参数时，ffmpeg会根据容器类型自动选择合适的流。-map还能用来选择filtergraph中的滤镜输出。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#filter","level":4,"title":"filter 滤镜","text":"<p>分为 filtergraph filterchain 和 filter * filtergraph 是包含很多个filter的有向图，每两个滤镜之间都可以有多个连接。 * filter 分为source filter, sink filter, filter，其中source filter没有输入端，sink filter没有输出端。 </p> <p>多个filter用\",\"来连接，形成filterchain，而多个chain用\";\"来连接，形成fitergraph。</p> <p>简单滤镜格式参数格式 -f:v 或 -f:a [输入流或标记名]滤镜参数[临时标记名];(重复n个)。复杂滤镜格式 -filter_complex overlay滤镜用来设置显示层次，例如[overlay]filter 将输入显示在另一个上面。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_2","level":5,"title":"加速","text":"<p>使用滤镜来加速播放</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_3","level":6,"title":"加速视频","text":"<p>使用setpts来加速视频 -f:v setpts=0.5*PTS, 注意：1调整范围[0.25,4]，越小越快，从加速4倍到减速4倍。2若只是调整视频则将音频关掉。3对视频加速时，如果不想丢帧，则使用-r参数调整输出的FPS。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_4","level":6,"title":"加速音频","text":"<p>最简单的方法是调整采样率，但这样会改变音色，一般使用对原音进行重采样。 -f:a atempo:2.0。范围 [0.5,2.0]，若要4倍加速，使用滤镜组合 -f:a atempo=2.0,atempo=2</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_5","level":6,"title":"同时加速音频和视频","text":"<p>可以用 -filter_complex \"[0:v]setpts=0.5*PTS[v];[0:a]atempo=2.0[a]\" -map [v] -map [a] 。也可以组合使用上面的两个滤镜。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_6","level":5,"title":"视频裁剪","text":"<p>-ss 选项seek，从开头跳过一段片长，参数两种形式 00:00:00或者秒数。-ss设置在输入对象和输出对象上有不同效果。 * -ss 指定在输入时，不仅可以用于复制，也可以用于转码。并且都是基于关键帧来寻找位置，默认启用选项“frame_accurate\" * -ss 指定在输出时，源文件依旧会每帧都要解码并丢弃，知道跳过指定的时间所以要等待。但是-SS用在输出时，最大的优点是当使用滤镜时，其timestamp不会重置0,这个在录制字幕时有用，不需要修改字幕的时间戳。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#frame_accurate_seek-noaccurate_seek","level":6,"title":"在裁剪时有两个选项 frame_accurate_seek 和 -noaccurate_seek 区别, 后者会使用附近的关键帧。","text":"","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#-ss-t-ss-to-ss-10-t-2010s30s-ss-10-to-20-10s20s","level":6,"title":"-ss -t 与 -ss -to的区别，-ss 10 -t 20表示截取10s~30s的视频，而 -ss 10 -to 20 表示截取10s~20s的视频。","text":"<p>截取视频不准确问题： * 当使用-ss和-c:copy时，由于ffmpeg强制使用I帧，所以可能调整起始时间到负值，即提前于ss设置的时间 * 例如 -ss 157 但直到159时才有I帧，它会有2秒的时间只有声音没有画面。 </p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_7","level":4,"title":"编译问题","text":"<ul> <li>编译ffmpeg支持h265, 因为h265库是用c++写的，所以编译ffmpeg时要加上额外库<code>-lstdc++</code></li> <li>如果pc文件不在标准路径，需要修改环境变量<code>export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:\"pc文件路径\"</code></li> <li>如果链接到了动态库，可以使用enable-rpath设置运行时找库路径</li> </ul>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#ffplay","level":3,"title":"ffplay 播放媒体文件","text":"<ul> <li>在视频中插入字幕 <code>ffplay -f:v \"subtitle=input.srt\" input.mp4</code></li> <li>音频可视化 <code>ffplay -showmode 1 input.mp3</code> 默认是0, 用傅立叶变换显示声音的频率频谱，处理时长差不多是1s。</li> <li>视频显示运动方向 <code>ffplay -flags2 +export_mvs  -vf codecview=mv=pf -i input.mp4</code></li> </ul> <p>ffplay 指定视频显示大小，当播放原始视频时如input.h264，用-video_size来指定视频大小，而非设置播放器显示大小。如果要控制播放器显示大小用 scale/resize滤镜。</p> <p>-s 选项，当用在输入选项时，可以替代video_size。当用在输出选项时，可以替代scale滤镜，但只能于filtergraph最后的filter，若想作用在filtergraph其它位置，则必须显示使用scale。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#ptsdts","level":4,"title":"时间戳 PTS/DTS","text":"<p>PTS是显示时间戳, presentation timestamp 指表示渲染的时间点，而DTS是Decode timestamp，解码时间戳，表示解码时间点。因为视频的B帧要等待下一个I帧，所以B帧会先保存在缓冲区。 在ffplay和ffmpeg 播放/转码视频时，控制台显示了tbn，tbc，tbr， 这些都是timebase，也叫时间精度。每次处理后当前的时间戳会增加一个timebase。 * tbn: timebase of AVstream, 表示从容器中读取的timestamp的增加一次timebase。  * tbc: timebase of codec, 表示某个流的对应的编码采用的时间基，每次解码都增加一次timebase。 50tbc时，1S有50帧。 * tbr: 一帧的timebase，是预估值。 </p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#ffprobe","level":3,"title":"ffprobe 查看媒体文件信息","text":"<p>视频分析软件除了ffprobe还有 mp4info。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_8","level":3,"title":"直播","text":"<p>视频直播技术里， HLS和DASH等分片技术比较流行。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#rtp","level":3,"title":"rtp流","text":"<p>rtp是通信语音行业的常用协议，可以发送视频和语音之一，不可以同时发送视频和语音，语音也只支持单通道（对于PCM类型的语言而言，而rtp支持OPUS发送多通道）。rtp有多流同步机制，接收终端可以将多个rtp流合并，支持类似webrtc的会议模式，rtp也能支持5G的视频通话。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#rtpsdp","level":4,"title":"rtp的sdp","text":"<p>在建立rtp连接之前，两个终端要协商一个两边都支持的视频和语音编码，否则无法建立。 sdp则描述了ip/端口/媒体编码相关的信息，这些不能通过rtp协议来传送（in-band）。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#clockrate","level":4,"title":"clockrate 时钟频率","text":"<p>sdp中的a属性有clok</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#ffmpegrtp","level":3,"title":"ffmpeg发送接收rtp","text":"<p>rtp对于ffmpeg而言是一种容器，与其它的mp4/avi类似，代码实现也同样在libavformat里。只是不同在于前着是写文件，rtp容器则是发送网络包。例如读取mp4文件并发送音频的命令<code>ffmpeg -i input.mp4 -vn -ac 1 -f rtp rtp://ip:port</code>，<code>-vn</code>表示不发送视频，<code>-ac 1</code>表示合并音频多通道为单通道。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_9","level":2,"title":"常见分辨率","text":"<p>640x480（480p）分辨率比4:3 1280x720（720p HD） 1920x1080(1080p FHD） 3840x2160(4k UHD)</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#h264","level":2,"title":"h264","text":"<p>I/P/B 三种类型的帧: * I帧, Index frame, 是完整的一幅图片，不依赖其它帧就能解码显示。 * P帧, Delta frame, 是向前帧，依赖I帧来解码。只有运动的对象，而没有背景信息。 * B帧， Bidirectional pridict picture, B帧则依赖P帧和下一个I帧来解码<code>I-&gt;P-&gt;B-&gt;I</code>，最节省字节。 所以视频种的B帧越多，视频文件的体积越小，而解码的复杂度越高。</p> <p>ffmpeg转码h264的命令，<code>ffmpeg -i input.mp4 -av sample-rate -crf {17~23} -b:v video-bitrate -r frame-rate -profile {baseline|main|high}</code> * -av 指定sample rate采样率 * -crf 指定视频质量 * -b:v video bitrate 视频的比特率 * -b:a audio bitrate 音频的比特率 * -r frame rate 指定帧率 * -profile 指定视频的档次 * -level 指定视频等级</p> <p>使用baseline prfile时，不会包含B帧，当使用实时流媒体直播时，采用baseline编码相对main和high相对可靠，但加入B帧可以减小比特率。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#pi","level":3,"title":"视频格式P/I","text":"<p>p代表progressive代表逐行扫描，I代表interlaced 隔行扫描，但是一旦视频损坏时，视频几乎无法观看。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_10","level":3,"title":"音视频同步","text":"<p>音频和视频都是独立的线程处理，主要通过各自PTS来同步，但实际上音视频大部分情况是不同步的，偶尔是同步的。当音频和视频时间误差超过阈值时，就会去重同步。重同步主要是调整视频，因为人眼对视频的敏感度不如对音频的敏感度。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#ffmpegh264bpsbit-per-second","level":3,"title":"ffmpeg播放h264时，限制比特率（bps,bit per second)","text":"<p>视频的比特率分为两个码率，CBR恒定比特率，VBR波动比特率。互联网视频多为VBR。如果想用CBR，-b:v 设置编码比特率，但这里设定的平均值，不能很好控制最大和最小码率。要控制最大最小比特率，需要组合使用 -b:v，maxrate，minrate。另外还要设置buff打小<code>-bufsize</code>。例如: <pre><code>ffmpeg -i input.avi -bo 15M -minrate 0.5M -maxrate 0.5M -bufsize 1M out.mkv\n</code></pre> bufsize 说明，如果不使用bufsize，其变化范围将比我们的预期大很多。当设置bufsize很大时浮动范围比较大，设置太小时，会导致视频质量降低。最合适的大小时-b:v的大小一半，然后逐渐增加bufsize，直到bitrate变化比较明显时，这是质量最高而且比较恒定的大小。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_11","level":3,"title":"通过比特率来计算文件大小：","text":"<p>视频大小 = 比特率 * time_in_second / 8 未压缩音频大小 = 采样率 * 采样深度 * channel数 * time_in_second / 8 压缩音频文件大小 = 比特率 * time_in_second /8</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_12","level":3,"title":"图片","text":"<p>alpha 通道是RGB通道外的一个通道，用来表示像素的透明度，是另一个维度。 * 当使用16bit的位图时，对于每个像素5bit表示红，5bite表示绿，5表示蓝，最后一个bit表示alpha。所以这时只有1/0选择，所以只有透明和不透明的。 * 当使用32bit的位图时，8bit来表示alpha通道，就有0～255个值表示不同程度的透明。而alpha的值不直接表示透明度而是通过与RGB三个通道的值相乘，这样得道了显示的值。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#outline","level":4,"title":"高频洗劫低频轮廓 outline","text":"<p>在傅里叶边换中，用不同频率相位的正弦波，可以模拟出各种类型的信号。其中高频信号越高，还原效果越好。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#avframe-avpacket","level":4,"title":"Avframe 存储一帧解码后的像素数据，Avpacket 存储一帧压缩的数据。","text":"","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#pcm","level":3,"title":"音频pcm","text":"<ul> <li>采样：是将音频模拟信号定时取值，得到一个离散序列。为了能将离散序列恢复成为模拟信号供播放器播放，采样频率要是声音频率的至少两倍。所以若要采样1k频率的声音，需要用2k采样率。</li> <li>采样深度：单个采样的储存长度。</li> <li>音频帧：单位时间里的多个采样。</li> </ul>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_13","level":2,"title":"数学","text":"","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#difference-equation-differential-equation","level":3,"title":"差分和微分 difference equation / differential equation","text":"<p>差分是离散，各个连续项之间不存在其它元素。例如1,2,3,4,5 不存在1.1,1.2,1.3。而微分是连续的，1和2之间可以有1.1,1.11,1.12,1.2等。总结是差分是微分的离散化。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"notes/#_14","level":3,"title":"信号和系统","text":"<p>离散傅里叶边换 DFT discret fourier transform，傅里叶变换出来的结果是复数=X+YI，I^2=-1。 谐波是什么，为何傅里叶变换要复数，因为表示波的方法要用到频率和相位还有振幅。  复数模等于振幅 <code>e^(jwb) = cos(wb) + isin(wb)</code></p> <p>波的表示方法： y=Asin(B(x+C)), A振幅，B频率，C相位。</p>","path":["Notes"],"tags":["ffmpeg"]},{"location":"oauth2/","level":1,"title":"oauth2 认证说明","text":"<p>oauth2 是依赖第三方的认证方式， 例如玩游戏的时候弹出QQ登录，微信登录。 这种游戏运营商并不需要用户注册，而是直接从QQ或者微信那里获取用户的OPENID， 然后游戏游戏运营商存储并通过OPENID来识别用户</p> <p>而且， 有资质的游戏运营商还可以通过玩家的openid来获取用户的信息， 例如用户的手机号，网名，年龄等信息。 但<code>有资质</code>这个是有QQ和微信来决定的，游戏运营商需要先去腾讯那里注册认证。腾讯愿意给游戏运营商分享多少信息是腾讯说了算。 所以有用户的数据在手， 腾讯稳稳当国内老大</p> <p>以QQ登录为例，当玩家登录游戏时，游戏运营商先让用户访问QQ的auth2服务器，并带上游戏运营商的id。待QQ认证后会回调运营商注册的回调接口 一般为<code>oauth/callback</code>，并且带上用户的openid。 这样游戏运营商就知道是谁登录了。</p> <p>如果游戏运营商需要更多用户资料时，例如注册， 运营商可以通过QQ的查询接口，密钥以及用户的openid 去查询。 这样就拉取到了用户的信息。 然后如果资料不全， 再让玩家补充，例如输入身份证号。这应该国家不准腾讯向别人分享的，必须要用户自己输入。。</p>","path":["oauth2 认证说明"],"tags":["tool"]},{"location":"oauth2/#githuboauth","level":2,"title":"使用github的oauth认证","text":"<ol> <li> <p>先去github -&gt; developer 创建oauth应用， 输入自己的回调地址。 当用户被github认证后，会调用这个地址</p> </li> <li> <p>在服务端配置，利用一个开源 <code>oauth2_proxy</code>工具, 项目地址：</p> </li> </ol> <pre><code>https://github.com/oauth2-proxy/oauth2-proxy\n</code></pre> <ol> <li>配置nginx</li> </ol>","path":["oauth2 认证说明"],"tags":["tool"]},{"location":"oauth2/#oauth2_proxy","level":3,"title":"配置`oauth2_proxy","text":"<p>之前遇到问题，一直授权不成功， 原因是cookie_secure 配成了true， 即使是https下。原因未知 <pre><code>auth_logging = true\nauth_logging_format = \"{{.Client}} - {{.Username}} [{{.Timestamp}}] [{{.Status}}] {{.Message}}\"\n## pass HTTP Basic Auth, X-Forwarded-User and X-Forwarded-Email information to upstream\npass_basic_auth = true\n# pass_user_headers = true\n## pass the request Host Header to upstream\n## when disabled the upstream Host is used as the Host Header\npass_host_header = true\n## Email Domains to allow authentication for (this authorizes any email on this domain)\n## for more granular authorization use `authenticated_emails_file`\n## To authorize any email addresses use \"*\"\n# email_domains = [\n#     \"yourcompany.com\"\n# ]\nemail_domains=\"*\"\n## The OAuth Client ID, Secret\nprovider=\"github\"\nclient_id = \"cef54714c84e3b0c2248\"\nclient_secret = \"a96d3d94771273b5295202d03c0c2d3ca7f625dc\"\n## Pass OAuth Access token to upstream via \"X-Forwarded-Access-Token\"\npass_access_token = false\n## Authenticated Email Addresses File (one email per line)\n# authenticated_emails_file = \"\"\n## Htpasswd File (optional)\n## Additionally authenticate against a htpasswd file. Entries must be created with \"htpasswd -s\" for SHA encryption\n## enabling exposes a username/login signin form\n# htpasswd_file = \"\"\n## Templates\n## optional directory with custom sign_in.html and error.html\n# custom_templates_dir = \"\"\n## skip SSL checking for HTTPS requests\n# ssl_insecure_skip_verify = false\n## Cookie Settings\n## Name     - the cookie name\n## Secret   - the seed string for secure cookies; should be 16, 24, or 32 bytes\n##            for use with an AES cipher when cookie_refresh or pass_access_token\n##            is set\n## Domain   - (optional) cookie domain to force cookies to (ie: .yourcompany.com)\n## Expire   - (duration) expire timeframe for cookie\n## Refresh  - (duration) refresh the cookie when duration has elapsed after cookie was initially set.\n##            Should be less than cookie_expire; set to 0 to disable.\n##            On refresh, OAuth token is re-validated.\n##            (ie: 1h means tokens are refreshed on request 1hr+ after it was set)\n## Secure   - secure cookies are only sent by the browser of a HTTPS connection (recommended)\n## HttpOnly - httponly cookies are not readable by javascript (recommended)\n# cookie_name = \"_oauth2_proxy\"\ncookie_secret = \"beautyfly\"\ncookie_domains = \"beautyflying.cn\"\ncookie_expire = \"168h\"\n# cookie_refresh = \"\"\ncookie_secure = false\n# cookie_httponly = true\n</code></pre></p> <p>可以将oauth2 配置成服务</p> <pre><code>[Unit]\nDescription = OAuth2 proxy for www blog\n\n[Service]\nType=simple\nExecStart=/usr/bin/oauth2_proxy -config /etc/oauth2-proxy.cfg\n[Install]\nWantedBy=multi-user.target\n</code></pre>","path":["oauth2 认证说明"],"tags":["tool"]},{"location":"oauth2/#nginx","level":2,"title":"nginx 配置","text":"<pre><code>    location /oauth2/ {\n            proxy_pass       http://127.0.0.1:4180;\n            proxy_set_header Host                    $host;\n            proxy_set_header X-Real-IP               $remote_addr;\n            proxy_set_header X-Scheme                $scheme;\n            proxy_set_header X-Auth-Request-Redirect $request_uri;\n        # or, if you are handling multiple domains:\n        # proxy_set_header X-Auth-Request-Redirect $scheme://$host$request_uri;\n    }\n\n    location = /oauth2/auth {\n    proxy_pass       http://127.0.0.1:4180;\n    proxy_set_header Host             $host;\n    proxy_set_header X-Real-IP        $remote_addr;\n    proxy_set_header X-Scheme         $scheme;\n    # nginx auth_request includes headers but not body\n    proxy_set_header Content-Length   \"\";\n    proxy_pass_request_body           off;\n    }\n\n    location / {\n\n    auth_request /oauth2/auth;\n    error_page 401 = /oauth2/sign_in;\n\n    # pass information via X-User and X-Email headers to backend,\n    # requires running with --set-xauthrequest flag\n    auth_request_set $user   $upstream_http_x_auth_request_user;\n    auth_request_set $email  $upstream_http_x_auth_request_email;\n    proxy_set_header X-User  $user;\n    proxy_set_header X-Email $email;\n\n    # if you enabled --pass-access-token, this will pass the token to the backend\n    auth_request_set $token  $upstream_http_x_auth_request_access_token;\n    proxy_set_header X-Access-Token $token;\n\n    # if you enabled --cookie-refresh, this is needed for it to work with auth_request\n    auth_request_set $auth_cookie $upstream_http_set_cookie;\n    add_header Set-Cookie $auth_cookie;\n\n    # When using the --set-authorization-header flag, some provider's cookies can exceed the 4kb\n    # limit and so the OAuth2 Proxy splits these into multiple parts.\n    # Nginx normally only copies the first `Set-Cookie` header from the auth_request to the response,\n    # so if your cookies are larger than 4kb, you will need to extract additional cookies manually.\n    auth_request_set $auth_cookie_name_upstream_1 $upstream_cookie_auth_cookie_name_1;\n\n    # Extract the Cookie attributes from the first Set-Cookie header and append them\n    # to the second part ($upstream_cookie_* variables only contain the raw cookie content)\n    if ($auth_cookie ~* \"(; .*)\") {\n        set $auth_cookie_name_0 $auth_cookie;\n        set $auth_cookie_name_1 \"auth_cookie_name_1=$auth_cookie_name_upstream_1$1\";\n    }\n\n    # Send both Set-Cookie headers now if there was a second part\n    if ($auth_cookie_name_upstream_1) {\n        add_header Set-Cookie $auth_cookie_name_0;\n        add_header Set-Cookie $auth_cookie_name_1;\n    }\n\n        root   /usr/share/nginx/html/blog;\n        index  index.html index.htm;\n    }\n\n    #error_page  404              /404.html;\n\n    # redirect server error pages to the static page /50x.html\n    #\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n        root   /usr/share/nginx/html;\n    }\n</code></pre>","path":["oauth2 认证说明"],"tags":["tool"]},{"location":"oauth2/#baidu-oauth","level":2,"title":"使用baidu 的oauth 认证","text":"","path":["oauth2 认证说明"],"tags":["tool"]},{"location":"optarg-in-gdb/","level":1,"title":"gdb中打印optarg永远是0x0, 但是依然能传递参数","text":"","path":["gdb中打印optarg永远是0x0, 但是依然能传递参数"],"tags":["gdb"]},{"location":"optarg-in-gdb/#optarg","level":2,"title":"发现两个optarg不相同","text":"<pre><code>(gdb) p &amp;optarg\n$7 = (char **) 0x7ffff7fa5840 &lt;optarg&gt;\n(gdb) x/1gx &amp;optarg\n0x7ffff7fa5840 &lt;optarg&gt;:        0x0000000000000000\n(gdb) x/1gx $rip+7+0x2edf    // from disassembly of what *actually* gets passed to printf\n0x555555558040 &lt;optarg@GLIBC_2.2.5&gt;:    0x00007fffffffdf32\n</code></pre>","path":["gdb中打印optarg永远是0x0, 但是依然能传递参数"],"tags":["gdb"]},{"location":"package-problem/","level":1,"title":"背包问题","text":"<p>有一个承重为V的背包，有N个物品，重量分别为Cost[i], 价值分别为Value[i], 问选择放哪些物品时包的价值最大</p>","path":["背包问题"],"tags":["算法","dp"]},{"location":"package-problem/#_2","level":2,"title":"状态方程","text":"<p>解决动态编程的关键是找到状态方程，如下。 解决背包问题就是比较<code>放</code>与<code>不放</code>哪个价值高 <pre><code>F [i, v] ← max{F [i − 1, v], F [i − 1, v − Ci] + Wi}\n</code></pre></p>","path":["背包问题"],"tags":["算法","dp"]},{"location":"package-problem/#01","level":2,"title":"01背包","text":"<p>要求物品最大为1个, 这里有几个版本</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;sys/param.h&gt;\n\nconst int V = 4, N = 3;\nconst int cost[N] = {1, 3, 4};\nconst int value[N] = {15, 20, 30};\n\n// const int V = 10, N = 5;\n// const int cost[N] = {2, 3, 5, 2, 4};\n// const int value[N] = {2, 2, 1, 1, 2};\n\nvoid O1Package_N() {\n  int dp[N][V + 1];\n\n  // 0容量的价值为0, 合法\n  for (int i = 0; i &lt;= V; i++) {\n    dp[0][i] = 0;\n  }\n\n  // 初始化当包承重大于物品0重量的情况\n  for (int j = cost[0]; j &lt;= V; j++) {\n    // 当只装物品0时，包的价值就是物品0的价值\n    dp[0][j] = value[0];\n  }\n\n  // 先遍历物品，后遍历重量\n  for (int i = 1; i &lt; N; i++) {\n    for (int v = 0; v &lt;= V; v++) {\n      // F [i, v] ← max{F [i − 1, v], F [i − 1, v − Ci] + Wi}\n      // F[i][v] = MAX(F[i - 1][v], F[i - 1][v - cost[i]] + value[i]);\n      int bufang = dp[i - 1][v];\n      dp[i][v] = bufang;\n      if (v &gt;= cost[i]) {\n        int fang = dp[i - 1][v - cost[i]] + value[i];\n        dp[i][v] = MAX(bufang, fang);\n      }\n    }\n  }\n\n  for (int i = 0; i &lt; N; i++) {\n    for (int j = 0; j &lt;= V; j++) {\n      printf(\"%d\\t\", dp[i][j]);\n    }\n    printf(\"\\n\");\n  }\n  printf(\"%d\\n\", dp[N - 1][V]);\n}\n\nvoid O1Package_N_plus_1() {\n\n  int dp[N + 1][V + 1];\n\n  // 使用0个物品的价值为0\n  for (int i = 0; i &lt;= V; i++) {\n    dp[0][i] = 0;\n  }\n\n  // 先遍历物品，后遍历重量\n  for (int i = 1; i &lt;= N; i++) {\n    for (int v = 0; v &lt;= V; v++) {\n      dp[i][v] = dp[i - 1][v]; //当重量不够装i时，价值为装i-1的价值,\n                               //此步骤以备i+1时使用（下一个i循环）\n      if (v &gt;= cost[i - 1]) {\n        dp[i][v] = MAX(dp[i - 1][v], dp[i - 1][v - cost[i - 1]] + value[i - 1]);\n      }\n    }\n  }\n\n  for (int i = 0; i &lt;= N; i++) {\n    for (int j = 0; j &lt;= V; j++) {\n      printf(\"%d\\t\", dp[i][j]);\n    }\n    printf(\"\\n\");\n  }\n  printf(\"%d\\n\", dp[N][V]);\n}\n\nvoid O1Package_N_plus_1_origin() {\n\n  int dp[N + 1][V + 1];\n\n  // 使用0个物品的价值为0\n  for (int i = 0; i &lt;= V; i++) {\n    dp[0][i] = 0;\n  }\n\n  // 先遍历物品，后遍历重量\n  for (int i = 0; i &lt; N; i++) {\n    for (int v = 0; v &lt;= V; v++) {\n      // 1. 当物品大于承重，物品不会放到背包，价值等于不放此物品时的情况\n      // 即使物品小于承重，说明物品会放到背包。提前多赋值一次也是允许的\n      dp[i + 1][v] = dp[i][v];\n      if (v &gt;= cost[i]) {\n        dp[i + 1][v] = MAX(dp[i][v], dp[i][v - cost[i]] + value[i]);\n      }\n    }\n  }\n\n  for (int i = 0; i &lt;= N; i++) {\n    for (int j = 0; j &lt;= V; j++) {\n      printf(\"%d\\t\", dp[i][j]);\n    }\n    printf(\"\\n\");\n  }\n  printf(\"%d\\n\", dp[N][V]);\n}\n\nvoid O1Package_one_array_n() {\n\n  int dp[V + 1];\n\n  // 使用0个物品的价值为0\n  for (int i = 0; i &lt;= V; i++) {\n    dp[i] = 0;\n  }\n\n  // 先遍历物品，后遍历重量\n  for (int i = N - 1; i &gt;= 0; i--) {\n    for (int v = V; v &gt;= cost[i]; v--) {\n      int bufang = dp[v];\n      int fang = dp[v - cost[i]] + value[i];\n      dp[v] = MAX(bufang, fang);\n    }\n  }\n\n  for (int j = 0; j &lt;= V; j++) {\n    printf(\"%d\\t\", dp[j]);\n  }\n  printf(\"\\n\");\n  printf(\"%d\\n\", dp[V]);\n}\n</code></pre>","path":["背包问题"],"tags":["算法","dp"]},{"location":"package-problem/#_3","level":2,"title":"完全背包","text":"<p>要求物品可以取无限个，但由于包的承重为V,所以每种物品最大数量为 V/cost[i] <pre><code>void CompletePackage_use_n() {\n\n  int dp[N][V + 1];\n\n  // 0容量的价值为0, 合法\n  for (int i = 0; i &lt; cost[0]; i++) {\n    dp[0][i] = 0;\n  }\n\n  // 初始化当包承重大于物品0重量的情况\n  for (int i = cost[0]; i &lt;= V; i++) {\n    // 当只装物品0时，包的价值就是物品0的价值\n    dp[0][i] = i / cost[0] * value[0];\n  }\n\n  // 先遍历物品，后遍历重量\n  for (int i = 1; i &lt; N; i++) {\n    for (int v = 0; v &lt;= V; v++) {\n      dp[i][v] = dp[i - 1][v]; //当重量不够装i时，价值为装i-1的价值,\n                               //此步骤以备i+1时使用（下一个i循环）\n      for (int k = 1; k &lt;= v / cost[i]; k++) {\n        dp[i][v] = MAX(dp[i - 1][v], dp[i - 1][v - k * cost[i]] + k * value[i]);\n      }\n    }\n  }\n\n  for (int i = 0; i &lt; N; i++) {\n    for (int j = 0; j &lt;= V; j++) {\n      printf(\"%d\\t\", dp[i][j]);\n    }\n    printf(\"\\n\");\n  }\n  printf(\"%d\\n\", dp[N - 1][V]);\n}\n\nvoid CompletePackage_use_n_plus_1() {\n\n  int dp[N + 1][V + 1];\n\n  // 0容量的价值为0, 合法\n  for (int i = 0; i &lt;= V; i++) {\n    dp[0][i] = 0;\n  }\n\n  // 先遍历物品，后遍历重量\n  for (int i = 1; i &lt;= N; i++) {\n    for (int v = 0; v &lt;= V; v++) {\n      dp[i][v] = dp[i - 1][v]; //当重量不够装i时，价值为装i-1的价值,\n                               //此步骤以备i+1时使用（下一个i循环）\n      for (int k = 1; k &lt;= v / cost[i-1]; k++) {\n        dp[i][v] = MAX(dp[i - 1][v], dp[i - 1][v - k * cost[i-1]] + k * value[i-1]);\n      }\n    }\n  }\n\n  for (int i = 0; i &lt;= N; i++) {\n    for (int j = 0; j &lt;= V; j++) {\n      printf(\"%d\\t\", dp[i][j]);\n    }\n    printf(\"\\n\");\n  }\n  printf(\"%d\\n\", dp[N][V]);\n}\n\nvoid CompletePackage_use_one_array_no_reverse_V() {\n\n  int dp[V + 1];\n\n  // 0容量的价值为0, 合法\n  for (int i = 0; i &lt;= V; i++) {\n    dp[i] = 0;\n  }\n\n  // 先遍历物品，后遍历重量\n  for (int i = 1; i &lt;= N; i++) {\n    for (int v = 0; v &lt;= V; v++) {\n      for (int k = 1; k &lt;= v / cost[i-1]; k++) {\n        dp[v] = MAX(dp[v], dp[v - k * cost[i-1]] + k * value[i-1]);\n      }\n    }\n  }\n\n  for (int j = 0; j &lt;= V; j++) {\n    printf(\"%d\\t\", dp[j]);\n  }\n  printf(\"\\n\");\n  printf(\"%d\\n\", dp[V]);\n}\n\nvoid CompletePackage_use_one_array_reverse_V() {\n\n  int dp[V + 1];\n\n  // 0容量的价值为0, 合法\n  for (int i = 0; i &lt;= V; i++) {\n    dp[i] = 0;\n  }\n\n  // 先遍历物品，后遍历重量\n  for (int i = 1; i &lt;= N; i++) {\n    for (int v = V; v &lt;= cost[i-1]; v--) {\n      for (int k = 1; k &lt;= v / cost[i-1]; k++) {\n        dp[v] = MAX(dp[v], dp[v - k * cost[i-1]] + k * value[i-1]);\n      }\n    }\n  }\n\n  for (int j = 0; j &lt;= V; j++) {\n    printf(\"%d\\t\", dp[j]);\n  }\n  printf(\"\\n\");\n  printf(\"%d\\n\", dp[V]);\n}\n</code></pre></p>","path":["背包问题"],"tags":["算法","dp"]},{"location":"package-problem/#_4","level":2,"title":"多重背包","text":"<p>多重背包规定了每个物品的最大数量cap[i], 但由于要考虑背包承重，所以真正可以容纳物品的最大个数是max（cap[i], V/cost[i])</p>","path":["背包问题"],"tags":["算法","dp"]},{"location":"package-problem/#_5","level":2,"title":"疑问","text":"","path":["背包问题"],"tags":["算法","dp"]},{"location":"package-problem/#_6","level":3,"title":"为何不需要将背包排序， 比如按重量排序或按价值排序，再将重量下而价值高的物品优先计算？","text":"<p>即使没有排序，由于第二层循环都是从<code>0-&gt;V</code>遍历和放物品i与不放物品i比较，所以顺序不重要 <pre><code>  for (int i = 1; i &lt; N; i++) {\n    for (int v = 0; v &lt;= V; v++) {\n      int bufang = dp[i - 1][v];\n      dp[i][v] = bufang;\n      if (v &gt;= cost[i]) {\n        int fang = dp[i - 1][v - cost[i]] + value[i];\n        dp[i][v] = MAX(bufang, fang);\n      }\n    }\n  }\n</code></pre></p>","path":["背包问题"],"tags":["算法","dp"]},{"location":"package-problem/#_7","level":3,"title":"算法复杂度和优化","text":"<p>矩阵数组的时间复杂度为O(V*N),即两层for循环；空间复杂度为O(V*N) 即申请一个矩形数组，经过一元数组优化后，空间复杂度变为O(V) 除此之外， 大多情况下，通过两层遍历，可以只保留重量相同且价值最大的那个物品，这个操作的时间复杂度为O(N^2), 但当最糟糕的情况，即精心设计的物品没有相同重量或者相同价值的情况则此优化无效 另外，先加物品重量大于背包重量的物品忽略，可以加快速度</p>","path":["背包问题"],"tags":["算法","dp"]},{"location":"package-problem/#_8","level":3,"title":"理解优化","text":"<p>无论是用矩阵数组还是优化成一元数组，最好的理解方式是单步调试一遍</p>","path":["背包问题"],"tags":["算法","dp"]},{"location":"package-problem/#nn1","level":3,"title":"N行与N+1行","text":"<p>两种方式可以通用，只是当N行时，需要提前初始化物品0的情况</p>","path":["背包问题"],"tags":["算法","dp"]},{"location":"package-problem/#_9","level":3,"title":"初始化问题","text":"<p>我们看到的求最优解的背包问题题目中，事实上有两种不太相同的问法。有的题目要求“恰好装满背包”时的最优解，有的题目则并没有要求必须把背包装满。一种区别这两种问法的实现方法是在初始化的时候有所不同。</p> <p>如果是第一种问法，要求恰好装满背包，那么在初始化时除了 F[0] 为 0，其它F[1..V ] 均设为 −∞，这样就可以保证最终得到的 F[V ] 是一种恰好装满背包的最优解。 如果并没有要求必须把背包装满，而是只希望价格尽量大，初始化时应该将 F[0..V ]全部设为 0。</p> <p>这是为什么呢？可以这样理解：初始化的 F 数组事实上就是在没有任何物品可以放入背包时的合法状态。如果要求背包恰好装满，那么此时只有容量为 0 的背包可以在什么也不装且价值为 0 的情况下被“恰好装满”，其它容量的背包均没有合法的解，属于未定义的状态，应该被赋值为 -∞ 了。如果背包并非必须被装满，那么任何容量的背包都有一个合法解“什么都不装”，这个解的价值为 0，所以初始时状态的值也就全部为 0了。</p>","path":["背包问题"],"tags":["算法","dp"]},{"location":"package-problem/#_10","level":2,"title":"贪心算法","text":"<p>由于背包问题里的物品具备**重量**和**价值**两个维度，所以无法用贪心算法解决。而当维度为1的时候，可以用贪心算法，例如<sub>~零钱问题</sub>~和会议安排问题，因为不同零钱价值不同但其“重量”都为1，会议的“重量”也为1 注: leetcode上的零钱问题不能用贪心算法</p>","path":["背包问题"],"tags":["算法","dp"]},{"location":"package-problem/#_11","level":2,"title":"参考","text":"<p>《背包问题九讲》</p>","path":["背包问题"],"tags":["算法","dp"]},{"location":"passthrough/","level":1,"title":"pci passthrough","text":"<p>Linux中可以将硬件分配给虚拟机独占使用，或者给应用独占（dpdk），此时内核不负责该硬件。这涉及一系列东西（内核驱动卸载，vfio, iommu等）</p>","path":["pci passthrough"],"tags":["dpdk","pve","linux"]},{"location":"passthrough/#dpdk","level":2,"title":"dpdk","text":"<p>对于支持vfio（支持或不支持iommu）的主机，dpdk或者宿主机可以绑定vfio驱动。除此之外dpdk还支持uio。</p>","path":["pci passthrough"],"tags":["dpdk","pve","linux"]},{"location":"passthrough/#sr-iov","level":2,"title":"sr-iov 基于硬件虚拟化","text":"<p>绑定vfio-pci驱动后，可以支持一些硬件offload功能</p>","path":["pci passthrough"],"tags":["dpdk","pve","linux"]},{"location":"passthrough/#iommu-dma","level":2,"title":"IOMMU 是 DMA 的进化","text":"<p>当CPU要读取外设的数据时，发内存传输指令，由DMA执行，此时cpu可以做别的事情。而DMA是直接内存映射，需要连续的空间来支持大块的内存，而IOMMU则不需要，而且还能支持申请比系统寻址能力更大的内存，（例如32位只能支持4G， IOMMU能支持4G以上）。 但IOMMU需要硬件支持的功能，intel vt-d 和 amd amd-vi支持iommu，但arm不支持。</p> <p></p>","path":["pci passthrough"],"tags":["dpdk","pve","linux"]},{"location":"passthrough/#reference","level":2,"title":"reference","text":"<p>https://pve.proxmox.com/wiki/PCI(e)_Passthrough https://doc.dpdk.org/guides/linux_gsg/linux_drivers.html#vfio-noiommu https://en.wikipedia.org/wiki/Input%E2%80%93output_memory_management_unit</p>","path":["pci passthrough"],"tags":["dpdk","pve","linux"]},{"location":"pessimistic-lock-optimistic-lock/","level":1,"title":"乐观锁悲观锁","text":"<p>先说这两种锁都不是编程里面用到的锁， 而是一种策略。 在数据库中用的多。 而且在java里面有个原子bool AtomicBoolean 的实现也用到乐观锁的策略， <code>AtomicBoolean::compareandswap</code> </p> <p>这里以数据库管理服务（DBMS）来说明这两种锁的区别，在并发的情况下</p>","path":["乐观锁悲观锁"],"tags":["c","cpp","lock"]},{"location":"pessimistic-lock-optimistic-lock/#_2","level":2,"title":"悲观锁","text":"<p>悲观锁策略预期是多个请求会操作同一个数据，导致数据不可靠。 悲观锁的策略就是上锁，不让其它请求修改， 即排他锁。</p> <p>这种排他锁与我们平常编程用的互斥锁道理相同， 是性能比较低的一种锁，但能保证数据准确。</p>","path":["乐观锁悲观锁"],"tags":["c","cpp","lock"]},{"location":"pessimistic-lock-optimistic-lock/#_3","level":2,"title":"乐观锁","text":"<p>乐观锁实际是不上锁， 预期多个请求不会修改同一分数据。而是在最后提交的时候再去确认数据是否一致，如果一致则提交，如果不一致则报错，需要认为干涉</p> <p>所以乐观锁的数据也是可靠的， 且性能较好。 这里关键是如何确认数据一致  </p>","path":["乐观锁悲观锁"],"tags":["c","cpp","lock"]},{"location":"pessimistic-lock-optimistic-lock/#_4","level":2,"title":"乐观锁的确认并提交","text":"<p>这里举例sql的来说明 </p> <p><pre><code>select quanity from items where id =1;\n\n//得到quanity=3，然后更新\n\nupdate items set quantity=2 where id=2 and quantity=3\n</code></pre> 更新时，会确认quantity为预期的3，否则不执行或者报错。</p> <p>这样有个问题， 虽然单条语句是原子的，但是两条语句不是， 会出现ABA的情况</p> <p>例如当一个请求1执行到select后，得知<code>quantity=3</code>， 然后请求2先更新quantity=2，然后又更新为quantity=3  然后请求1继续执行update，这会成功，虽然quantity=3是一致的，但是不能保证其它数据是一致的或者完全没有引起安全问题</p> <p>因此另一种办法是判断只增version或者timestamp，每次请求时去更新。这两种办法都能确保数据一致。 但是因为数据库同时只允许一个请求修改version，那么就出现了竞争情况，会导致其它请求失败</p> <p>例如多个请求同时记录了version=1, 则当一个请求完成的时候，version=2， 那么其它请求提交时发现verison变了，只能报告失败 虽然这样能保证数据正确，但是会导致其它请求失败</p> <p>而电商平台中， 则采用另一种方式确认</p> <pre><code>select quanity from items where id =1;\n\n//得到quanity=3，然后更新\n\nupdate items set quantity=2 where id=2 and quantity &gt; 0\n</code></pre> <p>这样就规避了上面两个方法的缺点</p>","path":["乐观锁悲观锁"],"tags":["c","cpp","lock"]},{"location":"pessimistic-lock-optimistic-lock/#compareandswap","level":2,"title":"compareandswap","text":"<pre><code>compareAndSet(expect_val, new_val)\n</code></pre> <p>上面的乐观锁就是compareandswap的解释：</p> <p>先对比，如果一致则更新</p> <p>再说一下java的实现, <pre><code>    UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x))  \n      UnsafeWrapper(\"Unsafe_CompareAndSwapInt\");  \n      oop p = JNIHandles::resolve(obj);  \n      jint* addr = (jint *) index_oop_from_field_offset_long(p, offset);  \n      return (jint)(Atomic::cmpxchg(x, addr, e)) == e;  \n    UNSAFE_END  \n</code></pre></p> <p>在unsafe.cpp 找到实现如下</p> <p><pre><code>#define LOCK_IF_MP(mp) __asm cmp mp, 0 \\\n__asm je L0 \\\n__asm _emit 0xF0 \\\n__asm L0:\n\nint mp = os::is_MP();\n__asm {\nmov edx, dest\nmov ecx, exchange_value\nmov eax, compare_value\nLOCK_IF_MP(mp)\ncmpxchg dword ptr [edx], ecx\n}\n</code></pre> _emit 是用于生成指令的， 生成锁的指令，有cpu提供锁机制 从上下文看， 这个指令应该是上锁， 如果mp != 0 则上锁。 </p>","path":["乐观锁悲观锁"],"tags":["c","cpp","lock"]},{"location":"pointer/","level":1,"title":"c语言中pointer和array的区别","text":"<p>在stackoverflow上搜到一个有趣帖子 讨论了指针解引用和数组下标访问的区别，而根本原因就是<code>指针有时不同于数组</code>，这是《c专家编程》有仔细讨论的，故再看了一遍</p>","path":["c语言中pointer和array的区别"],"tags":["c"]},{"location":"pointer/#_1","level":2,"title":"问题","text":"<p>帖子的问题可以用<code>类型不同</code>和<code>指针在extern声明时不同于数组</code>来直接了当地解释。而类型不匹配如何导致程序崩溃的呢</p> <pre><code>//file file1.c\n\nint a[2] = {800, 801};\nint b[2] = {100, 101};\n</code></pre> <pre><code>//file file2.c\n\nextern int a[2];\n\n// here b is declared as pointer,\n// although the external unit defines it as an array\nextern int *b; \n\nint main() {\n\n  int x1, x2;\n\n  x1 = a[1]; // ok\n  x2 = b[1]; // crash at runtime, segment fault\n\n  return 0;\n}\n</code></pre> <p>当声明为<code>extern 数组</code>时，编译后符号表保存了数组的地址，那么a[1]解引用只是在数组地址上加偏移量<code>a+1</code>得到新地址，然后取新地址的内容，所以数组的地址提前可知 当声明为<code>extern 指针</code>时，编译后符号表保存的是符号b，让编译器以指针的方式处理b，所以b是一个指针，其指针地址被赋值为数组的内容（101100）。在运行时，先取出b的地址为（101100）， 再加上偏移量得到新地址(101101), 最后访问这个非法地址导致崩溃</p> <p>因为当声明为<code>extern int *b</code>时，在file1中的b应该是存放一个内存地址而实际存放的是数组内容，就导致程序把数组的内容当地址访问。</p>","path":["c语言中pointer和array的区别"],"tags":["c"]},{"location":"pointer/#_2","level":2,"title":"打印指针地址","text":"<p>如果在coredump之前，先打印b的地址，得到的是b数组的值为'0x6500000064', 正好指针长度是两个int之和。所以file2中把数组内容当成了指针地址，然后偏移一个int长度后，地址是'0x6500000068', 然后这个无效地址导致段错误。 <pre><code>printf(\"%p\\n\", (void*)b);\n</code></pre></p>","path":["c语言中pointer和array的区别"],"tags":["c"]},{"location":"pointer/#_3","level":2,"title":"从汇编角度看这个问题","text":"<p>b存放的是内容，而程序以为是地址。因为实际上编译器不会为数组额外分配空间来存储指针, 但是要为指针分配空间。 <pre><code>int main() {\n    int *a = 0;\n    int b[4];\n    *b = 0;\n    // 为了显示栈大小\n    foo();\n}\n</code></pre> 从汇编代码可见，分配了32个字节的空间，指针8 + 4*4 =  <pre><code>        sub     rsp, 32\n        mov     QWORD PTR -8[rbp], 0\n        mov     DWORD PTR -32[rbp], 0\n</code></pre></p>","path":["c语言中pointer和array的区别"],"tags":["c"]},{"location":"pointer/#_4","level":2,"title":"弱符号","text":"","path":["c语言中pointer和array的区别"],"tags":["c"]},{"location":"power-and-logarithm/","level":1,"title":"指数和对数","text":"","path":["指数和对数"],"tags":["math"]},{"location":"pricious/","level":1,"title":"编程语言中小数精度问题","text":"<p>计算机使用2进制存储数据，而2进制可以表示所有的10进制整数，这样在整数范围内不存在问题，但导致小数的精度不够。</p> <p>例如表示整数时，二进制不存在问题:  |十进制|二进制| |--|--| |0| 0| |1|2^0| |2|2^1| |3|2^2 + 2^1|</p> <p>而表示小数时，二进制只能有0.5, 0.25, 0.125...。 |二进制|十进制| |--|--| |2^-1| 0.5| |2^-2|0.25| |2^-3|0.125|</p> <p>所以二进制表示10进制的小数颗粒比较大，若想表示0.6: 就要使用<code>二进制小数</code> <code>*</code> <code>2^n</code>来表示，有些数始终无法相等</p>","path":["编程语言中小数精度问题"],"tags":["c"]},{"location":"pricious/#_2","level":2,"title":"浮点型和双精度","text":"<p>计算机显然没有无穷大的位置来存储”高阶的X“，只能折衷一下。故在c/c++中，有两种类型来表示小数，对应不同精度:   内存分布，两种类型的内存分布都为: 符号位(sign)+偏移位(exponent)+尾数位(mantissa)， 其值则为 (-1)^sign * mantissa * 2^exponent</p>","path":["编程语言中小数精度问题"],"tags":["c"]},{"location":"pricious/#float","level":3,"title":"float: 浮点类型","text":"<p>占用4字节（32位），精度为10^-6, 即第7位小数开始可能四舍五入或者直接忽略</p> <p>内存分布： 第一位是符号位，后8位为偏移位，最后23位为尾数位，则有23+1位来表示小数，10^7 &lt; 2^23+1 &lt; 10^8，所以可以精确到第7位， 但最后以为可能会4四舍五入，精确到第6位</p>","path":["编程语言中小数精度问题"],"tags":["c"]},{"location":"pricious/#double","level":3,"title":"double: 双精度类型","text":"<p>占用8字节（64位），精度为10^-15, 即第16位小数开始可能四舍五入或者直接忽略</p> <p>内存分布： 第一位是符号位，后11位为偏移位，最后52位为尾数位，则有52+1位来表示小数，10^16 &lt; 2^52+1 &lt; 10^17，所以可以精确到第16位， 但最后以为可能会4四舍五入，精确到第15位</p>","path":["编程语言中小数精度问题"],"tags":["c"]},{"location":"pricious/#_3","level":2,"title":"计算问题","text":"<p>由于精度问题，精度之外的小数就会被忽略掉，导致出现下面的相等 </p> <p><pre><code>double i = 0.1;\ndouble j = 0.2;\ni+j == 0.3 + 4e-17;// 后面的数被忽略了\n</code></pre> 注意如果要使用float类型，需要显式使用'0.1f', 因为默认以double处理  </p>","path":["编程语言中小数精度问题"],"tags":["c"]},{"location":"pricious/#_4","level":2,"title":"如何比较两个浮点数","text":"<p>浮点数比较不可能100%正确，但下面都是错的 <pre><code>float a = 0.15 + 0.15\nfloat b = 0.1 + 0.2\nif(a == b) // can be false!\nif(a &gt;= b) // can also be false!\nif( Math.abs(a-b) &lt; 0.00001) // wrong - don't do this\nif( Math.abs((a-b)/b) &lt; 0.00001 ) // still not right!\n</code></pre></p> <p>下面的才是大部分正确 <pre><code>float absA = fabs(a);\nfloat absB = fabs(b);\nfloat diff = fabs(a - b);\nif (a == b) { // shortcut, handles infinities\n    return true;\n} else if (a == 0 || b == 0 || (absA + absB &lt; 1e-16)) {\n            // a or b is zero or both are extremely close to it\n            // relative error is less meaningful here\n    return diff &lt; (epsilon * Float.MIN_NORMAL);\n} else { // use relative error\n    return diff / Math.min((absA + absB), Float.MAX_VALUE) &lt; epsilon;\n}\n</code></pre></p> <p>但如果知道精度，直接将其乘以10^n变成整数来比较是最佳的方法</p>","path":["编程语言中小数精度问题"],"tags":["c"]},{"location":"pve-usage/","level":1,"title":"pve入门","text":"","path":["pve入门"],"tags":["pve"]},{"location":"pve-usage/#lxc","level":2,"title":"lxc 配置","text":"<p>pve使用lxc来运行容器而不是docker。 docker对应的“镜像”概念在pve里叫<code>模板(template)</code>，默认的pve容器模板是从官网下载，非常慢，可以替换成清华源。另外在模板列表里面的模板都是比较新的，老版本可以上清华源上找，例如centos7，然后通过url来上传，怎样都非常方便。</p>","path":["pve入门"],"tags":["pve"]},{"location":"pve-usage/#_1","level":3,"title":"容器网络问题","text":"<p>有的容器模板没有安装红帽的NetworkManger，这导致创建容器时选择的DHCP网卡配置不会生效，即使给网卡设置静态ip也不行。有个解决办法是启动后再加一个静态ip的网卡，这样容器就有网络访问权限了，然后赶紧安装NetworkManger吧。</p>","path":["pve入门"],"tags":["pve"]},{"location":"pve-usage/#console","level":3,"title":"低版本容器启动不能进入console的问题","text":"<p>如果systemd的版本低于232，启动容器时pve提示:WARN: old systemd (&lt; v232) detected, container won't run in a pure cgroupv2 environment! 也打不开控制台，只能通过在宿主机上执行 <code>pct enter id</code>来进入容器。网上有帖子说在容器里面执行软件更新后，可以恢复，也许是systemd版本更新了，但是这个方法不适用于centos7。最后只能通过修改宿主机的grub，修改启动参数: <pre><code>#/etc/default/grub\nGRUB_CMDLINE_LINUX_DEFAULT=\"systemd.unified_cgroup_hierarchy=0 quiet\"\n</code></pre> 再执行<code>update-grub</code>命令，最后重启宿主机后问题解决。</p>","path":["pve入门"],"tags":["pve"]},{"location":"pve-usage/#_2","level":3,"title":"低版本容器问题","text":"<p>pve的容器ENTERPOINT都是<code>/sbin/init</code>，跟我现在公司的管理docker方式相同。 会启动systemd，包括sshd等，对于远程访问非常方便。但是版本低的容器启动时不仅无法进入控制台，而且不会启动systemd。手动使用systemctl启动sshd时会失败，因为dbus没有启动，而启动dbus也失败。总之新版本容器就不会有这个问题，总之要配置启动参数。</p> <p>对于通过/sbin/init来启动sshd的方式值得讨论，因为通过在Dockerfile中设置<code>ENTRYPOINT service ssh restart &amp;&amp; bash</code>也可以有相同的效果。而公司的大量容器都启动systemd时，会启动udev服务，这时硬件故障，直接导致宿主机卡死。</p>","path":["pve入门"],"tags":["pve"]},{"location":"pve-usage/#map-directory-to-lxc-container","level":3,"title":"map directory to lxc container","text":"<p>pct set 110 -mp0 /srv/music,mp=/srv/music</p>","path":["pve入门"],"tags":["pve"]},{"location":"pve-usage/#_3","level":2,"title":"虚拟机配置声音","text":"<p>我安装过一个win7的虚拟机作为测试环境用，而且需要使用音频，在添加音频网卡时，使用了SPICE驱动，会导致虚拟机无法启动，必须将显示器的驱动也改成SPICE。然而我使用remmina来远程访问这个虚拟机，听不到声音。 最后将音频驱动改为None，然后remmina的advance标签卡的<code>Auido output mode</code>设置<code>Local</code>就能听到声音了，虽然声音质量不佳，不过勉强能用!</p>","path":["pve入门"],"tags":["pve"]},{"location":"pve-usage/#_4","level":2,"title":"参考","text":"<ul> <li>https://forum.proxmox.com/threads/solved-warn-old-systemd-v232-detected-container-wont-run-in-a-pure-cgroupv2-environment.114736/</li> <li>https://stackoverflow.com/questions/25135897/how-to-automatically-start-a-service-when-running-a-docker-container/32179054#32179054</li> </ul>","path":["pve入门"],"tags":["pve"]},{"location":"python-arguement-types/","level":1,"title":"python arguement types","text":"<pre><code># accept tupe and list\ndef calc(numbers):\n    sum = 0\n    for n in numbers:\n        sum = sum + n\n    print(sum)\n\ncalc([1,2])\ncalc((1,2,3))\n\n# accept varidict argument\ndef calc2(*numbers):\n    sum = 0\n    for n in numbers:\n        sum = sum + n\n    return sum\n\ncalc2(0)\ncalc2(1,2,3,4)\n\nnumbers = [1,2,3]\n# transform list to varidcit argument\nprint(calc(*numbers))\n\n\n# varidict named arguments will be transformed to dict\n\n# only accept named varidict argument\ndef person2(**kw):\n    if 'hello' in kw:\n        passs\n\n    print(kw)\n\n# accept compose argument in sequence: normal argument &amp; named varidict argument\ndef person(name, age, **kw):\n    print('name', name, 'age', age, 'other', kw)\n\nperson('mike',12)\nperson('mike',12, city='sh')\nperson('mike',12, city='sh', birth=1990)\nperson2(name='mike',age = 12, city='sh', birth=1990)\n\n# compose normal type argument, varidict type argument, and varidict named type argument \ndef f2(a, b, c=0, *d, **kw):\n    print('a =', a, 'b =', b, 'c =', c, 'd =', d, 'kw =', kw)\n\ncs=[3,4]\nf2(1,2,*cs,hello='hello')\n\n\n# use * to sepcify named type argument\ndef f3(a,b,c,*,d,e):\n    print('a =', a, 'b =', b, 'c =', c, 'd =', d, 'e =', e)\n\n# don't accept other named argument\nf3(1,2,3,d=4,e=5)\n\n# use tupe and dict can call all kind of function\n# so *arg and **kw are always used to forward all argument to another function of any type of argument\nargs = (1,2,3)\nkw = {'c':1,'d':2}\nf2(*arg, **kw)\n\n# at last, use base type for default value\n</code></pre>","path":["python arguement types"],"tags":["python"]},{"location":"python-namespace/","level":1,"title":"namespace 介绍","text":"<p>namespace是比package更高一级的组织方式，用于分解多个package 官方链接 例如， 原本我们有一个大的package: web，cmd, core, web 和 cmd 都依赖与core，但web和cmd之间没有依赖关系。 <pre><code>    project\n        __init__.py\n        web\n        cmd\n        core\n</code></pre> 所以我们可以将三者分离成3个package，同时选择project作为namespace <pre><code>   project\n        web/__init__.py\n        cmd/__init__.py\n        core/__init__.py\n</code></pre> 这样，我们可以通过分开部署的方式，只需要web时，需要web和core。需要cmd时部署cmd和core。 以达到减少交付大小</p>","path":["namespace 介绍"],"tags":["python"]},{"location":"python-namespace/#namespace-package","level":2,"title":"namespace 与 package 的区别","text":"<p>namespace 非常类似package，最大区别是namespace下没有<code>__init__.py</code> 除此之外还有区别：  </p> <ol> <li>namespace 下的包可以分布在不同的目录下。而package 必须在相同的目录</li> <li>namespace 没有__file__属性</li> <li>namespace 的__path__属性是只读的，会根据其父目录自动生成，例如从A目录换到B目录，namespace的path随之改变</li> </ol>","path":["namespace 介绍"],"tags":["python"]},{"location":"python-namespace/#namespace_1","level":2,"title":"namespace 示例","text":"<p>如下目录结构， parent 和 child 都是 namespace（因为没有<code>__init__.py</code>） <pre><code>Lib/test/namespace_pkgs\n    project1\n        parent\n            child\n                one.py\n    project2\n        parent\n            child\n                two.py\n</code></pre></p> <p>执行以下操作 <pre><code>&gt;&gt;&gt; import sys\n&gt;&gt;&gt; sys.path += ['Lib/test/namespace_pkgs/project1', 'Lib/test/namespace_pkgs/project2']\n&gt;&gt;&gt; import parent.child.one\n&gt;&gt;&gt; parent.__path__\n_NamespacePath(['Lib/test/namespace_pkgs/project1/parent', 'Lib/test/namespace_pkgs/project2/parent'])\n&gt;&gt;&gt; parent.child.__path__\n_NamespacePath(['Lib/test/namespace_pkgs/project1/parent/child', 'Lib/test/namespace_pkgs/project2/parent/child'])\n&gt;&gt;&gt; import parent.child.two\n&gt;&gt;&gt;\n</code></pre></p> <p>可见，处于不同文件夹下的parent.child 存在<code>one.py</code> <code>two.py</code>， 好像one和two在同一个目录下</p>","path":["namespace 介绍"],"tags":["python"]},{"location":"python-namespace/#namespce","level":2,"title":"namespce的发现和路径计算","text":"<p>有如下目录结构 <pre><code>Lib/test/namespace_pkgs\n    project1\n        parent\n            child\n                one.py\n    project2\n        parent\n            child\n                two.py\n    project3\n        parent\n            child\n                three.py\n</code></pre></p> <p>执行如下操作 <pre><code># add the first two parent paths to sys.path\n&gt;&gt;&gt; import sys\n&gt;&gt;&gt; sys.path += ['Lib/test/namespace_pkgs/project1', 'Lib/test/namespace_pkgs/project2']\n\n# parent.child.one can be imported, because project1 was added to sys.path:\n&gt;&gt;&gt; import parent.child.one\n&gt;&gt;&gt; parent.__path__\n_NamespacePath(['Lib/test/namespace_pkgs/project1/parent', 'Lib/test/namespace_pkgs/project2/parent'])\n\n# parent.child.__path__ contains project1/parent/child and project2/parent/child, but not project3/parent/child:\n&gt;&gt;&gt; parent.child.__path__\n_NamespacePath(['Lib/test/namespace_pkgs/project1/parent/child', 'Lib/test/namespace_pkgs/project2/parent/child'])\n\n# parent.child.two can be imported, because project2 was added to sys.path:\n&gt;&gt;&gt; import parent.child.two\n\n# we cannot import parent.child.three, because project3 is not in the path:\n&gt;&gt;&gt; import parent.child.three\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1286, in _find_and_load\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1250, in _find_and_load_unlocked\nImportError: No module named 'parent.child.three'\n\n# now add project3 to sys.path:\n&gt;&gt;&gt; sys.path.append('Lib/test/namespace_pkgs/project3')\n\n# and now parent.child.three can be imported:\n&gt;&gt;&gt; import parent.child.three\n\n# project3/parent has been added to parent.__path__:\n&gt;&gt;&gt; parent.__path__\n_NamespacePath(['Lib/test/namespace_pkgs/project1/parent', 'Lib/test/namespace_pkgs/project2/parent', 'Lib/test/namespace_pkgs/project3/parent'])\n\n# and project3/parent/child has been added to parent.child.__path__\n&gt;&gt;&gt; parent.child.__path__\n_NamespacePath(['Lib/test/namespace_pkgs/project1/parent/child', 'Lib/test/namespace_pkgs/project2/parent/child', 'Lib/test/namespace_pkgs/project3/parent/child'])\n&gt;&gt;&gt;\n</code></pre></p> <p>可见，将project3 加入到 sys.path 后, 系统自动更新了namespace的<code>__path__</code>， 并将新的module 载入</p>","path":["namespace 介绍"],"tags":["python"]},{"location":"python-namespace/#_1","level":1,"title":"使用","text":"<p>假设项目结构如下 <pre><code>    doc\n    src\n        namespace1\n        namespace2\n</code></pre> 我们通常将src 目录做为顶层目录，将src 追加到 <code>sys.path</code> <pre><code>sys.path.insert(0, os.path.join(\n    os.path.dirname(os.path.abspath(__file__)), 'src'))\n</code></pre> 这样，在src 目录下的namespace 就会被发现。  在import 的时候，就会到namespace下查找。如果没有这一步， 就会提示package不存在，实际上这是个namespace</p>","path":["namespace 介绍"],"tags":["python"]},{"location":"python-namespace/#btwpython","level":1,"title":"BTW，python 查找原理","text":"<p>在import foo 的时候 <pre><code>1. 找到foo/__init__.py 则会 import 整个 foo 下的所有module， 查找结束。\n2. 如果查到某个目录下存在 foo.{py,pyc,so,pyd}， 则这个module 会被导入， 查找结束\n3. 如果找到一个名为 foo的文件夹， 这个文件夹会被记下， 然后在同级目录继续查找\n   最终回到父目录，在父目录查找同级目录的其它文件夹。 \n\n   查找结束之后，没有发现1 和 2 的情况， 而且找到foo的文件夹， 这是就会创建一个foo的namespace\n   1. 这个 foo 具备`__path__`的数组，内容为所有名为foo的文件夹路径 \n   2. foo 没有 `__file__` 属性\n</code></pre> 这就很好解释了之前我们说的namespce 路径计算原理</p>","path":["namespace 介绍"],"tags":["python"]},{"location":"python-package-1/","level":1,"title":"python 安装方式有2种 pip 和 easy_install","text":"<p>easy_install 是随setuptools 附带的安装工具 pip 是后出的替 代setuptools 的工具</p>","path":["python package2"],"tags":["python"]},{"location":"python-package-1/#_1","level":2,"title":"支持情况","text":"<p>pip 支持新的sdist标准，包括whl二进制包和源码tar包，支持安装和卸载 easy_install 支持老的 Egg  格式</p>","path":["python package2"],"tags":["python"]},{"location":"python-package-1/#_2","level":2,"title":"总结一句话","text":"<p>使用pip 不要使用easy_install</p>","path":["python package2"],"tags":["python"]},{"location":"python-package-1/#platform-tags","level":2,"title":"包 Platform tags","text":"<p>linux的包的tags有好几个，向后兼容 <pre><code>manylinux1 支持 x86_64 i686\nmanylinux2010 支持 x86_64 i686\nmanylinux2014 支持 x86_64 i686 arm ppc\n</code></pre> manylinux2010 取代了 manylinux1, 而且已经EOL,  所以尽早使用manylinux2014</p>","path":["python package2"],"tags":["python"]},{"location":"python-package-1/#pip","level":2,"title":"使用pip打包","text":"<p>先生成 requirements.txt, 手动加上自己的包myapp <pre><code>pip list &gt; requirements.txt\n\n# 打包命令\npython -m pip wheel --wheel-dir=./local/wheels -r requirements.txt\n</code></pre></p> <p>查看生成的包 <pre><code>cd local/wheels\nBootstrap_Flask-1.5.1-py2.py3-none-any.whl  Flask_SQLAlchemy-2.4.4-py2.py3-none-any.whl  Jinja2-2.11.2-py2.py3-none-any.whl                SQLAlchemy-1.3.20-cp38-cp38-manylinux2010_x86_64.whl\nclick-7.1.2-py2.py3-none-any.whl            Flask_WTF-0.14.3-py2.py3-none-any.whl        MarkupSafe-1.1.1-cp38-cp38-manylinux1_x86_64.whl  Werkzeug-1.0.1-py2.py3-none-any.whl\nFlask-1.1.2-py2.py3-none-any.whl            itsdangerous-1.1.0-py2.py3-none-any.whl      myapp-0.1.dev0-py3-none-any.whl                   WTForms-2.3.3-py2.py3-none-any.whl\n</code></pre></p>","path":["python package2"],"tags":["python"]},{"location":"python-package-1/#pip_1","level":2,"title":"使用pip 安装","text":"<pre><code>python -m pip install --no-index --find-links=./local/wheels -r requirements.txt\n</code></pre>","path":["python package2"],"tags":["python"]},{"location":"python-package-1/#_3","level":2,"title":"对于外部的包，需要本地安装","text":"<p>这个通常是在ci/cd上使用， 先把所有依赖拉到本地，就可以直接从本地的repo里下载依赖，离线安装</p> <p>首先下载包的依赖，然后进行安装 <pre><code>python -m pip download --destination-directory DIR -r requirements.txt\n\npython -m pip install --no-index --find-links=DIR -r requirements.txt\n</code></pre></p>","path":["python package2"],"tags":["python"]},{"location":"python-package-1/#_4","level":2,"title":"总结","text":"<p>pip和 whell 作为新的打包和安装方式，比较简单也支持多平台CPU, 推荐</p>","path":["python package2"],"tags":["python"]},{"location":"python-package/","level":1,"title":"python 包的管理","text":"<p>python 有 sdist 和 wheel 两种方式管理包：</p> <p>sdist 是在 <code>python setup.py sdist</code>时产生的包，是一个源码压缩包，在安装时需要编译，所以环境依赖make和gcc wheel 是在<code>python setup.py  bdist_wheel</code>是产生的whl 格式包</p> <p>从命令都可以看出来sdist即source源码包， bdist 即binary二进制包  </p> <p>sdist 由distutils、setuptools 定义和依赖的编译系统， 可以运行任意的代码 wheel 包为编译和安装时提供了简单的接口，里面包含了二进制的包，可以让安装者不需要知道编译体系,依赖wheel <pre><code>pip install wheel\n</code></pre></p>","path":["python 包的管理"],"tags":["python","包管理"]},{"location":"python-package/#_1","level":2,"title":"两种包的打包命令","text":"<p>前提是环境安装了setuptools和wheel, 且编写了setup.py文件如  </p> <p><pre><code># setup.py\n\nfrom setuptools import setup,find_namespace_packages\n#import pathlib\n#import pkg_resources\n#import os\n#import sys\n\n#sys.path.insert(0, os.path.join(\n#    os.path.dirname(os.path.abspath(__file__)), 'src'))\n\n# 解析文本文件\n#with pathlib.Path('requirements.txt').open() as requirements_txt:\n#    install_requires = [str(requirement) for requirement in pkg_resources.parse_requirements(requirements_txt) ]\n\nsetup(name='myflask',\n      version='1.3',\n      install_requires=[\n            'Bootstrap-Flask==1.4',\n            'Flask==1.1.2',\n            'Flask-Login==0.5.0',\n            'SQLAlchemy==1.3.18',\n            'Werkzeug==1.0.1',\n            'WTForms==2.3.1'\n          ],\n      entry_points={\n             'console_scripts':[\n                   'myflask=wsgi:main'\n                   ]\n            },\n      package_data = {\n        '': ['*.html'],\n        '': ['*.css'],\n        '': ['*.js'],\n        '': ['static/*'],\n        '': ['templates/*'],\n      },\n      py_modules=['myflask'],\n      packages=find_namespace_packages(),\n      zip_safe=False,\n      include_package_data=True,\n      )\n</code></pre> 我这里定义了安装模块，myflask,可以被uwsgi 文件引入，方便管理， 同时也加入了很多html的静态文件， 是一个完整的网站  </p> <ol> <li> <p>生成sdist包， 在项目目录执行<code>python setup.py sdist</code>，可以在sdit目录看到tar包 <pre><code># myflask &gt; ls dist                                                                                                                                                                                                      \nmyflask-1.3.tar.gz\n</code></pre></p> </li> <li> <p>生成wheel包，在项目目录执行<code>python setup.py bdist_wheel</code>，可以在sdit目录看到whl包 <pre><code># myflask &gt; ls dist\nmyflask-1.3-py3-none-any.whl  myflask-1.3.tar.gz\n</code></pre></p> </li> </ol>","path":["python 包的管理"],"tags":["python","包管理"]},{"location":"python-package/#_2","level":2,"title":"安装","text":"<p>安装命令相同，<code>pip install myflask-1.3.tar.gz</code> <code>pip instal myflask-1.3-py3-none-any.whl</code>。但过程不同</p> <p>举例安装yarl 的源码包, 源码包需要编译，如果环境没有gcc,就会安装失败 <pre><code>Collecting yarl&lt;2.0,&gt;=1.0 (from aiohttp==3.6.2)\n  Downloading yarl-1.6.2.tar.gz (177kB)\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n    Preparing wheel metadata: started\n    Preparing wheel metadata: finished with status 'done'\n...\n\n  gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -I/opt/ha/include/python3.8 -c yarl/_quoting_c.c -o build/temp.linux-x86_64-3.8/yarl/_quoting_c.o\n  error: command 'gcc' failed with exit status 1\n  ----------------------------------------\n  ERROR: Failed building wheel for yarl\n  Running setup.py clean for yarl\nFailed to build yarl\n</code></pre></p> <p>此时，如果使用wheel包就不会出问题，但如果wheel包里面依赖了二进制文件，则需要区分cpu架构和系统了 我的myflask不依赖任何二进制文件，所以是none, 所有cpu和系统都可以安装 <pre><code>myflask-1.3-py3-none-any.whl \n</code></pre> 对于yarl不同， 在pypi.org 下载时，需要选择正确的包。或者选择源码包<code>yarl-1.6.2.tar.gz</code>来安装编译  </p> <p>当然如果让pip选择在线安装就不需要考虑， 他会自动帮你寻找对应你系统的版本</p> <pre><code>Download files\n\nDownload the file for your platform. If you're not sure which to choose, learn more about installing packages.\nFiles for yarl, version 1.6.2\nFilename, size  File type   Python version  Upload date     Hashes\nyarl-1.6.2-cp36-cp36m-macosx_10_14_x86_64.whl (128.3 kB)    Wheel   cp36    Oct 13, 2020    View\nyarl-1.6.2-cp36-cp36m-manylinux1_i686.whl (293.5 kB)    Wheel   cp36    Oct 13, 2020    View\nyarl-1.6.2-cp36-cp36m-manylinux2014_aarch64.whl (294.5 kB)  Wheel   cp36    Oct 13, 2020    View\n\n...\n\nyarl-1.6.2.tar.gz (177.5 kB)    Source  None    Oct 13, 2020    View \n</code></pre>","path":["python 包的管理"],"tags":["python","包管理"]},{"location":"python-setuptools/","level":1,"title":"setuptools 是disutils 的升级版。","text":"<p>比起 disutils 只能处理包的打包，安装。setuptools提供入口功能，意味着可以直接使用的命令</p>","path":["setuptools 是disutils 的升级版。"],"tags":["python"]},{"location":"python-setuptools/#entry_point","level":1,"title":"entry_point","text":"","path":["setuptools 是disutils 的升级版。"],"tags":["python"]},{"location":"python-setuptools/#find_name_space","level":1,"title":"支持find_name_space","text":"<p>上个文章我们说了怎么去定义namespace， 然后将了要将namespace 的父目录添加到sys.path。 但如果使用 find_name_space，可以不用指定其父目录, setuptools 会自动去找</p> <p><pre><code>setup(\n    name = \"demo\",\n    version = \"0.1\",\n    packages = find_namespace_packages(),\n)\n</code></pre> 1. 还支持筛选条件，比如默认会查找当前目录的所有包，加上筛选<code>find_namespace_packages(include=[\"namespace.*\"])</code> 这样只会搜索namespace下的包 2. 支持指定目录，例如所有的namespace都在目录project1下，那么 <pre><code>setup(\n    name = \"demo\",\n    version = \"0.1\",\n    package_dir = {\"\":\"project1\"},\n    packages = find_namespace_packages(where=\"project1\"),\n)\n</code></pre> 这样，就只会搜索project1 文件夹, </p> <p>疑问</p> <p>如何指定多个目录？</p>","path":["setuptools 是disutils 的升级版。"],"tags":["python"]},{"location":"python-wraper/","level":1,"title":"python decoder 介绍","text":"<p>python decoder（装饰器）是python的高级用法，用来拓展函数或类的功能。不过也增加初学者 阅读代码的难度</p> <p>例如flask可以在需要验证用户登录的请求函数上添加装饰器，只有当用户登录了才可以调用该&gt;页面，非常方便</p>","path":["python decoder 介绍"],"tags":["python"]},{"location":"python-wraper/#_1","level":2,"title":"原理","text":"<p>decoder 其实也是一个函数，装饰器函数会返回真实函数，并会增加额外的代码，如</p> <p><pre><code># 定义wraper\ndef log(func):\n    def wrapper(*arg):\n        print('func called')\n        return func(*arg)\n\n    return wrapper\n\n# 使用\ndef hello(Name=None):\n    print('Hello %s'%Name)\n\nnew_hello = log(hello)\n\nnew_hello('bob')\n</code></pre> 输出 func called Hello bob</p>","path":["python decoder 介绍"],"tags":["python"]},{"location":"python-wraper/#wraper","level":2,"title":"使用wraper 的原因","text":"<p>提供额外的功能，例如计时，日志等。 另外wraper还有更多强大的功能</p> <pre><code>def fib(n):\n    if n &lt;= 1: return 1\n    return fib(n-1) + fib(n-2)\n</code></pre> <p>这种递归调用非常费时，而使用wraper 可以提供一个缓存器</p> <p><pre><code>def memory(func):\n    cache = {}\n    def wrapper(*args):\n        if args not in cache:\n            cache[args] = func(*args)\n        return cache[args]\n    return wrapper\n\n@memory\ndef fib(n):\n    if n &lt;= 1: return 1\n    return fib(n-1) + fib(n-2)\n\n\n## 给类wraper\n\n上面是函数wraper， 类也可以作为wraper， 但需要类支持（）调用，类似c++的类函数。\n在python里需要实现 `__call__` 方法\n\n```python\nimport functools\n\nclass MemoryClass():\n    def __init__(self, is_logging, func):\n        self.is_logging = is_logging\n        self.func = func\n        if self.is_logging:\n            print('logging')\n        self.cache = {}\n\n    def __call__(self, *args):\n        if args not in self.cache:\n            self.cache[args] = self.func(*args)\n\n        return self.cache[args]\n\ndef memory(is_logging):\n    return functools.partitial(MemoryClass, is_logging)\n\n\n@memory(is_loging=True)\ndef fib(n):\n    if n &lt;= 1: return 1\n    return fib(n-1) + fib(n-2)\n\n\nprint(fib(5))\n</code></pre> 类wrapr 可以增加参数，相比函数装饰器，类装饰器具有更加灵活，封装性更好等优点~</p>","path":["python decoder 介绍"],"tags":["python"]},{"location":"python-wraper/#wraper_1","level":2,"title":"wraper 带来的问题","text":"<ol> <li>改变原来的函数属性，例如函数名， 因为装饰器用新函数替换了原来的旧函数。 所以新函&gt;数少了旧函数的属性 解决办法</li> </ol> <pre><code>import functools\n\ndef advertising(func):\n    @functools.wraps(func)\n    def wrapper(*args):\n        print('欢迎关注微信公众号: Charles的皮卡丘')\n        return func(*args)\n    return wrapper\n\n@advertising\ndef add_1(a, b):\n    '''加法运算'''\n    return a + b\n</code></pre> <ol> <li>获取参数</li> </ol> <pre><code>import inspect\nimport functools\n\ndef check(func):\n    a = 0\n    @functools.wraps(func)\n    def wraper(*args, **kwargs):\n        a += 1\n        print(a)\n        # 在wraper里检查参数\n        getcallargs = inspect.getcallargs(func, *args, **kwargs)\n        if getcallargs.get('divisor') &lt;= 1e-6 and getcallargs.get('divisor') &gt;= -1e-6:\n            return False\n        return func(*args, **kwargs)\n\n    return wraper\n\n\n@check\ndef dowork(arg1, arg2):\n    return arg1 + arg2\n\ndowork(1,2)\n</code></pre> <p>此时会报错，a在赋值之前引用了。 需要将a声明为 <code>nonlocal</code></p>","path":["python decoder 介绍"],"tags":["python"]},{"location":"reg-match/","level":1,"title":"使用正则来校验输入合法性","text":"<p>软件加固里面经常使用的办法就是校验用户输入，例如要求名词需要是大小写或_开头， 支持包含大小写 ，中划线 -，下划线_以及点.</p> <p>那么相应的正则表到式为<code>^[a-zA-Z_][-a-zA-Z1-9_.]*$</code>，校验方法为</p> <pre><code>echo $1 | grep -q '^[a-zA-Z_][-a-zA-Z1-9_.]*$'\ntest $? -eq 0 &amp;&amp; echo \"yes\" || echo \"no\"\n</code></pre> <p>用python实现</p> <pre><code>Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; import re\n&gt;&gt;&gt; print(re.match('^[a-zA-Z_][a-zA-Z0-9\\-_.]*$', '_abcdedf.', flags=0))\n&lt;re.Match object; span=(0, 9), match='_abcdedf.'&gt;\n&gt;&gt;&gt; print(re.match('^[a-zA-Z_][a-zA-Z0-9\\-_.]*$', '._abcdedf.', flags=0))\nNone\n</code></pre>","path":["使用正则来校验输入合法性"],"tags":["tool"]},{"location":"register/","level":1,"title":"c 中 register 关键字","text":"<p>register 关键字是c/c++ 里面唯一能操作寄存器的指令，强制将数据存放在寄存器里，而不是放在堆栈里，这样读写速度最快。</p> <p>而汇编语言强大之处是能直接操作寄存器，且可以指定使用哪些寄存器。 </p> <p>通过汇编一段代码来演示register的作用  </p> <p>先是c语言代码 <pre><code>int main(){\n\n    register int i;\n\n    for(i = 0 ;i&lt;10;i++){\n        int j = i;\n    }\n\n}\n</code></pre> 对应的汇编 <pre><code>main:\n.LFB0:\n        .cfi_startproc\n        pushq   %rbp\n        .cfi_def_cfa_offset 16\n        .cfi_offset 6, -16\n        movq    %rsp, %rbp\n        .cfi_def_cfa_register 6\n        pushq   %rbx\n        .cfi_offset 3, -24\n        movl    $0, %ebx\n        jmp     .L2\n.L3:\n        movl    %ebx, -12(%rbp)\n        addl    $1, %ebx\n.L2:\n        cmpl    $9, %ebx\n        jle     .L3\n        movl    $0, %eax\n        movq    -8(%rbp), %rbx\n        leave\n        .cfi_def_cfa 7, 8\n        ret\n</code></pre></p> <p>没有register关键字的时候  <pre><code>int main(){\n\n    int i;\n\n    for(i = 0 ;i&lt;10;i++){\n        int j = i;\n    }\n\n}\n</code></pre></p> <pre><code>main:\n.LFB0:\n    .cfi_startproc\n    pushq   %rbp\n    .cfi_def_cfa_offset 16\n    .cfi_offset 6, -16\n    movq    %rsp, %rbp\n    .cfi_def_cfa_register 6\n    movl    $0, -8(%rbp)\n    jmp .L2\n.L3:\n    movl    -8(%rbp), %eax\n    movl    %eax, -4(%rbp)\n    addl    $1, -8(%rbp)\n.L2:\n    cmpl    $9, -8(%rbp)\n    jle .L3\n    movl    $0, %eax\n    popq    %rbp\n    .cfi_def_cfa 7, 8\n    ret\n</code></pre> <p>可见，当register修饰int i时， i的值存放在%ebx里，当没有register修饰时，i的值放在栈里<code>%rbp -8</code>的位置 <code>movl    %ebx, -12(%rbp)</code> 可见当register时， j的值复用了ebx的高32位。 此时的内存如下</p> <pre><code>--- 栈底\n旧的rbp 64位\n---\n旧的rbx 高32位\n---  j\n旧的rbx 低32位\n---栈顶\n</code></pre> <p>rbp表示基地址指针，指向的是函数栈的起始地址，这个起始地址只是对于当前函数而言的 rsp表示栈顶指针，指向当前的栈顶 每次函数调用时(main 函数被内核<code>_start_main__</code>调用): 1. 将调用者的函数栈基地址保存起来  2. 参数压栈, 可能由调用者压栈，可能由被调用者压栈，影响的是当前的栈顶，继而栈顶影响rbp 3. 将被调用函数当前的栈顶复制给基地址寄存器。新的rbp == rsp即当前的栈顶。相当于构造了新的函数运行环境</p>","path":["c 中 register 关键字"],"tags":["c","cpp","asm"]},{"location":"register/#rbprsp","level":2,"title":"rbp和rsp","text":"<p>实例代码，main函数中调用foo函数。 <pre><code>int foo(){\n  printf(\"hello\");\n  return 1;\n}\n\nint main(){\n  foo();\n  return 0;\n}\n</code></pre></p> <pre><code>(gdb) disassemble \nDump of assembler code for function main:\n   0x0000555555555158 &lt;+0&gt;: push   %rbp\n   0x0000555555555159 &lt;+1&gt;: mov    %rsp,%rbp\n   0x000055555555515c &lt;+4&gt;: mov    $0x0,%eax\n=&gt; 0x0000555555555161 &lt;+9&gt;: call   0x555555555139 &lt;foo&gt;\n   0x0000555555555166 &lt;+14&gt;:    mov    $0x0,%eax\n   0x000055555555516b &lt;+19&gt;:    pop    %rbp\n   0x000055555555516c &lt;+20&gt;:    ret\n</code></pre> <ol> <li>main 函数&gt; <code>push %rbp</code> 将栈底寄存器的值保存到堆栈中</li> <li>main 函数&gt; <code>mov %rsp,%rbp</code> 将当前的栈顶寄存器的值复制到栈底寄存器</li> <li>main 函数&gt; <code>mov $0x0,%eax</code> 将foo函数的返回值初始化成0</li> </ol> <p>进入到foo函数中 <pre><code>(gdb) disassemble \nDump of assembler code for function foo:\n   0x0000555555555139 &lt;+0&gt;: push   %rbp\n   0x000055555555513a &lt;+1&gt;: mov    %rsp,%rbp\n=&gt; 0x000055555555513d &lt;+4&gt;: lea    0xec0(%rip),%rax        # 0x555555556004\n   0x0000555555555144 &lt;+11&gt;:    mov    %rax,%rdi\n   0x0000555555555147 &lt;+14&gt;:    mov    $0x0,%eax\n   0x000055555555514c &lt;+19&gt;:    call   0x555555555030 &lt;printf@plt&gt;\n   0x0000555555555151 &lt;+24&gt;:    mov    $0x1,%eax\n   0x0000555555555156 &lt;+29&gt;:    pop    %rbp\n   0x0000555555555157 &lt;+30&gt;:    ret\nEnd of assembler dump.\n</code></pre></p> <p>附录 <pre><code>General-Purpose Registers\n\nThe 64-bit versions of the 'original' x86 registers are named:\n\n    rax - register a extended\n    rbx - register b extended\n    rcx - register c extended\n    rdx - register d extended\n    rbp - register base pointer (start of stack)\n    rsp - register stack pointer (current location in stack, growing downwards)\n    rsi - register source index (source for data copies)\n    rdi - register destination index (destination for data copies)\n\nThe registers added for 64-bit mode are named:\n\n    r8 - register 8\n    r9 - register 9\n    r10 - register 10\n    r11 - register 11\n    r12 - register 12\n    r13 - register 13\n    r14 - register 14\n    r15 - register 15\n\nThese may be accessed as:\n\n    64-bit registers using the 'r' prefix: rax, r15\n    32-bit registers using the 'e' prefix (original registers: e_x) or 'd' suffix (added registers: r__d): eax, r15d\n    16-bit registers using no prefix (original registers: _x) or a 'w' suffix (added registers: r__w): ax, r15w\n    8-bit registers using 'h' (\"high byte\" of 16 bits) suffix (original registers - bits 8-15: _h): ah, bh\n    8-bit registers using 'l' (\"low byte\" of 16 bits) suffix (original registers - bits 0-7: _l) or 'b' suffix (added registers: r__b): al, bl, r15b\n\nUsage during syscall/function call:\n\n    First six arguments are in rdi, rsi, rdx, rcx, r8d, r9d; remaining arguments are on the stack.\n    For syscalls, the syscall number is in rax.\n    Return value is in rax.\n    The called routine is expected to preserve rsp,rbp, rbx, r12, r13, r14, and r15 but may trample any other registers.\n</code></pre></p>","path":["c 中 register 关键字"],"tags":["c","cpp","asm"]},{"location":"register/#_1","level":2,"title":"参考","text":"<p>https://shikaan.github.io/assembly/x86/guide/2024/09/08/x86-64-introduction-hello.html</p>","path":["c 中 register 关键字"],"tags":["c","cpp","asm"]},{"location":"resize-windows-disk-pve/","level":1,"title":"pve中给windows扩容","text":"<p>当初创建windows时给的40G硬盘，就一个分区，后来装了一些软件，发现不够用了，就第一次扩容，然后加了另一个分区。后来有些东西必须放在C盘里，这次扩容就比较复杂些。</p>","path":["pve中给windows扩容"],"tags":["pve","vnc","gparted"]},{"location":"resize-windows-disk-pve/#_1","level":2,"title":"第一次扩容","text":"<p>pve的web界面点击硬盘的resize可以修改硬盘大小，这个硬盘实际上是一个lvm块设备，而对于虚拟机Windows而言就是硬盘变大了。</p> <p>硬盘加大后，进入windows磁盘管理，发现Windows已经有3个区：efi，C盘，恢复分区。为了方便直接加了一个D盘。</p> <p>备注：pve的虚拟机安装在块设备上，而qemu是用文件（raw or qcow2），所以qemu的虚拟机可以复制移动，不过pve支持异地部署。</p>","path":["pve中给windows扩容"],"tags":["pve","vnc","gparted"]},{"location":"resize-windows-disk-pve/#_2","level":2,"title":"第二次扩容","text":"<p>这次扩容是为了增加C盘大小，而C盘后面有恢复分区和D分区。不得不在gparted 中执行: 1. 删除D分区 2. 移动恢复分区到磁盘末尾 3. 拓展C盘大小。 gparted操作很方便，不过windows启动不成功，通过windows安装iso修复之后正常了，恢复分区也还在。</p>","path":["pve中给windows扩容"],"tags":["pve","vnc","gparted"]},{"location":"resize-windows-disk-pve/#virtual-vnc-gparted","level":2,"title":"virtual vnc 可视化打开gparted","text":"<p>因为pve没有连接显示器，只能用虚拟vnc，远程连接到pve桌面。</p>","path":["pve中给windows扩容"],"tags":["pve","vnc","gparted"]},{"location":"resize-windows-disk-pve/#tigervnc","level":2,"title":"安装tigervnc服务端","text":"<p>pve只需要安装服务端，tigervnc-standalone-server。本地电脑安装客户端，选择很多例如 remmina。</p>","path":["pve中给windows扩容"],"tags":["pve","vnc","gparted"]},{"location":"resize-windows-disk-pve/#_3","level":2,"title":"启动","text":"<p>创建密码后启动vnc 服务端失败，提示没有桌面。原因是没有安装桌面环境更没有启动桌面，好在tigervnc 支持指定可视化进程（xVNC就不支持这种方式）。 <pre><code>tigervncserver -xstartup /usr/sbin/gparted  --  /dev/dm-15\n</code></pre></p> <p>这里直接给的gparted可执行文件路径和参数，<code>--</code>表示后面的参数是给gparted的，不是给tigervncserver的，/dev/dm-15是要操作的windows磁盘，也能在gparted界面里面再选。</p>","path":["pve中给windows扩容"],"tags":["pve","vnc","gparted"]},{"location":"resize-windows-disk-pve/#remmina","level":2,"title":"remmina设置窗口大小","text":"<p>tigervncserver默认启动1024x768的窗口，当内容多时不方便。重新启动 <pre><code>tigervncserver -geometry 1920x1080 -xstartup /usr/sbin/gparted  --  /dev/dm-15\n</code></pre></p> <p>但是重新连接发现窗口还是很小，以为参数不生效。后来发现这时候窗口右下角可以拖动，手动拖成满屏</p>","path":["pve中给windows扩容"],"tags":["pve","vnc","gparted"]},{"location":"resize-windows-disk-pve/#gparted","level":2,"title":"gparted问题","text":"<p>启动gparted后出现没有光标，后面按了鼠标右键就恢复X光标了。arch wiki里面有解决办法 </p>","path":["pve中给windows扩容"],"tags":["pve","vnc","gparted"]},{"location":"rhce8-question/","level":1,"title":"记录一下rhce8上课笔记","text":"<ol> <li>进入nfs，autofs目录卡住，如何退出，应该是进入了D状态 </li> <li>chrome 需要笔记本插件，js控制插件</li> <li>修改root密码时，在linux 选项后面添加 rd.break 然后默认进入内核根目录，然后rw重新挂载系统根目录 /sysroot/ </li> <li>fdisk 设置分区类型: 在创建分区结束后，使用<code>t</code>来标记文件类型, 然后使用<code>L</code>查看类型代码，查找到Linux swap 对应的代码是85</li> </ol>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#rhcia","level":2,"title":"RHCIA","text":"","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#nmcli-connection-downup-connection","level":3,"title":"修改了网络信息之后，必须使用nmcli connection down和up connection才会生效","text":"<pre><code>nmtui connection down Wired_connection1\nnmtui connection up Wired_connection1\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#httpdportportsemanagetagjourneyctl-e","level":3,"title":"配置httpd服务时，修改port后，因为port非标准端口，需要用semanage打tag。否则失败，可以查看journeyctl -e 查看到错误信息和解决办法","text":"<pre><code>semanage port -a -t http_port_t -p tcp 82\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#homeadmins-adminusr-s-","level":3,"title":"创建/home/admins 目录，并设置在目录中创建的文件，其组所有权自动设置为 adminusr。 这里就是设置s位，有数值方法和+-法","text":"<pre><code>chmod 2770 /home/admins\n\n# 或\n\nchmod o-x /home/admins\nchmod o-r /home/admins\nchmod g+w /home/admins\nchmod g+s /home/admins # 这里设置组的s位\n</code></pre> <p>验证方法，进入目录创建文件，查看组名</p>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#autofs-etcautomasterd-autofs","level":3,"title":"autofs 挂载有两个关键，第一在/etc/auto.master.d/ 目录下创建后缀名为autofs的文件， 第二是编辑挂载配置文件","text":"<p>内容格式 <pre><code># cat /etc/auto.master.d/indirect\n#主挂载点   挂载配置\n/internal   /etc/auto.demo\n</code></pre></p> <p>内容配置，* 表示所有目录（根据nfsserver的情况）， 和&amp;搭配使用 <pre><code># cat /etc/auto.demo\n# 间接挂载目录    挂载配置    挂载路径（nfs地址）\n*   -rw,fstype=nfs4,sync    servera:/shares/indirect/&amp;\n</code></pre></p>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#setfacl-getfacl","level":3,"title":"setfacl 和getfacl 设置和显示文件属性","text":"<pre><code>设置natash用户读写权限\nsetfacl u:natasha:rw    /var/tmp/fstab\n设置harry用户没有任何权限 \nsetfacl u:harry:-   /var/tmp/fstab\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#rootlinux-rdlocal-ctrlx","level":3,"title":"重置root密码，在linux 行末追加 rd.local, 按ctrl+x 启动","text":"<p>重新挂载系统根目录, chroot到根目录和修改密码 <pre><code>mount -orw,remount /systemroot/\nchroot /systemroot/\npasswd\n</code></pre></p>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#_1","level":3,"title":"逻辑卷扩容","text":"<p>设置分区start位置的时候，输入2048s。 s指扇区，一个扇区为512字节， 2048s指1M，这1M的分区为esp分区</p> <p>扩容命令lvextrend，这个扩容只是将逻辑卷扩容， 而题目要求对文件系统扩容， 还需要执行文件系统类型对应的扩容命令如resize2fs(ext), xfs_growfs(xfs)。  但对lvextend命令添加 -r 参数可以一步到位 <pre><code># 扩容到300MB\nlvextend -r -L 300MB /dev/new_redhat/lv1\n</code></pre></p>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#-s","level":3,"title":"创建逻辑分区, 注意避免磁盘不够用，尽量共用上一题的磁盘。而且创建卷组的时候不要忘记-s参数","text":"<p>题目可能不是直接给分区大小，而是给出扩展块大小和拓展块个数，其实分区大小=拓展块大小 × 拓展块个数。 在lvcreate -l 来指定块个数 </p> <p>这时必须使用msdos分区类型才有主分区和拓展分区，而且为拓展分区分配剩余的所有空间。 最后在拓展分区上创建逻辑分区， 并将创建的逻辑分区加入卷组</p> <p>创建分区，大小通过上面的算法计算出来 <pre><code>parted \nmkpart\nprint\nexit\n</code></pre></p> <p>创建卷组 <pre><code>vgcreate -s 20MB -n npgroup /dev/vdb2\n</code></pre> 创建逻辑卷, 注意是小写l <pre><code>lvcreate -l 45 -n np npgroup\n</code></pre> 这样就创建了一个 20×45 = 900MB的逻辑卷</p>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#swapfstab","level":3,"title":"创建新的swap分区，注意需要修改fstab, 而且验证的时候，不需要重启系统，而是执行","text":"<pre><code>systemctl daemon-reload \nswapon -a  # 类似mount -a\nswapon --show \n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#vdo-vdologicalsize-5g-gb","level":3,"title":"vdo  --vdoLogicalSize 5G, 不能使用GB","text":"<p><pre><code>vdo create --name test --vdoLogicalSize 5G --device /dev/vdb\n</code></pre> <code>blkid</code> 查到 UUID, 最后添加到fstab</p>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#vdo-mount","level":3,"title":"vdo 持久挂载 mount","text":"<pre><code>default,x-systemd.requires=vdo.service\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#rhce","level":2,"title":"RHCE","text":"<p>ansible的有用命令 ansbile-doc -l | grep  查找模块和介绍 ansible-doc 模块 查看模块具体说明</p>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#inventory","level":3,"title":"创建inventory 文件， 子组的写法为","text":"<p>[webservices:children] prod</p> <p>prod 是webserverices组的子组</p>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#ansiblecfg-etcansbileansiblecfg-ansbile","level":3,"title":"创建ansible.cfg 文件，可以复制 /etc/ansbile/ansible.cfg 到～/ansbile/目录下","text":"<p>容易忘记的选项是远程登陆身份， 即配置 remote_user = devops 如果环境没有配置免密登陆，需要在[defaults] 栏添加 <code>ask_pass = True</code></p> <p>验证方法 <code>ansible all -m ping</code></p>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#ansbile-ad-hoc-yum-ansible-ansible-m-a","level":3,"title":"ansbile ad-hoc 添加yum 源  ansible 模块的使用方法 ansible 主机名 -m 模块 -a '参数'","text":"<p>脚本要添加可执行权限</p> <pre><code>#!/bin/bash\n\n# 先要切换到工作目录\ncd /home/devops/ansible/\n\nansible all -m yum-repository  -a 'name=  description=  baseurl=  enabled= gpgcheck= gpgkey= '\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#_2","level":3,"title":"安装软件包","text":"<p>安装软件包如'Development Tools', 需要在包名前面加'@'即 '@Development Tools' 验证yaml 语法格式: <code>ansible-playbook --syntax-check *.yml</code></p> <pre><code>- name: install  development tools\n  hosts: dev\n  tasks:\n    - name: install development tools\n        yum:\n          name: \"@Development Tools\"\n          state: present                  \n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#rhel-system-roles-roles","level":3,"title":"同步时间依赖角色，安装角色包'rhel-system-roles' 需要在配置文件里添加上roles路径","text":"<p>playbook 示例在/usr/share/ansibe/roles/rhel-system-roles.timesync/Readme.md 现成的yml示例在/usr/share/doc/rhel-system-roles/timesync/example-timesync-playbook.yml</p> <pre><code># ansible.cfg\n[default]\nroles_path = /home/devops/ansible/roles:/usr/share/ansible/roles\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#ansible-galaxy-roles","level":3,"title":"使用ansible-galaxy 命令安装角色，安装到本地roles目录","text":"<p>yml文件很简单, 执行命令 ansible-galaxy install -r roles/requirement.yml -p roles/ -p 表示安装路径 </p> <pre><code>- name: balancer\n  file: /home/devops/ansible/files/5/haproxy.tar\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#apache","level":3,"title":"创建apache角色， 角色对应一系列的任务和模板文件","text":"<p>通过<code>ansible-galaxy init apache</code> 来初始化角色目录，修改角色目录下的tasks/mail.yml 来添加任务，任务所需的模板文件在同级目录templates下 通过<code>ansible servera -m setup</code> 来查询环境变量， 在模板文件中使用<code>ansible_facts['fqdn']</code> 来引用变量 题目说的hostname 是<code>serverc.lab.example.com</code> 对应变量是fqdn, 另外一个是ip即 ['default_ipv4']['address']</p> <p>例如，安装httpd用到yum模块， 启用httpd 用到service模块， 防火墙配置用到firewalld模块 <pre><code># home/devops/ansible/role/apache/tasks/main.yml\n\n---\n- name: install httpd\n  yum:\n    name: httpd\n    state: present\n\n- name: enable httpd\n  service:\n    name: httpd\n    state: started\n    enabled: yes\n\n- name: firewalld config\n  firewalld:\n    service: httpd\n    immediate: yes\n    permanent: yes\n    state: enabled\n\n- name: install templates\n  template:\n    src: index.html.j2\n    dest: /var/www/html/index.html \n</code></pre></p> <p>模块文件放到templates目录下 <pre><code># home/devops/ansible/role/apache/templates/index.html.j2\nWelcome to {{ ansible_facts['fqdn'] }} on {{ ansible_facts['default_ipv4']['address'] }}\n</code></pre></p> <p>最后还需要创建一个playbook, 如同其他playbook 一样执行 <pre><code># newrole.yml\n---\n- name: install new role\n  hosts: webservers\n  roles:\n    - apache\n</code></pre></p>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#balancer","level":3,"title":"执行balancer 角色, 创建一个负载均衡","text":"<p>验证： ssh到serverd 上，curl localhost, 先是访问的serverb, 然后访问的serverc</p> <pre><code>---\n- name: deploy apache on webservers\n  hosts: webservers\n  roles:\n    - apache\n\n- name: deploy balancer on balancer\n  hosts: balancers\n  roles:\n    - balancer\n\n- name: deploy phpinfo on webservers\n  hosts: webservers\n  roles:\n    - phpinfo\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#bindbalance-roletemplate","level":4,"title":"可能出现的错误，提示应该使用bind，这是由于balance role的template 错误","text":"<p>修改办法, 将listen行换行并加上bind</p> <pre><code># /home/devops/ansible/roles/balancer/templates/haproxy.cfg.j2\n\nbackend app\n  {% for host in groups.balancers %}\n-   listen {{ daemonname }} 0.0.0.0:{{ listenport }}\n+   listen {{ daemonname }} \n+   bind 0.0.0.0:{{ listenport }}\n  {% endfor %}\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#blockrescuealways-lvolwhen-play","level":3,"title":"创建逻辑卷，考验block/rescue/always, 使用lvol，<code>when</code> 和play对齐","text":"<p>使用了block/rescue/always就不需要tasks关键词</p> <pre><code>---\n- name: create a logic volume with size of 5000 and format\n  hosts: all\n  block:\n    - name: create logic volume\n      lvol:\n        vg: research\n        lv: data\n        size: 1500\n    - name: fomat data volume\n        filesystem:\n          fstype: ext4\n          dev: /dev/research/data\n  rescue:\n    - name: debug message\n      debug:\n        msg: can't create a size of 1800\n    - name: create a logical volume with size of 800 and format\n        lvol:\n          vg: research\n          lv: data\n          size: 1500\n    - name: fomat data volume\n        filesystem:\n          fstype: ext4\n          dev: /dev/research/data\n      when: ansible_facts['lvm']['vgs']['research'] is defined\n      ignore_errors: yes\n    - name: debug 2 \n        debug:\n          msg: volume group does not exist\n      when: ansible_facts['lvm']['vgs']['research'] is undefined\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#hosts-jinija-forinventory","level":3,"title":"创建hosts文件， 考验jinija 的for循环和读inventory文件","text":"<p>取facts变量的方法参考balancer的模板：  /home/ansible/roles/balancer/roles/template/haproxy.cfg.j2</p> <p>基于给的hosts.j2 文件修改, 拼凑出<code>ip url alias</code>格式，分别对应 default_ipv4.address, fqdn, hostname ansible_facts在hostvars[host]中</p> <pre><code># 取\n{% for host in groups.all %}\n{{ hostvars[host]['ansible_facts'] *忽露不写了* }} × × \n{% endfor %}\n--- \n\n创建playbook的要小心，题目要求生成所有主机的纪录，所以hosts是all, 但只部署在dev组的主机上要加when,   \n要加`when: 'dev' in group_names`\n\n```yml\n---\n- name: gen hosts and deploy on dev group\n  tasks:\n    - name: gen hosts and deploy\n        template:\n          src: hosts.j2\n          dest: /etc/myhosts\n      when: \"'dev' in group_names\"\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#web-server-setypehttpd_system_content_t","level":3,"title":"创建web server, 注意将文件标注setype为httpd_system_content_t","text":"<p>通过man semanager-fcontext 查询setype, 或者使用<code>ls -ldZ</code>来查询selinux标签</p> <p>创建文件，目录、链接都用file模块，但操作文件内容用copy模块 创建组用group模块,创建用户用user模块 容易搞反的链接的src是指向的文件，所以是/webdev, 可以看帮助文档</p> <pre><code>---\n- name: create web server\n  hosts: webservers\n  tasks:\n    - name: add group\n        group:\n           name: webdev\n           state: present\n    - name: create directory\n        file:\n          path: /webdev\n          group: webdev\n          state: directory\n          mode: u+rwx,g+rwxs,o-rx\n -        setype: httpd_system_content_t\n    - name: create a symbolic link\n        file:\n -        src: /var/www/html/webdev\n -        dest: /webdev\n +        src: /webdev\n +        dest: /var/www/html/webdev\n          state: link\n    - name: create index.html\n        copy:\n          content: Development\n          dest: /var/www/html/webdev/index.html\n+         setype: httpd_system_content_t                    \n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#loopsitem-regexslineinfile","level":3,"title":"创建硬件报告，用到loops进行数组循环，内置变量item和 regexs匹配，lineinfile 进行文件编辑","text":"<pre><code>---\n- name: generate hw report\n  hosts: all\n  vars:\n    hw_all:\n      - hw_name: HOST\n        hw_content: \"{{ ansible_facts['hostname'] }}\"\n      - hw_name: BIOS_version\n        hw_content: \"{{ ansible_facts['bios_version'] }}\"\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#ansible-vault","level":3,"title":"创建加密文件，用到ansible-vault命令","text":"<pre><code>ansible-vault encrypt lock.yml --vault-password-file=secret.txt \n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#ansible-playbook-vault-password-filesecrettxt","level":3,"title":"添加用户， ansible-playbook 通过 --vault-password-file=secret.txt 来传密码文件","text":"<p>通过<code>vars_files</code>来读取变量文件， loop 来循环遍历数组变量， 然后模板直接取密码后用'| password_hash('sha512')' 来加密密码 通常情况下在playbook中，开头位置引用一个变量时都需要\"{{ variable }}\"， 但是在when块里，则直接使用 variable。 另外字符串要用“string”  </p> <p>创建用户时， 指定附属组用groups, 主要组是group</p> <pre><code>- {{ variable }} ## 错误\nkey: {{ variable }} ## 错误\n- \"{{ variable}}\" ## 正确\nkey: \"{{ variable }}\" ## 正确\n</code></pre> <p>结果 <pre><code>---\n- name: create user on dev,test\n  hosts: dev,test\n  vars_files:\n    - lock.yml\n    - user_list.yml\n  tasks:\n    - name: create group devops\n      group:\n        name: devops\n        state: present\n    - name: create user \n      user:\n        name: \"{{ item.name }}\"\n-       group: devops\n+       groups: devops        \n        password: \"{{ pw_developer | password_hash('sha512') }}\"\n      loop: \"{{ user }}\"\n-     when: \"{{ item.job }}\" == developer\n+     when: item.job == \"developer\"\n- name: create user on prod\n  hosts: prod\n  vars_files:\n    - lock.yml\n    - users_list.yml\n  tasks:\n    - name: create group manager\n      group:\n        name: manager\n        state: present\n    - name: create user\n      user:\n        name: \"{{ item.name }}\"\n        groups: manager\n        password: \"{{ pw_manager | password_hash('sha512') }}\"\n      loop: \"{{ user }}\"\n-     when: \"{{ item.job }}\" == manager\n+     when: item.job == \"manager\"\n</code></pre></p>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#ansible-vault-rekey","level":3,"title":"修改密码, 使用<code>ansible-vault rekey</code> 修改密码，或者先解密后加密","text":"","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#copywhen","level":3,"title":"修改文件内容, 使用copy模块，以及when条件判断","text":"<p>在playbook的内建变量 inventory_hostname 表示定义在inventory里的主机名称 也可以使用ansible_facts['hostname'],前提是被管理节点的hostname必须如果管理节点定义名称一样。 因为后者是到被管理节点获取。</p> <p>使用when 限定条件， 满足条件才能执行这个task <pre><code>---\n- name: create issue\n  hosts: all\n  tasks:\n    - name: create issue file\n      copy:\n        content: \"Development\"\n        dest: /etc/issue\n      when: inventory_name in groups.dev  \n</code></pre></p>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#_3","level":3,"title":"第二次排错","text":"","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#ansible-galaxy-srcname","level":4,"title":"ansible-galaxy 安装角色, 指定方法分别是 src/name","text":"<pre><code>- src: files/5/balancer.tar\n  name: balancer\n- src: files/5/phpinfo.tar\n  name: phpinfo\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#timesync-doc-timedatectl-system-clock-syncronize-yes","level":3,"title":"timesync 看doc 示例， 验证方法是看timedatectl 看system clock syncronize 为 yes","text":"<pre><code>---\n- name: use timesync role\n  hosts: all\n  vars:\n    timesync_ntp_servers:\n      - hostname: \n        iburst: yes\n  roles:\n    - rhel_system_roles.timesync\n</code></pre>","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#hosts-for-host-in-groupsall-hostvarshostansible_facts-endfor","level":3,"title":"创建hosts, 要用 {% for  host in groups.all %} {{ hostvars[host].ansible_facts }} {% endfor %}","text":"","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#firewalldimmediate","level":3,"title":"使用firewalld模块时，需要指定immediate 参数，确保能立即生效","text":"","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rhce8-question/#urwxgrwxsorw-urwx","level":3,"title":"设置文件的权限时，应使用u=rwx,g=rwxs,o=rw, 而不是u+rwx，原因很好理解","text":"","path":["记录一下rhce8上课笔记"],"tags":["rhce","linux"]},{"location":"rotate-list/","level":1,"title":"单向链表翻转算法","text":"","path":["单向链表翻转算法"],"tags":["算法"]},{"location":"rotate-list/#_2","level":2,"title":"三指针法翻转单向链表","text":"<p>定义3个指针, 原理是三个指针分别指向前三个元素，将第一个元素指向第二个元素，然后全部后移 1. 第三个指针向前移动 2. 将第二个元素指向第一个元素 3. 第一个指针和第二个指针向前移动</p> <pre><code>struct Node{\n　　int data;\n　　Node *next;\n};\n\nNode *reverse(Node *head) {\n  Node *pPrev = nullptr;\n  Node *pHead = head;\n  Node *pNext = nullptr;\n  while (pHead) {\n    pNext = pHead-&gt;next;\n    pHead-&gt;next = pPrev;\n    pPrev = pHead;\n    pHead = pNext;\n  }\n  return pHead;\n}\n</code></pre> <pre><code>Node *reverse(Node *head) {\n  if (!head) {\n    return head;\n  }\n  Node *first = nullptr;\n  Node *second = head;\n  Node *third = head-&gt;next;\n\n  while (third) {\n    second-&gt;next = first;\n\n    first = second;\n    second = third;\n    third = third-&gt;next;\n  }\n\n  second-&gt;next = first;\n\n  return second;\n}\n</code></pre>","path":["单向链表翻转算法"],"tags":["算法"]},{"location":"rotate-list/#_3","level":2,"title":"翻转链表的部分节点","text":"<p>翻转node[m]-&gt;node[N]部分， 理解时先将链表分为3部分: part1-&gt;part2-&gt;part3, 只翻转part2  </p> <p>翻转动作套用三指针法，但部分翻转的难点在于处理part1为空和非空的情况，所以要判断m时候为1 * m==1即要翻转第一个元素时，需要先记录part2翻转后的tail node，最后将其next指向part3的第一个元素 * m!=1即part1不为空，需要先记录part2翻转后的tail node和part1的最后一个node，最后将其指向part2的新head,以及将part2的第一个node指向part3</p> <pre><code>struct ListNode *reverseBetween(struct ListNode *head, int m, int n) {\n  if (m == n) {\n    return head;\n  }\n\n  if(!head || !head-&gt;next){\n    return head;\n  }\n\n  // write code here\n  struct ListNode *pleft = NULL;\n  struct ListNode *phead = head;\n  struct ListNode *pright = NULL;\n\n\n  // 只有当m！=1时才需要，指向part1的最后一个元素\n  struct ListNode *pPart1Tail = NULL;\n  // 当m=1时指向part2的第一个元素\n  struct ListNode *pPart2NewTail = NULL;\n\n  // skip m\n  for (int i = 1; i &lt; m; i++) {\n    pleft = phead; \n    phead = phead-&gt;next;\n  }\n\n  // 保存part2的head,也是翻转后的tail\n  pPart2NewTail = phead;\n  // m != 1 时pleft不为NULL\n  struct ListNode *pPartOneTail = pleft;\n\n  int i = 0;\n  // 翻转次数要比m-n大1\n  while (phead &amp;&amp; i &lt; n - m + 1) {\n    pright = phead-&gt;next;\n\n    phead-&gt;next = pleft;\n\n    pleft = phead;\n    phead = pright;\n    i++;\n  }\n\n  if(m==1){\n    // 指向part3的头\n    pPart2NewTail-&gt;next = phead;\n    return pleft;\n  }\n\n  pPartOneTail-&gt;next = pleft;\n  pPart2NewTail-&gt;next = phead;\n\n  return head;\n}\n</code></pre>","path":["单向链表翻转算法"],"tags":["算法"]},{"location":"run%20docker%20in%20pve%20vm/","level":1,"title":"difference of lxc container and docker container","text":"<ul> <li>creating a lxc container will alloc a new partition from lvm(a new logic partition), create a root-fs and copy image into it, and the image is a zip file. </li> <li>creating a docker container will mount docker image layers one by one into the host's fs</li> </ul>","path":["difference of lxc container and docker container"],"tags":["pve","docker","lxc"]},{"location":"run%20docker%20in%20pve%20vm/#best-way","level":2,"title":"best way","text":"<p>best way of running docker in pve is probably install docker inner a lxc container</p>","path":["difference of lxc container and docker container"],"tags":["pve","docker","lxc"]},{"location":"run%20docker%20in%20pve%20vm/#speed-up-docker-installation","level":2,"title":"speed up docker installation","text":"<p>https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/</p>","path":["difference of lxc container and docker container"],"tags":["pve","docker","lxc"]},{"location":"run%20docker%20in%20pve%20vm/#remove-old","level":3,"title":"remove old","text":"<p>for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do apt-get remove $pkg; done</p>","path":["difference of lxc container and docker container"],"tags":["pve","docker","lxc"]},{"location":"run%20docker%20in%20pve%20vm/#setup-repository","level":3,"title":"setup repository","text":"<p>apt-get update apt-get install ca-certificates curl gnupg install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/debian/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg echo \\   \"deb [arch=\\((dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/debian \\   \"\\)(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\")\" stable\" | \\   tee /etc/apt/sources.list.d/docker.list &gt; /dev/null</p>","path":["difference of lxc container and docker container"],"tags":["pve","docker","lxc"]},{"location":"run%20docker%20in%20pve%20vm/#install","level":3,"title":"install","text":"<p>apt-get update apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</p>","path":["difference of lxc container and docker container"],"tags":["pve","docker","lxc"]},{"location":"run%20docker%20in%20pve%20vm/#copy-image-to-another-host","level":2,"title":"copy image to another host","text":"<p>docker save  | bzip2 | ssh user@host docker load","path":["difference of lxc container and docker container"],"tags":["pve","docker","lxc"]},{"location":"run%20docker%20in%20pve%20vm/#fix-problem-modprobe-fatal-module-fuse-not-found-in-directory-libmodules6110-1-pve","level":2,"title":"fix problem 'modprobe: FATAL: Module fuse not found in directory /lib/modules/6.1.10-1-pve'","text":"<p>enable the Options of your container (Select the container on the left-hand side &gt; Options &gt; Features) and then enable FUSE</p> <p>warn Just be aware that FUSE in LXC containers can cause some problems (no snapshots, no suspend backup, lower security since there is less containment).</p>","path":["difference of lxc container and docker container"],"tags":["pve","docker","lxc"]},{"location":"run%20docker%20in%20pve%20vm/#convert-docker-image-to-lxc-image","level":2,"title":"convert docker image to lxc image","text":"<p>https://www.reddit.com/r/Proxmox/comments/u9ru5c/comment/i640ixf/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button</p> <p>https://gist.github.com/flaki/9a6c58447e50219a9b77a7cd15433896</p>","path":["difference of lxc container and docker container"],"tags":["pve","docker","lxc"]},{"location":"run%20vllm%20locally/","level":1,"title":"run vllm Qwen3 locally","text":"<ul> <li>torch==2.5.1+cu121  https://mirrors.aliyun.com/pytorch-wheels/cu121/torch-2.5.1+cu121-cp313-cp313-linux_x86_64.whl</li> <li>vllm_pascal-0.7.2   https://github.com/sasha0552/pascal-pkgs-ci/releases/download/wheels/vllm_pascal-0.7.2-cp38-abi3-linux_x86_64.whl</li> <li>python 3.9</li> <li>uv 0.9.0</li> <li>Tesla P40</li> <li>Ubuntu 22</li> </ul>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#cuda","level":2,"title":"cuda版本","text":"<p>系统的cuda开发编译环境（/usr/local/cuda）可以不安装，除非需要本地编译。为了避免编译，就下载whl包。 whl包是别人用nvcc编译的二进制包，所以固定了cuda版本。例如torch-2.5.1+cu121表示用了cuda 12.1的编译工具编译的。 而且为了vllm能调用pytorch, vllm就必须和pytorch一样的cu版本，所以我两个都下载了cu121。</p>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#vllm_pascalvllm","level":2,"title":"安装vllm_pascal后，还需要执行下面的命令，来生成一个新的vllm 包","text":"<p>npx 相当于npm -g, 来安装一个全局的包+cli。 <pre><code>npx install transient-package\ntransient-package create --source vllm --source-version 0.7.2 --target vllm-pascal --target-version 0.7.2 --output-directory .\nuv pip install vllm-0.7.2-py3-none-any.whl\n</code></pre> 如果没有这一步, vllm命令提示找不到cuda <pre><code>WARNING 03-14 23:02:38 init.py:26] The vLLM package was not found, so its version could not be inspected. This may cause platform detection to fail.\nINFO 03-14 23:02:38 init.py:211] No platform detected, vLLM is running on UnspecifiedPlatform\n0.7.2\n</code></pre></p>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#_1","level":2,"title":"安装其他依赖","text":"<p><code>uv pip install ./*.whl</code>命令不会安装依赖，运行一个一个这样报缺包再安装包很烦，所以直接到vllm的代码里找requrement,一次安装。还有到pytorch官网看对应torch==2.5.1的torch-audio torch-vision包。</p>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#_2","level":2,"title":"验证和验证和修改参数","text":"<ul> <li>参数类型不匹配，模型配置文件里设定了<code>\"torch_dtype\": \"bfloat16\"</code>, 而显卡只能支持float16, 所以修改了模型配置。</li> <li>输出token长度太大，导致vllm不支持， 修改模型配置\"max_position_embeddings\"，从40960改成了10240。 </li> </ul>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#install-cuda-117-toolkit-and-driver","level":2,"title":"Install CUDA 11.7 toolkit and driver","text":"<p>sudo apt install -y cuda-11-7</p>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#uv-install-uv-add","level":2,"title":"uv install 和 uv add 的区别","text":"<p>新项目应该用 uv add, 在用 uv add 之前，需要先执行 * uv init 初始化项目 * uv venv ./.venv 创造虚拟环境</p>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#nvidia-smi","level":2,"title":"nvidia-smi 输出","text":"<p>| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |</p> <ul> <li>Driver Version 是GPU硬件驱动</li> <li>CUDA Version 是最大支持的cuda toolkits，也叫运行时。而实际的cuda toolkit version 通过<code>nvcc --version</code>来确认</li> </ul>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#nvcc","level":2,"title":"nvcc","text":"<p>nvcc 是/usr/local/cuda/bin/下的，也就是cuda toolkits，cuda目录通常是软链接到实际的cuda toolkits <pre><code>lrwxrwxrwx  1 root root   22 Nov  3 18:23 cuda -&gt; /etc/alternatives/cuda\nlrwxrwxrwx  1 root root   25 Nov  3 18:23 cuda-11 -&gt; /etc/alternatives/cuda-11\ndrwxr-xr-x 15 root root 4096 Nov  3 18:23 cuda-11.7\n</code></pre> 上面的cuda和cuda-11 都链接到cuda-11.7 也就是实际的toolkit version, 并且通过<code>nvcc --version</code>确认版本 nvcc --version nvcc: NVIDIA (R) Cuda compiler driver Copyright © 2005-2022 NVIDIA Corporation Built on Wed_Jun__8_16:49:14_PDT_2022 Cuda compilation tools, release 11.7, V11.7.99 Build cuda_11.7.r11.7/compiler.31442593_0</p> <p>11.7 小于 nvidia-smi打印的 13.0, 所以这个toolkit是支持的。</p>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#cuda-capabilities","level":2,"title":"cuda capabilities","text":"<p>虽然GPU driver 可以向前兼容，所以 Driver 535可以替代Driver 515。但是硬件架构限定了cuda capabilities，无法向前兼容的。例如Tesla P40的硬件架构是Pascal sm_6.1，而pytorch 的2.7.0 版本不支持sm_6.1了。</p>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#install-pytorch","level":2,"title":"Install pytorch","text":"<p>因为 cuda capability限制，知道最高版本支持sm 6.1的pytorch版本是2.6.0, 而pytroch有专门对cuda特定版本的二进制包，在官网上能找到 https://pytorch.org/get-started/previous-versions/ 下面可见，2.6.0版本有 cuda-11.8 cuda-12.4 cuda-12.6版本的二进制安装包。  <pre><code># ROCM 6.1 (Linux only)\npip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/rocm6.1\n# ROCM 6.2.4 (Linux only)\npip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/rocm6.2.4\n# CUDA 11.8\npip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118\n# CUDA 12.4\npip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124\n# CUDA 12.6\npip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu126\n# CPU only\npip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cpu\n</code></pre> 然后搜索得知 11.8 要求最低的cuda capability 版本是 5.0, 所以也支持6.1的Tesla P40, 于是安装安装命令是 <pre><code>uv pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118\n</code></pre></p>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#install-vllm","level":2,"title":"Install vllm","text":"<p>vllm 0.9 开始不支持pytorch 2.6了，所以只能用vllm 0.8.5。从githup release找到了二进制安装包 vllm-0.8.5.post1+cu118-cp38-abi3-manylinux1_x86_64.whl 下载到本地后运行  uv pip install ~/vllm-0.8.5.post1+cu118-cp38-abi3-manylinux1_x86_64.whl</p>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#vllm-serve-qwen3-8b-fail-runtimeerror-cuda-error-no-kernel-image-is-available-for-execution-on-the-device","level":3,"title":"vllm serve Qwen3-8B fail: RuntimeError: CUDA error: no kernel image is available for execution on the device","text":"<p>可惜，vllm 0.8.5 不支持 pytorch-cuda-6.1, 不知道这跟pytroch 支持 sm-6.1有什么区别。好在可以手动编译vllm来支持 <pre><code>git clone https://github.com/vllm-project/vllm.git\ncd vllm\ngit checkout v0.8.5\nexport TORCH_CUDA_ARCH_LIST=\"6.1\"\npip install -e . --no-build-isolation\n</code></pre></p>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#_3","level":3,"title":"run vllm Qwen3 locally","text":"","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#vramvideo-ram","level":2,"title":"计算VRAM(Video RAM)","text":"<p>dtype 是参数类型，所需的大小分别是 * FP32  4B 单精度 * BP16  2B 双精度 * FP16  2B 单精度 * INT8 1B * INT4 0.5B 量化 vllm 可以运行时指定量化</p> <p>而大模型的参数常见有32B，7B。7B的大模型，使用FP32时，需要VRAM=4*7G。 使用FP16时，只需要2*7G。</p> <p>注意，模型的config.torch_dtype是可以改的，最大输出token也是可以改的。</p>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"run%20vllm%20locally/#_4","level":2,"title":"参考","text":"<p>https://github.com/vllm-project/vllm/pull/4290</p> <p>pytroch 2.7 不支持 6.1: https://www.reddit.com/r/LocalLLaMA/comments/1lrerwe/pytorch_27x_no_longer_supports_pascal_architecture/ vllm 0.11.5 才能支持Qwen/Qwen3-VL-32B-Instruct，否则报错 \"'Qwen3VLConfig' object has no attribute 'vocab_size'\" https://huggingface.co/Qwen/Qwen3-VL-32B-Instruct/discussions/3</p>","path":["run vllm Qwen3 locally"],"tags":[]},{"location":"sdcc-compile-for-51/","level":1,"title":"在Linux下使用sdcc进行单片机编译","text":"<p>周末研究了下单片机，本来准备写个定时器来控制电扇开关，发现比起树梅派，单片机实在不太方便</p>","path":["在Linux下使用sdcc进行单片机编译"],"tags":["51单片机"]},{"location":"sdcc-compile-for-51/#_1","level":2,"title":"开发环境搭建","text":"<p>Windows大家都用Keil, 一站式比较方便，但这是个收费软件。而在Linux下，使用到一些组合来实现编译和烧录</p> <ol> <li>sdcc 开源的编译器，类似gcc</li> <li>stcflash github上的开发者开发的烧录脚本</li> </ol> <p>sdcc 在Debian有包可以直接安装 <pre><code># apt install sdcc\n</code></pre> 再 clone github的代码到本地，需要使用root权限执行烧录。而我执行是发现缺少python serial包，要全局安装就使用apt命令</p> <pre><code># apt install python3-serial\n</code></pre> <p>这样环境就搭建好了</p>","path":["在Linux下使用sdcc进行单片机编译"],"tags":["51单片机"]},{"location":"sdcc-compile-for-51/#_2","level":2,"title":"编写代码","text":"<p>用c语言开发时要引入比较的定义头文件，我的单片机是好多年前买的国产<code>stc 89C52RC</code>， 是基于51的拓展版本，于是用了sdcc的<code>8052.h</code>头，路径在 <pre><code>// /usr/share/sdcc/include/mcs51/8052.h\n#ifndef REG8052_H\n#define REG8052_H\n\n#include &lt;8051.h&gt;     /* load definitions for the 8051 core */\n\n#ifdef REG8051_H\n#undef REG8051_H\n#endif\n</code></pre></p> <p>不过不需要我们指定路径，sdcc会自动引入。窥视其内容可以发现它包含了8051的东西，所以说52是基于51的</p>","path":["在Linux下使用sdcc进行单片机编译"],"tags":["51单片机"]},{"location":"sdcc-compile-for-51/#51","level":2,"title":"回顾一下51单片机知识","text":"<ol> <li>单片机的寄存器初始是0, 而引脚初始都是高点位</li> <li>定时器和计数器的触发事件都是靠中断，中断执行当前（main）中的函数而执行中断响应函数，这跟Unix内核是一样的。 单片机还具有多个优先级的中断，可以嵌套</li> <li>中断的触发靠计数寄存器（TLx和THx）溢出，这两个都是8位寄存器，所以同时使用时，在2^16时溢出。但也有只用其中一个寄存器的时候，这由<code>TMOD</code>寄存器控制</li> </ol>","path":["在Linux下使用sdcc进行单片机编译"],"tags":["51单片机"]},{"location":"sdcc-compile-for-51/#tmod","level":3,"title":"TMOD寄存器","text":"<p>TMOD是不可按位访问的寄存器，意思是只能一次性赋值所有位。 TMOD控制着两个定时器/计数器0和1</p> <p>![[timer.png]]</p> <ul> <li>TMOD高四位用于设置定时器/计数器1，低四位用于设置定时器/计数器0；</li> <li>GATE寄存器决定是否使用外部INTx控制，即软件自动启动，还是外部启动，这里赋值0</li> <li>GATE=1时，“与门”的输出信号K由INTx输入电平和TRx位的状态一起决定(即此时K=TRx·INTx)，当且仅当TRx=1,INTx=1(高电平)时，计数启动；否则，计数停止。当INT0引脚为高平时且TR0置位，TR0=1；启动定时器T0</li> <li>GATE=0时，“A”输出恒为1，“B”的值由TRx决定，当TR0=1,启动定时器/计数器T0，当TR1=1，启动定时器/计数器T1</li> <li>CT位为1时选择计数器模式，为0时选择定时器模式</li> <li>M1,M0用于选择工作方式，当M0=1,M1=0时，使用TL0和TH0的16位来计数</li> </ul>","path":["在Linux下使用sdcc进行单片机编译"],"tags":["51单片机"]},{"location":"sdcc-compile-for-51/#tcon","level":3,"title":"TCON寄存器","text":"<p>![[TCON.png]]</p>","path":["在Linux下使用sdcc进行单片机编译"],"tags":["51单片机"]},{"location":"sdcc-compile-for-51/#_3","level":3,"title":"定时器初始化","text":"<p>这里使用定时器0 <pre><code>void Timer0Init(void) // 1毫秒@12.000MHz\n{\n    TMOD = 0x01; //设置定时器模式 0000 0001\n    // TCON\n    TF0 = 0; //初始化溢出标志\n    TR0 = 1; //定时器0开始计时\n    // 计数器初始值，再触发一次就溢出了\n    TH0 = 0xFF; //设置定时初值\n    TL0 = 0xFE; //设置定时初值\n    // 中断通路\n    EA = 1; \n    ET0 = 1;\n    PT0 = 0;\n}\n</code></pre></p>","path":["在Linux下使用sdcc进行单片机编译"],"tags":["51单片机"]},{"location":"sdcc-compile-for-51/#_4","level":3,"title":"计数器模式","text":"<p>这里使用计数器0 <pre><code>void Count0Init(void) // 1毫秒@12.000MHz\n{ \n    TMOD = 0x05; //设置计数器模式 0000 0101\n\n    // TCON\n    TF0 = 0; \n    TR0 = 1; //定时器0开始计时\n\n    // 计数器初始值，再触发一次就溢出了\n    TH0 = 0xFF;  //设置定时初值\n    TL0 = 0xFE;  //设置定时初值\n\n    // 中断通路\n    EA = 1;\n    ET0 = 1;\n    PT0 = 0;\n}\n</code></pre></p>","path":["在Linux下使用sdcc进行单片机编译"],"tags":["51单片机"]},{"location":"sdcc-compile-for-51/#_5","level":3,"title":"中断响应函数","text":"<p>sdcc和keil有一些区别，中断标志符使用<code>__interrupt</code> <pre><code>static unsigned int T0Count = 0;\nvoid timer0_routine() __interrupt (1) {\n  T0Count++;\n  TH0 = 0xFF; //设置定时初值\n  TL0 = 0xFE; //设置定时初值\n  if (T0Count == 3) {\n    T0Count = 0;\n    P1_1 = 0;  // 0输出低电平，灯泡亮\n  }\n}\n</code></pre></p>","path":["在Linux下使用sdcc进行单片机编译"],"tags":["51单片机"]},{"location":"sdcc-compile-for-51/#_6","level":3,"title":"完整代码","text":"<pre><code>// main.c\n#include \"8052.h\"\n\nvoid Timer0Init(void) // 1毫秒@12.000MHz\n{\n  TMOD = 0x01;\n  TF0 = 0;\n  TR0 = 1;\n  TH0 = 0xFF;\n  TL0 = 0xFE;\n  EA = 1;\n  ET0 = 1;\n  PT0 = 0;\n}\n\nvoid main(void) {\n\n  Timer1Init();\n  while (1)\n    ;\n}\n\nunsigned int T0Count = 0;\nvoid timer0_routine() __interrupt(1) {\n  T0Count++;\n  TH0 = 0xFF;\n  TL0 = 0xFE;\n  if (T0Count == 3) {\n    T0Count = 0;\n    P1_1 = 0;\n  }\n}\n</code></pre>","path":["在Linux下使用sdcc进行单片机编译"],"tags":["51单片机"]},{"location":"sdcc-compile-for-51/#_7","level":2,"title":"编译和烧录","text":"<p>代码保存为main.c</p> <pre><code># 使用sdcc编译\nsdcc main.c\n将sdcc生成的ihx文件转为hex文件\npackihx main.ihx  &gt; main.hex   \n</code></pre> <p>烧录到单片机 <pre><code>sudo python ~/github/stcflash/stcflash.py main.hex\nConnect to /dev/ttyUSB0 at baudrate 2400\nDetecting target... done\n FOSC: 11.955MHz\n Model: STC89C52RC (ver4.3C) \n ROM: 8KB\n [X] Reset stops watchdog\n [X] Internal XRAM\n [X] Normal ALE pin\n [X] Full gain oscillator\n [X] Not erase data EEPROM\n [X] Download regardless of P1\n [X] 12T mode\nBaudrate: 38400\nErasing target... done\nSize of the binary: 147\nProgramming: #################### done\nSetting options... done\n</code></pre></p>","path":["在Linux下使用sdcc进行单片机编译"],"tags":["51单片机"]},{"location":"sed-vim-difference/","level":1,"title":"sed和vim替换文本的小区别","text":"","path":["sed和vim替换文本的小区别"],"tags":["linux","tool"]},{"location":"sed-vim-difference/#vimsed","level":2,"title":"替换招行的账单中发现vim和sed区别","text":"<p>在vim中 1. <code>:%s/\\n/,/g</code> 2. <code>:% s/\\t,\\t,\\t,\\t,/\\r/g</code> 用sed: <code>cat bill.txt| sed -z 's/\\n/,/g'  | sed 's/\\t,\\t,\\t,\\t,/\\n/g'</code></p>","path":["sed和vim替换文本的小区别"],"tags":["linux","tool"]},{"location":"sed-vim-difference/#_1","level":2,"title":"可见","text":"<ol> <li>vim中匹配换行符用<code>\\n</code>, 而替换用<code>\\r</code>。替换成<code>\\n</code>在vim中显示成<code>^@</code></li> <li>sed 中的换行符统一用<code>\\n</code>，这比vim好，但sed 中不能直接用<code>\\n</code>匹配，还得加上 -z 参数。</li> </ol>","path":["sed和vim替换文本的小区别"],"tags":["linux","tool"]},{"location":"segmentation-fault-in-dmesg/","level":1,"title":"segfault in dmesg","text":"<p>偶尔看到自己或者客户的/var/log/message 日志出现segfault, 查询了一下相关信息 <pre><code>Apr  6 09:43:37 icm kernel: rhsm-icon[13402]: segfault at 12b0000 ip 0000003c89845c00 sp 00007ffce18396e0 error 4 in libglib-2.0.so.0.2800.8[3c89800000+115000]\n</code></pre></p>","path":["segfault in dmesg"],"tags":["debug"]},{"location":"segmentation-fault-in-dmesg/#_1","level":2,"title":"解释","text":"<ul> <li>address (after the at) - the location in memory the code is trying to access (it's likely that 10 and 11 are offsets from a pointer we expect to be set to a valid value but which is instead pointing to 0)</li> <li>ip - instruction pointer, ie. where the code which is trying to do this lives</li> <li>sp - stack pointer</li> <li>error - An error code for page faults; see below for what this means on x86. <pre><code>/*\n * Page fault error code bits:\n *\n *   bit 0 ==    0: no page found       1: protection fault\n *   bit 1 ==    0: read access         1: write access\n *   bit 2 ==    0: kernel-mode access  1: user-mode access\n *   bit 3 ==                           1: use of reserved bit detected\n *   bit 4 ==                           1: fault was an instruction fetch\n */\n</code></pre></li> </ul>","path":["segfault in dmesg"],"tags":["debug"]},{"location":"segmentation-fault-in-dmesg/#message","level":2,"title":"message日志","text":"<p>使用<code>dmesg</code>打印ring buffer的内容，关于硬件和i/o的信息</p>","path":["segfault in dmesg"],"tags":["debug"]},{"location":"segmentation-fault-in-dmesg/#coredump","level":2,"title":"coredump","text":"<pre><code> A core file is an image of a process that has crashed It contains all process information pertinent to debugging: contents of hardware registers, process status, and process data. Gdb will allow you use this file to determine where your program crashed. \n</code></pre>","path":["segfault in dmesg"],"tags":["debug"]},{"location":"segmentation-fault-in-dmesg/#_2","level":2,"title":"复现","text":"<pre><code>void foo(){\n    int *p = 0;\n    *p = 100;\n}\n\nint main(){\n  foo();\n}\n</code></pre> <pre><code>[ 5902.293905] a.out[6085]: segfault at 0 ip 000055c0eddca129 sp 00007ffe65372110 error 6 in a.out[55c0eddca000+1000]\n[ 5902.293916] Code: 00 c3 66 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 40 00 f3 0f 1e fa e9 67 ff ff ff 55 48 89 e5 48 c7 45 f8 00 00 00 00 48 8b 45 f8 &lt;c7&gt; 00 64 00 00 00 90 5d c3 55 48 89 e5 b8 00 00 00 00 e8 d9 ff ff\n</code></pre> <pre><code>(gdb) info registers \nrax            0x0                 0\nrbx            0x55c0eddca150      94287112741200\nrcx            0x7faa085eb598      140368261592472\nrdx            0x7ffe65372228      140730596532776\nrsi            0x7ffe65372218      140730596532760\nrdi            0x1                 1\nrbp            0x7ffe65372110      0x7ffe65372110\nrsp            0x7ffe65372110      0x7ffe65372110\nr8             0x0                 0\nr9             0x7faa08621070      140368261812336\nr10            0x69682ac           110527148\nr11            0x202               514\nr12            0x55c0eddca020      94287112740896\nr13            0x0                 0\nr14            0x0                 0\nr15            0x0                 0\nrip            0x55c0eddca129      0x55c0eddca129 &lt;foo+16&gt;\neflags         0x10246             [ PF ZF IF RF ]\ncs             0x33                51\nss             0x2b                43\nds             0x0                 0\nes             0x0                 0\nfs             0x0                 0\ngs             0x0                 0\n</code></pre>","path":["segfault in dmesg"],"tags":["debug"]},{"location":"segmentation-fault-in-dmesg/#addr2line","level":2,"title":"addr2line","text":"<pre><code>addr2line -e yourSegfaultingProgram 00007f9bebcca90d\n</code></pre>","path":["segfault in dmesg"],"tags":["debug"]},{"location":"serialized-and-deserialize/","level":1,"title":"序列化和反序列化","text":"<p>c/cpp中，序列化是将基本类型或struct变为可存储和传递的形式，比如常用的<code>socket send</code>，将按协议组装的struct（pack)显示转换二进制（序列化）并发送给其他主机。而反序列化是将二进制转成基本类型或struct。另外还有<code>fwrite/fread</code>将结构体保存到文本中。 这种方式高效但容易出错。 而其他语言中可以使用xml, json等高级方式</p>","path":["序列化和反序列化"],"tags":["seralize"]},{"location":"serialized-and-deserialize/#_2","level":2,"title":"转换方式","text":"","path":["序列化和反序列化"],"tags":["seralize"]},{"location":"serialized-and-deserialize/#_3","level":3,"title":"强制类型转换","text":"<p>上面讲到的两个函数send和fwrite,都是将基本类型或struct类型强转为字符串, 这种可能受不同机器的对齐影响 <pre><code>ssize_t send(int sockfd, const void *buf, size_t len, int flags);\n\nsize_t fwrite(const void *ptr, size_t size, size_t nmemb,\n    FILE *stream);\n</code></pre></p> <p>序列化 <pre><code>struct buffer {\n  int a;\n  char b;\n  double c;\n};\n\nint main() {\n\n  struct buffer buf;\n  buf.a = 1;\n  buf.b = 'a';\n  buf.c = 2;\n\n  FILE *f = fopen(\"/tmp/buf\", \"w+\");\n  if (f == NULL) {\n    return 1;\n  }\n  fwrite(&amp;buf, sizeof(struct buffer), 1, f);\n}\n</code></pre></p> <p>反序列化 <pre><code>struct buffer {\n  int a;\n  char b;\n  double c;\n};\n\nint main() {\n\n  struct buffer buf;\n\n  FILE *f = fopen(\"/tmp/buf\", \"r\");\n  if (f == NULL) {\n    return 1;\n  }\n\n  fread(&amp;buf, sizeof(struct buffer), 1, f);\n  printf(\"%d--%c--%lf--\\n\", buf.a, buf.b, buf.c);\n}\n</code></pre></p>","path":["序列化和反序列化"],"tags":["seralize"]},{"location":"serialized-and-deserialize/#protobuf","level":3,"title":"使用protobuf","text":"<pre><code>syntax = \"proto3\";\npackage serialize;\n\noption optimize_for = LITE_RUNTIME;\n\nmessage Person {\n    string name = 1;\n    int32 id = 2;\n}\n</code></pre> <pre><code>tutorial::Person Serialize(std::string name, int id, std::string email){\n    tutorial::Person person;\n    person.set_name(name);\n    person.set_id(id);\n\n    return person;\n}\n\nvoid Deserialize(tutorial::Person person){\n    std::cout &lt;&lt; person.SerializeAsString();\n}\n</code></pre>","path":["序列化和反序列化"],"tags":["seralize"]},{"location":"serialized-and-deserialize/#optimize_for-option","level":3,"title":"optimize_for option","text":"<p>optimize_for (file option): Can be set to SPEED, CODE_SIZE, or LITE_RUNTIME. This affects the C++ and Java code generators (and possibly third-party generators) in the following ways:</p> <ul> <li>SPEED (default): The protocol buffer compiler will generate code for serializing, parsing, and performing other common operations on your message types. This code is highly optimized.</li> <li>CODE_SIZE: The protocol buffer compiler will generate minimal classes and will rely on shared, reflection-based code to implement serialialization, parsing, and various other operations. The generated code will thus be much smaller than with SPEED, but operations will be slower. Classes will still implement exactly the same public API as they do in SPEED mode. This mode is most useful in apps that contain a very large number of .proto files and do not need all of them to be blindingly fast.</li> <li>LITE_RUNTIME: The protocol buffer compiler will generate classes that depend only on the \"lite\" runtime library (libprotobuf-lite instead of libprotobuf). The lite runtime is much smaller than the full library (around an order of magnitude smaller) but omits certain features like descriptors and reflection. This is particularly useful for apps running on constrained platforms like mobile phones. The compiler will still generate fast implementations of all methods as it does in SPEED mode. Generated classes will only implement the MessageLite interface in each language, which provides only a subset of the methods of the full Message interface.</li> </ul>","path":["序列化和反序列化"],"tags":["seralize"]},{"location":"serialized-and-deserialize/#xml-json-ninja","level":2,"title":"其他还有如xml, json, ninja","text":"","path":["序列化和反序列化"],"tags":["seralize"]},{"location":"setup-printer-use-avahi/","level":1,"title":"使用avahi将传统打印机支持无线打印","text":"<p>自从知道mdns之后，发现它非常方便，例如可以找到lan下有哪些ftp服务，ssh服务等。甚至我配置好的打印机服务。</p>","path":["使用avahi将传统打印机支持无线打印"],"tags":["mdns","printer"]},{"location":"setup-printer-use-avahi/#mdns","level":2,"title":"mdns介绍","text":"<p>有别于dns, mdns专门用来解析链路域名（TLD为*.local）， 且不需要域名服务器（nameserver）。  原理是同一个lan里的主机通过avahi或zeroconfig类似的工具，向lan广播自己的ip信息和服务</p>","path":["使用avahi将传统打印机支持无线打印"],"tags":["mdns","printer"]},{"location":"setup-printer-use-avahi/#avahi_1","level":2,"title":"avahi 介绍","text":"<p>avahi是zeroconfig的开源实现，在linux下还有systemd-resolve 同样可以实现mdns解析，但是avahi依旧是linux预装的软件。</p>","path":["使用avahi将传统打印机支持无线打印"],"tags":["mdns","printer"]},{"location":"setup-printer-use-avahi/#avahi_2","level":3,"title":"avahi 配置","text":"<p>主要修改<code>/etc/avahi/avahi-daemon.conf</code>, 这里使用了br0和wlan0两个网卡，avahi就可以访问两个网络 <pre><code>use-ipv4=yes\nallow-interfaces=br0,wlan0\n</code></pre> 再设置自启动</p>","path":["使用avahi将传统打印机支持无线打印"],"tags":["mdns","printer"]},{"location":"setup-printer-use-avahi/#nss","level":3,"title":"nss 配置","text":"<p>要让主机能解析到*.local 域名，需要修改配置文件<code>/etc/nsswitch.conf</code> <pre><code>- hosts: files mymachines myhostname resolve [!UNAVAIL=return] dns\n+ hosts: files mymachines myhostname mdns_minimal [NOTFOUND=return] resolve [!UNAVAIL=return] dns\n</code></pre> 这样，在主机请求解析域名的时候， 会先去请求avahi解析，如果avahi解析失败（说明不是一个local域名）才会去查找域名解析（dns）</p>","path":["使用avahi将传统打印机支持无线打印"],"tags":["mdns","printer"]},{"location":"setup-printer-use-avahi/#systemd-resolved","level":2,"title":"使用systemd-resolved","text":"<p>对于使用systemd-resoved来管理dns解析时，可以直接用<code>sudo systemd-resolve --set-mdns=yes --interface=eth0</code>启动eth0端口的mdns广播。</p> <p>顺便提一下，用systemd-networkd配置dns服务器和用systemd-resolved配置dns的区别，前者为每个以太网口单独配置，而systemd-resoved会读取每个以太网口配置，另外还有一个全局的dns配置。</p>","path":["使用avahi将传统打印机支持无线打印"],"tags":["mdns","printer"]},{"location":"setup-printer-use-avahi/#_1","level":3,"title":"测试","text":"<p>首先可以ping 本地local域名 <pre><code>~ &gt; ping hst.local                                                                                                                                                                                      \nPING hst.local(hst (fe80::3e9c:fff:fe8c:69c3%wlan0)) 56 data bytes\n64 bytes from hst (fe80::3e9c:fff:fe8c:69c3%wlan0): icmp_seq=1 ttl=64 time=0.113 ms\n64 bytes from hst (fe80::3e9c:fff:fe8c:69c3%wlan0): icmp_seq=2 ttl=64 time=0.144 ms\n</code></pre></p> <p>然后执行<code>avahi-discover-standalone</code> 可以查找到很多*.local的地址，特别是在公司网络里</p>","path":["使用avahi将传统打印机支持无线打印"],"tags":["mdns","printer"]},{"location":"setup-printer-use-avahi/#_2","level":2,"title":"广告自己的服务","text":"<p>配置好了avahi, 就可以向外界发布自己的服务，让其他人知道，也可以选择不发布 例如要广告我的ssh服务, 只需要将预设的配置文件拷贝到avahi的配置目录下 <pre><code>sudo cp /usr/share/doc/avahi/ssh.service /etc/avahi/services\n</code></pre> 这样，别人就能发现我的ssh服务了</p>","path":["使用avahi将传统打印机支持无线打印"],"tags":["mdns","printer"]},{"location":"setup-printer-use-avahi/#_3","level":2,"title":"配置打印机","text":"<p>linux的打印功能依赖CUPS这个软件，先安装CUPS，设置自启动，然后就可以访问CUPS的网页版管理界面<code>http://localhost:631</code> 在这个网页中添加网络打印机或者本地打印机，然后测试打印是否正常</p>","path":["使用avahi将传统打印机支持无线打印"],"tags":["mdns","printer"]},{"location":"setup-printer-use-avahi/#_4","level":2,"title":"最后，配置无线功能","text":"<p>上一部添加的打印机可能是有线网络打印机，也可能是串口打印机，都不能让我们的手机直接使用。  </p> <p>但是通过cups + avahi 就可以将你的有线打印机变成无线打印机了 首先在cups里配置，勾选<code>Share This Printer</code>，  </p> <p>然后像刚才添加ssh服务一样， 添加打印服务 在<code>/etc/avahi/services/</code> 创建一个service后缀的文件<code>airprint.service</code></p> <p><pre><code>&lt;?xml version=\"1.0\" standalone='no'?&gt;&lt;!--*-nxml-*--&gt;\n&lt;!DOCTYPE service-group SYSTEM \"avahi-service.dtd\"&gt;\n&lt;service-group&gt;\n  &lt;name&gt;Printer&lt;/name&gt;\n  &lt;service&gt;\n    &lt;type&gt;_ipp._tcp&lt;/type&gt;\n    &lt;subtype&gt;_universal._sub._ipp._tcp&lt;/subtype&gt;\n    &lt;port&gt;631&lt;/port&gt;\n    &lt;txt-record&gt;txtver=1&lt;/txt-record&gt;\n    &lt;txt-record&gt;qtotal=1&lt;/txt-record&gt;\n    &lt;txt-record&gt;rp=printers/Ricoh_MP_4055&lt;/txt-record&gt;\n    &lt;txt-record&gt;ty=Ricoh_MP_4055&lt;/txt-record&gt;\n    &lt;txt-record&gt;adminurl=http://yourip:631/printers/Ricoh_MP_4055&lt;/txt-record&gt;\n    &lt;txt-record&gt;note=Ricoh_MP_4055&lt;/txt-record&gt;\n    &lt;txt-record&gt;priority=0&lt;/txt-record&gt;\n    &lt;txt-record&gt;product=(GPL Ghostscript)&lt;/txt-record&gt;\n    &lt;txt-record&gt;printer-state=3&lt;/txt-record&gt;\n    &lt;txt-record&gt;printer-type=0x801046&lt;/txt-record&gt;\n    &lt;txt-record&gt;Transparent=T&lt;/txt-record&gt;\n    &lt;txt-record&gt;Binary=T&lt;/txt-record&gt;\n    &lt;txt-record&gt;Fax=F&lt;/txt-record&gt;\n    &lt;txt-record&gt;Color=T&lt;/txt-record&gt;\n    &lt;txt-record&gt;Duplex=T&lt;/txt-record&gt;\n    &lt;txt-record&gt;Staple=F&lt;/txt-record&gt;\n    &lt;txt-record&gt;Copies=T&lt;/txt-record&gt;\n    &lt;txt-record&gt;Collate=F&lt;/txt-record&gt;\n    &lt;txt-record&gt;Punch=F&lt;/txt-record&gt;\n    &lt;txt-record&gt;Bind=F&lt;/txt-record&gt;\n    &lt;txt-record&gt;Sort=F&lt;/txt-record&gt;\n    &lt;txt-record&gt;Scan=F&lt;/txt-record&gt;\n    &lt;txt-record&gt;pdl=application/octet-stream,application/pdf,application/postscript,image/jpeg,image/png,image/urf&lt;/txt-record&gt;\n    &lt;txt-record&gt;URF=W8,SRGB24,CP1,RS600&lt;/txt-record&gt;\n  &lt;/service&gt;\n&lt;/service-group&gt;\n</code></pre> 根据情况修改一下内容，就完成了, 亲测iphone可以使用这个服务打印</p>","path":["使用avahi将传统打印机支持无线打印"],"tags":["mdns","printer"]},{"location":"setup-printer-use-avahi/#_5","level":2,"title":"注意","text":"<p>上面的情况假设防火墙处于关闭状态，如果启用防火墙的情况下，需要开放avahi、ssh以及ipp服务</p> <pre><code>sudo firewall-cmd --add-service ssh ipp --permanent\nsudo firewall-cmd --add-port=5353/tcp --permanent\nsudo firewall-cmd --reload\n</code></pre>","path":["使用avahi将传统打印机支持无线打印"],"tags":["mdns","printer"]},{"location":"setup-sftp-service/","level":1,"title":"setup sftp service","text":"","path":["setup sftp service"],"tags":["linux","filesystem"]},{"location":"setup-sftp-service/#curlfs-sshfs","level":2,"title":"curlfs 和 sshfs 客户端","text":"<p>在debian上，之前一直用curlfs工具，将远程目录mount到本地目录。系统升级之后发现这个包没有了， 原来因为ftp不安全，所以现在推荐sshfs。</p>","path":["setup sftp service"],"tags":["linux","filesystem"]},{"location":"setup-sftp-service/#reference","level":2,"title":"reference","text":"<p>https://www.linuxtechi.com/configure-sftp-chroot-debian10/</p>","path":["setup sftp service"],"tags":["linux","filesystem"]},{"location":"setup-vue2/","level":1,"title":"初始化vue2","text":"<p>推荐方法3中的<code>vue create my-project</code></p>","path":["初始化vue2"],"tags":["vue","frontend"]},{"location":"setup-vue2/#method1","level":2,"title":"method1","text":"<p>手动创建各种文件</p> <p>mkdir vue2-app cd vue2-app</p> <p>npm init -y npm install vue@legacy npm install vite @vitejs/plugin-vue2 vue-template-compiler -D</p> <p>创建文件vite.config.js， 内容： <pre><code>// vite.config.js\nimport { defineConfig } from 'vite'\nimport vue from '@vitejs/plugin-vue2'\n\nexport default defineConfig({\n  plugins: [vue()]\n})\n</code></pre> 还有其他文件，这种方式显然不是大家通常想要的</p>","path":["初始化vue2"],"tags":["vue","frontend"]},{"location":"setup-vue2/#method2-vue-cli-vue2","level":2,"title":"method2 vue-cli 只适用vue2","text":"<p>npm install -g @vue/cli-init vue init webpack my-project cd my-project npm install npm run dev</p>","path":["初始化vue2"],"tags":["vue","frontend"]},{"location":"setup-vue2/#method3-vue-vue23","level":2,"title":"method3 vue 使用vue2和3,所以要手动选择","text":"<p>npm install -g @vue/cli vue create my-project</p> <p>然后选择 Manually select features</p> <p>回车后再选择 Choose Vue version</p> <p>最后选择 select 2.x when prompted for the version</p>","path":["初始化vue2"],"tags":["vue","frontend"]},{"location":"setup-vue2/#method3-method2","level":3,"title":"method3 可以兼容method2","text":"<p>method3也可以用vue init, 但需要另外安装</p> <p>npm install -g @vue/cli-init</p>","path":["初始化vue2"],"tags":["vue","frontend"]},{"location":"setup-vue2/#vue-init-now-works-exactly-the-same-as-vue-cli2x","level":1,"title":"vue init now works exactly the same as vue-cli@2.x","text":"<p>vue init webpack my-project</p>","path":["初始化vue2"],"tags":["vue","frontend"]},{"location":"setup-vue2/#method3-vue-create-vue-init-vue2","level":2,"title":"对比 method3 中的 <code>vue create</code> 和 <code>vue init</code> 的vue2结构区别","text":"<p>最大的区别是启动脚本， 前者是 <pre><code># cat package.json\n{                       \n  \"name\": \"my-project\",               \n  \"version\": \"0.1.0\",               \n  \"private\": true,                    \n  \"scripts\": {                    \n    \"serve\": \"vue-cli-service serve\", \n    \"build\": \"vue-cli-service build\",\n    \"lint\": \"vue-cli-service lint\"                                  \n  },   \n</code></pre> 后者 <pre><code>cat package.json\n{                                       \n  \"name\": \"webpack-vue2\",                \n  \"version\": \"1.0.0\",         \n  \"description\": \"A Vue.js project\",                                                            \n  \"author\": \"enerygreek &lt;greek_soon@hotmail.com&gt;\",\n  \"private\": true,                    \n  \"scripts\": {                                                                                  \n    \"dev\": \"webpack-dev-server --inline --progress --config build/webpack.dev.conf.js\",\n    \"start\": \"npm run dev\",\n    \"unit\": \"jest --config test/unit/jest.conf.js --coverage\",\n    \"e2e\": \"node test/e2e/runner.js\",\n    \"test\": \"npm run unit &amp;&amp; npm run e2e\",\n    \"lint\": \"eslint --ext .js,.vue src test/unit test/e2e/specs\",\n    \"build\": \"node build/build.js\"\n  },\n</code></pre></p>","path":["初始化vue2"],"tags":["vue","frontend"]},{"location":"setup-vue2/#_1","level":2,"title":"参考","text":"<p>https://cli.vuejs.org/guide/creating-a-project.html#pulling-2-x-templates-legacy</p>","path":["初始化vue2"],"tags":["vue","frontend"]},{"location":"shared-pointer/","level":1,"title":"智能指针","text":"<p>智能指针是c++11加入的特性，包括shared_ptr和unique_ptr，weak_ptr，以及make_shared函数，但make_unique是c++14才出来 不过c++11可以通过模版来实现make_unique</p>","path":["智能指针"],"tags":["cpp"]},{"location":"shared-pointer/#_2","level":2,"title":"普通指针和智能指针的区别","text":"<p>shared_ptr和unique_ptr都是异常安全的(exception-safe)，而普通指针不是，举例如下 <pre><code>void nonsafe_call(T1* t1, T2* t2);\nvoid safe_call(unique_ptr&lt;T1&gt; t1, unique_ptr&lt;T2&gt; t2);\n\nnonsafe_call(new T1, new T2);\nsafe_call(make_unique&lt;T1&gt;, make_unique&lt;T2&gt;);\n</code></pre></p>","path":["智能指针"],"tags":["cpp"]},{"location":"shared-pointer/#_3","level":3,"title":"引用计数","text":"<p>![[shared_ptr.png]]</p>","path":["智能指针"],"tags":["cpp"]},{"location":"shared-pointer/#_4","level":3,"title":"当形参为普通指针时","text":"<p>虽然new是安全的，会先申请内存再构造对象t1。 如果t1的构造函数抛异常，申请的内存会自动释放，不会内存泄漏 但当两个new作为函数参数时，情况不同。 因为参数必须在调用函数前决断，所以步骤如下 <pre><code>1. 为t1申请内存\n2. 构造t1\n3. 为t2申请内存\n4. 构造t2\n5. 调用函数\n</code></pre></p> <ul> <li>当执行到2失败时，不会泄漏，new会释放t1的内存</li> <li>当执行到4失败是，会泄漏t1，因为t1已经构造完成，不会释放内存</li> </ul>","path":["智能指针"],"tags":["cpp"]},{"location":"shared-pointer/#_5","level":3,"title":"当形参为智能指针时","text":"<p>步骤为 <pre><code>1. t1 = make_unique&lt;T1&gt;()\n2. t2 = make_unique&lt;T2&gt;()\n3. 调用函数\n</code></pre> 如果2失败，t1的对象由unique_ptr管理，当t1释放时，会释放内存，所以无论t1构造失败还是t2构造失败，都能正确释放内存，不会导致泄漏 就因为unique_ptr和shared_ptr是内存安全的</p>","path":["智能指针"],"tags":["cpp"]},{"location":"shared-pointer/#_6","level":3,"title":"但以普通指针构造智能指针的方式不是异常安全的","text":"<p>即<code>foo(std::unique_ptr&lt;T1&gt;(new T1()), std::unique_ptr&lt;T2&gt;(new T2()));</code> 不是异常安全的</p> <p>此时步骤可能如下 <pre><code>1. 为t1申请内存\n2. 构造t1\n3. 为t2申请内存\n4. 构造t2\n5. 构造unique_ptr&lt;T1&gt;\n6. 构造unique_ptr&lt;T2&gt;\n7. 调用函数\n</code></pre> 当步骤4发生异常时，t1并未被unique_ptr管理，所以不会去释放t1的内存，故发生内存泄漏</p>","path":["智能指针"],"tags":["cpp"]},{"location":"shared-pointer/#_7","level":2,"title":"智能指针的构造","text":"<p>shared_ptr对应的函数是make_shared 但c++11中没有make_unique, 可以使用模版实现如下 <p><pre><code>template&lt;typename T,typename ...Args&gt;\nstd::unique_ptr&lt;T&gt; make_unique(Args&amp;&amp; ...args){\n    return std::unique_ptr&lt;T&gt;(new T(std::forward&lt;Args&gt;(args)... ));\n}\n</code></pre> 那为什么这样就能异常安全呢？因为调用make_uniqe时，可以确保t1的内存被unique_ptr管理了 </p>","path":["智能指针"],"tags":["cpp"]},{"location":"shared-pointer/#make_sharednew","level":2,"title":"make_shared创建智能指针和用new创建智能指针的区别","text":"<p>除了上面说所的make_shared/make_unique是异常安全，而unique_ptr(new T()) 不是异常安全外，其构造的智能指针也不同   <p>智能指针之所以会释放内存，是因为智能指针本身也是一个对象，在其生命周期结束后会调用dtor, 并在那里释放内存 所以智能指针的对象内存即包含了T，也包含了智能指针本身，而make_shared() 和 shared_ptr(new T)的区别在于<code>前者是两个部分的地址连续，而后者并不一定连续</code>","path":["智能指针"],"tags":["cpp"]},{"location":"shared-pointer/#unique_ptr","level":2,"title":"unique_ptr的区别","text":"<p>unique_ptr和shared_ptr不同，后者为了多变量同时拥有资源的访问，而unique_ptr表示任何时刻，只有一个变量能访问资源和释放资源，比如打开的文件设备,  而且通常为管理的资源设置析构函数，比如指定析构时关闭文件和设备</p> <p>如下代码，当fp析构时，自动关闭文件 <pre><code>// helper function for the custom deleter demo below\nvoid close_file(std::FILE* fp)\n{\n    std::fclose(fp);\n}\nusing unique_file_t = std::unique_ptr&lt;std::FILE, decltype(&amp;close_file)&gt;;\nunique_file_t fp(std::fopen(\"demo.txt\", \"r\"), &amp;close_file);\n</code></pre></p> <p>unique_ptr要配合move使用，当move之后，原对象不拥有指针资源</p>","path":["智能指针"],"tags":["cpp"]},{"location":"shared-pointer/#_8","level":2,"title":"总结","text":"<p>为了避免多参数决断时，导致已经决断的参数内存泄漏，应尽可能使用智能指针来管理内存</p>","path":["智能指针"],"tags":["cpp"]},{"location":"shell-file-operation/","level":1,"title":"shell 中文件操作接口","text":"","path":["shell 中文件操作接口"],"tags":["linux","file"]},{"location":"shell-file-operation/#_1","level":2,"title":"读行","text":"<pre><code>while read line ;do\n#or while read -r line ;do\necho $line\ndone &lt; $1\n</code></pre> <pre><code>cat $1 | while read line ;do\necho $line\ndone\n</code></pre> <p>使用for时，结果略有不同, for以空格为一行 <pre><code>for line in $(cat $1) ;do\necho $line\ndone\n</code></pre></p>","path":["shell 中文件操作接口"],"tags":["linux","file"]},{"location":"shell-file-operation/#reference","level":2,"title":"reference","text":"<p>https://bash.cyberciti.biz/guide/Reads_from_the_file_descriptor_(fd)</p>","path":["shell 中文件操作接口"],"tags":["linux","file"]},{"location":"shell-scripts-learning/","level":1,"title":"shell 笔记","text":"<p>shell 是unix-like系统下，用户与系统交互的媒介，用来解析用户的输入并调用系统函数。  而shell的实现有常见的bash,zsh,ksh等, 他们实现有很多差别，但bash最为通用</p>","path":["shell 笔记"],"tags":["shell"]},{"location":"shell-scripts-learning/#bash","level":2,"title":"bash 模式拓展","text":"","path":["shell 笔记"],"tags":["shell"]},{"location":"shell-scripts-learning/#bash_1","level":2,"title":"bash 字符串操作","text":"","path":["shell 笔记"],"tags":["shell"]},{"location":"shell-scripts-learning/#bash_2","level":2,"title":"bash 数组操作","text":"","path":["shell 笔记"],"tags":["shell"]},{"location":"shell-scripts-learning/#_1","level":2,"title":"环境变量","text":"<p>测试程序定时获取和打印环境变量 <pre><code>int main() {\n  while (1) {\n    char *env = getenv(\"TEST_ENV\");\n    printf(\"env: %s\\n\", env);\n    sleep(5);\n  }\n}\n</code></pre></p> <p>通过bash来修改环境变量 <pre><code>#test.sh\nexport TEST_ENV=TEST\n./a.out\nexport TEST_ENV=NNN\n</code></pre></p> <p>执行<code>test.sh</code>，c程序没有更新环境变量, 所以环境变量不会变化。</p> <pre><code>env: TEST\nenv: TEST\nenv: TEST\n</code></pre> <pre><code>#include &lt;stdio.h&gt;\n\nextern char **environ;\n\nint main() {\n  char **var;\n  for (var = environ; *var != NULL; ++var) {\n    printf(\"%s\\n\", *var);\n  }\n}\n</code></pre>","path":["shell 笔记"],"tags":["shell"]},{"location":"shell-scripts-learning/#set-unset","level":2,"title":"set unset","text":"","path":["shell 笔记"],"tags":["shell"]},{"location":"small-string-optimization-in-c/","level":1,"title":"c++的basic_string优化","text":"<p>Small-string optimization is basically </p> <p><pre><code>union { \n  struct { char*, size_t, size_t; }\n  struct { char[23]; bool; } \n} \n</code></pre> - but with bit-tricks instead. When allocated, the local buffer's space is reused for size and capacity. It's not wasted. But gdb just shows both sides of the union, which can be confusing.</p>","path":["c++的basic_string优化"],"tags":["cpp","string"]},{"location":"spdlog-learn/","level":1,"title":"spdlog learning","text":"<p>spdlog 支持多spdlog::logger, 适用与多个隔离模块的日志分别保存  </p> <p>而且logger含有多个sink的vector。sink与文件对应，如果想把日志输出到多个文件，就创建多个sink <pre><code>std::vector&lt;sink_ptr&gt; sinks_;\n</code></pre></p> <p>logger和sink的级别独立 <pre><code>// logger级别的判断\ntemplate&lt;typename... Args&gt;\ninline void spdlog::logger::log(source_loc source, level::level_enum lvl, const char *fmt, const Args &amp;... args)\n{\n    if (!should_log(lvl))\n    {\n        return;\n    }\n</code></pre></p> <pre><code>// sink级别的判断\ninline void spdlog::logger::sink_it_(details::log_msg &amp;msg)\n{\n#if defined(SPDLOG_ENABLE_MESSAGE_COUNTER)\n    incr_msg_counter_(msg);\n#endif\n    for (auto &amp;sink : sinks_)\n    {\n        if (sink-&gt;should_log(msg.level))\n        {\n            sink-&gt;log(msg);\n        }\n    }\n</code></pre> <p>所以可以支持不同的级别到不同的文件，例如logger设置为trace级别， sink1 设置为info级别， sink2设置为trace级别，这样就能创建两个日志文件 <pre><code>info.log  # 只保存info级别\nfull.log  # 保存所有级别（logger级别或者sink2的级别）\n</code></pre></p>","path":["spdlog learning"],"tags":["cpp"]},{"location":"sql-learning/","level":1,"title":"数据库优化总结","text":"<p>这里总结了从数据库设计和sql结构两个方面的优化</p>","path":["数据库优化总结"],"tags":["sql"]},{"location":"sql-learning/#normal-form","level":2,"title":"数据库设计范式 Normal Form","text":"<p>范式是在数据库的设计时总结出来的一套规范，通常满足3范式就足够了。但由于3范式也存在问题，所以有了3.5范式</p> <p>范式从1到3是越来越严格，所以满足1NF不一定满足2NF，但满足2NF就肯定满足1NF    </p> <p>满足所有范式的表没有冗余数据，但也有问题，比如效率不高。这就有了反范式做法，即允许数据冗余，用空间换时间</p>","path":["数据库优化总结"],"tags":["sql"]},{"location":"sql-learning/#1nf","level":3,"title":"1NF：原子化，单元格里的值不能被分割","text":"Employee Id Employee Name Phone Number Salary 1EDU001 Alex +91 85532065  +91 85532066 60,131 1EDU002 Alex +91 85532066 75,331 1EDU003 Alex +91 85532068 63,231 1EDU004 Alex +91 85532069 70,231 1EDU005 Alex +91 85543065  +91 85543075 60,531 <p>可见，有条目的电话格里有两个号码，是可以分割的， 所以不满足1NF。应改为</p> Employee Id Employee Name Phone Number Salary 1EDU001 Alex +91 85532065 60,131 1EDU001 Alex +91 85532066 60,131 1EDU002 Alex +91 85532066 75,331 1EDU003 Alex +91 85532068 63,231 1EDU004 Alex +91 85532069 70,231 1EDU005 Alex +91 85543065 60,531 1EDU005 Alex +91 85543075 60,531 <p>当所有单元格都无法分割了，就满足了第一范式</p>","path":["数据库优化总结"],"tags":["sql"]},{"location":"sql-learning/#2nf","level":3,"title":"2NF：属性不允许部分依赖（复合）主键","text":"<p>满足2NF前提要满足1NF, 范式2要求非主属性必须依赖完整复合主键或者主键。  </p> <p>下表<code>Employee Id</code>和<code>Department Id</code>组成复合主键 |Employee Id|Department Id |Office Location | |---|---|---| |1EDUO01 | ED-T1 | Pune | |1EDUO02 | ED-S2 |Bengaluru | |1EDUO03 | ED-M1 | Delhi | |1EDUO04 | ED-T3 | Mumbai | |1EDUO05 | ED-T1 | Pune |</p> <p>但<code>Office Location</code>只依赖主键的<code>Employee Id</code>部分。或者说只需<code>Department Id</code>就能保证<code>Office Location</code>唯一， 所以是部分依赖。这样不满足2NF了，应改成两个表</p> Employee Id Department Id 1EDUO01 ED-T1 1EDUO02 ED-S2 1EDUO03 ED-M1 1EDUO04 ED-T3 1EDUO05 ED-T1 Department Id Office Location ED-T1 Pune ED-S2 Bengaluru ED-M1 Delhi ED-T3 Mumbai","path":["数据库优化总结"],"tags":["sql"]},{"location":"sql-learning/#3nf","level":3,"title":"3NF： 依赖不能传递","text":"<p>满足3NF前提要满足2NF, 还有非主属性必须依赖主键/复合主键，不能依赖其他非主属性</p> Student Id Student name Subject Id Subject Adress 1DT1SENGO1 Alex 15CS11 SQL Goa 1DT1SENGO2 Barry 15CS13 JAVA Bengaluru 1DT15ENGO3 Clair 15CS12 C++ Delhi 1DT15ENG04 DavId 15CS13 JAVA Kochi <p>上表的<code>Subject</code>依赖非主属性<code>Subject Id</code>，而不是依赖<code>Student Id</code>， 这就不满足3NF了。应改成</p> Student Id Student name Subject Id 1DT1SENGO1 Alex 15CS11 1DT1SENGO2 Barry 15CS13 1DT15ENGO3 Clair 15CS12 1DT15ENG04 DavId 15CS13 Subject Id Subject Adress 15CS11 SQL Goa 15CS13 JAVA Bengaluru 15CS12 C++ Delhi 15CS13 JAVA Kochi","path":["数据库优化总结"],"tags":["sql"]},{"location":"sql-learning/#3","level":4,"title":"不满足3范式的问题","text":"<p>不满足3范式的数据库会存在以下问题: * 插入问题： 插入数据时，如果只有部分数据，可能导致插入失败（若某列为NOT NULL）。举例2NF里原来的表，若只有<code>Department Id</code>和<code>Office Location</code>，就无法插入 * 更新问题： 当更新某个字段时，需要更新其它列。举例2NF的表，当更新Pune时， 第1列和第4列都要更新 * 删除问题： 当删除某些属性时，其他属性也要删除， 举例3NF原来的表，当删除SQL课程时，学生Alex的信息也会丢失</p>","path":["数据库优化总结"],"tags":["sql"]},{"location":"sql-learning/#35nf-bcnf","level":3,"title":"3.5NF： BCNF","text":"<p>3.5范式用于解决3范式遗留问题 例如</p> Student Id Subject Professor 1DT15ENG01 SQL Prof. Mishra 1DT15ENG02 JAVA Prof. Anand 1DT15ENG02 C++ Prof. Kanthi 1DT15ENG03 JAVA Prof. Anand 1DT15ENG04 DBMS Prof. Lokesh <p>说明： * 一个学生可以登记多个科目 * 多个老师可以教授同一个科目 * 每个科目会有一个老师分配给一个学生</p> <p>所以这个表满足3范式，因为<code>Student Id</code>和<code>Subject</code>组成了复合主键，决定了<code>Professor</code>。  </p> <p>但是不满足3.5NF，因为<code>Student Id</code>和<code>Subject</code>组成了复合主键，所以<code>Subject</code>是主属性， 而存在<code>Professor</code>依赖<code>Subject</code>， 虽然<code>Subject</code>是主属性，但<code>Professor</code>是非主属性，所以不满足BCNF。</p> <p>此表应改成</p> Student Id Professor Id 1DT15ENG01 1DTPF01 1DT15ENG02 1DTPF02 1DT15ENG02 1DTPF03 Professor ID Professor Subject 1DTPF01 Prof. Mishra SQL 1DTPF02 Prof. Anand JAVA 1DTPF03 Prof. Kanthi C++","path":["数据库优化总结"],"tags":["sql"]},{"location":"sql-learning/#_2","level":3,"title":"反范式","text":"<p>没有冗余数据的设计未必是好设计，有时为了效率，必须降低范式标准，适当允许保留冗余数据，以达到用空间换时间的目的。</p> <p>例如订单表存在<code>商品</code>，<code>单价</code>，<code>数量</code>，<code>总价</code>， 这里总价是冗余的，因为可以通过单价和数量来求得，但总价经常需要，所以冗余可以提高效率。</p>","path":["数据库优化总结"],"tags":["sql"]},{"location":"sql-learning/#having","level":2,"title":"HAVING 和查询语句优先级","text":"<p>SQL查询字句类似C语言的运算符优先级， 虽然标准里没有定义优先级，但大致为以下 <pre><code>FROM &gt; WHERE &gt; SELECT &gt; GROUP BY &gt; HAVING &gt; ORDER BY\n</code></pre> 这个顺序可以帮忙理解查询语句是如何执行的，比如因为SELECT优先级低于FROM, 所有只能在FROM中定义alais在SELECT中使用，而不能在SELECT中定义alias并在FROM中使用</p> <p>HAVING指令通常和GROUP一起用，因为优先级比GROUP低，所以HAVING可以计算出GROUP的值并进行筛选。</p> <p><pre><code>SELECT Sno FROM Grade GROUP BY Sno HAVING COUNT(Cno) &gt; 3;\n</code></pre> 这个语句筛选出相同Sno记录的个数&gt;3的集合</p>","path":["数据库优化总结"],"tags":["sql"]},{"location":"sql-learning/#view","level":2,"title":"VIEW和数据冗余","text":"<p>View是一种虚拟表，可以将多表的数据关联在一起，也可以做一些冗余数据，如计算平均值</p> <pre><code>CREATE VIEW Cl_avg_age AS SELECT Clno, AVG(Sage) AS avg_age FROM Student;\n</code></pre>","path":["数据库优化总结"],"tags":["sql"]},{"location":"sql-learning/#_3","level":2,"title":"事物，存储过程和触发器","text":"<p>存储过程需要提前创建再使用。 因为存储过程中定义变量， 输入输出明确，所以让数据库操作更安全。 <pre><code>CREATE PROCEDURE ap_returncount @Sno char(7) AS DECLARE @count int SELECT @count = Number FROM Class WHERE Clno = (SELECT Clno FROM Student WHERE Sno = @Sno) RETURN @count;\n</code></pre></p> <p>触发器是当触发条件时自动执行的命令，如当插入和更新满足条件时自动执行事物回撤。这是基于事物机制的。 事物可以保证多个操作的原子性， 当莫个操作不满足条件则全部<code>ROLLBACK</code>，回撤所有的操作，例如典型的转账场景，必须要扣除和增加都成功时才能成功。</p> <p>但事物导致效率比较低。</p> <pre><code>CREATE TRIGGER tri_ins_upd_student ON Student AFTER INSERT, UPDATE AS IF 40 &lt; (SELECT Number FROM Class WHERE Clno = (SELECT Clno FROM inserted )) ROLLBACK TRANSACTION;\n</code></pre>","path":["数据库优化总结"],"tags":["sql"]},{"location":"sql-learning/#_4","level":2,"title":"参考","text":"<p>https://www.edureka.co/blog/normalization-in-sql/</p>","path":["数据库优化总结"],"tags":["sql"]},{"location":"sql-operator-priority/","level":1,"title":"SQL优先级问题","text":"<p>例如数学中的加减乘除，以及编程里的运算符，在sql里也有优先级，依次是：</p> <pre><code>FROM clause\nWHERE clause\nSELECT clause\nGROUP BY clause\nHAVING clause\nORDER BY clause\n</code></pre> <p>优先级依次下降，所以FROM的优先级比WHREE高，这样会有什么影响？ </p>","path":["SQL优先级问题"],"tags":["sql"]},{"location":"sql-operator-priority/#_1","level":2,"title":"优先级的问题","text":"<p>因为SELECT的优先级比WHERE低，所以在<code>SELECT</code>里面定义的alias别称就不能在<code>WHERE</code> 里面使用 但可以在<code>ORDER</code>里面使用，因为ORDER 后执行  </p>","path":["SQL优先级问题"],"tags":["sql"]},{"location":"sql-operator-priority/#_2","level":2,"title":"常见问题","text":"<pre><code>...\nGROUP BY a, b, c\nORDER BY NULL\n</code></pre> <pre><code>. . .\nGROUP BY a, b, c\nORDER BY a, b, c\n</code></pre> <p>在上面的两个例子里的ORDER BY都不会执行，分别解释：</p> <ol> <li>第一个例子里的ORDER 是删除GROUP的排序</li> <li>第二个例子的ORDER是重复了GROUP已经干了的事情</li> </ol>","path":["SQL优先级问题"],"tags":["sql"]},{"location":"sql-operator-priority/#_3","level":2,"title":"验证方法","text":"<p>可以找个在线SQL工具，例如 <code>http://sqlfiddle.com/</code> </p> <p>先执行创建数据库命令  <pre><code>DROP TABLE if exists new_table;\n\nCREATE TABLE `new_table` (\n`id` int(11) NOT NULL AUTO_INCREMENT,\n`testdecimal` decimal(6,2) DEFAULT NULL,\nPRIMARY KEY (`id`));\n\nINSERT INTO `new_table` (`testdecimal`) VALUES ('1234.45');\nINSERT INTO `new_table` (`testdecimal`) VALUES ('1234.45');\n\nset @mysqlorder := '';\n\nselect @mysqlorder := CONCAT(@mysqlorder,\" SELECT \") from new_table,(select @mysqlorder := CONCAT(@mysqlorder,\" FROM \")) tt\nJOIN (select @mysqlorder := CONCAT(@mysqlorder,\" JOIN1 \")) t on ((select @mysqlorder := CONCAT(@mysqlorder,\" ON1 \")) or rand() &lt; 1)\nJOIN (select @mysqlorder := CONCAT(@mysqlorder,\" JOIN2 \")) t2 on ((select @mysqlorder := CONCAT(@mysqlorder,\" ON2 \")) or rand() &lt; 1)\nwhere ((select @mysqlorder := CONCAT(@mysqlorder,\" WHERE \")) or IF(new_table.testdecimal = 1234.45,true,false))\ngroup by (select @mysqlorder := CONCAT(@mysqlorder,\" GROUPBY \")),id\nhaving (select @mysqlorder := CONCAT(@mysqlorder,\" HAVING \"))\norder by (select @mysqlorder := CONCAT(@mysqlorder,\" ORDERBY \"));\n</code></pre></p> <p>在执行 <code>select @mysqlorder;</code> 结果如下: <pre><code>@mysqlor`der\n(null)\n</code></pre></p> <p>可见其优先级顺序为 <pre><code>FROM JOIN1 JOIN2 WHERE ON2 ON1 ORDERBY GROUPBY SELECT WHERE ON2 ON1 ORDERBY GROUPBY SELECT HAVING HAVING\n</code></pre></p>","path":["SQL优先级问题"],"tags":["sql"]},{"location":"static-compile-warning-if-namespace-resolving-function-used/","level":1,"title":"static compile warning if namespace resolving function used","text":"<p>当程序里面有使用到解析函数的时候， 静态编译程序会报warning</p>","path":["static compile warning if namespace resolving function used"],"tags":["c","cpp","compile"]},{"location":"static-compile-warning-if-namespace-resolving-function-used/#_1","level":2,"title":"现象","text":"<pre><code>../../lib/libhacore.a(File.cpp.o): In function `_ZN2ha4core9gid2groupB5cxx11Ej':\n/tmp/src/ha/core/File.cpp:213: warning: Using 'getgrgid_r' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n../../lib/libhacore.a(File.cpp.o): In function `ha::core::group2gid(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, unsigned int&amp;)':\n/tmp/src/ha/core/File.cpp:291: warning: Using 'getgrnam_r' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n../../lib/libhacore.a(File.cpp.o): In function `ha::core::username2uid(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, unsigned int&amp;)':\n/tmp/src/ha/core/File.cpp:271: warning: Using 'getpwnam_r' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n../../lib/libhacore.a(File.cpp.o): In function `_ZN2ha4core12uid2usernameB5cxx11Ej':\n/tmp/src/ha/core/File.cpp:194: warning: Using 'getpwuid_r' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\nCMakeFiles/hasync-exec.dir/main.cpp.o: In function `boost::asio::detail::socket_ops::getaddrinfo(char const*, char const*, addrinfo const&amp;, addrinfo**, boost::system::error_code&amp;)':\n/usr/local/include/boost/asio/detail/impl/socket_ops.ipp:3348: warning: Using 'getaddrinfo' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n/usr/local/lib/gcc/x86_64-pc-linux-gnu/8.2.0/../../../../lib64/libcrypto.a(b_sock.o): In function `BIO_gethostbyname':\nb_sock.c:(.text+0x51): warning: Using 'gethostbyname' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n/usr/local/lib/gcc/x86_64-pc-linux-gnu/8.2.0/../../../../lib64/libcares.a(libcares_la-ares_getaddrinfo.o): In function `ares_getaddrinfo':\nares_getaddrinfo.c:(.text+0x73f): warning: Using 'getservbyname' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n/usr/local/lib/gcc/x86_64-pc-linux-gnu/8.2.0/../../../../lib64/libcares.a(libcares_la-ares_getnameinfo.o): In function `lookup_service.part.0.constprop.2':\nares_getnameinfo.c:(.text+0x32d): warning: Using 'getservbyport_r' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n</code></pre>","path":["static compile warning if namespace resolving function used"],"tags":["c","cpp","compile"]},{"location":"static-compile-warning-if-namespace-resolving-function-used/#_2","level":2,"title":"结论","text":"<p>即使静态链接glibc, glibc内部在运行时依旧要调用<code>动态库</code>，这些库函数多与域名解析有关, 所以要求运行时的库版本要与编译时相同， 当然基于容器化部署就不用担心了  </p>","path":["static compile warning if namespace resolving function used"],"tags":["c","cpp","compile"]},{"location":"storage-duration/","level":1,"title":"c++ 存储周期、链接和作用域","text":"","path":["c++ 存储周期、链接和作用域"],"tags":["c,","cpp"]},{"location":"storage-duration/#c_1","level":2,"title":"c++中变量和函数的三个重要属性","text":"<p>存储周期类型： 有关变量的创建和销毁 链接类型： 有关变量函数的内存位置 作用域: 有关变量函数的可见范围</p> <p>本文讨论的标识符，包括变量和函数</p>","path":["c++ 存储周期、链接和作用域"],"tags":["c,","cpp"]},{"location":"storage-duration/#_1","level":2,"title":"存储说明符","text":"<p><code>存储说明符</code>控制变量何时分配和释放，有以下几种</p> <ul> <li>automatic</li> <li>thread_local</li> <li>static </li> <li>register</li> <li>mutable</li> <li>extern</li> </ul> <p>说明 - automatic: 最常见的局部变量，且没有声明为static或者thread_local，位于栈上, 随着代码块的执行和结束而自动分配和销毁 - static: 静态变量, 在程序启动和结束时创建和销毁，但初始化是在第一次执行初始化代码时执行 - thread: 在线程开始和结束时分配和销毁 - dynamic: 最常见的堆上的变量, 需要执行new和delete, </p> <p>auto 在c++11中不是声明存储周期，而是类型推导符, 但这种存储周期类型的依然存在（局部变量）  </p>","path":["c++ 存储周期、链接和作用域"],"tags":["c,","cpp"]},{"location":"storage-duration/#_2","level":2,"title":"初始化的时机","text":"<ul> <li>automatic: 必须手动初始化，换句话说局部变量必须初始化，否则值为不确定</li> <li>static: 在执行时初始化，且初始化一次，特殊情况下在执行前初始化</li> <li>thread: 因为thread_local变量自带static性质，所以认为其同于static</li> <li>dynamic: 在new时初始化</li> </ul>","path":["c++ 存储周期、链接和作用域"],"tags":["c,","cpp"]},{"location":"storage-duration/#linkage","level":2,"title":"Linkage","text":"<p>标识符（变量&amp;函数）用一块内存里的值或者函数体来表示的， 而linkage决定其他相同的标识符是否指向同一块内存。c/c++有3种linkage, no-linkage, internal linkage和external linkage</p> <ul> <li>no linkage 局部变量没有linkage, 所以两个a是独立的，后面的a会覆盖前面的a，不相干。此时linkage与可见域(scope)类似</li> <li>internal linkage 表示只能在文件内部访问(file scope)，换句话就是不会暴露给链接器， 用修饰符<code>static</code>声明internal linkage，所以允许在不同文件声明两个名称&amp;类型相同的internal linkage 标识符，他们指向不同的内存单元。 </li> <li>external linkage 表示可以在程序所有地方访问，包括外部文件(global scope)，所以是真“全局”（scope&amp;linkage）， 所有标识符指向独一份内存。</li> </ul>","path":["c++ 存储周期、链接和作用域"],"tags":["c,","cpp"]},{"location":"storage-duration/#_3","level":3,"title":"修饰符","text":"<ul> <li>全局const变量和全局constexpr变量默认具备internal linkage, 再加上<code>static</code>没有影响</li> <li>全局非const变量默认是external linkage， 故再加上extern没有影响。在其他文件使用<code>extern</code>声明这个变量，就能使用指向同一内存的变量</li> <li>函数默认external linkage，故再加上extern没有影响。 在其他文件使用<code>extern</code>声明这个函数（可省），就能使用指向同一内存的函数</li> <li>使用extern修饰全局const变量和constexpr变量可以使起具备external linkage</li> </ul> <p>可见<code>static</code>和<code>extern</code>即表示存储周期，又表示linkage， static相对简单，extern则比较复杂，如以下情况 <pre><code>int g_x = 1; // 定义有初始化的全局变量（可加可不加extern）\nint g_x; // 定义没有初始化的全局变量（不可加extern），可选初始化\nextern int g_x; // 前置声明一个全局变量，不可初始化\n\nextern const int g_y { 1 }; // 定义全局常量，const必须初始化\nextern const int g_y; // 前置声明全局常量，不可初始化\n</code></pre></p> <p>所以若是定义未初始化的全局变量，不能加extern，不然就成了前置声明了。</p>","path":["c++ 存储周期、链接和作用域"],"tags":["c,","cpp"]},{"location":"storage-duration/#constexpr","level":3,"title":"constexpr 特殊情况","text":"<p>虽然通过给constexpr添加<code>extern</code>修饰符来让其具备external属性，但不能在其他文件前置声明。因为constexpr是在编译期替换的，编译器（compile)的可见域限定在文件内，所以编译期无法知道constexpr的值，所以在编译期无法获取到其内存单元的值， 也就无法在其他文件进行声明，只能定义。</p>","path":["c++ 存储周期、链接和作用域"],"tags":["c,","cpp"]},{"location":"storage-duration/#file-scopeglobal-scope","level":2,"title":"file scope和global scope","text":"<p>局部变量的scope、no-linkage以及duration相同，从<code>{</code>开始到<code>}</code>结束。 理论上global scope涵盖了file scope。而linkage来规定其是否能在其他文件里使用。</p>","path":["c++ 存储周期、链接和作用域"],"tags":["c,","cpp"]},{"location":"storage-duration/#local-class","level":2,"title":"local class","text":"<p>local class 不允许有static data member</p>","path":["c++ 存储周期、链接和作用域"],"tags":["c,","cpp"]},{"location":"storage-duration/#_4","level":2,"title":"参考","text":"<p>https://en.cppreference.com/w/cpp/language/storage_duration</p>","path":["c++ 存储周期、链接和作用域"],"tags":["c,","cpp"]},{"location":"streaming-h264-with-rtp/","level":1,"title":"streaming h264 with rtp","text":"<p>这里记录了使用ffmpeg来发送h264的rtp流，主要问题是处理pps和sps的发送，看了非常多的文档和例子包括gptchat，直到用gdb跟ffmpeg才找到解决办法。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#_1","level":2,"title":"背景","text":"<p>公司的有个发送视频彩铃的业务，需要向终端发送h264。开始想法是创建ffmpeg进程来发送，不过发现进程太好资源并发上不去。后来用写代码来多线程发送。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#sdp","level":3,"title":"sdp协商转码问题","text":"<p>sdp协商结果会有不同的分辨率、等级、质量之类的参数(pps/sps)，为了避免转码，提前制作了不同参数的视频。不过后来发现只要正确发送pps/sps，终端都能正确解码，不是必须按sdp里的视频参数。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#ffmpeg","level":3,"title":"用ffmpeg发送","text":"<p>开始直接使用命令ffmpeg发送，发现终端不能解码。对比正常的rtp流发现缺少了pps/sps。 <pre><code>ffmpeg -i video.mp4 -an -c:v copy -f rtp rtp://ip:port\n</code></pre> 一番搜索发现ffmpeg将pps/sps等参数写到sdp中(out-of-band)，还用base64编码了。 <pre><code>a=fmtp:96 packetization-mode=1; sprop-parameter-sets=Z2QAKKzRAHgCJ+XAWoCAgKAAAAMAIAAAB4HjBiJA,aOvvLA==; profile-level-id=640028\n</code></pre></p> <p>ffplay等播放软件会解析sdp，载入pps/sps，所以正确解码，但是sip场景下只能通过rtp来发送sps/pps(in-band)。 后来发现用ffmpeg的'bit stream filter'能解决问题</p> <pre><code>ffmpeg -i video.mp4 -an -c:v copy -bsf h264_mp4toannexb -f rtp rtp://ip:port\n</code></pre> <p>即使不转码，使用ffmpeg进程发送视频，在两核的系统中大概只能发送十几路。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#_2","level":3,"title":"代码实现发送","text":"<p>基于ffmpeg的示例代码'doc/example/remux.c', 将原来写文件改为rtp即可。因为还没有用到'h264_mp4toannexb'，还不会发送pps和sps。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#bsf","level":4,"title":"关键问题就是如何使用这个bsf","text":"<p>网上看到的例子包括用gptchat生成的例子，都是类似下面的步骤。</p> <pre><code># 搜索bsf\nav_bsf_get_by_name(\"h264_mp4toannexb\")\n# 创建bsf的上下文\nav_bsf_alloc(bsf, &amp;bsf_ctx)\n# 从输入的format上下文中复制编码参数\navcodec_parameters_copy(bsf_ctx-&gt;par_in, input_ctx-&gt;streams[video_stream_idx]-&gt;codecpar)\n# 初始化bsf上下文\nav_bsf_init(bsf_ctx)\n# 读入packet\nav_read_frame(input_ctx, &amp;pkt)\n# 送到bsf中处理\nav_bsf_send_packet(bsf_ctx, pkt)\n# 取出处理后的pkt\nav_bsf_receive_packet(bsf_ctx, pkt)\n# 发送rtp\n</code></pre> <p>抓包发现还是没有发送PPS/SPS, 而且第一个NALU是SEI，并且是坏的(Malformed)。调试发现bsf确实成功将SEI从AVCC转换成了AnnexB形式，也在SEI后追加了PPS和SPS。 <pre><code>(gdb) x/150bx pkt-&gt;data\n0x5555556da310: 0x00    0x00    0x00    0x01    0x06    0x05    0x2e    0xdc\n0x5555556da318: 0x45    0xe9    0xbd    0xe6    0xd9    0x48    0xb7    0x96\n0x5555556da320: 0x2c    0xd8    0x20    0xd9    0x23    0xee    0xef    0x78\n0x5555556da328: 0x32    0x36    0x34    0x20    0x2d    0x20    0x63    0x6f\n0x5555556da330: 0x72    0x65    0x20    0x31    0x35    0x35    0x20    0x72\n0x5555556da338: 0x32    0x39    0x30    0x31    0x20    0x37    0x64    0x30\n0x5555556da340: 0x66    0x66    0x32    0x32    0x00    0x80    0x00    0x00\n0x5555556da348: 0x00    0x01    0x67    0x64    0x00    0x28    0xac    0xd1\n0x5555556da350: 0x00    0x78    0x02    0x27    0xe5    0xc0    0x5a    0x80\n0x5555556da358: 0x80    0x80    0xa0    0x00    0x00    0x03    0x00    0x20\n0x5555556da360: 0x00    0x00    0x07    0x81    0xe3    0x06    0x22    0x40\n0x5555556da368: 0x00    0x00    0x00    0x01    0x68    0xeb    0xef    0x2c\n0x5555556da370: 0x00    0x00    0x01    0x65    0x88    0x84    0x02    0xff\n0x5555556da378: 0x91    0x3c    0x4a    0x51    0x5b    0xfd    0x02    0x3f\n0x5555556da380: 0xc1    0x67    0x8d    0xc0    0x94    0x98    0xee    0x7d\n0x5555556da388: 0x43    0x23    0xc0    0x4f    0xf7    0x56    0x37    0xfc\n0x5555556da390: 0xf1    0xf3    0xd3    0x83    0x03    0xa9    0x6d    0xd2\n0x5555556da398: 0x07    0xcf    0x19    0xa2    0x1e    0x29    0x64    0xfe\n0x5555556da3a0: 0x1f    0x8e    0xd6    0x71    0x5f    0x33\n</code></pre> <code>0x00 0x00 0x00 0x01</code>是annexb格式的起始码，第一个NALU是0x06(SEI)，第二个NALU是0x07(SPS)，第三个是0x08(PPS)。问题出在rtp打包的<code>ff_rtp_send_h264_hevc</code>。这里判断出<code>s-&gt;nal_length_size</code>不是0而是4, 所以还是以AVCC格式的首四个字节代表长度来解析pkt，而这是pkt是annexB格式了，前四个字节就是0x00, 0x00, 0x00, 0x01。所以打包错误。 问题怎么使rtp按annexB来打包，为什么<code>nal_length_size</code>是4不是0。</p> <pre><code>void ff_rtp_send_h264_hevc(AVFormatContext *s1, const uint8_t *buf1, int size)\n{\n    const uint8_t *r, *end = buf1 + size;\n    RTPMuxContext *s = s1-&gt;priv_data;\n\n    s-&gt;timestamp = s-&gt;cur_timestamp;\n    s-&gt;buf_ptr   = s-&gt;buf;\n    if (s-&gt;nal_length_size)\n        r = ff_avc_mp4_find_startcode(buf1, end, s-&gt;nal_length_size) ? buf1 : end;\n    else\n        r = ff_avc_find_startcode(buf1, end);\n</code></pre> <p>找到初始化rtp的初始化函数<code>rtp_write_header</code>，发现设置<code>nal_length_size</code>的地方，原来判断extradata，如果第一个字节是1,则按avcc打包。 <pre><code>    case AV_CODEC_ID_H264:\n        /* check for H.264 MP4 syntax */\n        if (st-&gt;codecpar-&gt;extradata_size &gt; 4 &amp;&amp; st-&gt;codecpar-&gt;extradata[0] == 1) {\n            s-&gt;nal_length_size = (st-&gt;codecpar-&gt;extradata[4] &amp; 0x03) + 1;\n        }\n        break;\n</code></pre> 而当前的extradata是类似avcc的（又不同于AVCC, 因为多一个header)，第一个字节等于1，而通过调试ffmpeg_g到这里时，extradata是annexB格式，即首4个字节是0x00,0x00,0x00,0x01。关于extradata格式的问题，从开始我就发现刚初始化时，extradata就是0x01开头，那么问题ffmpeg_g的extradata什么时候变的，再次调试发现，bsf初始化跟上面的不同。在ffmpeg_g中bsf初始化在fftools/ffmpeg_mux.c文件中: <pre><code># fftools/ffmpeg_mux.c\nstatic int bsf_init(MuxStream *ms)\n{\n    OutputStream *ost = &amp;ms-&gt;ost;\n    AVBSFContext *ctx = ms-&gt;bsf_ctx;\n    int ret;\n\n    if (!ctx)\n        return avcodec_parameters_copy(ost-&gt;st-&gt;codecpar, ost-&gt;par_in);\n\n    ret = avcodec_parameters_copy(ctx-&gt;par_in, ost-&gt;par_in);\n    if (ret &lt; 0)\n        return ret;\n\n    ctx-&gt;time_base_in = ost-&gt;st-&gt;time_base;\n\n    ret = av_bsf_init(ctx);\n    if (ret &lt; 0) {\n        av_log(ms, AV_LOG_ERROR, \"Error initializing bitstream filter: %s\\n\",\n               ctx-&gt;filter-&gt;name);\n        return ret;\n    }\n\n    ret = avcodec_parameters_copy(ost-&gt;st-&gt;codecpar, ctx-&gt;par_out);\n    if (ret &lt; 0)\n        return ret;\n    ost-&gt;st-&gt;time_base = ctx-&gt;time_base_out;\n\n    ms-&gt;bsf_pkt = av_packet_alloc();\n    if (!ms-&gt;bsf_pkt)\n        return AVERROR(ENOMEM);\n\n    return 0;\n}\n</code></pre> 发现，ffmpeg的bsf初始化多一个步骤，将bsf的par_out拷贝到输出AVstream中。而这par_out中的extradata就是我们要的annexB格式！ <pre><code>ret = avcodec_parameters_copy(ost-&gt;st-&gt;codecpar, ctx-&gt;par_out);\n</code></pre></p> <p>问题找到答案了，1是初始化rtp muxer前先初始化bsf，2是初始化bsf后将par_out拷贝回rtp muxer，再初始化rtp muxer。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#_3","level":4,"title":"正确例子","text":"<p>基于ffmpeg的doc/example/remux.c 删除了错误处理。只关心h264，所以输入输出都只处理index=0的包。 <pre><code>int main(int argc, char **argv) {\n  const AVOutputFormat *ofmt = NULL;\n  AVFormatContext *ifmt_ctx = NULL, *ofmt_ctx = NULL;\n  AVPacket *pkt = NULL;\n  const char *in_filename, *out_filename;\n  int ret = 0;\n  in_filename = \"video.mp4\";\n  out_filename = \"rtp://127.0.0.1:10020\";\n  pkt = av_packet_alloc();\n  ret = avformat_open_input(&amp;ifmt_ctx, in_filename, 0, 0);\n  ret = avformat_find_stream_info(ifmt_ctx, 0);\n  av_dump_format(ifmt_ctx, 0, in_filename, 0);\n\n  // 创建输出rtp上下文，不初始化\n  avformat_alloc_output_context2(&amp;ofmt_ctx, NULL, \"rtp\", out_filename);\n  // 初始化bsf\n  const AVBitStreamFilter *bsf_stream_filter =\n      av_bsf_get_by_name(\"h264_mp4toannexb\");\n  AVBSFContext *bsf_ctx = NULL;\n  ret = av_bsf_alloc(bsf_stream_filter, &amp;bsf_ctx);\n  ret =\n      avcodec_parameters_copy(bsf_ctx-&gt;par_in, ifmt_ctx-&gt;streams[0]-&gt;codecpar);\n  ret = av_bsf_init(bsf_ctx);\n\n  ofmt = ofmt_ctx-&gt;oformat;\n  AVStream *out_stream = avformat_new_stream(ofmt_ctx, NULL);\n  // 关键在这！！ 原来是从ifmt_ctx的stream中拷贝codecpar，改成从bsf中拷贝\n  // ret = avcodec_parameters_copy(out_stream-&gt;codecpar, in_codecpar);\n  ret = avcodec_parameters_copy(out_stream-&gt;codecpar, bsf_ctx-&gt;par_out);\n  out_stream-&gt;codecpar-&gt;codec_tag = 0;\n  av_dump_format(ofmt_ctx, 0, out_filename, 1);\n  if (!(ofmt-&gt;flags &amp; AVFMT_NOFILE)) {\n    ret = avio_open(&amp;ofmt_ctx-&gt;pb, out_filename, AVIO_FLAG_WRITE);\n  }\n  // 初始化bsf后再初始化rtp\n  ret = avformat_write_header(ofmt_ctx, NULL);\n\n  while (1) {\n    AVStream *in_stream, *out_stream;\n    ret = av_read_frame(ifmt_ctx, pkt);\n    if (pkt-&gt;stream_index != 0) {\n      continue;\n    }\n    in_stream = ifmt_ctx-&gt;streams[pkt-&gt;stream_index];\n    out_stream = ofmt_ctx-&gt;streams[pkt-&gt;stream_index];\n    log_packet(ifmt_ctx, pkt, \"in\");\n\n    av_bsf_send_packet(bsf_ctx, pkt);\n    av_bsf_receive_packet(bsf_ctx, pkt);\n    /* copy packet */\n    av_packet_rescale_ts(pkt, in_stream-&gt;time_base, out_stream-&gt;time_base);\n    pkt-&gt;pos = -1;\n    log_packet(ofmt_ctx, pkt, \"out\");\n    ret = av_interleaved_write_frame(ofmt_ctx, pkt);\n  }\n\n  av_write_trailer(ofmt_ctx);\n}\n</code></pre></p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#h264_mp4toannexb","level":3,"title":"h264_mp4toannexb","text":"<p>这个bsf将从mp4文件中读取的avcc格式的packet转换成annexb格式的packet。调试发现第一个读出来的包是SEI一个I帧，通过bsf处理后，会在SEI后面追加上PPS和SPS信息。而读取mp4文件时，sps/pps在extradata中。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#_4","level":3,"title":"相关知识","text":"<p>这些知识反复看来看去，总也不能贯穿起来，直到问题解决才算明白。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#nalu","level":4,"title":"NALU","text":"<p>NALU是真正用来保存h264视频信息的，包括I帧，P/B帧，PPS，SEI，SPS等。NALU由两部分组成：头（1字节）和payload，头中包含nalu的类型。h264规范只定义了NALU本身单元，但没有定义怎么保存NALU单元，所以有了两种格式保存NALU，AVCC和AnnexB。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#nalu_1","level":5,"title":"NALU类型","text":"<p>NAL unit type的值和说明，类型后面跟payload。详细参见在Rec. ITU-T H.264文件的63页，这里展示常用的 * 5,Coded slice of an IDR picture (I帧) * 6,Supplemental enhancement information (SEI) * 7,Sequence parameter set (SPS)  * 8,Picture parameter set (PPS) * 24,Single-Time Aggregation Packet(STAP-A)</p> <p>从抓包看到SPS算上payload的长度为30，PPS算上payload的长度为4。不知道长度是不是固定的。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#stap-a","level":5,"title":"STAP-A","text":"<p>STAP-A是多个NALU的聚合(Aggregation)，即这个NALU的payload里是多个NALU。STAP-A类型的NAL用来发送PPS/SPS/SEI等多种聚合。因为这些单元都很小。STRAP-A类型的header也是一个字节，但是payload里面有多个NALU，并且每个NALU前面用2字节来表示这个NALU的大小。 <pre><code>|STAP-A header|NALU-1 size|NALU-1|NALU-2 size|NALU-2|\n</code></pre></p> <p>NALU-1中又有header和payload。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#avccannexb","level":4,"title":"AVCC和AnnexB","text":"<p>上面说了规范没有定义怎么保存NALU，所以有了这两个格式，他们两是平等关系，只有保存的格式不同而已。AVCC用来保存，annexB用来流传输。 * AVCC用1~4个字节来表示NALU的长度，长度后面是NALU。读取方法是先读长度，再读取NALU。再读下一个长度，再读下一个NALU... * 而annexb用<code>0x00,0x00,0x00,0x01</code>或者<code>0x00,0x00,0x01</code>的起始码(start code)来分隔不同的NALU，所以方法是先读起始码，再一直读，直到发现下一个起始码，表示这个NALU结束，下一个NALU开始。</p> <p>ffmpeg使用中发现，AVCC一般用4字节表示NALU的长度，具体多少字节，在ffmpeg的extradata中有定义。annexB也是用4字节的起始码，也就是0x00,0x00,0x00,0x01。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#fragmentation-units-fus","level":4,"title":"Fragmentation Units (FUs) 分片","text":"<p>FU就是网络分片，因为I帧是一个完整的图片，所以非常大，为了保证udp不丢包，所以要分次发送。 第一个分片的FU的头设置了Start bit， 最后一个分片的FU头设置了END bit。分片是在rtp muxer中完成，注意ffmpeg中一个packet可以包含多个音频帧，但是只包含一个帧，直到发送rtp之前，一个packet总是完整的一帧视频（I/P/B）。 对于比较小的packet，例如聚合了PPS/SPS等信息的STAP-A包，不需要分片。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#extradata","level":4,"title":"extradata","text":"<p>上面很多次提到ffmpeg的extradata, 就是AVCodecParameters.extradata，它的长度是AVCodecParameters.extradata_size。在读取mp4文件的时候，ffmpeg会自动填充，在解码rtp的时候可能就需要手动填充了。extradata的比特位如下，首先是6字节的头，然后是多个SPS类型的NALU（2字节的长度分割多个NALU），再然后是PPS类型的NALU个数，最后是PPS类型的多个NALU(2字节的长度分割多个NALU）。 <pre><code>bits    \n8   version ( always 0x01 )\n8   avc profile ( sps[0][1] )\n8   avc compatibility ( sps[0][2] )\n8   avc level ( sps[0][3] )\n6   reserved ( all bits on )\n2   NALULengthSizeMinusOne\n3   reserved ( all bits on )\n5   number of SPS NALUs (usually 1)\n\nrepeated once per SPS:\n  16         SPS size\n  variable   SPS NALU data\n\n8   number of PPS NALUs (usually 1)\n\nrepeated once per PPS:\n  16       PPS size\n  variable PPS NALU data\n</code></pre></p> <p>里面包含了一个或多个PPS/SPS(NALU)，但保存的格式，既不是AVCC也不是AnnexB。因为上面可知AVCC用1<sub>4个字节表示NALU的长度，AnnexB用3</sub>4字节的起始码，而extradata是有一个6字节的header，里面有个字段叫<code>NALULengthSizeMinusOne</code>就是定义了AVCC使用多少个字节来表示NALU的长度。如果<code>NALULengthSizeMinusOne</code>等于0，那么AVCC用1字节表示NALU的长度。通常就是用4字节。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#extradata_1","level":5,"title":"extradata例子","text":"<pre><code>(gdb) x /150bx fmt_ctx-&gt;streams[0]-&gt;codecpar-&gt;extradata\n0x55555571d9c0: 0x01    0x64    0x00    0x28    0xff    0xe1    0x00    0x1e\n0x55555571d9c8: 0x67    0x64    0x00    0x28    0xac    0xd1    0x00    0x78\n0x55555571d9d0: 0x02    0x27    0xe5    0xc0    0x5a    0x80    0x80    0x80\n0x55555571d9d8: 0xa0    0x00    0x00    0x03    0x00    0x20    0x00    0x00\n0x55555571d9e0: 0x07    0x81    0xe3    0x06    0x22    0x40    0x01    0x00\n0x55555571d9e8: 0x04    0x68    0xeb    0xef    0x2c    0x00    0x00    0x00\n0x55555571d9f0: 0x00    0x00    0x00    0x00    0x00    0x00    0x00    0x00\n0x55555571d9f8: 0x00    0x00    0x00    0x00    0x00    0x00    0x00    0x00\n0x55555571da00: 0x00    0x00    0x00    0x00    0x00    0x00    0x00    0x00\n0x55555571da08: 0x00    0x00    0x00    0x00    0x00    0x00    0x00    0x00\n0x55555571da10: 0x00    0x00    0x00    0x00    0x00    0x00    0x00    0x00\n0x55555571da18: 0x00    0x00    0x00    0x00    0x00    0x00    0x00    0x00\n0x55555571da20: 0x00    0x00    0x00    0x00    0x00    0x00    0x00    0x00\n0x55555571da28: 0x00    0x00    0x00    0x00    0x00    0x00    0x00    0x00\n0x55555571da30: 0x00    0x00    0x00    0x00    0x00    0x00    0x00    0x00\n0x55555571da38: 0xc1    0x00    0x00    0x00    0x00    0x00    0x00    0x00\n0x55555571da40: 0x9d    0xad    0x00    0x00    0x50    0x55    0x00    0x00\n0x55555571da48: 0xfa    0x19    0xc4    0x92    0x40    0xa0    0xdc    0xba\n0x55555571da50: 0x00    0x00    0x00    0x00    0x00    0x00\n</code></pre> <ul> <li>第5字节0xff,二进制为:1111 1111, 后2位表示<code>NALULengthSizeMinusOne</code>=3，所以ffmpeg用4字节表示NALU的大小（AVCC格式）。</li> <li>第6字节0xe1,二进制为:1110 0001，后5位表示SPS的个数=1,所以只有一个SPS。</li> <li>第7，8字节表示SPS的长度，0x00，0x1e，二进制为:0000 0000, 0001 1110，所以SPS长度为30。</li> <li>跳过30个字节，0x01，二进制为:0000 0001, 表示有1个PPS。</li> <li>后面的2个字节，0x00,0x04,二进制为:0000,0004,表示PPS的长度为4个字节。</li> </ul>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#nalu_2","level":5,"title":"NALU头的解析","text":"<p>NALU头是1字节，第一位F bit, 后两位NRI bit, 后五位表示NALU的type。</p> <p>SPS的头是0x67，而进制为: 01100111，所以type值正好是7。 PPS的头是0x68，而进制为: 01101000，所以type值正好是8。</p> <p>对比wireshark解析结果可以确认上面的理解正确，可见extradata就是6个字节的header加多个AVCC格式的NALU。</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#extradata_2","level":5,"title":"创建extradata","text":"<p>rtp解码时，需要手动生成extradata。创建AVCC格式的extradata <pre><code>write(0x1);  // version\nwrite(sps[0].data[1]); // profile\nwrite(sps[0].data[2]); // compatibility\nwrite(sps[0].data[3]); // level\nwrite(0xFC | 3); // reserved (6 bits), NULA length size - 1 (2 bits)\nwrite(0xE0 | 1); // reserved (3 bits), num of SPS (5 bits)\nwrite_word(sps[0].size); // 2 bytes for length of SPS\nfor(size_t i=0 ; i &lt; sps[0].size ; ++i)\n  write(sps[0].data[i]); // data of SPS\n\nwrite(&amp;b, pps.size());  // num of PPS\nfor(size_t i=0 ; i &lt; pps.size() ; ++i) {\n  write_word(pps[i].size);  // 2 bytes for length of PPS\n  for(size_t j=0 ; j &lt; pps[i].size ; ++j)\n    write(pps[i].data[j]);  // data of PPS\n}\n</code></pre></p> <p>创建annexB格式的extradata <pre><code>write(0x00)\nwrite(0x00)\nwrite(0x00)\nwrite(0x01)\nfor each byte b in SPS\n  write(b)\n\nfor each PPS p in PPS_array\n  write(0x00)\n  write(0x00)\n  write(0x00)\n  write(0x01)\n  for each byte b in p\n    write(b)\n</code></pre></p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#wireshark","level":2,"title":"wireshark解析","text":"<p>从wiresshark对比用bsf和不用bsf的抓包发现，SEI包的内容没有变化，是不是可以不需要转成annexb，直接将PPS/SPS直接拷贝到packet中发出去呢？</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"streaming-h264-with-rtp/#_5","level":2,"title":"参考","text":"<p>https://membrane.stream/learn/h264/3 https://github.com/cisco/openh264/issues/2501#issuecomment-231340268 https://stackoverflow.com/questions/17667002/how-to-add-sps-pps-read-from-mp4-file-information-to-every-idr-frame https://stackoverflow.com/questions/24884827/possible-locations-for-sequence-picture-parameter-sets-for-h-264-stream https://aviadr1.blogspot.com/2010/05/h264-extradata-partially-explained-for.html</p>","path":["streaming h264 with rtp"],"tags":["ffmpeg","rtp","音视频"]},{"location":"subprocess/","level":1,"title":"linux子进程使用方法","text":"<p>Linux的exec(3)是一系列函数。之前总是稀里糊涂地用，这次搞清楚了。 <pre><code>       #include &lt;unistd.h&gt;\n\n       extern char **environ;\n\n       int execl(const char *pathname, const char *arg, ...\n                       /*, (char *) NULL */);\n       int execlp(const char *file, const char *arg, ...\n                       /*, (char *) NULL */);\n       int execle(const char *pathname, const char *arg, ...\n                       /*, (char *) NULL, char *const envp[] */);\n       int execv(const char *pathname, char *const argv[]);\n       int execvp(const char *file, char *const argv[]);\n       int execvpe(const char *file, char *const argv[], char *const envp[]);\n</code></pre></p>","path":["linux子进程使用方法"],"tags":["linux","fork","exec"]},{"location":"subprocess/#_1","level":2,"title":"规律","text":"<p>这6个函数可以分为两组'execl组'和'execv组'。 后缀p表示从$PATH中查找程序， 后缀e表示最后一个参数是数组，里面是环境变量。</p>","path":["linux子进程使用方法"],"tags":["linux","fork","exec"]},{"location":"subprocess/#_2","level":2,"title":"验证","text":"<p>这里通过c语言和python调用命令<code>cat hello.txt</code>， 验证每个函数。</p> <p><pre><code>#include &lt;unistd.h&gt;\n\nint main(){\n  int pid=-1;\n  pid=fork();\n  if(pid == 0)\n  execl(\"/usr/bin/cat\", \"cat\", \"hello-execl.txt\", NULL);\n\n  pid=fork();\n  if(pid == 0)\n  execlp(\"cat\", \"cat\", \"hello-execlp.txt\", NULL);\n\n  pid=fork();\n  if(pid == 0)\n  execle(\"/usr/bin/cat\", \"cat\", \"hello-execle.txt\", NULL, (char*[]){NULL});\n\n  pid=fork();\n  if(pid == 0)\n  execv(\"/usr/bin/cat\",  (char*[]){\"cat\", \"hello-execv.txt\", NULL});\n\n  pid=fork();\n  if(pid == 0)\n  execvp(\"cat\",  (char*[]){\"cat\", \"hello-execvp.txt\", NULL});\n\n  pid=fork();\n  if(pid == 0)\n  execve(\"/usr/bin/cat\",  (char*[]){\"cat\", \"hello-execve.txt\", NULL}, (char*[]){NULL});\n}\n</code></pre> 注意当使用选项参数时，选项和参数需要分开成两个字符串。例如<code>grep -n 10 \"target\" file</code>命令， 调用方法是 <pre><code>execlp(\"grep\", \"grep\", \"-n\", \"10\",  \"target\", \"file\", NULL);\n</code></pre></p> <p>使用环境变量，要用sh来拓展ENV1符号</p> <pre><code>execle(\"/usr/bin/sh\", \"sh\",\"-c\" ,\"echo $ENV1\", NULL, (char*[]){\"ENV1=HELLO\", NULL});\n</code></pre> <p>python 的os库的方法更全，且不需要带NULL <pre><code>&gt;&gt;&gt; [method for method in dir(os) if method.startswith(\"exec\")]\n['execl', 'execle', 'execlp', 'execlpe', 'execv', 'execve', 'execvp', 'execvpe']\n</code></pre></p> <p>实现<code>cat hello.txt</code> <pre><code>import os\nos.execlp(\"cat\", \"cat\", \"hello.txt\")\n</code></pre></p> <p>使用环境变量, 同样要用sh来拓展ENV1符号 <pre><code>import os\n\nenv = os.environ.copy()\nenv[\"ENV1\"]=\"hello\"\nos.execlpe(\"sh\", \"sh\", \"-c\", \"echo $ENV1\", env)\n</code></pre></p>","path":["linux子进程使用方法"],"tags":["linux","fork","exec"]},{"location":"subprocess/#_3","level":2,"title":"实用替代方法","text":"<p>exec族的函数都会替换当前进程的堆栈，所以需要用fork生成新的进程。更方便的方法是在c中用system, python中用subprocess</p>","path":["linux子进程使用方法"],"tags":["linux","fork","exec"]},{"location":"system-calls-method/","level":1,"title":"system calls method","text":"<p>之前学汇编发现教材和实际的有出入， 书上写的int, 但是汇编不通过，而gcc 反汇编的结果是调用syscall。 原来这是两种方式调用方式即： int  0x80 和 syscall  </p> <p>除此之外还有一个名词是vdso,  很多elf文件会链接这个vdso库</p> <pre><code>ldd a.out                                                                                                                                                                                                                   √ 19:03:30 \n    linux-vdso.so.1 (0x00007fffb3de0000)\n    libc.so.6 =&gt; /usr/lib/libc.so.6 (0x00007f5b48d4a000)\n    /lib64/ld-linux-x86-64.so.2 =&gt; /usr/lib64/ld-linux-x86-64.so.2 (0x00007f5b48f36000)\n</code></pre>","path":["system calls method"],"tags":["linux","api"]},{"location":"system-calls-method/#_1","level":2,"title":"词汇说明","text":"<p><code>int 0x80</code> 即80中断， 是最老的系统函数调用方式 <code>syscall/sysret</code> 是amd64 制定的标准， 也是目前的x86 64位的标准，即<code>amd64</code> <code>sysenter/syssysexit</code> 是inter制定的x86 64位标准， 目前已被放弃 <code>vdso</code> 是linux内核虚拟出的so, 实现了int 80 和 syscall，调用方式为 <code>vsyscall</code></p>","path":["system calls method"],"tags":["linux","api"]},{"location":"system-calls-method/#_2","level":2,"title":"系统函数调用路径","text":"<p>系统调用多被封装成库函数提供给应用程序调用，应用程序调用库函数后，由 glibc 库负责进入内核调用系统调用函数。 即<code>用户函数-&gt; glibc -&gt; 系统调用</code></p>","path":["system calls method"],"tags":["linux","api"]},{"location":"system-calls-method/#int-0x80","level":2,"title":"int 0x80","text":"<p>int 即是interrupt 中断， 0x80是IDT上注册的中断向量， 每个编号对应一个处理函数handle， linux的0x80的handle即是内核，即系统调用。 所以不同的系统设置的0x80的handle可能不同</p> <p>调用方式：首先是将参数复制到寄存器， 参数包括系统调用编号和传入参数，然后执行 init  0x80  例如，以下的进程退出的系统调用 <pre><code>.data\n    s:\n        .ascii \"hello world\\n\"\n        len = . - s\n.text\n    .global _start\n    _start:\n\n        movl $4, %eax   /* write system call number */\n        movl $1, %ebx   /* stdout */\n        movl $s, %ecx   /* the data to print */\n        movl $len, %edx /* length of the buffer */\n        int $0x80\n\n        movl $1, %eax   /* 退出的系统调用编号 */\n        movl $0, %ebx   /* exit status */\n        int $0x80\n</code></pre></p>","path":["system calls method"],"tags":["linux","api"]},{"location":"system-calls-method/#vdos","level":2,"title":"vdos","text":"<p>vdos即 linux-vdso.so.1， 几乎很多elf 都会链接这个库，但其实他并不是真实存在的so文件， 而是由内核虚拟的文件，再映射到用户的进程来调用。</p> <p>vdos  是对以下几个函数的实现，称作快速调用</p> <pre><code>#define __NR_gettimeofday 96 //0x60\n#define __NR_time 201 //0xc9\n#define __NR_clock_gettime 228 //0xE4\n#define __NR_getcpu 309 //0x135\n</code></pre>","path":["system calls method"],"tags":["linux","api"]},{"location":"system-calls-method/#_3","level":2,"title":"对比","text":"<p>所以以上总结其实就3种方式， int ，syscall/sysret ， vdso</p> <p>int 0x80 方式很慢，所以出现了syscall 即快速调用</p> <p>执行区别 <pre><code>在 x86 保护模式中，处理 INT 中断指令时，CPU 首先从中断描述表 IDT 取出对应的门描述符，判断门描述符的种类，然后检查门描述符的级别 DPL 和 INT 指令调用者的级别 CPL，当 CPL&lt;=DPL 也就是说 INT 调用者级别高于描述符指定级别时，才能成功调用，最后再根据描述符的内容，进行压栈、跳转、权限级别提升。内核代码执行完毕之后，调用 IRET 指令返回，IRET 指令恢复用户栈，并跳转会低级别的代码。\n\n其实，在发生系统调用，由 Ring3 进入 Ring0 的这个过程浪费了不少的 CPU 周期，例如，系统调用必然需要由 Ring3 进入 Ring0（由内核调用 INT 指令的方式除外，这多半属于 Hacker 的内核模块所为），权限提升之前和之后的级别是固定的，CPL 肯定是 3，而 INT 80 的 DPL 肯定也是 3，这样 CPU 检查门描述符的 DPL 和调用者的 CPL 就是完全没必要。正是由于如此，Intel x86 CPU 从 PII 300（Family 6，Model 3，Stepping 3）之后，开始支持新的系统调用指令 sysenter/sysexit。sysenter 指令用于由 Ring3 进入 Ring0，SYSEXIT 指令用于由 Ring0 返回 Ring3。由于没有特权级别检查的处理，也没有压栈的操作，所以执行速度比 INT n/IRET 快了不少。\n</code></pre></p> <p>返回的区别 <pre><code>在 Intel 的手册中，还提到了 sysenter/sysexit 和 int n/iret 指令的一个区别，那就是 sysenter/sysexit 指令并不成对，sysenter 指令并不会把 SYSEXIT 所需的返回地址压栈，sysexit 返回的地址并不一定是 sysenter 指令的下一个指令地址。调用 sysenter/sysexit 指令地址的跳转是通过设置一组特殊寄存器实现的。\n</code></pre></p> <p>vdos的局限（syscall） <pre><code>而\"快速系统调用指令\"比起中断方式的系统调用方式，还存在一定局限，例如无法在一个系统调用处理过程中再通过\"快速系统调用指令\"调用别的系统调用。因此，并不一定每个系统调用都需要通过\"快速系统调用指令\"来实现。比如，对于复杂的系统调用例如 fork，两种系统调用方式的时间差和系统调用本身运行消耗的时间来比，可以忽略不计，此处采取\"快速系统调用指令\"方式没有什么必要。而真正应该使用\"快速系统调用指令\"方式的，是那些本身运行时间很短，对时间精确性要求高的系统调用，例如 getuid、gettimeofday 等等。\n</code></pre></p>","path":["system calls method"],"tags":["linux","api"]},{"location":"system-calls-method/#_4","level":2,"title":"最后总结","text":"<p>int 是最老的方式，目前用amd64的 syscall 方式， 而vdso是基于syscall实现的快速调用。 只有在调用clock_gettime、gettimeofday、getcpu、time这些系统调用时，才会使用vdso，其他系统调用是通过syscall实现的</p>","path":["system calls method"],"tags":["linux","api"]},{"location":"systemd%20socket/","level":1,"title":"systemd socket 服务","text":"<p>一直非常喜欢用unix domain作为nginx和反代服务之间通讯方式， 将能支持的服务软件都尽量走unix domain。因为众所周知比127.0.0.1快，之前也测试过的确如此。</p>","path":["systemd socket 服务"],"tags":["systemd","unix-domain"]},{"location":"systemd%20socket/#unix-domian-socket-in-systemd","level":2,"title":"unix domian socket in systemd","text":"","path":["systemd socket 服务"],"tags":["systemd","unix-domain"]},{"location":"systemd%20socket/#_1","level":3,"title":"设置权限","text":"<p>SocketMode=0666 SocketUser=root SocketGroup=root</p>","path":["systemd socket 服务"],"tags":["systemd","unix-domain"]},{"location":"systemd%20socket/#_2","level":2,"title":"性能测试","text":"","path":["systemd socket 服务"],"tags":["systemd","unix-domain"]},{"location":"systemd%20socket/#c","level":3,"title":"c","text":"<pre><code>recieve 440014 message\n</code></pre>","path":["systemd socket 服务"],"tags":["systemd","unix-domain"]},{"location":"systemd-service/","level":1,"title":"创建 systemd 服务","text":"<p>说一个老话， 现在systemd作为linux的启动管理和服务管理已经越来越重要了， 上周考试也遇到用systemd 来管理容器，这里记录一下如何编写systemd服务</p>","path":["创建 systemd 服务"],"tags":["linux","systemd"]},{"location":"systemd-service/#systemd_1","level":2,"title":"关于systemd","text":"<p>systemd是只能运行在Linux上的init, 也就是启动后看到的1号进程。 除了启动， systemd还管理着很多东西，例如网络（systemd-networkd）， 域名解析（systemd-resolved），为服务创建socket(systemd.socket) 文件系统挂载，还有系统和用户的服务 systemd太大，说不完，需要查看各种文档</p>","path":["创建 systemd 服务"],"tags":["linux","systemd"]},{"location":"systemd-service/#systemd_2","level":2,"title":"systemd 的两种使用模式","text":"<p>systemd 分为system级别和user级别， 对应的unit文件分别在/etc/systemd/ 和 ～/.config/systemd/下， 前者是系统级别，后者是用户级别。 用户只能运行自己设置的服务</p> <p><pre><code>systemctl start system_service.service\n</code></pre> 而普通用户只能执行 <pre><code>systemctl --user user_service.service\n</code></pre></p> <p>这个name就是文件名称，例如必须'/etc/systemd/system/'下存在'system_service.service'文件，在能执行第一条的命令、 必须在 '~/.config/systemd/user/'下存在'user_service.service'在能执行第二条命令</p>","path":["创建 systemd 服务"],"tags":["linux","systemd"]},{"location":"systemd-service/#_1","level":3,"title":"系统服务以其他用户运行服务","text":"<p>系统级别的服务默认会以root来运行服务，但是也可以设置以其他用户来运行来最小化权限，例如音视频服务。也可以以某个用户来执行，那么service unit 文件就变为'system_service@user.service'</p> <pre><code># system_service@user.service\n[Unit]\nDescription=Watchman for user %i\nAfter=remote-fs.target\nConflicts=shutdown.target\n\n[Service]\nExecStart=/usr/local/bin/watchman --foreground --inetd\nExecStop=pkill -u %i -x watchman\nRestart=on-failure\nUser=%i\nGroup=users\nStandardInput=socket\nStandardOutput=syslog\nSyslogIdentifier=watchman-%i\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>上面的服务以下面的socket 单元启动， 前提要这个服务实现接收socket,通过<code>sd_listen_fds(3)</code> <pre><code># system_service@user.socket\n\n[Unit]\nDescription=Watchman socket for user %i\n\n[Socket]\nListenStream=/var/facebook/watchman/%i-state/sock\nAccept=false\nSocketMode=0664\nSocketUser=%i\nSocketGroup=othergroup\n\n[Install]\nWantedBy=sockets.target\n</code></pre></p>","path":["创建 systemd 服务"],"tags":["linux","systemd"]},{"location":"systemd-service/#_2","level":3,"title":"普通用户运行服务","text":"<p>注意， 普通用户因为只会以自己的身份启动，所以不能想系统服务那样指定'User/Group' <pre><code>[Unit]\nDescription=tun2socks for vpn\n#Requires=ssh_to_alpha.service\n\n[Service]\nType=simple\nExecStart=/usr/bin/badvpn-tun2socks \n\n[Install]\nWantedBy=default.target\n</code></pre></p> <p>若希望这个用户自定义服务能自启动， WantedBy需要设置成'default.target'</p>","path":["创建 systemd 服务"],"tags":["linux","systemd"]},{"location":"systemd-service/#unit-file","level":2,"title":"自动创建unit-file","text":"<p>以下命令可以自动在对应目录创建*.service文件 <pre><code>systemctl --user --force --full edit test.service \n</code></pre></p>","path":["创建 systemd 服务"],"tags":["linux","systemd"]},{"location":"tailcale/","level":1,"title":"tailscale 使用记录","text":"<p>tailscale 免费最大提供10个节点，足够个人使用。在如今大内网的时代，非常方便组建子网，实现家中和公司互联互通。</p>","path":["tailscale 使用记录"],"tags":["tailcale","pve"]},{"location":"tailcale/#derp","level":2,"title":"添加DERP节点","text":"<p>如果两个节点有一个有公网IP, 或者能打洞（NAT1. NAT2），那么两个节点可以直连，速度很快。否则要通过DERP节点转发，但是tailscale在大陆没有DERP节点，HK的DERP节点都有300+的延迟，完全没法用。 所以只能自己搭建或租赁一个在大陆的私人搭建的节点。</p>","path":["tailscale 使用记录"],"tags":["tailcale","pve"]},{"location":"tailcale/#_1","level":2,"title":"出口节点","text":"<p>出口节点A是流量可以从这个节点出去，比如节点B可以从A查询IP地址时，显示的ip是节点A的公网ip 而不是B的。</p>","path":["tailscale 使用记录"],"tags":["tailcale","pve"]},{"location":"tailcale/#_2","level":3,"title":"转发到出口节点","text":"<p>在B节点上设置流量都从节点A出去 tailscale up --exit-node=","path":["tailscale 使用记录"],"tags":["tailcale","pve"]},{"location":"tailcale/#_3","level":3,"title":"添加转发例外","text":"<p>启动转发后，所有流量都会从出口节点走。如果单机就没事，但是局域网多台电脑需要交互，例如从局域网主机C访问主机B, 由于主机B的流量都从节点A出去了，会导致主机C收不到请求答复。结果是C 无法ping B, C也不能ssh登录B。 所以要添加例外</p> <p>将来自本地局域网主机C的流量不被转发到出口节点。例如路由器的子网是192.168.10.0/24，主机C是192.168.10.111, 本机ip是192.168.10.100 <pre><code># ip rule add to &lt;your-local-network&gt; lookup main\nip rule add to 192.168.10.111/32 lookup main\n</code></pre></p>","path":["tailscale 使用记录"],"tags":["tailcale","pve"]},{"location":"temporary-object-and-reference/","level":1,"title":"右值, 临时变量与引用","text":"<p>我们说的临时变量通常是指在语句块里定义的短暂生命周期的局部变量, 其存储周期为'auto'，但这里讨论的是c++中'temporary object', 是在老版本c++中 而语句块里定义的变量以及非引用类型参数，并不属于这里的临时变量  </p> <p>c++中的临时变量出现情况： * litteral常量, 如1 * 类型转换   // 赋值语句结束后，自动销毁 * 函数返回值 // 赋值语句结束后，自动销毁 * 表达式的值 </p> <p>而临时变量的定义就是<code>编译器自动创建和销毁的没有名字的变量</code>, 也无法取地址。并且规定： - 常量类型的引用（<code>reference to const</code>）可以绑定到临时变量 - 非常量类型的引用（<code>reference to non-const</code>）类型不能绑定到临时变量</p> <p>这个规定的原因是： 因为上面说的<code>编译器自动创建和销毁</code>，所以去修改一个会销毁变量是<code>没有意义的</code></p>","path":["右值, 临时变量与引用"],"tags":["cpp"]},{"location":"temporary-object-and-reference/#_2","level":2,"title":"什么时候编译器要需要创建临时变量","text":"创建原因 销毁时机 Result of expression evaluation All temporaries created as a result of expression evaluation are destroyed at the end of the expression statement (that is, at the semicolon), or at the end of the controlling expressions for for, if, while, do, and switch statements. Initializing const references If an initializer is not an l-value of the same type as the reference being initialized, a temporary of the underlying object type is created and initialized with the initialization expression. This temporary object is destroyed immediately after the reference object to which it is bound is destroyed. <p>主要是以下两个地方会需要临时变量： * 函数接受引用类型参数的时候 * 函数返回的时候 * 类型转换的时候</p> <p>举例：</p> <p>函数参数 <pre><code>void foo(const int &amp;arg){}\nfoo(1);  // 此时创建了临时变量，可以想象成'foo(int _tmp(i));' 而且这个_tmp 不能被修改\n</code></pre></p> <p>函数返回值 <pre><code>int foo(){return 1;}\nint i=foo(); // 此时创建了临时变量， int _tmp = foo(); int i = _tmp;\n</code></pre></p> <p>类型转换 <pre><code>int i = 1;\ndouble d = i; // double _tmp = i; double d = _tmp;\n</code></pre></p>","path":["右值, 临时变量与引用"],"tags":["cpp"]},{"location":"temporary-object-and-reference/#_3","level":2,"title":"单独讨论这些似乎意义不大， 但是在实际编写代码的时候，可能会有疑惑","text":"<p>例如如何解释 <pre><code>const int&amp; cr = 1; // ok\nint &amp;r = 1; // ng\n</code></pre> 这里赋值和函数传参一样， 因为1是常数，这里为常量<code>1</code>创建临时变量， 而只有<code>reference to const</code> 才能绑定到临时变量上</p> <p>还有解释一个经常被引用的例子 <pre><code>void foo(int &amp;arg){}\nint i = 1; foo(i); // ok\ndouble d = 1.0; foo(d); // ng\n</code></pre></p> <p><pre><code>void foo(const int &amp;arg){}\nint i = 1; foo(i); // ok\ndouble d = 1.0; foo(d); // ok\n</code></pre> 这里虽然i和d都不是常量（不会创建临时变量）， 但是因为类型不同， 发生了类型转换，创建了临时变量。同样地，只有<code>reference to const</code> 才能绑定到临时变量上</p>","path":["右值, 临时变量与引用"],"tags":["cpp"]},{"location":"text%20process/","level":1,"title":"Linux 文本处理三剑客","text":"<p>grep awk sed</p>","path":["Linux 文本处理三剑客"],"tags":["linux","tool"]},{"location":"text%20process/#sed-vmstatcsv","level":2,"title":"sed 将vmstat的输出转成csv","text":"<p>vmstat的输出如下，空格分割的。sed命令<code>sed 's/^  *//;s/  */,/g'  vmstat.dat &gt; vmstat.02.csv</code>做了两件事： 1. 将行首的空格去掉 2. 将其他空格转成','符合csv的格式</p> <p>多个sed命令用';'分隔，且共用/g命令</p> <p><pre><code>procs -----------memory---------- ---swap-- -----io---- -system-- -------cpu-------\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st gu\n 1  0 999208 3603968 353020 8258580    0    0    22   166 1016    2  4  1 94  0  0  0\n</code></pre> 处理后 <pre><code>procs,-----------memory----------,---swap--,-----io----,-system--,-------cpu-------\nr,b,swpd,free,buff,cache,si,so,bi,bo,in,cs,us,sy,id,wa,st,gu\n1,0,999208,3603968,353020,8258580,0,0,22,166,1016,2,4,1,94,0,0,0\n</code></pre></p>","path":["Linux 文本处理三剑客"],"tags":["linux","tool"]},{"location":"text%20process/#awk","level":2,"title":"awk 遍历","text":"<p>我之前的awk通常用来打印某一列的内容，例如<code>cat vmstat.dat | awk -F' ' '{print $1}'</code> 打印$1第一列, -F设定分隔符。除此之外还能遍历查找。 例如查找'TARGET' <pre><code>awk '{for(i=1;i&lt;=NF;i++)if($i==\"TARGET\"){print \"TARGET located at row: \" NR \" col: \" i }}' \n</code></pre></p> <p>这里NR表示当前的<code>行</code>， NF代表当前的<code>列</code>。 NR还可以用来指定要处理的行号，例如vmstat中有两个header。例如 1. 只打印第二行的命令是<code>awk '(NR==2){print $0}'</code> 2. 要知道'id'在哪一列，则遍历第二行的每一列数据 <code>awk '(NR==2){for(i=1;i&lt;NF;i++) if($i==\"id\"){print i}'</code> 会打印'15' 3. 要打印id这列的第一行的值, <code>awk '(NR==2){for(i=1;i&lt;NF;i++) if($i==\"id\"){getline; print $i}'</code> 会打印'94'</p> <p>要打印id这列的第N行的值时，就循环调用getline N次。</p>","path":["Linux 文本处理三剑客"],"tags":["linux","tool"]},{"location":"text%20process/#python-openpyxl-excel","level":2,"title":"使用python库 openpyxl 处理excel","text":"<p>体验了 openpyxl, 接口设计非常自然， 功能也非常全， 包括合并格子、字体、颜色。典型用法如下 <pre><code>import openpyxl\n\n\nworkbook = openpyxl.load_workbook('output.xlsx')\nprint(workbook.sheetnames)\n\nsheet = workbook['Sheet']\nprint(sheet.max_row) #总行数\nprint(sheet.max_column) #总列数\nprint(sheet.dimensions) #左上角:右下角\n\ncell1 = sheet['A1']\nprint(cell1.row) #1\nprint(cell1.column) #A\nprint(cell1.coordinate) #A1\n\n# 单元格的内容\nprint(cell1.value)\n\n# 遍历\n#先行后列\nfor row in sheet.iter_rows():\n  for c in row:\n    print(f\"[{c.row}][{c.column}] = {c.value}\")\n\n#先列后行\nfor col in sheet.iter_cols():\n  for r in col:\n    print(f\"[{r.row}][{r.column}] = {r.value}\")\n\n# 保存\nworkbook.save('test.xlsx')\n</code></pre></p>","path":["Linux 文本处理三剑客"],"tags":["linux","tool"]},{"location":"text%20process/#_1","level":3,"title":"插入图片","text":"<p>openpyxl还能插入图片，感觉非常棒</p> <p><pre><code>from openpyxl import Workbook\nfrom openpyxl.drawing.image import Image\n\nwb = Workbook()\nws = wb.active\nws['A1'] = 'You should see three logos below'\n\n# create an image\nimg = Image('logo.png')\n\n# add to worksheet and anchor next to cells\nws.add_image(img, 'A1')\nwb.save('logo.xlsx')\n</code></pre> https://openpyxl.readthedocs.io/en/stable/images.html</p>","path":["Linux 文本处理三剑客"],"tags":["linux","tool"]},{"location":"text%20process/#xlwings","level":2,"title":"xlwings","text":"<p>Currently, xlwings can only run as a remote interpreter on Linux, see: https://docs.xlwings.org/en/stable/remote_interpreter.html There are plans to add read/write capabilities, but for now you have to use one of OpenPyXL, XlsxWriter, or pyxlsb,</p>","path":["Linux 文本处理三剑客"],"tags":["linux","tool"]},{"location":"text%20process/#libreoffice","level":2,"title":"Libreoffice","text":"<p>类比Excel使用vba来编程，Libreoffice sheet使用Basic，同时也支持 python</p> <p>在chatgpt帮助下写了个url转图片的BASIC脚本 <pre><code>REM  *****  BASIC  *****\nOption Explicit\n\nSub InsertAndResizeImages()                \n    Dim oSheet As Object\n    DIM oCell as Object \n    Dim oGraphic As Object\n    Dim i As Long\n    Dim imageURL As String\n    Dim oSize As New com.sun.star.awt.Size\n      Dim oColumns as Object\n      Dim oRows As Object\n\n\n    oSheet = ThisComponent.CurrentController.getActiveSheet()\n\n    oColumns = oSheet.getColumns()\n    oColumns.getByIndex(0).Width = 3200\n\n\n    i = 160\n    Do\n\n        oCell = oSheet.getCellByPosition(0, i)\n        oRows = oSheet.getRows()\n        oRows.getByIndex(i).Height = 3200\n\n        imageURL = oCell.String\n        If imageURL = \"\" Then Exit Do\n        'Debug.Print oCell.String\n        'MsgBox imageURL\n\n        On Error GoTo NextImage\n        oGraphic = ThisComponent.createInstance(\"com.sun.star.drawing.GraphicObjectShape\") \n        oGraphic.GraphicURL = imageURL\n        oGraphic.Position = oCell.Position\n\n        oSheet.DrawPage.add(oGraphic)\n\n        oSize.Width = 3200\n        oSize.Height = 3200\n        oGraphic.Size = oSize\n\n        Wait 500  ' Pauses for 0.5 seconds\n\n    Exit Do\nNextImage:\n        i = i + 1\n    Loop\n\nEnd Sub\n</code></pre></p>","path":["Linux 文本处理三剑客"],"tags":["linux","tool"]},{"location":"text%20process/#libreoffice-python","level":3,"title":"libreoffice 也支持 python","text":"<p>libreoffice 的UNO API是独立于编程语言的，BASIC可以直接用 <code>ThisComponent</code>，而python需要通过'XSCRIPTCONTEXT'来用，获取sheet的BOOK对象方法是<code>doc = XSCRIPTCONTEXT.getDocument()</code></p> <p>有个Basic和Python的对比写法，总结是很相似。用python重写BASIC代码就是</p> <pre><code>def insert_and_resize_images():\n    from com.sun.star.awt import Size\n    import time\n\n    doc = XSCRIPTCONTEXT.getDocument()\n    sheet = doc.CurrentController.ActiveSheet\n\n    columns = sheet.getColumns()\n    columns.getByIndex(0).Width = 3200\n\n    i = 160\n    while True:\n        cell = sheet.getCellByPosition(0, i)\n        rows = sheet.getRows()\n        rows.getByIndex(i).Height = 3200\n\n        image_url = cell.String\n        if image_url == \"\":\n            break\n\n        try:\n            graphic = doc.createInstance(\"com.sun.star.drawing.GraphicObjectShape\")\n            graphic.GraphicURL = image_url\n            graphic.Position = cell.Position\n\n            sheet.DrawPage.add(graphic)\n\n            size = Size()\n            size.Width = 3200\n            size.Height = 3200\n            graphic.Size = size\n\n            time.sleep(0.5)  # 0.5 seconds pause\n\n        except:\n            pass  # Continue on error\n\n        i += 1\n</code></pre> <p>无论是excel的xlwings还是libreoffice sheet的pyUNO, 都不能独立使用，都要安装套件。 </p>","path":["Linux 文本处理三剑客"],"tags":["linux","tool"]},{"location":"thread-local-variable/","level":1,"title":"线程局部变量","text":"<p>众所周知的，所有线程共享堆栈，所以主线程的变量都是公用的，但如何让每个线程单独拥有一份变量呢</p>","path":["线程局部变量"],"tags":["cpp","thread"]},{"location":"thread-local-variable/#pthread_key_create","level":2,"title":"使用<code>pthread_key_create</code>","text":"","path":["线程局部变量"],"tags":["cpp","thread"]},{"location":"thread-local-variable/#stdthread_local","level":2,"title":"使用<code>std::thread_local</code>","text":"","path":["线程局部变量"],"tags":["cpp","thread"]},{"location":"udp-loader-balance/","level":1,"title":"udp 的端口复用实现负载均衡","text":"","path":["udp 的端口复用实现负载均衡"],"tags":["socket","udp","socketopt"]},{"location":"udp-loader-balance/#_1","level":2,"title":"前言","text":"<p>偶尔看到 python 3.9 的release note 里面提到一个bug <pre><code>asyncio¶\n\n出于重要的安全性考量，asyncio.loop.create_datagram_endpoint() 的 reuse_address 形参不再被支持。 这是由 UDP 中的套接字选项 SO_REUSEADDR 的行为导致的。 更多细节请参阅 loop.create_datagram_endpoint() 的文档。 （由 Kyle Stanley, Antoine Pitrou 和 Yury Selivanov 在 bpo-37228 中贡献。。）\n</code></pre> 意思是tcp的socket option:SO_REUSEADDR不适用于udp： 在tcp中这个选项表示立即回收端口，减少 time_wait 的时间。而在udp中，这个选项表示多个socket可以绑定一个端口， 由内核来分发请求。</p> <p>所以看到此功能，自己试了一下，确实如此， 顺便回顾一下知识</p>","path":["udp 的端口复用实现负载均衡"],"tags":["socket","udp","socketopt"]},{"location":"udp-loader-balance/#_2","level":2,"title":"主要代码","text":"<pre><code>    struct sockaddr_in addr;\n    addr.sin_family = AF_INET;\n    addr.sin_port = htons(8888);\n    inet_pton(AF_INET,\"127.0.0.1\",(void*)&amp;addr.sin_addr);\n    // inet_pton 支持ipv4和ipv6,是比较新的转换函数\n\n    sfd = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);\n    if(sfd == -1)\n    {\n        perror(\"socket\");\n        exit(1);\n    }\n    int val = 1;\n    if(0 != setsockopt(sfd, SOL_SOCKET, SO_REUSEPORT,&amp;val, sizeof(val))){\n        perror(\"setsockopt\");\n        exit(1);\n    }\n    /* sockaddr 和 sockaddr_in 有什么区别？\n       struct sockaddr {  \n        sa_family_t sin_family;//地址族\n　　      char sa_data[14]; //14字节，包含套接字中的目标地址和端口信息               \n　　    }; \n　　    struct sockaddr_in {\n　　      sa_family_t sin_family;//地址族\n　　      uint16_t sin_port;\n　　      struct in_addr sin_addr;    // 32 位地址\n　　      char    sin_zero[8];    // reserve\n　　    };\n　　    struct in_addr {\n　　      In_addr_t   s_addr;  //32位\n　　    };\n　　    \n　　    sockaddr_in 和 sockaddr 长度相同，都 sin_family + 14 个字节，但是前者显式划分了\n　　 */ \n    if(bind(sfd, (struct  sockaddr*) &amp;addr, sizeof(addr)) != 0)\n    {\n        perror(\"bind\");\n        exit(1);\n    }\n</code></pre>","path":["udp 的端口复用实现负载均衡"],"tags":["socket","udp","socketopt"]},{"location":"udp-loader-balance/#_3","level":2,"title":"效果","text":"<p>先启动两个服务端，再使用ncat 来模拟请求, </p> <pre><code>ncat -uv 0.0.0.0 8888\n</code></pre> <p>启动ncat时，系统会分配给一个服务端处理。 但是重启ncat时， 会切换到另一个服务端处理</p>","path":["udp 的端口复用实现负载均衡"],"tags":["socket","udp","socketopt"]},{"location":"udp-statistic/","level":1,"title":"udp 查看统计的方法","text":"<ul> <li>/proc/net/snmp</li> <li>/proc/net/udp</li> </ul> <p>除此之外，还有通常使用netstat/ss 来查看发送队列和接收队列的缓冲区占用。</p>","path":["udp 查看统计的方法"],"tags":["debug","linux"]},{"location":"udp-statistic/#procnetsnmp","level":3,"title":"/proc/net/snmp","text":"<p><pre><code>cat /proc/net/snmp | grep Udp\\:\n</code></pre> 输出格式 Udp: InDatagrams NoPorts InErrors OutDatagrams RcvbufErrors SndbufErrors</p> <ul> <li>InDatagrams recvmsg调用时，值会增加。</li> <li>NoPorts 发送到没有监听的端口，值会增加</li> <li>InErrors 没有内存，或者checksum失败</li> <li>OutDatagrams 成功发送到IP层，注意这不代表包成功发送出去了，因为在IP层可能有错误，比如路由错误，会导致IP层的OutNoRoutes值增加</li> </ul>","path":["udp 查看统计的方法"],"tags":["debug","linux"]},{"location":"udp-statistic/#procnetudp","level":3,"title":"/proc/net/udp","text":"<p><pre><code>cat /proc/net/udp\n</code></pre> 输出格式   sl  local_address rem_address   st tx_queue rx_queue tr tm-&gt;when retrnsmt   uid  timeout inode ref pointer drops</p> <ul> <li>sl hash slot for the socket</li> <li>local_address 16进制的ip.端口</li> <li>st socket state</li> <li>tx_queue 发送队列的内存大小</li> <li>rx_queue 接收队列的内存大小</li> <li>inode socket对应的inode，可以判断哪个进程打开了这个socket</li> <li>drops 只记录了接收方向被丢掉的包，不包括发送方向丢掉的包。</li> </ul>","path":["udp 查看统计的方法"],"tags":["debug","linux"]},{"location":"udp-statistic/#_1","level":2,"title":"参考","text":"<p>https://blog.packagecloud.io/monitoring-tuning-linux-networking-stack-sending-data/#monitoring-udp-protocol-layer-statistics</p>","path":["udp 查看统计的方法"],"tags":["debug","linux"]},{"location":"use-mdns-in-systemd-networkd/","level":1,"title":"使用systemd-resolved的mdns","text":"<p>之前的博客中使用了avahi来广播本机的hostname和服务，这对于打印机和其他无屏设备非常重要。而较新版本Linux发行版中systemd-networkd+systemd-resolved同样能实现此功能</p>","path":["使用systemd-resolved的mdns"],"tags":["mdns","network"]},{"location":"use-mdns-in-systemd-networkd/#network-manager","level":2,"title":"Network Manager","text":"<p>目前不少发行版默认的网络管理工具是NetworkManager, 需要先将其关闭和卸载，安装systemd-networkd包</p>","path":["使用systemd-resolved的mdns"],"tags":["mdns","network"]},{"location":"use-mdns-in-systemd-networkd/#systemd-networkd","level":2,"title":"配置systemd-networkd","text":"<p>networkd 中可以配置网桥，tun等设备，也可以直接在其中配置dns和dhcp等，在其中加入MulticastDNS=yes和Multicast=yes来启用mDns <pre><code>[Match]\nName=eth0\n\n[Network]\nAddress=192.168.4.42/24\nDNS=114.114.114.114\nGataway=192.168.4.1\nMulticastDNS=yes\n\n[Link]\nMulticast=yes\n</code></pre></p>","path":["使用systemd-resolved的mdns"],"tags":["mdns","network"]},{"location":"use-mdns-in-systemd-networkd/#systemd-resolved","level":2,"title":"配置systemd-resolved","text":"<p>systemd-resolved功能类似与dnsmasq, 他会继承systemd-networkd中的dns信息，也会读取hostname用来广播，一般不用修改任何配置，之需要将其stub文件链接到/etc/resov.conf, 这样让系统的dns请求发到systemd-resolved</p> <pre><code># ln -sf /run/systemd/resolve/stub-resolv.conf /etc/resolv.conf\n# ls -l /etc/resolv.conf\nlrwxrwxrwx. 1 root root 37 May 22 22:03 /etc/resolv.conf -&gt; /run/systemd/resolve/stub-resolv.conf\n</code></pre>","path":["使用systemd-resolved的mdns"],"tags":["mdns","network"]},{"location":"use-mdns-in-systemd-networkd/#_1","level":2,"title":"确认效果","text":"<p>通过<code>resolvectl status</code>命令可以查看resolve配置，如下全局的MulticastDNS是启用的，而networkd中的配置是per link的，也处于启用状态，Scopes里显示了mDNS,说明其启用了  </p> <pre><code>      Current Scopes: DNS LLMNR/IPv4 LLMNR/IPv6 mDNS/IPv4 mDNS/IPv6\n</code></pre> <pre><code>[root@netpanc ~]# resolvectl status\nGlobal\n       LLMNR setting: yes\nMulticastDNS setting: yes\n  DNSOverTLS setting: no\n      DNSSEC setting: allow-downgrade\n    DNSSEC supported: yes\n          DNSSEC NTA: 10.in-addr.arpa\n                      16.172.in-addr.arpa\n                      168.192.in-addr.arpa\n                      17.172.in-addr.arpa\n                      18.172.in-addr.arpa\n                      19.172.in-addr.arpa\n                      20.172.in-addr.arpa\n                      21.172.in-addr.arpa\n                      22.172.in-addr.arpa\n                      23.172.in-addr.arpa\n                      24.172.in-addr.arpa\n                      25.172.in-addr.arpa\n                      26.172.in-addr.arpa\n                      27.172.in-addr.arpa\n                      28.172.in-addr.arpa\n                      29.172.in-addr.arpa\n                      30.172.in-addr.arpa\n                      31.172.in-addr.arpa\n                      corp\n                      d.f.ip6.arpa\n                      home\n                      internal\n                      intranet\n                      lan\n                      local\n                      private\n                      test\n\nLink 2 (eth0)\n      Current Scopes: DNS LLMNR/IPv4 LLMNR/IPv6 mDNS/IPv4 mDNS/IPv6\n       LLMNR setting: yes\nMulticastDNS setting: yes\n  DNSOverTLS setting: no\n      DNSSEC setting: allow-downgrade\n    DNSSEC supported: yes\n  Current DNS Server: 114.114.114.114\n         DNS Servers: 114.114.114.114\n</code></pre> <p>在其他设备上ping可以成功</p> <pre><code>PING netpanc.local (192.168.4.43) 56(84) bytes of data.\n64 bytes from netpanc.local (192.168.4.43): icmp_seq=1 ttl=64 time=0.350 ms\n64 bytes from netpanc.local (192.168.4.43): icmp_seq=2 ttl=64 time=0.799 ms\n64 bytes from netpanc.local (192.168.4.43): icmp_seq=3 ttl=64 time=0.733 ms\n</code></pre>","path":["使用systemd-resolved的mdns"],"tags":["mdns","network"]},{"location":"use-mdns-in-systemd-networkd/#_2","level":2,"title":"参考","text":"<p>https://wiki.archlinux.org/title/Systemd-resolved#mDNS</p>","path":["使用systemd-resolved的mdns"],"tags":["mdns","network"]},{"location":"virtio%20nic%20configure%20multi-queue/","level":1,"title":"virtio nic configure multi-queue","text":"<p>virtio虚拟出来的网卡默认是单队列的，ip link 显示如下。 多核系统下，单队列要要阻塞收发， 影响性能， 多队列可以并发，内核也支持（TUN/TAP）。这里记录开启多队列的方式。 因为virtio的限制，队列最大256个。 <pre><code>2: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000\n    link/ether 52:54:00:16:b5:50 brd ff:ff:ff:ff:ff:ff\n</code></pre></p>","path":["virtio nic configure multi-queue"],"tags":["virtio"]},{"location":"virtio%20nic%20configure%20multi-queue/#libvirt-virsh-xml","level":2,"title":"libvirt 或者 virsh 修改网卡xml文件","text":"<pre><code>&lt;interface type='network'&gt; \n      &lt;source network='default'/&gt; \n      &lt;model type='virtio'/&gt; \n+     &lt;driver name='vhost' queues='N'/&gt; \n&lt;/interface&gt; \n</code></pre>","path":["virtio nic configure multi-queue"],"tags":["virtio"]},{"location":"virtio%20nic%20configure%20multi-queue/#qemu","level":2,"title":"qemu","text":"<pre><code>qemu-kvm -netdev tap,id=hn0,queues=N -device virtio-net-pci,netdev=hn0,vectors=2M+2 ...\n</code></pre>","path":["virtio nic configure multi-queue"],"tags":["virtio"]},{"location":"virtio%20nic%20configure%20multi-queue/#openstack","level":2,"title":"openstack","text":"<pre><code>openstack image set &lt;IMG_ID&gt; --property hw_vif_multiqueue_enabled=true\n</code></pre>","path":["virtio nic configure multi-queue"],"tags":["virtio"]},{"location":"virtio%20nic%20configure%20multi-queue/#_1","level":2,"title":"验证","text":"<p>ip link 的输出多了**mq** <pre><code>$ ip link\n2: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000    \n\n$ ethtool -l enp1s0\nChannel parameters for enp1s0:\nPre-set maximums:\nRX:             0\nTX:             0\nOther:          0\nCombined:       256\nCurrent hardware settings:\nRX:             0\nTX:             0\nOther:          0\nCombined:       40\n</code></pre></p>","path":["virtio nic configure multi-queue"],"tags":["virtio"]},{"location":"virtio%20nic%20configure%20multi-queue/#_2","level":2,"title":"参考","text":"<p>https://docs.paloaltonetworks.com/vm-series/10-1/vm-series-deployment/set-up-the-vm-series-firewall-on-kvm/performance-tuning-of-the-vm-series-for-kvm/enable-multi-queue-support-for-nics-on-kvm https://cloud.vk.com/docs/en/computing/iaas/how-to-guides/vm-multiqueue https://www.linux-kvm.org/page/Multiqueue</p>","path":["virtio nic configure multi-queue"],"tags":["virtio"]},{"location":"vulnerable-case/","level":1,"title":"主要收集一些常见缺陷和加固方法","text":"","path":["主要收集一些常见缺陷和加固方法"],"tags":["safety"]},{"location":"vulnerable-case/#javascript","level":2,"title":"javascript","text":"<ol> <li>xss漏洞： 在输入框注入代码如 <code>&lt;script&gt; alert(1)&lt;/script&gt;</code>  解决办法是校验输入</li> </ol>","path":["主要收集一些常见缺陷和加固方法"],"tags":["safety"]},{"location":"ways-to-use-third-party-library-in-cmake/","level":1,"title":"cmake 使用第三方库","text":"<p>在项目中链接第三方库的方法都是'target_include_directories' 和 'target_link_library', 前提引入第三方包. 而查找可以使用<code>find_package</code></p>","path":["cmake 使用第三方库"],"tags":["cmake"]},{"location":"ways-to-use-third-party-library-in-cmake/#find_package","level":2,"title":"find_package找包","text":"<p>find_package分为Module和Config两种方式</p>","path":["cmake 使用第三方库"],"tags":["cmake"]},{"location":"ways-to-use-third-party-library-in-cmake/#module","level":3,"title":"Module方式","text":"<p>find_package先在'/usr/share/cmake/Modules/Find/'下添加FindXXX.cmake文件，以及自定义路径(CMAKE_MODULE_PATH)下查找 然后在项目的CMakeList.txt中使用find_package(), 然后可以在链接的时候使用第三方库</p> <pre><code>find_package()\n</code></pre>","path":["cmake 使用第三方库"],"tags":["cmake"]},{"location":"ways-to-use-third-party-library-in-cmake/#config","level":3,"title":"Config模式","text":"<p>当find_package找不到FindXXX.cmake文件，则会找 - Config.cmake - -config.cmake <p>如果第三方项目支持cmake, 那么先通过cmake编译和安装到环境或者docker环境，这时会在'/usr/lib/cmake//'下添加上述文件","path":["cmake 使用第三方库"],"tags":["cmake"]},{"location":"ways-to-use-third-party-library-in-cmake/#findxxxcmake","level":3,"title":"安装FindXXX.cmake文件","text":"<p>当没有FindXXX.cmake时，可以使用安装包管理工具安装cmake-extra包, 可能找到需要的 <pre><code>$ pacman -S extra-cmake-modules\n</code></pre></p> <p>然后执行下面的命令，可以看到大量的'Find*.cmake'文件 <pre><code>ls /usr/share/cmake-3.20/Modules/\n</code></pre></p>","path":["cmake 使用第三方库"],"tags":["cmake"]},{"location":"ways-to-use-third-party-library-in-cmake/#findxxxcmake_1","level":3,"title":"自定义FindXXX.cmake文件","text":"<p>如果上述方式都不行，那么需要自己写FindXXX.cmake，放到CMAKE_MODULE_PATH下 例如在项目根目录创建文件夹<code>cmake_module</code>, 再使用<code>set(CMAKE_MODULE_PATH ${CMAKE_SOURCE_DIR}/cmake_module)</code>来指定module的路径  最后在'cmake_module'下创建FindXXX.cmake结尾的文件，这个文件用来写找header和lib规则, 内容大致为</p> <pre><code>find_path(Grpc_INCLUDE_DIR grpc++/grpc++.h)\nmark_as_advanced(Grpc_INCLUDE_DIR)\n\nfind_library(Grpc++_LIBRARY NAMES grpc++ grpc++-1-dll)\nmark_as_advanced(Grpc++_LIBRARY)\n</code></pre> <p>有这个文件之后，可以在项目的cmake中直接使用<code>find_package()</code></p>","path":["cmake 使用第三方库"],"tags":["cmake"]},{"location":"ways-to-use-third-party-library-in-cmake/#_1","level":2,"title":"源代码编译链接","text":"<p>将第三方库源码放到项目指定目录如third</p> <ol> <li>放到third目录并可以使用<code>git submodule</code>管理</li> <li>在thrid目录添加CMakeList.txt，在其中添加目标，已备在项目中链接 <pre><code># for gsl-lite target\nadd_library(gsl-lite INTERFACE)\ntarget_include_directories(gsl-lite SYSTEM INTERFACE ${CMAKE_CURRENT_SOURCE_DIR}/gsl-lite/include)\n</code></pre></li> </ol>","path":["cmake 使用第三方库"],"tags":["cmake"]},{"location":"ways-to-use-third-party-library-in-cmake/#fetchcontent","level":2,"title":"FetchContent 自动源代码链接","text":"<p>cmake3.11之后，可以使用这个办法来自动拉取网上的库，并可以直接在自己的项目中使用</p> <pre><code># NOTE: This example uses cmake version 3.14 (FetchContent_MakeAvailable).\n# Since it streamlines the FetchContent process\ncmake_minimum_required(VERSION 3.14)\n\ninclude(FetchContent)\n\n# In this example we are picking a specific tag.\n# You can also pick a specific commit, if you need to.\nFetchContent_Declare(GSL\n    GIT_REPOSITORY \"https://github.com/microsoft/GSL\"\n    GIT_TAG \"v3.1.0\"\n)\n\nFetchContent_MakeAvailable(GSL)\n\n# Now you can link against the GSL interface library\nadd_executable(foobar)\n\n# Link against the interface library (IE header only library)\ntarget_link_libraries(foobar PRIVATE GSL)\n</code></pre>","path":["cmake 使用第三方库"],"tags":["cmake"]},{"location":"ways-to-use-third-party-library-in-cmake/#cmakeopenssl","level":2,"title":"cmake使用openssl存在问题","text":"<p>因为openssl不用cmake,也就没有.cmake文件, 导致项目配置失败  <pre><code> Could NOT find OpenSSL, try to set the path to OpenSSL root folder in the\n  system variable OPENSSL_ROOT_DIR (missing: OPENSSL_LIBRARIES\n  OPENSSL_INCLUDE_DIR)\n</code></pre> 后面发现它是使用package_config方式 <pre><code>#/usr/local/lib/pkgconfig/openssl.pc\nprefix=/usr\nexec_prefix=${prefix}\nlibdir=${exec_prefix}/lib\nincludedir=${prefix}/include\n\nName: OpenSSL\nDescription: Secure Sockets Layer and cryptography libraries and tools\nVersion: 1.1.1k\nRequires: libssl libcrypto\n</code></pre></p> <p>这种情况除了通过cmake_module来解决之外，还可以通过指定pc文件的路径 <pre><code>cmake -DOPENSSL_ROOT_DIR=/usr/local/ \n</code></pre></p>","path":["cmake 使用第三方库"],"tags":["cmake"]},{"location":"ways-to-use-third-party-library-in-cmake/#externalproject_add","level":2,"title":"ExternalProject_Add","text":"<p>这个不常用</p>","path":["cmake 使用第三方库"],"tags":["cmake"]},{"location":"ways-to-use-third-party-library-in-cmake/#find_package-find_library","level":2,"title":"find_package 和 find_library 区别","text":"<p>find_library 是cmake的底层方法，在find_path指定的目录下查找库文件  而find_package 使用了find_library的来找库文件，而且find_package在找到目标后，会定义一些变量，如下面的'Findlibproxy.cmake'文件头</p> <pre><code># - Try to find libproxy\n# Once done this will define\n#\n#  LIBPROXY_FOUND - system has libproxy\n#  LIBPROXY_INCLUDE_DIR - the libproxy include directory\n#  LIBPROXY_LIBRARIES - libproxy library\n#\n# Copyright (c) 2010, Dominique Leuenberger\n#\n# Redistribution and use is allowed according the license terms\n# of libproxy, which this file is integrated part of.\n\n# Find proxy.h and the corresponding library (libproxy.so)\nFIND_PATH(LIBPROXY_INCLUDE_DIR proxy.h )\nFIND_LIBRARY(LIBPROXY_LIBRARIES NAMES proxy )\n</code></pre> <p>当找到libproxy.so的时候，LIBPROXY_FOUND被设置为TRUE等</p>","path":["cmake 使用第三方库"],"tags":["cmake"]},{"location":"website%20status%20announce/","level":1,"title":"website status announce","text":"","path":["website status announce"],"tags":["website"]},{"location":"website%20status%20announce/#status-page","level":2,"title":"status page","text":"<p>从theoldreader的崩溃页面使用了statuspage这个网站，来帮用户追踪网站的情况。 通过第三方网站公告网站问题，这样挺好。又发现这个服务也是免费的 https://manage.statuspage.io/</p>","path":["website status announce"],"tags":["website"]},{"location":"weechat-manual/","level":1,"title":"weechat 使用方法","text":"<p>weechat 是一个irc客户端， 在终端中运行，不需要gui桌面，非常方便。 这里记录配置方法</p> <p>主要参考链接</p>","path":["weechat 使用方法"],"tags":["tool","irc"]},{"location":"weechat-manual/#weechat_1","level":2,"title":"安装和运行weechat","text":"<p>安装后，直接在终端运行<code>weechat</code>，就能进入weechat</p>","path":["weechat 使用方法"],"tags":["tool","irc"]},{"location":"weechat-manual/#_1","level":2,"title":"配置","text":"","path":["weechat 使用方法"],"tags":["tool","irc"]},{"location":"weechat-manual/#server","level":3,"title":"添加server","text":"<p>irc有很多server, 常用的是freenode。 另外有darkscience。 添加方法如下，另外weechat里面命令都是以'/' 开头，还能使用tab补全 <pre><code>/server add freenode chat.freenode.net/6697 -ssl\n</code></pre> irc 除了有很多服务器url, 每个url 还有多个端口供链接，比如6697</p>","path":["weechat 使用方法"],"tags":["tool","irc"]},{"location":"weechat-manual/#_2","level":3,"title":"设置昵称","text":"<p>昵称默认是linux系统的用户名，昵称用来在聊天中显示名称 <pre><code>/nick mynickname\n</code></pre> **注意： 手动修改昵称不是简单的事情，特别是当已经连接serer时。 比较方便的办法就是直接改配置文件 <pre><code># ～/.weechat/irc.conf\nnicks = \"malloy,malloy1,malloy2\"\n</code></pre> 带后缀的昵称用来当malloy占用时的备用，比如网络重连时昵称有冲突就需要备用昵称</p>","path":["weechat 使用方法"],"tags":["tool","irc"]},{"location":"weechat-manual/#_3","level":3,"title":"注册昵称","text":"<p>因为有很多聊天室要求注册后才能进入，所以先要使用邮箱注册 <pre><code>/msg nickserv register userpassword example@email\n</code></pre></p> <p>然后irc 会提示查收邮件，在邮件里面提示你在irc输入命令完成注册</p>","path":["weechat 使用方法"],"tags":["tool","irc"]},{"location":"weechat-manual/#_4","level":3,"title":"加入聊天室","text":"<p>聊天室都是以#开头，例如我使用的 '#archlinuxcn' <pre><code>/join #weechat\n</code></pre></p>","path":["weechat 使用方法"],"tags":["tool","irc"]},{"location":"weechat-manual/#_5","level":3,"title":"退出聊天室","text":"<p><pre><code>/parted \"leave message\"\n</code></pre> 或者 <pre><code>/close\n</code></pre></p>","path":["weechat 使用方法"],"tags":["tool","irc"]},{"location":"weechat-manual/#_6","level":2,"title":"自动设置","text":"<p>设置打开weechat时，自动登陆和自动进入聊天室</p> <pre><code>/set irc.server.freenode.autoconnect on\n/set irc.server.networkname.autojoin \"#channel1,#channel2\"\n</code></pre>","path":["weechat 使用方法"],"tags":["tool","irc"]},{"location":"weechat-manual/#_7","level":2,"title":"界面设置","text":"<p>先介绍weechat的各名称对应命令 :  聊天室称为buffer, 切换聊天室命令 <code>/buffer n</code> 最左边的聊天列表是bufferlist bar 进入buffer后，最右边的是nicklist bar，一个聊天室界面叫做window， 所以下面的命令设置就与 /bar /windows 有关</p> <p>隐藏和显示bufferlist <pre><code>/bar hiden bufferlist \n/bar show bufferlist\n/bar toggle bufferlist\n</code></pre> 分屏显示所有聊天室，水平分屏splith,竖直分屏 splitev <pre><code>/window splitv \n</code></pre> 窗口切换 <pre><code>/window +1\n/window -1\n</code></pre> 窗口合并 <pre><code>/window merge\n</code></pre></p>","path":["weechat 使用方法"],"tags":["tool","irc"]},{"location":"weechat-manual/#_8","level":2,"title":"安全设置","text":"<ol> <li>上面添加服务器时，已经配置了ssl选项，就表示使用通讯加密了，但irc的聊天记录一般是对外公开的  </li> <li>设置weechat开启密码， 进入weechat前验密 <pre><code>/secure passphrase superSecretPassphrase\n</code></pre></li> </ol>","path":["weechat 使用方法"],"tags":["tool","irc"]},{"location":"weechat-manual/#_9","level":2,"title":"自动化设置和鉴权","text":"<p>注册好昵称之后，配置自动化登陆，而不需要手动执行命令</p> <p>设置irc登陆昵称，作为identify的参数，务必要跟register的保持一致 <pre><code>/secure set networkname_nickname password\n</code></pre> 设置irc登陆密码，作为identify的参数，务必要跟register的密码保持一致 <pre><code>/secure set networkname_password password\n</code></pre></p> <p>设置weechat启动时自动登陆服务器，以及自动加入channel <pre><code>/set irc.server.libera.autoconnect on\n/set irc.server.libera.autojoin \"#archlinux-cn,#c,#c++\"\n</code></pre> 以及自动验密 <pre><code>/set irc.server.networkname.command \"/msg nickserv identify ${sec.data.networkname_nickname} ${sec.data.network_password}\"\n</code></pre> 其实显而易见地，<code>sec.data.networkname_nickname</code>和<code>sec.data.network_password</code> 都只是保存在sec.data里的变量，其实可以两个变量合成一条也没问题</p>","path":["weechat 使用方法"],"tags":["tool","irc"]},{"location":"weechat-manual/#_10","level":2,"title":"更多功能","text":"<p>weechat有很多拓展插件，可以完成很多事情，比如自动回复，远程控制，连接telegram等, 参考</p>","path":["weechat 使用方法"],"tags":["tool","irc"]},{"location":"wifi-tool/","level":1,"title":"随身wifi工具刷机","text":"<p>本文记录了淘宝卖的随身wifi刷机成Debian，还能收发短信。还有救砖的艰辛过程，不过结局美满。</p>","path":["随身wifi工具刷机"],"tags":["debian","tool"]},{"location":"wifi-tool/#_1","level":2,"title":"依赖","text":"<ul> <li>edl备份恢复工具，https://github.com/bkerler/edl, 下载源代码后执行<code>git submodule update --init --recursive</code>和 <code>pip install -r requirements.txt</code></li> <li>openstick编译好的debian https://github.com/OpenStick/OpenStick。 在release页面下载 base.zip, debian.zip, firmware-ufi001c.zip，boot-ufi001c.img</li> <li>apt 安装 adb fastboot</li> </ul>","path":["随身wifi工具刷机"],"tags":["debian","tool"]},{"location":"wifi-tool/#_2","level":2,"title":"切卡","text":"<p>刚接触时看网上的都是在后台页面切卡，但是刷机了没有后台页面如何切卡呢？ 为了切卡又重刷安卓，导致变砖了。参考网上资料发现，Debian下可以直接切。 <pre><code>debian默认卡槽位1:\n\necho 1 &gt; /sys/class/leds/sim:sel/brightness\necho 0 &gt; /sys/class/leds/sim:en/brightness\necho 0 &gt; /sys/class/leds/sim:sel2/brightness\necho 0 &gt; /sys/class/leds/sim:en2/brightnessR\nmodprobe -r qcom-q6v5-mss\nmodprobe qcom-q6v5-mss\nsystemctl restart rmtfs\nsystemctl restart dbus-org.freedesktop.ModemManager1.service\n\nesim槽位3:\n\necho 0 &gt; /sys/class/leds/sim:sel/brightness\necho 0 &gt; /sys/class/leds/sim:en/brightness\necho 1 &gt; /sys/class/leds/sim:sel2/brightness\necho 0 &gt; /sys/class/leds/sim:en2/brightness\nmodprobe -r qcom-q6v5-mss\nmodprobe qcom-q6v5-mss\nsystemctl restart rmtfs\nsystemctl restart dbus-org.freedesktop.ModemManager1.service\n\n其他两个槽位\n\n槽位2:\n\necho 0 &gt; /sys/class/leds/sim:sel/brightness\necho 1 &gt; /sys/class/leds/sim:en/brightness\necho 0 &gt; /sys/class/leds/sim:sel2/brightness\necho 0 &gt; /sys/class/leds/sim:en2/brightness\nmodprobe -r qcom-q6v5-mss\nmodprobe qcom-q6v5-mss\nsystemctl restart rmtfs\nsystemctl restart dbus-org.freedesktop.ModemManager1.service\n\n槽位4:\necho 0 &gt; /sys/class/leds/sim:sel/brightness\necho 0 &gt; /sys/class/leds/sim:en/brightness\necho 0 &gt; /sys/class/leds/sim:sel2/brightness\necho 1 &gt; /sys/class/leds/sim:en2/brightness\nmodprobe -r qcom-q6v5-mss\nmodprobe qcom-q6v5-mss\nsystemctl restart rmtfs\nsystemctl restart dbus-org.freedesktop.ModemManager1.service\n\n有些棒子esim槽位不一样槽位3不行自行试试槽位2 4\n</code></pre> https://github.com/OpenStick/OpenStick/issues/49#issuecomment-1568202001</p>","path":["随身wifi工具刷机"],"tags":["debian","tool"]},{"location":"wifi-tool/#_3","level":2,"title":"刷机","text":"<p>先使用edl全量备份，方法在最下面。先刷base包，解压base.zip后执行里面的<code>flash.sh</code>。然后刷debian包，解压debian.zip后执行里面的<code>flash.sh</code>。这时进入系统发现可能出现问题（我也没明显感觉到问题），因为他们是ufi001b的。 所以再刷适配ufi001c的包，解压firmware-ufi001c.zip。 <pre><code>cd firmware-ufi001c\nadb push ./* /lib/firmware\nadb reboot bootloader\nfastboot flash boot boot-ufi001c.img\nfastboot reboot\n</code></pre> 但是在刷ufi001c的包之前我能找到modem网络，刷完就没了，所以有了下面基带恢复的步骤。</p>","path":["随身wifi工具刷机"],"tags":["debian","tool"]},{"location":"wifi-tool/#_4","level":2,"title":"基带","text":"<p>基带文件在随身wifi的modem分区，先用edl备份modem分区。当然下面介绍了edl全量备份，跳过了userdata，估计是root和home目录。</p>","path":["随身wifi工具刷机"],"tags":["debian","tool"]},{"location":"wifi-tool/#_5","level":3,"title":"恢复基带文件","text":"<p>我在安装debian系统时，发现移动网络不可用，于是参考网上说的，将原始基带恢复后正常。 基带文件名为\"modem.bin\", edl全量备份后在dumps目录下。直接mount该文件，然后将modem.*和mba.mbn取出来，当发现刷机后发现移动网络不能使用时，重新拷回去就能用了。 <pre><code>sudo mount modem.bin /mnt\n</code></pre> 复制到firmware-ufi001c目录，覆盖之前的文件。 <pre><code>cp /mnt/modem.* .\ncp /mnt/mba.mbn .\n</code></pre></p> <p>再次拷贝到wifi棒子的/lib/firmware目录, 配合再刷一次适配001C的boot文件。 <pre><code>adb push ./* /lib/firmware\nadb reboot bootloader\nfastboot flash boot boot-ufi001c.img\nfastboot reboot #重启\n</code></pre></p> <p>然后就能找到modem网卡了。</p>","path":["随身wifi工具刷机"],"tags":["debian","tool"]},{"location":"wifi-tool/#modem","level":2,"title":"重启modem","text":"<p>有时重刷了firmware，还是出现没有modem网卡的情况，也就是<code>mmcli -m 0</code>提示找不到modem设备的时候，需要执行下面的命令。或者直接等一会重启ModemManager <pre><code>systemctl stop ModemManager\nqmicli -d /dev/wwan0qmi0 --uim-sim-power-off=1 &amp;&amp; qmicli -d /dev/wwan0qmi0 --uim-sim-power-on=1\nsystemctl start ModemManager\n</code></pre></p>","path":["随身wifi工具刷机"],"tags":["debian","tool"]},{"location":"wifi-tool/#_6","level":2,"title":"短信收发和转发邮件","text":"<p>下载两个python文件，地址 https://gitee.com/jiu-xiao/ufi-message。配置smtp.py中的邮箱信息，我使用的QQ邮箱登录，然后转发到另一个邮箱。开始发送不成功，修改后能发送了，内容如下。 <pre><code>#!python3\n\nmy_sender='@qq.com'\nmy_user='@hotmail.com'\nserver_address='smtp.qq.com'\nserver_port=465\nserver_passwd='' #填写qq邮箱授权码\n\n\nimport smtplib\nfrom email.mime.text import MIMEText\nfrom email.utils import formataddr\nimport datetime\nimport time\n\ndef mail(text):\n    msg=MIMEText(text,'plain','utf-8')\n    msg['From']=formataddr([\"随身Wifi\",my_sender])\n    msg['To']=formataddr([my_user,my_user])\n    msg['Subject']=\"转发 \"+time.strftime(\"%H:%%M:%S %m/%d\")\n\n    server=smtplib.SMTP_SSL(server_address,server_port)\n\n    server.login(my_sender,server_passwd)\n    server.auth_plain()\n    server.sendmail(my_sender,[my_user,],msg.as_string())\n    server.quit()\n</code></pre></p> <p>然后就能写进crontab自动跑了。</p>","path":["随身wifi工具刷机"],"tags":["debian","tool"]},{"location":"wifi-tool/#_7","level":2,"title":"救砖","text":"","path":["随身wifi工具刷机"],"tags":["debian","tool"]},{"location":"wifi-tool/#edl","level":3,"title":"edl使用","text":"<p>github上的开源工具，可以替代Windows那些高通工具，Miko，星海啥的。是我这Linux用户的福音，并且简单，windows常常失败。 使用edl工具之前要先重启到edl也就是9008模式，使用命令<code>adb reboot edl</code>，不需要按RST键。</p> <p>备份：推荐第一种方式，第二种方式生成的一个文件刷到另一个设备失败，但是可以刷MiKo导出的单文件。 <pre><code>edl rl dumps --skip=userdata --genxml\nor\nedl rf flash.bin #单文件\n</code></pre></p> <p>恢复: <pre><code>edl qfil rawprogram0.xml patch0.xml .\n</code></pre></p>","path":["随身wifi工具刷机"],"tags":["debian","tool"]},{"location":"wifi-tool/#_8","level":3,"title":"恢复分区","text":"<p>刷了debian后，分区会变，这样导致有些分区不存在所以无法刷回去。这里介绍下恢复分区的方法。不过上面的edl恢复应该不需要这个操作。</p> <p>备份分区 <pre><code>./edl gpt . --genxml\n</code></pre> 备份后有两个文件，恢复时只用gpt_main0.bin文件，恢复分区命令 <pre><code>./edl w gpt gpt_main0.bin\n</code></pre> 打印分区来验证下</p> <pre><code>./edl printgpt\n</code></pre>","path":["随身wifi工具刷机"],"tags":["debian","tool"]},{"location":"wifi-tool/#_9","level":2,"title":"参考","text":"<p>https://forum.openwrt.org/t/uf896-qualcomm-msm8916-lte-router-384mib-ram-2-4gib-flash-android-openwrt/131712/160 https://www.kancloud.cn/handsomehacker/openstick/2636505</p>","path":["随身wifi工具刷机"],"tags":["debian","tool"]},{"location":"drafts/familly%20funcion%20of%20exec/","level":1,"title":"exec family functions","text":"<pre><code>#include &lt;unistd.h&gt;\n\nint main(){\n  int pid=-1;\n  pid=fork();\n  if(pid == 0)\n  execl(\"/usr/bin/cat\", \"cat\", \"hello-execl.txt\", NULL);\n\n  pid=fork();\n  if(pid == 0)\n  execlp(\"cat\", \"cat\", \"hello-execlp.txt\", NULL);\n\n  pid=fork();\n  if(pid == 0)\n  execle(\"/usr/bin/cat\", \"cat\", \"hello-execle.txt\", NULL, (char*[]){NULL});\n\n  pid=fork();\n  if(pid == 0)\n  execv(\"/usr/bin/cat\",  (char*[]){\"cat\", \"hello-execv.txt\", NULL});\n\n  pid=fork();\n  if(pid == 0)\n  execvp(\"cat\",  (char*[]){\"cat\", \"hello-execvp.txt\", NULL});\n\n  pid=fork();\n  if(pid == 0)\n  execve(\"/usr/bin/cat\",  (char*[]){\"cat\", \"hello-execve.txt\", NULL}, (char*[]){NULL});\n\n\n  pid=fork();\n  if(pid == 0)\n  execle(\"/usr/bin/sh\", \"sh\",\"-c\" ,\"echo $ENV1\", NULL, (char*[]){\"ENV1=HELLO\", NULL});\n}\n</code></pre>","path":["Drafts","exec family functions"],"tags":["c"]},{"location":"drafts/isatty/","level":1,"title":"isatty 打印日志","text":"<p>程序运行时往文件里写日志时页缓冲，一旦程序奔溃前没有flush就会导致日志截断，但是每次写日志都flush就不如无缓冲的write了。 而往命令行打印日志则是行缓冲，但是会影响使用，如果用nohup来启动，日志还是打印到nohup中了，也是存在截断问题。</p> <p>通过isatty来判断程序是写往控制台还是文件， 如果不是控制台就往文件里写，并加上flush</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n\nint main() {\n    // Check if stdin (file descriptor 0) is a terminal\n    if (isatty(STDIN_FILENO)) {\n        printf(\"Input is coming from a terminal.\\n\");\n    } else {\n        printf(\"Input is not coming from a terminal (e.g., pipe or file).\\n\");\n    }\n\n    // Check if stdout (file descriptor 1) is a terminal\n    if (isatty(STDOUT_FILENO)) {\n        printf(\"Output is going to a terminal.\\n\");\n    } else {\n        printf(\"Output is not going to a terminal (e.g., redirected to a file).\\n\");\n    }\n\n    return 0;\n}\n</code></pre>","path":["Drafts","isatty 打印日志"],"tags":["linux","c"]},{"location":"drafts/learn%20asm/","level":1,"title":"asm learning","text":"","path":["Drafts","asm learning"],"tags":["asm"]},{"location":"drafts/learning%20dtmf/","level":1,"title":"非常渴望学习FFT","text":"<p>傅里叶变换将时域采样信号转换成许多频域（频谱列表）信号，基于“任何波形都能用N个正弦波来模拟”， N越大模拟的效果越好。</p> <p>注意： 1. 采样是按一定的频率将连续的波形(模拟信号)转换成一组<code>值</code>（数字信号）， 这个值的类型可以是signed integer </p> <p>从简单开始，先学习<code>goertzel</code>算法， </p>","path":["Drafts","非常渴望学习FFT"],"tags":["fft","dsp"]},{"location":"drafts/learning%20dtmf/#goertzel","level":2,"title":"goertzel","text":"<p>下面的代码是chatgpt生成的，用来检测一个指定频率的振幅。</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;math.h&gt;\n\n#define PI 3.14159265358979323846\n\n// Function to calculate the Goertzel magnitude for a given frequency f_0\ndouble goertzel(int16_t *data, int N, int f_0, int f_s) {\n    // Calculate the Goertzel coefficient\n    double k = 0.5 + ((N * f_0) / (double) f_s);  // N * f_0 / f_s\n    double omega = 2 * PI * k;\n    double coeff = 2 * cos(omega);\n\n    // Variables for the Goertzel recurrence\n    double s_prev = 0.0, s_prev2 = 0.0;\n    double s_curr;\n\n    // Loop through all samples and apply the Goertzel recurrence\n    for (int i = 0; i &lt; N; i++) {\n        s_curr = data[i] + coeff * s_prev - s_prev2;\n        s_prev2 = s_prev;\n        s_prev = s_curr;\n    }\n\n    // Calculate the magnitude of the frequency f_0\n    double magnitude = sqrt(s_prev2 * s_prev2 + s_prev * s_prev - coeff * s_prev * s_prev2);\n\n    return magnitude;aa\n}\n\nint main() {\n    // Example PCM data (16-bit signed integers)\n    int16_t pcm_data[] = {100, 200, 150, -50, 200, -150, 100, -100};  // Replace with actual PCM data\n    int N = sizeof(pcm_data) / sizeof(pcm_data[0]);  // Number of samples\n    int f_s = 44100;  // Sample rate (Hz)\n    int f_0 = 1000;    // Frequency to detect (Hz)\n\n    // Calculate the magnitude of the specified frequency using Goertzel algorithm\n    double magnitude = goertzel(pcm_data, N, f_0, f_s);\n\n    // Print the magnitude\n    printf(\"Magnitude at %d Hz: %f\\n\", f_0, magnitude);\n\n    return 0;\n}\n</code></pre>","path":["Drafts","非常渴望学习FFT"],"tags":["fft","dsp"]},{"location":"rhce8/rhce8/","level":1,"title":"rhce8 考试记录","text":"<p>-- 考试日期：7月19日</p>","path":["Rhce8","rhce8 考试记录"],"tags":["rhce"]},{"location":"rhce8/rhce8/#_1","level":1,"title":"学习笔记","text":"","path":["Rhce8","rhce8 考试记录"],"tags":["rhce"]},{"location":"rhce8/rhce8/#0426-networkmanager","level":2,"title":"04/26 NetworkManager 配置","text":"<p>rhel8 安装后没有安装dhcpd，只有dhcpclient， 所以必须手动执行dhcpclient 才能获取ip。 如果要自动连接，需要配置NM。  开始的时候以为直接设置NM接管网卡和设置自动连接即可，重启发现不行 <pre><code>$ nmcli device set enp1s0 autoconnect yes managed yes\n</code></pre> 正确办法是新建一个连接，这样重启后才会自动获取ip <pre><code># 语法\nnmcli connection add type ethernet con-name connection-name ifname interface-name\n</code></pre> <pre><code>$ nmcli connection add type ethernet con-name con-hst ifname enp1s0\n</code></pre></p>","path":["Rhce8","rhce8 考试记录"],"tags":["rhce"]},{"location":"rhce8/rhce8/#0506-rhce8root","level":2,"title":"0506 rhce8学习笔记，修改root密码","text":"<ol> <li>在控制台启动，选择内核的时候，按e修改内核启动脚本</li> <li>在内核选项后面，即在quiet 后面追加 rd.break，按ctrl+x 继续启动</li> <li>进入系统后hostname为<code>switch_root</code>，使用<code>mount | grep sysroot</code> 查看挂载选项，这时候是ro只读挂载</li> <li>执行<code>mount -o remount,rw /sysroot/</code> 重新挂载sysroot</li> <li>再次执行<code>mount | grep sysroot</code> 查看到挂载选项变为 rw 可读可写</li> <li>执行<code>chroot /sysroot</code> 切换，然后执行<code>passwd</code> 来修改root密码</li> <li>执行<code>touch /.autorelabel</code>，然后exit退出，然后logout 重启系统</li> </ol>","path":["Rhce8","rhce8 考试记录"],"tags":["rhce"]},{"location":"rhce8/rhce8/#0512-rhce8-tuned-adm","level":2,"title":"0512 rhce8学习笔记，系统调优 tuned-adm 工具","text":"<p>tune 是redhat开发的调优工具，已经制定好了一些方案，通过tuned-adm list 可以查看各种方案 <pre><code>[root@servera tuned]# tuned-adm list\nAvailable profiles:\n- balanced                    - General non-specialized tuned profile\n- desktop                     - Optimize for the desktop use-case\n- hpc-compute                 - Optimize for HPC compute workloads\n- latency-performance         - Optimize for deterministic performance at the cost of increased power consumption\n- network-latency             - Optimize for deterministic performance at the cost of increased power consumption, focused on low latency network performance\n- network-throughput          - Optimize for streaming network throughput, generally only necessary on older CPUs or 40G+ networks\n- powersave                   - Optimize for low power consumption\n- throughput-performance      - Broadly applicable tuning that provides excellent performance across a variety of common server workloads\n- virtual-guest               - Optimize for running inside a virtual guest\n- virtual-host                - Optimize for running KVM guests\nCurrent active profile: virtual-guest\n</code></pre> 1. 可以看到有针对desktop powersave 等优化。当前处于virtual-guest 的优化方案。 2. tuned 是服务进程，用来监控和收集各个组件的数据，并依据这些数据来动态调整。 3. tuned-adm 是客户端，通过这个命令来配置</p>","path":["Rhce8","rhce8 考试记录"],"tags":["rhce"]},{"location":"rhce8/rhce8/#_2","level":3,"title":"配置方法","text":"<ol> <li>查看推荐, 当前是虚拟主机，所以推荐了virtual-guest <pre><code>tuned-adm recommend\nvirtual-guest\n</code></pre></li> <li>选择方案和确认 <pre><code>[root@servera tuned]# tuned-adm profile powersave\n[root@servera tuned]# tuned-adm active\nCurrent active profile: powersave\n</code></pre> 这样就修改到powersave 模式了</li> </ol>","path":["Rhce8","rhce8 考试记录"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/","level":1,"title":"00 Introduction","text":"<p>388-4881-1 - About the Course 388-4881-2 - About the Author 388-4881-3 - About the Exam  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/#01-basic-red-hat-certified-administrator-skills","level":1,"title":"01 Basic Red Hat Certified Administrator Skills","text":"<p>388-4867-1 - Understand and Use Essential Tools (Part 1) 388-4867-2 - Understand and Use Essential Tools (Part 2) 388-4867-3 - Operate Running Systems 388-4867-4 - Configure Local Storage 388-4867-5 - Create and Configure File Systems 388-4867-6 - Deploy, Configure, and Maintain systems 388-4867-7 - Manage Users and Groups 388-4867-8 - Manage Security (Part 1) 388-4867-9 - Manage Security (Part 2)  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/#02-understand-core-components-of-ansible","level":1,"title":"02 Understand Core Components of Ansible","text":"<p>388-4868-1 - Inventories 388-4868-2 - Modules 388-4868-3 - Variables 388-4868-4 - Facts 388-4868-5 - Plays and Playbooks 388-4868-6 - Configuration Files  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/#03-install-and-configure-an-ansible-control-node","level":1,"title":"03 Install and Configure an Ansible Control Node","text":"<p>388-4869-1 - Install Required Packages 388-4869-2 - Create a Static Host Inventory File 388-4869-3 - Create a Configuration File  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/#04-configure-ansible-managed-nodes","level":1,"title":"04 Configure Ansible Managed Nodes","text":"<p>388-4870-1 - Create and Distribute SSH Keys to Manage Nodes and Configure Privilege Escalation 388-4870-2 - Validate a Working Configuration Using Ad Hoc Ansible Commands  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/#05-script-administration-tasks","level":1,"title":"05 Script Administration Tasks","text":"<p>388-4871-1 - Create Simple Shell Scripts 388-4871-2 - Create Shell Scripts That Run Ad Hoc Ansible Commands  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/#06-create-ansible-plays-and-playbooks","level":1,"title":"06 Create Ansible Plays and Playbooks","text":"<p>388-4872-1 - Know How to Work with Commonly Used Ansible Modules 388-4872-2 - Use Variables to Retrieve the Results of Running a Command 388-4872-3 - Use Conditionals to Control Play Execution 388-4872-4 - Configure Error Handling 388-4872-5 - Create Playbooks to Configure Systems to a Specified State  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/#07-use-ansible-modules-for-system-administration-tasks","level":1,"title":"07 Use Ansible Modules for System Administration Tasks","text":"<p>388-4873-1 - Software Packages and Repositories 388-4873-10 - Users and Groups 388-4873-2 - Services 388-4873-3 - Firewall Rules 388-4873-4 - Storage Devices 388-4873-5 - File Content 388-4873-6 - File Systems 388-4873-7 - Archiving 388-4873-8 - Scheduled Tasks 388-4873-9 - Security  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/#08-create-and-use-templates-to-create-customized-configuration-files","level":1,"title":"08 Create and Use Templates to Create Customized Configuration Files","text":"<p>388-4874-1 - Ansible Variables 388-4874-2 - Ansible Templates  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/#09-create-and-work-with-roles","level":1,"title":"09 Create and Work with Roles","text":"<p>388-4875-1 - Understanding Roles 388-4875-2 - Creating and Using Roles 388-4875-3 - Ansible Galaxy  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/#10-managing-parallelism","level":1,"title":"10 Managing Parallelism","text":"<p>388-4876-1 - Parallelism with Ansible  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/#11-protect-sensitive-data-in-playbooks-with-ansible-vault","level":1,"title":"11 Protect Sensitive Data in Playbooks with Ansible Vault","text":"<p>388-4877-1 - Ansible Vault 388-4877-2 - Using Ansible Vault in a Playbook  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/#12-ansible-documentation","level":1,"title":"12 Ansible Documentation","text":"<p>388-4878-1 - Local Documentation 388-4878-2 - Documentation on the Web  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]},{"location":"rhce8/rhce_course_name/#13-conclusion","level":1,"title":"13 Conclusion","text":"<p>388-4880-1 - Conclusion  </p>","path":["Rhce8","00 Introduction"],"tags":["rhce"]}]}